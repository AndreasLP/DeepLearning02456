{"episode_reward": 0.0, "episode": 1.0, "duration": 4.347923040390015, "step": 125}
{"episode_reward": 150.00420808689523, "episode": 2.0, "duration": 0.280062198638916, "step": 250}
{"episode_reward": 96.8844902586386, "episode": 3.0, "duration": 0.2804739475250244, "step": 375}
{"episode_reward": 165.55134832132507, "episode": 4.0, "duration": 0.30258727073669434, "step": 500}
{"episode_reward": 132.25407199751552, "episode": 5.0, "duration": 0.27959442138671875, "step": 625}
{"episode_reward": 132.38306843162448, "episode": 6.0, "duration": 0.28130316734313965, "step": 750}
{"episode_reward": 30.539500763380076, "episode": 7.0, "duration": 0.28147292137145996, "step": 875}
{"episode_reward": 98.79372901532558, "episode": 8.0, "duration": 0.28066229820251465, "step": 1000}
{"episode_reward": 141.04342537919226, "episode": 9.0, "batch_reward": 0.9460488586451236, "critic_loss": 2.617162755163539, "actor_loss": -4.730197927576056, "actor_target_entropy": -1.0, "actor_entropy": -0.2031728785814763, "alpha_loss": 0.06337726192420398, "alpha_value": 0.09854242285962292, "duration": 33.98474383354187, "step": 1125}
{"episode_reward": 172.04354112884877, "episode": 10.0, "batch_reward": 0.9810382604599, "critic_loss": 2.7053024997711184, "actor_loss": -9.84189102726598, "actor_target_entropy": -1.0, "actor_entropy": 0.925902493538395, "alpha_loss": 0.1459725145851412, "alpha_value": 0.09237115014424498, "duration": 3.8852882385253906, "step": 1250}
{"episode_reward": 107.52045835762276, "episode": 11.0, "batch_reward": 0.9698503098487854, "critic_loss": 2.5738371448516846, "actor_loss": -10.412937497335767, "actor_target_entropy": -1.0, "actor_entropy": 0.909936407255748, "alpha_loss": 0.1434616588410877, "alpha_value": 0.09170043787177042, "duration": 3.887489080429077, "step": 1375}
{"episode_reward": 56.43475453224044, "episode": 12.0, "batch_reward": 0.9088668112754822, "critic_loss": 2.428726201057434, "actor_loss": -10.87871459222609, "actor_target_entropy": -1.0, "actor_entropy": 0.9284124566662696, "alpha_loss": 0.1436381875987976, "alpha_value": 0.09104986103285015, "duration": 3.889195442199707, "step": 1500}
{"episode_reward": 59.39690503283091, "episode": 13.0, "batch_reward": 0.8838357276916504, "critic_loss": 2.3216043634414674, "actor_loss": -11.376731539529468, "actor_target_entropy": -1.0, "actor_entropy": 0.9588840594367375, "alpha_loss": 0.1438538491252869, "alpha_value": 0.09041021649836427, "duration": 3.8867244720458984, "step": 1625}
{"episode_reward": 74.55202831056808, "episode": 14.0, "batch_reward": 0.8828561954498291, "critic_loss": 2.3400397987365724, "actor_loss": -11.869933189884309, "actor_target_entropy": -1.0, "actor_entropy": 1.0122647170097596, "alpha_loss": 0.1440902157656608, "alpha_value": 0.08978154676270293, "duration": 3.886807441711426, "step": 1750}
{"episode_reward": 216.48985904931047, "episode": 15.0, "batch_reward": 0.9357551999092102, "critic_loss": 2.507672618865967, "actor_loss": -12.455707716563392, "actor_target_entropy": -1.0, "actor_entropy": 0.9970503175069415, "alpha_loss": 0.14235921558879672, "alpha_value": 0.08916555179944986, "duration": 3.888594388961792, "step": 1875}
{"episode_reward": 112.30599617813807, "episode": 16.0, "batch_reward": 0.9260434885025024, "critic_loss": 2.4411328411102295, "actor_loss": -12.971291911217474, "actor_target_entropy": -1.0, "actor_entropy": 0.9855502382401498, "alpha_loss": 0.14136886812986865, "alpha_value": 0.08856519578756977, "duration": 3.8823463916778564, "step": 2000}
{"episode_reward": 69.5912588221946, "episode": 17.0, "batch_reward": 0.9101411781311035, "critic_loss": 2.4266169357299803, "actor_loss": -13.469535600571405, "actor_target_entropy": -1.0, "actor_entropy": 1.0011941383755396, "alpha_loss": 0.14092588755819532, "alpha_value": 0.08797515657495826, "duration": 3.8809492588043213, "step": 2125}
{"episode_reward": 129.8399684586725, "episode": 18.0, "batch_reward": 0.9084646611213684, "critic_loss": 2.394675039291382, "actor_loss": -13.977853990370228, "actor_target_entropy": -1.0, "actor_entropy": 1.008939516159796, "alpha_loss": 0.1412244915000854, "alpha_value": 0.08739297771567589, "duration": 3.878045082092285, "step": 2250}
{"episode_reward": 71.10834330753735, "episode": 19.0, "batch_reward": 0.888391402721405, "critic_loss": 2.336555178642273, "actor_loss": -14.447360825917077, "actor_target_entropy": -1.0, "actor_entropy": 1.0344142327232966, "alpha_loss": 0.14018469717767504, "alpha_value": 0.08681908028085801, "duration": 3.8915762901306152, "step": 2375}
{"episode_reward": 152.54996794988875, "episode": 20.0, "batch_reward": 0.8970695643424987, "critic_loss": 2.3274967765808103, "actor_loss": -14.952844696660195, "actor_target_entropy": -1.0, "actor_entropy": 1.0612793468659925, "alpha_loss": 0.1407022923231125, "alpha_value": 0.08625210216284225, "duration": 3.8776888847351074, "step": 2500}
{"episode_reward": 140.82508305191058, "episode": 21.0, "batch_reward": 0.9244916949272156, "critic_loss": 2.4305002946853635, "actor_loss": -15.47867823403979, "actor_target_entropy": -1.0, "actor_entropy": 1.0603555062460521, "alpha_loss": 0.1400403692608788, "alpha_value": 0.08569070453582156, "duration": 3.889434337615967, "step": 2625}
{"episode_reward": 91.50702315479833, "episode": 22.0, "batch_reward": 0.9195526571273803, "critic_loss": 2.406825577735901, "actor_loss": -15.985896525844451, "actor_target_entropy": -1.0, "actor_entropy": 1.0011060814703665, "alpha_loss": 0.1376473826746787, "alpha_value": 0.08514061013360055, "duration": 3.882063865661621, "step": 2750}
{"episode_reward": 98.90995035032621, "episode": 23.0, "batch_reward": 0.8891741061210632, "critic_loss": 2.349924041748047, "actor_loss": -16.444579169863747, "actor_target_entropy": -1.0, "actor_entropy": 0.9832287307769533, "alpha_loss": 0.1361402159645444, "alpha_value": 0.08460318836307089, "duration": 3.8870203495025635, "step": 2875}
{"episode_reward": 64.90073356996038, "episode": 24.0, "batch_reward": 0.9150877289772034, "critic_loss": 2.383668807029724, "actor_loss": -16.957899616610618, "actor_target_entropy": -1.0, "actor_entropy": 0.9715978445545319, "alpha_loss": 0.1352040902260811, "alpha_value": 0.0840736036908079, "duration": 3.882641315460205, "step": 3000}
{"episode_reward": 226.39835567137612, "episode": 25.0, "batch_reward": 0.9114133763313294, "critic_loss": 2.50527393245697, "actor_loss": -17.43842781914605, "actor_target_entropy": -1.0, "actor_entropy": 0.962764196925693, "alpha_loss": 0.13368835619517735, "alpha_value": 0.0835519899930283, "duration": 3.8815650939941406, "step": 3125}
{"episode_reward": 30.423156442589292, "episode": 26.0, "batch_reward": 0.9039064807891846, "critic_loss": 2.485228442192078, "actor_loss": -17.922023680902296, "actor_target_entropy": -1.0, "actor_entropy": 0.9263742854518275, "alpha_loss": 0.13206017858559085, "alpha_value": 0.08303901292832142, "duration": 3.8803021907806396, "step": 3250}
{"episode_reward": 36.422783979666, "episode": 27.0, "batch_reward": 0.8670620746612548, "critic_loss": 2.3412248554229738, "actor_loss": -18.35581564524817, "actor_target_entropy": -1.0, "actor_entropy": 0.9064150480996995, "alpha_loss": 0.13082857997644515, "alpha_value": 0.0825365752288664, "duration": 3.883194923400879, "step": 3375}
{"episode_reward": 94.40533850784011, "episode": 28.0, "batch_reward": 0.8829472804069519, "critic_loss": 2.4508287448883057, "actor_loss": -18.83122951753678, "actor_target_entropy": -1.0, "actor_entropy": 0.9337565091348463, "alpha_loss": 0.13108907904355757, "alpha_value": 0.08203484889691236, "duration": 3.879344940185547, "step": 3500}
{"episode_reward": 174.90747476317327, "episode": 29.0, "batch_reward": 0.8989150538444519, "critic_loss": 2.5245372591018675, "actor_loss": -19.304996581304643, "actor_target_entropy": -1.0, "actor_entropy": 0.8942241839000157, "alpha_loss": 0.12923487855328453, "alpha_value": 0.08153911248755306, "duration": 3.8842620849609375, "step": 3625}
{"episode_reward": 264.05529623854466, "episode": 30.0, "batch_reward": 0.9278032450675965, "critic_loss": 2.6908328647613526, "actor_loss": -19.816677647252238, "actor_target_entropy": -1.0, "actor_entropy": 0.8747829352655718, "alpha_loss": 0.12759367472702457, "alpha_value": 0.08105194711916543, "duration": 3.8730568885803223, "step": 3750}
{"episode_reward": 95.38070128287046, "episode": 31.0, "batch_reward": 0.910157109260559, "critic_loss": 2.645235789299011, "actor_loss": -20.27433116852291, "actor_target_entropy": -1.0, "actor_entropy": 0.8514640766476828, "alpha_loss": 0.1264016172952122, "alpha_value": 0.08057211717381046, "duration": 3.8834002017974854, "step": 3875}
{"episode_reward": 39.40292806175124, "episode": 32.0, "batch_reward": 0.8968133668899536, "critic_loss": 2.6206326122283934, "actor_loss": -20.729690828631, "actor_target_entropy": -1.0, "actor_entropy": 0.8427433544589628, "alpha_loss": 0.12465543359998733, "alpha_value": 0.08009843157667687, "duration": 3.8773365020751953, "step": 4000}
{"episode_reward": 82.90305113292806, "episode": 33.0, "batch_reward": 0.8783528060913086, "critic_loss": 2.618042993545532, "actor_loss": -21.1534059918116, "actor_target_entropy": -1.0, "actor_entropy": 0.8349648600532895, "alpha_loss": 0.12400427886417933, "alpha_value": 0.07963164783607217, "duration": 3.8794376850128174, "step": 4125}
{"episode_reward": 62.042995259218046, "episode": 34.0, "batch_reward": 0.8682998208999634, "critic_loss": 2.4676682262420653, "actor_loss": -21.58584148653092, "actor_target_entropy": -1.0, "actor_entropy": 0.9002368257891747, "alpha_loss": 0.12584229342399106, "alpha_value": 0.07916219884091469, "duration": 3.865872621536255, "step": 4250}
{"episode_reward": 75.73754959962889, "episode": 35.0, "batch_reward": 0.8574607000350952, "critic_loss": 2.5233251953125, "actor_loss": -22.008605169871498, "actor_target_entropy": -1.0, "actor_entropy": 0.933007348151434, "alpha_loss": 0.12596853952559214, "alpha_value": 0.07868950241337935, "duration": 3.887953996658325, "step": 4375}
{"episode_reward": 57.64836094179242, "episode": 36.0, "batch_reward": 0.8646580457687378, "critic_loss": 2.5154755020141604, "actor_loss": -22.440258579869425, "actor_target_entropy": -1.0, "actor_entropy": 0.9933594003800423, "alpha_loss": 0.1274389887769376, "alpha_value": 0.07821739247917145, "duration": 3.880068302154541, "step": 4500}
{"episode_reward": 124.54798161901489, "episode": 37.0, "batch_reward": 0.8413834285736084, "critic_loss": 2.3532024669647216, "actor_loss": -22.834582646687824, "actor_target_entropy": -1.0, "actor_entropy": 1.0177510446972318, "alpha_loss": 0.12721786695340323, "alpha_value": 0.07774320671072052, "duration": 3.8843154907226562, "step": 4625}
{"episode_reward": 58.30478023745737, "episode": 38.0, "batch_reward": 0.8787351932525634, "critic_loss": 2.495434943199158, "actor_loss": -23.29083873379615, "actor_target_entropy": -1.0, "actor_entropy": 1.03979318757211, "alpha_loss": 0.12660853060022478, "alpha_value": 0.07727287567727413, "duration": 3.8820931911468506, "step": 4750}
{"episode_reward": 199.02508125606988, "episode": 39.0, "batch_reward": 0.8753284039497375, "critic_loss": 2.539995943069458, "actor_loss": -23.72168162512401, "actor_target_entropy": -1.0, "actor_entropy": 1.0150679955406794, "alpha_loss": 0.12551899810159017, "alpha_value": 0.07680706457433058, "duration": 3.8810808658599854, "step": 4875}
{"episode_reward": 128.60112180806428, "episode": 40.0, "batch_reward": 0.8998187155723572, "critic_loss": 2.6341906032562257, "actor_loss": -24.17797322427073, "actor_target_entropy": -1.0, "actor_entropy": 0.9350991595175958, "alpha_loss": 0.12287462803144608, "alpha_value": 0.07635134318724118, "duration": 3.8787853717803955, "step": 5000}
{"episode_reward": 182.4262837804096, "episode": 41.0, "batch_reward": 0.8955608510971069, "critic_loss": 2.6736613731384278, "actor_loss": -24.613071048070513, "actor_target_entropy": -1.0, "actor_entropy": 0.8862859199917505, "alpha_loss": 0.11977873316832952, "alpha_value": 0.07590481648247432, "duration": 3.881507158279419, "step": 5125}
{"episode_reward": 88.29928266601996, "episode": 42.0, "batch_reward": 0.8747410898208619, "critic_loss": 2.5381138429641723, "actor_loss": -25.017219789566532, "actor_target_entropy": -1.0, "actor_entropy": 0.8275484000482867, "alpha_loss": 0.11764031600567602, "alpha_value": 0.07546997563206691, "duration": 3.8822309970855713, "step": 5250}
{"episode_reward": 132.23742406911418, "episode": 43.0, "batch_reward": 0.881151976108551, "critic_loss": 2.657654670715332, "actor_loss": -25.434559504191082, "actor_target_entropy": -1.0, "actor_entropy": 0.8585065224814037, "alpha_loss": 0.11787152337649512, "alpha_value": 0.07504056334537237, "duration": 3.8761706352233887, "step": 5375}
{"episode_reward": 32.81656941943372, "episode": 44.0, "batch_reward": 0.8921259231567383, "critic_loss": 2.621084342956543, "actor_loss": -25.885992942317838, "actor_target_entropy": -1.0, "actor_entropy": 0.914604575403275, "alpha_loss": 0.11884866414531585, "alpha_value": 0.0746065226671969, "duration": 3.8730764389038086, "step": 5500}
{"episode_reward": 48.09273634473726, "episode": 45.0, "batch_reward": 0.86784530544281, "critic_loss": 2.597340069770813, "actor_loss": -26.257693215022012, "actor_target_entropy": -1.0, "actor_entropy": 0.9193087702705747, "alpha_loss": 0.11837161722637358, "alpha_value": 0.0741736462906449, "duration": 3.881875514984131, "step": 5625}
{"episode_reward": 63.88274576511732, "episode": 46.0, "batch_reward": 0.8748970813751221, "critic_loss": 2.578631567001343, "actor_loss": -26.68261201920048, "actor_target_entropy": -1.0, "actor_entropy": 0.9170194787363852, "alpha_loss": 0.11778533086180687, "alpha_value": 0.07374242845530013, "duration": 3.8756308555603027, "step": 5750}
{"episode_reward": 149.88294596226885, "episode": 47.0, "batch_reward": 0.8616205310821533, "critic_loss": 2.6105909032821657, "actor_loss": -27.0653257521372, "actor_target_entropy": -1.0, "actor_entropy": 0.8867616218233866, "alpha_loss": 0.11603528994416433, "alpha_value": 0.07331630951219666, "duration": 3.8816399574279785, "step": 5875}
{"episode_reward": 37.22616118631075, "episode": 48.0, "batch_reward": 0.8412285552024842, "critic_loss": 2.5608069038391115, "actor_loss": -27.437848675635554, "actor_target_entropy": -1.0, "actor_entropy": 0.9337917181753344, "alpha_loss": 0.1166540946691267, "alpha_value": 0.07289386440763786, "duration": 3.8759524822235107, "step": 6000}
{"episode_reward": 46.42452783677496, "episode": 49.0, "batch_reward": 0.8353840065002441, "critic_loss": 2.4937664289474486, "actor_loss": -27.81087197197808, "actor_target_entropy": -1.0, "actor_entropy": 0.9437626903019254, "alpha_loss": 0.1160133138062462, "alpha_value": 0.07247059149857916, "duration": 3.8819262981414795, "step": 6125}
{"episode_reward": 137.37538105305867, "episode": 50.0, "batch_reward": 0.860747001171112, "critic_loss": 2.5775110454559327, "actor_loss": -28.208375161693944, "actor_target_entropy": -1.0, "actor_entropy": 0.9191562629515125, "alpha_loss": 0.115077527660516, "alpha_value": 0.07205054878109751, "duration": 3.877072811126709, "step": 6250}
{"episode_reward": 114.77678550580005, "episode": 51.0, "batch_reward": 0.8574718074798584, "critic_loss": 2.5955689573287963, "actor_loss": -28.606123636639307, "actor_target_entropy": -1.0, "actor_entropy": 0.9022048030580793, "alpha_loss": 0.11381328011315966, "alpha_value": 0.07163710524903424, "duration": 3.8834266662597656, "step": 6375}
{"episode_reward": 85.96893167597892, "episode": 52.0, "batch_reward": 0.8432113952636718, "critic_loss": 2.515404661178589, "actor_loss": -28.95485837997929, "actor_target_entropy": -1.0, "actor_entropy": 0.951775723888028, "alpha_loss": 0.11498205736279488, "alpha_value": 0.07122261315792455, "duration": 3.8758654594421387, "step": 6500}
{"episode_reward": 81.91674462347625, "episode": 53.0, "batch_reward": 0.858934413433075, "critic_loss": 2.5493377113342284, "actor_loss": -29.35595633491637, "actor_target_entropy": -1.0, "actor_entropy": 0.981515886291625, "alpha_loss": 0.1144963169381732, "alpha_value": 0.07080858557854222, "duration": 3.8751237392425537, "step": 6625}
{"episode_reward": 64.64569566048381, "episode": 54.0, "batch_reward": 0.8266046152114869, "critic_loss": 2.4384426755905153, "actor_loss": -29.682004159496678, "actor_target_entropy": -1.0, "actor_entropy": 0.9736310166697348, "alpha_loss": 0.11391371632775953, "alpha_value": 0.07039528822068106, "duration": 3.8708713054656982, "step": 6750}
{"episode_reward": 59.67628123683606, "episode": 55.0, "batch_reward": 0.8302031998634338, "critic_loss": 2.378370787620544, "actor_loss": -30.051022211710613, "actor_target_entropy": -1.0, "actor_entropy": 0.9339539228923737, "alpha_loss": 0.11228889640834597, "alpha_value": 0.069988101964707, "duration": 3.8825297355651855, "step": 6875}
{"episode_reward": 88.1595564886332, "episode": 56.0, "batch_reward": 0.8292447357177735, "critic_loss": 2.4229992656707764, "actor_loss": -30.405647062486217, "actor_target_entropy": -1.0, "actor_entropy": 0.8957253617625083, "alpha_loss": 0.11024485816878657, "alpha_value": 0.0695873270637221, "duration": 3.8779144287109375, "step": 7000}
{"episode_reward": 32.334428544059946, "episode": 57.0, "batch_reward": 0.8267469921112061, "critic_loss": 2.4758584451675416, "actor_loss": -30.756586861988854, "actor_target_entropy": -1.0, "actor_entropy": 0.881417367193434, "alpha_loss": 0.1095914137032297, "alpha_value": 0.06919241208228863, "duration": 3.882540464401245, "step": 7125}
{"episode_reward": 146.28860985019008, "episode": 58.0, "batch_reward": 0.8176641516685486, "critic_loss": 2.403199835777283, "actor_loss": -31.095513743738973, "actor_target_entropy": -1.0, "actor_entropy": 0.8613005491995043, "alpha_loss": 0.10845768439673609, "alpha_value": 0.06880113829216321, "duration": 3.8726437091827393, "step": 7250}
{"episode_reward": 66.8677254626089, "episode": 59.0, "batch_reward": 0.8238703122138977, "critic_loss": 2.489588717460632, "actor_loss": -31.435591500902934, "actor_target_entropy": -1.0, "actor_entropy": 0.873518325033642, "alpha_loss": 0.10804319771982375, "alpha_value": 0.06841116748502847, "duration": 3.8857555389404297, "step": 7375}
{"episode_reward": 137.75094472079925, "episode": 60.0, "batch_reward": 0.8306042475700378, "critic_loss": 2.4787145166397093, "actor_loss": -31.791030422333748, "actor_target_entropy": -1.0, "actor_entropy": 0.8549048862149639, "alpha_loss": 0.1065212866712001, "alpha_value": 0.06802638439557998, "duration": 3.8678462505340576, "step": 7500}
{"episode_reward": 195.68477653936986, "episode": 61.0, "batch_reward": 0.8378547964096069, "critic_loss": 2.4886312046051025, "actor_loss": -32.14985375177292, "actor_target_entropy": -1.0, "actor_entropy": 0.9273210423333305, "alpha_loss": 0.10810844387326922, "alpha_value": 0.0676394266633611, "duration": 3.885186195373535, "step": 7625}
{"episode_reward": 61.428505504478494, "episode": 62.0, "batch_reward": 0.8419722533226013, "critic_loss": 2.5397441773414613, "actor_loss": -32.495390922792495, "actor_target_entropy": -1.0, "actor_entropy": 0.865013680150432, "alpha_loss": 0.10566911269580165, "alpha_value": 0.06725606891195, "duration": 3.8748116493225098, "step": 7750}
{"episode_reward": 30.806001629148028, "episode": 63.0, "batch_reward": 0.8105388169288635, "critic_loss": 2.3942737350463865, "actor_loss": -32.79838168431842, "actor_target_entropy": -1.0, "actor_entropy": 0.9085102857105316, "alpha_loss": 0.10640375292490399, "alpha_value": 0.0668746823964375, "duration": 3.8809776306152344, "step": 7875}
{"episode_reward": 95.56046359680093, "episode": 64.0, "batch_reward": 0.8102373819351196, "critic_loss": 2.3757289094924925, "actor_loss": -33.12664216564548, "actor_target_entropy": -1.0, "actor_entropy": 0.9596696399873302, "alpha_loss": 0.10743893610854302, "alpha_value": 0.06649135188583886, "duration": 3.8742311000823975, "step": 8000}
{"episode_reward": 215.44519239206187, "episode": 65.0, "batch_reward": 0.8396773405075073, "critic_loss": 2.47814873790741, "actor_loss": -33.48934906248062, "actor_target_entropy": -1.0, "actor_entropy": 0.9828851052692958, "alpha_loss": 0.1076400148726645, "alpha_value": 0.0661053787289851, "duration": 3.8777365684509277, "step": 8125}
{"episode_reward": 75.9201267615926, "episode": 66.0, "batch_reward": 0.8434565176963806, "critic_loss": 2.6180271911621094, "actor_loss": -33.83135143403084, "actor_target_entropy": -1.0, "actor_entropy": 0.9199144647967431, "alpha_loss": 0.10468184118790011, "alpha_value": 0.06572474685988487, "duration": 3.8789572715759277, "step": 8250}
{"episode_reward": 242.47880161774142, "episode": 67.0, "batch_reward": 0.8523838782310486, "critic_loss": 2.6952217445373536, "actor_loss": -34.187859126499724, "actor_target_entropy": -1.0, "actor_entropy": 0.98769630136944, "alpha_loss": 0.10593112640910679, "alpha_value": 0.0653492042035806, "duration": 3.8844058513641357, "step": 8375}
{"episode_reward": 187.13373805210938, "episode": 68.0, "batch_reward": 0.8705217308998108, "critic_loss": 2.7034591178894045, "actor_loss": -34.558914676789314, "actor_target_entropy": -1.0, "actor_entropy": 0.9895299519262006, "alpha_loss": 0.10565813883177695, "alpha_value": 0.06496983320941085, "duration": 3.8751015663146973, "step": 8500}
{"episode_reward": 221.45036454417112, "episode": 69.0, "batch_reward": 0.8862627520561218, "critic_loss": 2.7984839849472047, "actor_loss": -34.928002251519096, "actor_target_entropy": -1.0, "actor_entropy": 0.9040747464649261, "alpha_loss": 0.10293649160672748, "alpha_value": 0.06459745259526584, "duration": 3.8830883502960205, "step": 8625}
{"episode_reward": 105.68975105820489, "episode": 70.0, "batch_reward": 0.8775056300163269, "critic_loss": 2.708070903778076, "actor_loss": -35.28006756690241, "actor_target_entropy": -1.0, "actor_entropy": 0.8580069118930448, "alpha_loss": 0.1010304396190951, "alpha_value": 0.06423316524478453, "duration": 3.8723156452178955, "step": 8750}
{"episode_reward": 181.01396226098058, "episode": 71.0, "batch_reward": 0.8892858357429504, "critic_loss": 2.7990081205368043, "actor_loss": -35.637627556210475, "actor_target_entropy": -1.0, "actor_entropy": 0.8141962706096588, "alpha_loss": 0.09918905404352006, "alpha_value": 0.06387524354989378, "duration": 3.8846240043640137, "step": 8875}
{"episode_reward": 41.658926007962506, "episode": 72.0, "batch_reward": 0.8718321022987365, "critic_loss": 2.7232195892333984, "actor_loss": -35.97280871483587, "actor_target_entropy": -1.0, "actor_entropy": 0.767266369635059, "alpha_loss": 0.09712175988862591, "alpha_value": 0.06352448610260257, "duration": 3.877291440963745, "step": 9000}
{"episode_reward": 75.98296979618912, "episode": 73.0, "batch_reward": 0.8563542943000794, "critic_loss": 2.665698369026184, "actor_loss": -36.30203513493613, "actor_target_entropy": -1.0, "actor_entropy": 0.7299103528734238, "alpha_loss": 0.09499337086601863, "alpha_value": 0.06318123475887626, "duration": 3.886009454727173, "step": 9125}
{"episode_reward": 71.49588448948049, "episode": 74.0, "batch_reward": 0.8687388229370118, "critic_loss": 2.671958338737488, "actor_loss": -36.66128324693249, "actor_target_entropy": -1.0, "actor_entropy": 0.6899282278553132, "alpha_loss": 0.0926637404387997, "alpha_value": 0.06284335728761505, "duration": 3.87740421295166, "step": 9250}
{"episode_reward": 59.370642177016585, "episode": 75.0, "batch_reward": 0.8798755097389221, "critic_loss": 2.8110345859527586, "actor_loss": -37.01148460024879, "actor_target_entropy": -1.0, "actor_entropy": 0.671650661362542, "alpha_loss": 0.09176594917736357, "alpha_value": 0.0625122271956861, "duration": 3.8858261108398438, "step": 9375}
{"episode_reward": 186.97019687697662, "episode": 76.0, "batch_reward": 0.8663739085197448, "critic_loss": 2.7169844093322753, "actor_loss": -37.324577208488215, "actor_target_entropy": -1.0, "actor_entropy": 0.6807530503119191, "alpha_loss": 0.09193716835110419, "alpha_value": 0.0621803669402523, "duration": 3.876244068145752, "step": 9500}
{"episode_reward": 25.586454991206853, "episode": 77.0, "batch_reward": 0.8493819055557251, "critic_loss": 2.671414087295532, "actor_loss": -37.65003567650204, "actor_target_entropy": -1.0, "actor_entropy": 0.6595892092538258, "alpha_loss": 0.09063968050574499, "alpha_value": 0.06184829246853887, "duration": 3.8743886947631836, "step": 9625}
{"episode_reward": 63.14590443326901, "episode": 78.0, "batch_reward": 0.8554490118026733, "critic_loss": 2.660045852661133, "actor_loss": -37.971298402355565, "actor_target_entropy": -1.0, "actor_entropy": 0.7229255284032514, "alpha_loss": 0.09217925285620074, "alpha_value": 0.061517824896267066, "duration": 3.879457950592041, "step": 9750}
{"episode_reward": 108.14484073400318, "episode": 79.0, "batch_reward": 0.8472046689987183, "critic_loss": 2.5971930809020995, "actor_loss": -38.290308573889355, "actor_target_entropy": -1.0, "actor_entropy": 0.7678061761553325, "alpha_loss": 0.09287908259365293, "alpha_value": 0.06117944211274985, "duration": 3.8788626194000244, "step": 9875}
{"episode_reward": 45.23722887466617, "episode": 80.0, "batch_reward": 0.8520828981399536, "critic_loss": 2.691309808731079, "actor_loss": -38.59922556723318, "actor_target_entropy": -1.0, "actor_entropy": 0.8170339407459382, "alpha_loss": 0.0940824250780767, "alpha_value": 0.060838913530509096, "duration": 3.8783791065216064, "step": 10000}
{"episode_reward": 149.4855185650728, "episode": 81.0, "batch_reward": 0.8534415283203125, "critic_loss": 2.700137927055359, "actor_loss": -38.91171155657087, "actor_target_entropy": -1.0, "actor_entropy": 0.9069487121370103, "alpha_loss": 0.0965014405193783, "alpha_value": 0.060491852426065744, "duration": 7.88267183303833, "step": 10125}
{"episode_reward": 119.02864543907252, "episode": 82.0, "batch_reward": 0.8537802767753601, "critic_loss": 2.723960912704468, "actor_loss": -39.21341502281927, "actor_target_entropy": -1.0, "actor_entropy": 0.9522664047056629, "alpha_loss": 0.09644812357521826, "alpha_value": 0.06013930173263096, "duration": 3.8773248195648193, "step": 10250}
{"episode_reward": 55.28568174207458, "episode": 83.0, "batch_reward": 0.8635575551986694, "critic_loss": 2.7139026069641115, "actor_loss": -39.54378176492358, "actor_target_entropy": -1.0, "actor_entropy": 0.9049742884106107, "alpha_loss": 0.09511561632629424, "alpha_value": 0.0597910458978047, "duration": 3.8776471614837646, "step": 10375}
{"episode_reward": 177.50246647590757, "episode": 84.0, "batch_reward": 0.8574668970108033, "critic_loss": 2.6569393606185914, "actor_loss": -39.85119198214623, "actor_target_entropy": -1.0, "actor_entropy": 0.8198444497200751, "alpha_loss": 0.09254537534809881, "alpha_value": 0.05944995834827122, "duration": 3.8770694732666016, "step": 10500}
{"episode_reward": 129.59874608625822, "episode": 85.0, "batch_reward": 0.8554006638526916, "critic_loss": 2.616442904472351, "actor_loss": -40.15609838092138, "actor_target_entropy": -1.0, "actor_entropy": 0.9049367923585195, "alpha_loss": 0.09389115503383061, "alpha_value": 0.05911207243775778, "duration": 3.8781933784484863, "step": 10625}
{"episode_reward": 34.086830017102, "episode": 86.0, "batch_reward": 0.840574402332306, "critic_loss": 2.5901243772506715, "actor_loss": -40.44505137781943, "actor_target_entropy": -1.0, "actor_entropy": 0.968600461559911, "alpha_loss": 0.0951154570906393, "alpha_value": 0.0587685580589719, "duration": 3.884613513946533, "step": 10750}
{"episode_reward": 39.32562830750496, "episode": 87.0, "batch_reward": 0.8489717373847961, "critic_loss": 2.665101140975952, "actor_loss": -40.741702670142764, "actor_target_entropy": -1.0, "actor_entropy": 0.8957052855264573, "alpha_loss": 0.09278560713643119, "alpha_value": 0.05842719247492743, "duration": 3.8847665786743164, "step": 10875}
{"episode_reward": 134.70510958366205, "episode": 88.0, "batch_reward": 0.8519308071136474, "critic_loss": 2.7038737564086914, "actor_loss": -41.04825081363801, "actor_target_entropy": -1.0, "actor_entropy": 0.8346194182672808, "alpha_loss": 0.09050508300142904, "alpha_value": 0.05809539412297288, "duration": 3.8786633014678955, "step": 11000}
{"episode_reward": 68.506768952088, "episode": 89.0, "batch_reward": 0.8508288745880127, "critic_loss": 2.60560569190979, "actor_loss": -41.342112889365545, "actor_target_entropy": -1.0, "actor_entropy": 0.7832959360546536, "alpha_loss": 0.0882464772652066, "alpha_value": 0.05777280452435736, "duration": 3.883388042449951, "step": 11125}
{"episode_reward": 76.41211420752819, "episode": 90.0, "batch_reward": 0.8295617198944092, "critic_loss": 2.522648606300354, "actor_loss": -41.60899057695943, "actor_target_entropy": -1.0, "actor_entropy": 0.8020188308531239, "alpha_loss": 0.0882895889301454, "alpha_value": 0.05745418636430088, "duration": 3.8756842613220215, "step": 11250}
{"episode_reward": 92.31365981720973, "episode": 91.0, "batch_reward": 0.8426521506309509, "critic_loss": 2.5555179109573363, "actor_loss": -41.91679103790768, "actor_target_entropy": -1.0, "actor_entropy": 0.8191743445774865, "alpha_loss": 0.08818486202803869, "alpha_value": 0.057133406402391944, "duration": 3.885326862335205, "step": 11375}
{"episode_reward": 125.82207812942423, "episode": 92.0, "batch_reward": 0.8618469614982605, "critic_loss": 2.6823271141052247, "actor_loss": -42.21794159181656, "actor_target_entropy": -1.0, "actor_entropy": 0.8190237052979008, "alpha_loss": 0.08776361543324686, "alpha_value": 0.0568136583452492, "duration": 3.875281572341919, "step": 11500}
{"episode_reward": 41.82071457200466, "episode": 93.0, "batch_reward": 0.8340951414108276, "critic_loss": 2.5824570112228393, "actor_loss": -42.490415906149245, "actor_target_entropy": -1.0, "actor_entropy": 0.7692555946017069, "alpha_loss": 0.08620581965124796, "alpha_value": 0.05649725830579641, "duration": 3.877903699874878, "step": 11625}
{"episode_reward": 58.772631266395166, "episode": 94.0, "batch_reward": 0.834512981891632, "critic_loss": 2.651764183998108, "actor_loss": -42.754475993494836, "actor_target_entropy": -1.0, "actor_entropy": 0.7633839307292816, "alpha_loss": 0.08539749970359187, "alpha_value": 0.0561856992252074, "duration": 3.8721208572387695, "step": 11750}
{"episode_reward": 61.637732837528965, "episode": 95.0, "batch_reward": 0.8432904424667358, "critic_loss": 2.6479440202713014, "actor_loss": -43.052404070657396, "actor_target_entropy": -1.0, "actor_entropy": 0.7597124179204305, "alpha_loss": 0.08434399583983043, "alpha_value": 0.05587772224051062, "duration": 3.8849637508392334, "step": 11875}
{"episode_reward": 41.13940079671241, "episode": 96.0, "batch_reward": 0.8381414046287536, "critic_loss": 2.6247763633728027, "actor_loss": -43.31989251413653, "actor_target_entropy": -1.0, "actor_entropy": 0.7669239236462501, "alpha_loss": 0.08464071154594421, "alpha_value": 0.05556880949837418, "duration": 3.8723831176757812, "step": 12000}
{"episode_reward": 174.7947116375662, "episode": 97.0, "batch_reward": 0.8464005718231201, "critic_loss": 2.5715224866867064, "actor_loss": -43.60249534485832, "actor_target_entropy": -1.0, "actor_entropy": 0.7544795463955591, "alpha_loss": 0.08372532824675243, "alpha_value": 0.055262514749316975, "duration": 3.883816957473755, "step": 12125}
{"episode_reward": 116.87674173258758, "episode": 98.0, "batch_reward": 0.8431187062263489, "critic_loss": 2.685412434577942, "actor_loss": -43.87580127100791, "actor_target_entropy": -1.0, "actor_entropy": 0.7575363843671737, "alpha_loss": 0.08366496716776202, "alpha_value": 0.054955834643598114, "duration": 3.879108190536499, "step": 12250}
{"episode_reward": 154.76747867670812, "episode": 99.0, "batch_reward": 0.8264923753738403, "critic_loss": 2.4958109970092774, "actor_loss": -44.13449048239087, "actor_target_entropy": -1.0, "actor_entropy": 0.7348313426214551, "alpha_loss": 0.0822159576983679, "alpha_value": 0.054653096839167734, "duration": 3.877732992172241, "step": 12375}
{"episode_reward": 26.94105687181214, "episode": 100.0, "batch_reward": 0.8271233811378479, "critic_loss": 2.5273860998153688, "actor_loss": -44.39309286302136, "actor_target_entropy": -1.0, "actor_entropy": 0.8047920234741703, "alpha_loss": 0.08383208080645531, "alpha_value": 0.054349930391799736, "duration": 3.8752660751342773, "step": 12500}
{"episode_reward": 82.22498729165287, "episode": 101.0, "batch_reward": 0.8207733497619629, "critic_loss": 2.5700300407409666, "actor_loss": -44.64323964194646, "actor_target_entropy": -1.0, "actor_entropy": 0.7097389149287391, "alpha_loss": 0.08094989981443163, "alpha_value": 0.05404577191218045, "duration": 3.877716064453125, "step": 12625}
{"episode_reward": 30.966077244546042, "episode": 102.0, "batch_reward": 0.8264663767814636, "critic_loss": 2.5136949224472045, "actor_loss": -44.907715459023755, "actor_target_entropy": -1.0, "actor_entropy": 0.6053882914204751, "alpha_loss": 0.07621677472226081, "alpha_value": 0.05375816378746497, "duration": 3.8755719661712646, "step": 12750}
{"episode_reward": 107.3970152022662, "episode": 103.0, "batch_reward": 0.8182577719688415, "critic_loss": 2.5259763135910034, "actor_loss": -45.149998256138396, "actor_target_entropy": -1.0, "actor_entropy": 0.6784980429543389, "alpha_loss": 0.07845299501740743, "alpha_value": 0.053475318766129265, "duration": 3.8873112201690674, "step": 12875}
{"episode_reward": 15.216695467613592, "episode": 104.0, "batch_reward": 0.8264618468284607, "critic_loss": 2.5855481472015382, "actor_loss": -45.41016492535991, "actor_target_entropy": -1.0, "actor_entropy": 0.8462252347700058, "alpha_loss": 0.0830649770796299, "alpha_value": 0.05317678279196269, "duration": 3.8742494583129883, "step": 13000}
{"episode_reward": 102.92215563665198, "episode": 105.0, "batch_reward": 0.8196131224632264, "critic_loss": 2.5631054487228395, "actor_loss": -45.6501952882797, "actor_target_entropy": -1.0, "actor_entropy": 0.7728714734788925, "alpha_loss": 0.08037517692834611, "alpha_value": 0.052873827003240496, "duration": 3.8820230960845947, "step": 13125}
{"episode_reward": 89.38066326328327, "episode": 106.0, "batch_reward": 0.8227741541862488, "critic_loss": 2.5603862199783327, "actor_loss": -45.90911243807885, "actor_target_entropy": -1.0, "actor_entropy": 0.7981303776464155, "alpha_loss": 0.08108450340167168, "alpha_value": 0.052578043498218104, "duration": 3.872981309890747, "step": 13250}
{"episode_reward": 46.22560863454456, "episode": 107.0, "batch_reward": 0.813376347064972, "critic_loss": 2.5433851947784425, "actor_loss": -46.1337401374938, "actor_target_entropy": -1.0, "actor_entropy": 0.9352008899052938, "alpha_loss": 0.08386979216621035, "alpha_value": 0.052273432278759774, "duration": 3.879087448120117, "step": 13375}
{"episode_reward": 62.95747103658781, "episode": 108.0, "batch_reward": 0.803960196018219, "critic_loss": 2.517934676170349, "actor_loss": -46.364610056723315, "actor_target_entropy": -1.0, "actor_entropy": 0.9730084519232473, "alpha_loss": 0.08417709772625277, "alpha_value": 0.05196342431670546, "duration": 3.8780481815338135, "step": 13500}
{"episode_reward": 176.33728078358934, "episode": 109.0, "batch_reward": 0.8078670797348022, "critic_loss": 2.5470158576965334, "actor_loss": -46.598423972962394, "actor_target_entropy": -1.0, "actor_entropy": 0.8730209914464799, "alpha_loss": 0.08110951265645405, "alpha_value": 0.05166028430862157, "duration": 3.88120174407959, "step": 13625}
{"episode_reward": 80.53077346703074, "episode": 110.0, "batch_reward": 0.7987252068519592, "critic_loss": 2.465233910560608, "actor_loss": -46.82440825431578, "actor_target_entropy": -1.0, "actor_entropy": 0.8727506706791539, "alpha_loss": 0.08064022131504552, "alpha_value": 0.05136401615108244, "duration": 3.8777761459350586, "step": 13750}
{"episode_reward": 98.10048623971679, "episode": 111.0, "batch_reward": 0.8202417206764221, "critic_loss": 2.5329442634582517, "actor_loss": -47.07828188699389, "actor_target_entropy": -1.0, "actor_entropy": 0.8737702312923613, "alpha_loss": 0.08041592569105209, "alpha_value": 0.051068699879965256, "duration": 3.88242769241333, "step": 13875}
{"episode_reward": 64.37979317136485, "episode": 112.0, "batch_reward": 0.800693461894989, "critic_loss": 2.3985778894424437, "actor_loss": -47.29341666929184, "actor_target_entropy": -1.0, "actor_entropy": 0.89427222359565, "alpha_loss": 0.08054007493680523, "alpha_value": 0.050775510042496426, "duration": 3.8757505416870117, "step": 14000}
{"episode_reward": 62.20409840218468, "episode": 113.0, "batch_reward": 0.8049084105491638, "critic_loss": 2.4865773839950562, "actor_loss": -47.51220212663923, "actor_target_entropy": -1.0, "actor_entropy": 0.8690995432081676, "alpha_loss": 0.07931904151799186, "alpha_value": 0.050482369472172946, "duration": 3.8837780952453613, "step": 14125}
{"episode_reward": 67.89316621935278, "episode": 114.0, "batch_reward": 0.794919138431549, "critic_loss": 2.4004371337890626, "actor_loss": -47.72202953215568, "actor_target_entropy": -1.0, "actor_entropy": 0.8036839308277253, "alpha_loss": 0.07771331973133548, "alpha_value": 0.050195610099965066, "duration": 3.874260187149048, "step": 14250}
{"episode_reward": 53.77708315594404, "episode": 115.0, "batch_reward": 0.7957882990837097, "critic_loss": 2.4023798904418947, "actor_loss": -47.9396840050107, "actor_target_entropy": -1.0, "actor_entropy": 0.8562429083718194, "alpha_loss": 0.0783889228625903, "alpha_value": 0.04991174386602169, "duration": 3.8826041221618652, "step": 14375}
{"episode_reward": 105.13756028835766, "episode": 116.0, "batch_reward": 0.7884862499237061, "critic_loss": 2.45202433013916, "actor_loss": -48.156741173036636, "actor_target_entropy": -1.0, "actor_entropy": 0.8125143243420508, "alpha_loss": 0.07632051516444452, "alpha_value": 0.04962851532148814, "duration": 3.877460479736328, "step": 14500}
{"episode_reward": 10.42500000850398, "episode": 117.0, "batch_reward": 0.8000820074081421, "critic_loss": 2.4982577419281005, "actor_loss": -48.36757078624907, "actor_target_entropy": -1.0, "actor_entropy": 0.7785379489262899, "alpha_loss": 0.07526862467565233, "alpha_value": 0.049352183790667796, "duration": 3.8809633255004883, "step": 14625}
{"episode_reward": 111.83366650953862, "episode": 118.0, "batch_reward": 0.7826753225326538, "critic_loss": 2.435804308891296, "actor_loss": -48.572904156100364, "actor_target_entropy": -1.0, "actor_entropy": 0.793032911516005, "alpha_loss": 0.07508138723431095, "alpha_value": 0.049078793741645046, "duration": 3.8719358444213867, "step": 14750}
{"episode_reward": 71.32939226166634, "episode": 119.0, "batch_reward": 0.7921762690544129, "critic_loss": 2.466352412223816, "actor_loss": -48.781350695897665, "actor_target_entropy": -1.0, "actor_entropy": 0.921752961855086, "alpha_loss": 0.07818676909757039, "alpha_value": 0.048798148338989884, "duration": 3.8833835124969482, "step": 14875}
{"episode_reward": 90.1305779139182, "episode": 120.0, "batch_reward": 0.800180064201355, "critic_loss": 2.424645435333252, "actor_loss": -49.002595409270256, "actor_target_entropy": -1.0, "actor_entropy": 0.8559670025302518, "alpha_loss": 0.07615399637049244, "alpha_value": 0.04851609900467749, "duration": 3.8702971935272217, "step": 15000}
{"episode_reward": 82.92271181182299, "episode": 121.0, "batch_reward": 0.7884831848144531, "critic_loss": 2.373804709434509, "actor_loss": -49.199619474865145, "actor_target_entropy": -1.0, "actor_entropy": 0.8113979025492593, "alpha_loss": 0.07440286094234103, "alpha_value": 0.04824289958725089, "duration": 3.880136489868164, "step": 15125}
{"episode_reward": 121.14670482104569, "episode": 122.0, "batch_reward": 0.7989877328872681, "critic_loss": 2.366081624984741, "actor_loss": -49.41918428482548, "actor_target_entropy": -1.0, "actor_entropy": 0.8208787402799053, "alpha_loss": 0.07482034388569093, "alpha_value": 0.04796974185892562, "duration": 3.8696722984313965, "step": 15250}
{"episode_reward": 76.65506508371578, "episode": 123.0, "batch_reward": 0.7992028908729554, "critic_loss": 2.484936643600464, "actor_loss": -49.624984135703436, "actor_target_entropy": -1.0, "actor_entropy": 0.7583393388324313, "alpha_loss": 0.07261157497054055, "alpha_value": 0.047701020263099025, "duration": 3.8799221515655518, "step": 15375}
{"episode_reward": 60.02791318952584, "episode": 124.0, "batch_reward": 0.7821863994598389, "critic_loss": 2.412340979576111, "actor_loss": -49.80439850591844, "actor_target_entropy": -1.0, "actor_entropy": 0.7733844364843061, "alpha_loss": 0.07232170527981173, "alpha_value": 0.047437331439000405, "duration": 3.8742775917053223, "step": 15500}
{"episode_reward": 83.58262454458217, "episode": 125.0, "batch_reward": 0.7865905032157898, "critic_loss": 2.445109889984131, "actor_loss": -50.00793232993474, "actor_target_entropy": -1.0, "actor_entropy": 0.9032099606498839, "alpha_loss": 0.0751503881007906, "alpha_value": 0.04716807235364326, "duration": 3.8705813884735107, "step": 15625}
{"episode_reward": 65.58909284265759, "episode": 126.0, "batch_reward": 0.7805108232498169, "critic_loss": 2.3040031518936157, "actor_loss": -50.19877353791268, "actor_target_entropy": -1.0, "actor_entropy": 0.9140521211008872, "alpha_loss": 0.07506114088239209, "alpha_value": 0.04689401139264032, "duration": 3.87273907661438, "step": 15750}
{"episode_reward": 125.79631206737557, "episode": 127.0, "batch_reward": 0.7822569303512573, "critic_loss": 2.341925605773926, "actor_loss": -50.39408608088418, "actor_target_entropy": -1.0, "actor_entropy": 0.8753565247096713, "alpha_loss": 0.07349457236982528, "alpha_value": 0.04662289690752331, "duration": 3.8791120052337646, "step": 15875}
{"episode_reward": 103.13205270562435, "episode": 128.0, "batch_reward": 0.7807759947776794, "critic_loss": 2.3340370903015137, "actor_loss": -50.58269900660361, "actor_target_entropy": -1.0, "actor_entropy": 0.7636607577723842, "alpha_loss": 0.07028939887400597, "alpha_value": 0.046360973729107725, "duration": 3.874819755554199, "step": 16000}
{"episode_reward": 56.37277067247038, "episode": 129.0, "batch_reward": 0.7770696296691895, "critic_loss": 2.2906756949424745, "actor_loss": -50.76440738496326, "actor_target_entropy": -1.0, "actor_entropy": 0.698817421519567, "alpha_loss": 0.06835284367913291, "alpha_value": 0.04610943078090271, "duration": 3.8788199424743652, "step": 16125}
{"episode_reward": 43.04986572327647, "episode": 130.0, "batch_reward": 0.7883245830535889, "critic_loss": 2.333876829147339, "actor_loss": -50.97598949555428, "actor_target_entropy": -1.0, "actor_entropy": 0.6613871397510651, "alpha_loss": 0.06701805130127937, "alpha_value": 0.04586129260542775, "duration": 3.8732197284698486, "step": 16250}
{"episode_reward": 101.23751925150513, "episode": 131.0, "batch_reward": 0.7765964193344116, "critic_loss": 2.350372878074646, "actor_loss": -51.14285944378565, "actor_target_entropy": -1.0, "actor_entropy": 0.6072504577182588, "alpha_loss": 0.06509880236690006, "alpha_value": 0.04562030025168326, "duration": 3.8832733631134033, "step": 16375}
{"episode_reward": 73.00263487726325, "episode": 132.0, "batch_reward": 0.7915322017669678, "critic_loss": 2.375050612449646, "actor_loss": -51.34392184595908, "actor_target_entropy": -1.0, "actor_entropy": 0.6353071774205854, "alpha_loss": 0.06550872710443312, "alpha_value": 0.045380015064329114, "duration": 3.875328540802002, "step": 16500}
{"episode_reward": 138.7184621116428, "episode": 133.0, "batch_reward": 0.7703526573181152, "critic_loss": 2.3962793674468994, "actor_loss": -51.49855071779282, "actor_target_entropy": -1.0, "actor_entropy": 0.6266955894137186, "alpha_loss": 0.06526713717787985, "alpha_value": 0.04513980887941575, "duration": 3.8847835063934326, "step": 16625}
{"episode_reward": 61.309429711542286, "episode": 134.0, "batch_reward": 0.769483995437622, "critic_loss": 2.2601407270431517, "actor_loss": -51.68116046536353, "actor_target_entropy": -1.0, "actor_entropy": 0.6988602953572427, "alpha_loss": 0.06607537716627121, "alpha_value": 0.04489716490570669, "duration": 3.873302698135376, "step": 16750}
{"episode_reward": 205.9849994283254, "episode": 135.0, "batch_reward": 0.7875210628509521, "critic_loss": 2.442773348808289, "actor_loss": -51.87524656265501, "actor_target_entropy": -1.0, "actor_entropy": 0.7636828365780058, "alpha_loss": 0.06816973407117147, "alpha_value": 0.04464761290482001, "duration": 3.881281614303589, "step": 16875}
{"episode_reward": 27.89907595941979, "episode": 136.0, "batch_reward": 0.7844613156318665, "critic_loss": 2.4268190126419067, "actor_loss": -52.05850761167465, "actor_target_entropy": -1.0, "actor_entropy": 0.6833633645888297, "alpha_loss": 0.06561722131746431, "alpha_value": 0.04439769678277032, "duration": 3.873446226119995, "step": 17000}
{"episode_reward": 257.2823615173716, "episode": 137.0, "batch_reward": 0.8108591060638428, "critic_loss": 2.6045969591140747, "actor_loss": -52.275388808477494, "actor_target_entropy": -1.0, "actor_entropy": 0.6763626904714675, "alpha_loss": 0.06509865477444633, "alpha_value": 0.04415651535322339, "duration": 3.8819053173065186, "step": 17125}
{"episode_reward": 155.20570232703355, "episode": 138.0, "batch_reward": 0.7976441645622253, "critic_loss": 2.411706167221069, "actor_loss": -52.45172586748677, "actor_target_entropy": -1.0, "actor_entropy": 0.6707509294632943, "alpha_loss": 0.06428515472479406, "alpha_value": 0.043916084618941496, "duration": 3.872708559036255, "step": 17250}
{"episode_reward": 34.05739924720898, "episode": 139.0, "batch_reward": 0.7888230319023133, "critic_loss": 2.437670709609985, "actor_loss": -52.62384457058377, "actor_target_entropy": -1.0, "actor_entropy": 0.6929098632600572, "alpha_loss": 0.06427860295488722, "alpha_value": 0.043675918789235615, "duration": 3.881525993347168, "step": 17375}
{"episode_reward": 62.77818644672195, "episode": 140.0, "batch_reward": 0.8008963384628296, "critic_loss": 2.45615592956543, "actor_loss": -52.82613342039047, "actor_target_entropy": -1.0, "actor_entropy": 0.6858008946141889, "alpha_loss": 0.0642449900868439, "alpha_value": 0.043435303681676335, "duration": 3.8808510303497314, "step": 17500}
{"episode_reward": 87.4236398531598, "episode": 141.0, "batch_reward": 0.791196786403656, "critic_loss": 2.5677329740524293, "actor_loss": -52.98483960590665, "actor_target_entropy": -1.0, "actor_entropy": 0.6319338348176744, "alpha_loss": 0.06243237533739635, "alpha_value": 0.043198347567051903, "duration": 3.878608226776123, "step": 17625}
{"episode_reward": 72.97855893165868, "episode": 142.0, "batch_reward": 0.7751276755332946, "critic_loss": 2.3343088617324828, "actor_loss": -53.151930409093055, "actor_target_entropy": -1.0, "actor_entropy": 0.6150343841122042, "alpha_loss": 0.06133957886167111, "alpha_value": 0.04296755911283625, "duration": 3.8783092498779297, "step": 17750}
{"episode_reward": 66.71215639355458, "episode": 143.0, "batch_reward": 0.7871104245185852, "critic_loss": 2.4502080726623534, "actor_loss": -53.33826725066654, "actor_target_entropy": -1.0, "actor_entropy": 0.6314152025041126, "alpha_loss": 0.061693002248094195, "alpha_value": 0.04273636427731932, "duration": 3.882772922515869, "step": 17875}
{"episode_reward": 70.24902187040156, "episode": 144.0, "batch_reward": 0.7858915982246399, "critic_loss": 2.381403241157532, "actor_loss": -53.509484998641476, "actor_target_entropy": -1.0, "actor_entropy": 0.6394476775200136, "alpha_loss": 0.061330327944409464, "alpha_value": 0.042504972032292886, "duration": 3.8751769065856934, "step": 18000}
{"episode_reward": 74.51870747878792, "episode": 145.0, "batch_reward": 0.7713860836029053, "critic_loss": 2.2655544958114624, "actor_loss": -53.66221981956845, "actor_target_entropy": -1.0, "actor_entropy": 0.6677323920386178, "alpha_loss": 0.06230087306291338, "alpha_value": 0.042270970618141224, "duration": 3.8818883895874023, "step": 18125}
{"episode_reward": 56.496354352137686, "episode": 146.0, "batch_reward": 0.772869559764862, "critic_loss": 2.421564509391785, "actor_loss": -53.82711133649272, "actor_target_entropy": -1.0, "actor_entropy": 0.6928844797995782, "alpha_loss": 0.06266690279927946, "alpha_value": 0.04203522344886851, "duration": 3.8640811443328857, "step": 18250}
{"episode_reward": 128.77766555829345, "episode": 147.0, "batch_reward": 0.784939489364624, "critic_loss": 2.39415260887146, "actor_loss": -53.99802531893291, "actor_target_entropy": -1.0, "actor_entropy": 0.7408068690981183, "alpha_loss": 0.06287049330652707, "alpha_value": 0.041798797401065416, "duration": 3.8841843605041504, "step": 18375}
{"episode_reward": 10.41434657821375, "episode": 148.0, "batch_reward": 0.7814979963302612, "critic_loss": 2.3741010389328, "actor_loss": -54.16265130812122, "actor_target_entropy": -1.0, "actor_entropy": 0.7971397715230142, "alpha_loss": 0.0639121301111675, "alpha_value": 0.04155888551543504, "duration": 3.8746705055236816, "step": 18500}
{"episode_reward": 208.9133103927671, "episode": 149.0, "batch_reward": 0.7951696496009827, "critic_loss": 2.455516881942749, "actor_loss": -54.345448387993706, "actor_target_entropy": -1.0, "actor_entropy": 0.8050066800344557, "alpha_loss": 0.06389176248321457, "alpha_value": 0.041317293494096526, "duration": 3.881009578704834, "step": 18625}
{"episode_reward": 203.51986894095418, "episode": 150.0, "batch_reward": 0.787618646144867, "critic_loss": 2.442069408416748, "actor_loss": -54.50593683796544, "actor_target_entropy": -1.0, "actor_entropy": 0.76944496170167, "alpha_loss": 0.06246052351930449, "alpha_value": 0.04107922694233131, "duration": 3.8817429542541504, "step": 18750}
{"episode_reward": 33.632925747639796, "episode": 151.0, "batch_reward": 0.7994917092323304, "critic_loss": 2.5035494079589844, "actor_loss": -54.69164875575474, "actor_target_entropy": -1.0, "actor_entropy": 0.7180163841398935, "alpha_loss": 0.061064467839305366, "alpha_value": 0.0408469009854425, "duration": 3.879185676574707, "step": 18875}
{"episode_reward": 110.28902236426026, "episode": 152.0, "batch_reward": 0.7884197897911072, "critic_loss": 2.4797025451660155, "actor_loss": -54.845249791299146, "actor_target_entropy": -1.0, "actor_entropy": 0.6277054855900426, "alpha_loss": 0.058281048471408504, "alpha_value": 0.040621990539474725, "duration": 3.8804380893707275, "step": 19000}
{"episode_reward": 80.34858979059034, "episode": 153.0, "batch_reward": 0.7784449405670166, "critic_loss": 2.3793142623901367, "actor_loss": -54.99531997196258, "actor_target_entropy": -1.0, "actor_entropy": 0.6850346629581754, "alpha_loss": 0.059385522431324396, "alpha_value": 0.040400711672493095, "duration": 3.8744285106658936, "step": 19125}
{"episode_reward": 76.88860764878171, "episode": 154.0, "batch_reward": 0.7909081087112427, "critic_loss": 2.406404295921326, "actor_loss": -55.1711423320155, "actor_target_entropy": -1.0, "actor_entropy": 0.7019133144809354, "alpha_loss": 0.05985223562006028, "alpha_value": 0.040175028193661436, "duration": 3.874753952026367, "step": 19250}
{"episode_reward": 79.02428106439157, "episode": 155.0, "batch_reward": 0.786289423942566, "critic_loss": 2.435579047203064, "actor_loss": -55.33756401425316, "actor_target_entropy": -1.0, "actor_entropy": 0.742414567205641, "alpha_loss": 0.06011688324903685, "alpha_value": 0.039949425128123627, "duration": 3.8784756660461426, "step": 19375}
{"episode_reward": 127.72605804214373, "episode": 156.0, "batch_reward": 0.7787385048866272, "critic_loss": 2.3624754734039306, "actor_loss": -55.46467719539519, "actor_target_entropy": -1.0, "actor_entropy": 0.7487956362385904, "alpha_loss": 0.05998608902577431, "alpha_value": 0.039721339359047925, "duration": 3.8743717670440674, "step": 19500}
{"episode_reward": 43.86206362819614, "episode": 157.0, "batch_reward": 0.7838065509796143, "critic_loss": 2.474724730491638, "actor_loss": -55.63918334718735, "actor_target_entropy": -1.0, "actor_entropy": 0.7396691659140209, "alpha_loss": 0.05949949218876778, "alpha_value": 0.039497181435066066, "duration": 3.8804843425750732, "step": 19625}
{"episode_reward": 32.027666634678646, "episode": 158.0, "batch_reward": 0.7939885449409485, "critic_loss": 2.4960379676818847, "actor_loss": -55.808180655202555, "actor_target_entropy": -1.0, "actor_entropy": 0.71298284299912, "alpha_loss": 0.0586443962228875, "alpha_value": 0.03927281191525051, "duration": 3.873562812805176, "step": 19750}
{"episode_reward": 163.01141452570425, "episode": 159.0, "batch_reward": 0.788857479095459, "critic_loss": 2.4873995332717898, "actor_loss": -55.95911577012804, "actor_target_entropy": -1.0, "actor_entropy": 0.6708943068035065, "alpha_loss": 0.05711548598039718, "alpha_value": 0.039053927420972634, "duration": 3.886776924133301, "step": 19875}
{"episode_reward": 40.57369561998134, "episode": 160.0, "batch_reward": 0.7886438345909119, "critic_loss": 2.441664517402649, "actor_loss": -56.12635126421529, "actor_target_entropy": -1.0, "actor_entropy": 0.6277979612350464, "alpha_loss": 0.05542903309387545, "alpha_value": 0.038842122930507476, "duration": 3.875652551651001, "step": 20000}
{"episode_reward": 185.26682028072628, "episode": 161.0, "batch_reward": 0.7829141039848327, "critic_loss": 2.376243118286133, "actor_loss": -56.27307395329551, "actor_target_entropy": -1.0, "actor_entropy": 0.5900516831685626, "alpha_loss": 0.054793465232092234, "alpha_value": 0.03863225386238498, "duration": 7.8888936042785645, "step": 20125}
{"episode_reward": 49.95354131520827, "episode": 162.0, "batch_reward": 0.7983347249031066, "critic_loss": 2.4086122798919676, "actor_loss": -56.4428907209827, "actor_target_entropy": -1.0, "actor_entropy": 0.615448001892336, "alpha_loss": 0.05491721564002575, "alpha_value": 0.038424420651641325, "duration": 3.8772597312927246, "step": 20250}
{"episode_reward": 182.96247588695067, "episode": 163.0, "batch_reward": 0.7765087609291077, "critic_loss": 2.3532990007400514, "actor_loss": -56.574003492082866, "actor_target_entropy": -1.0, "actor_entropy": 0.5520411313526215, "alpha_loss": 0.05315334243433816, "alpha_value": 0.038217743157167125, "duration": 3.8807899951934814, "step": 20375}
{"episode_reward": 21.27779702989241, "episode": 164.0, "batch_reward": 0.7687074580192566, "critic_loss": 2.3698650131225585, "actor_loss": -56.70415533742597, "actor_target_entropy": -1.0, "actor_entropy": 0.5044194844461256, "alpha_loss": 0.051549239084124565, "alpha_value": 0.03801793911954378, "duration": 3.8769547939300537, "step": 20500}
{"episode_reward": 9.820920514645001, "episode": 165.0, "batch_reward": 0.7928029022216797, "critic_loss": 2.479324935913086, "actor_loss": -56.88096763974144, "actor_target_entropy": -1.0, "actor_entropy": 0.4527618336299109, "alpha_loss": 0.04960406802239872, "alpha_value": 0.037823596419852085, "duration": 3.8821399211883545, "step": 20625}
{"episode_reward": 31.91944215402025, "episode": 166.0, "batch_reward": 0.7654281210899353, "critic_loss": 2.300399302482605, "actor_loss": -57.00351930433704, "actor_target_entropy": -1.0, "actor_entropy": 0.41300929361774075, "alpha_loss": 0.04838223424890349, "alpha_value": 0.03763474639763374, "duration": 3.8700459003448486, "step": 20750}
{"episode_reward": 56.738335231151474, "episode": 167.0, "batch_reward": 0.785244656085968, "critic_loss": 2.4042134256362915, "actor_loss": -57.165772210984, "actor_target_entropy": -1.0, "actor_entropy": 0.48916093319181414, "alpha_loss": 0.05034104232040663, "alpha_value": 0.037444433886761753, "duration": 3.879936933517456, "step": 20875}
{"episode_reward": 41.71929163192499, "episode": 168.0, "batch_reward": 0.7570455236434936, "critic_loss": 2.255356827735901, "actor_loss": -57.27050959679388, "actor_target_entropy": -1.0, "actor_entropy": 0.5655688047409058, "alpha_loss": 0.05223231756639096, "alpha_value": 0.037243917824661806, "duration": 3.876685857772827, "step": 21000}
{"episode_reward": 41.83698774756223, "episode": 169.0, "batch_reward": 0.7664146122932434, "critic_loss": 2.4164875440597533, "actor_loss": -57.40366872151693, "actor_target_entropy": -1.0, "actor_entropy": 0.5665750673839024, "alpha_loss": 0.051782446366453926, "alpha_value": 0.03703996072553782, "duration": 3.8749310970306396, "step": 21125}
{"episode_reward": 93.07976609918255, "episode": 170.0, "batch_reward": 0.769198314666748, "critic_loss": 2.337795316696167, "actor_loss": -57.54656680937736, "actor_target_entropy": -1.0, "actor_entropy": 0.5945679641539051, "alpha_loss": 0.05190536241617895, "alpha_value": 0.03683790315674823, "duration": 3.8754494190216064, "step": 21250}
{"episode_reward": 49.88252459725403, "episode": 171.0, "batch_reward": 0.7726486520767212, "critic_loss": 2.323596866607666, "actor_loss": -57.679741329616974, "actor_target_entropy": -1.0, "actor_entropy": 0.6189653476079305, "alpha_loss": 0.05241003744895496, "alpha_value": 0.036632502000765316, "duration": 3.8784050941467285, "step": 21375}
{"episode_reward": 216.65006432931528, "episode": 172.0, "batch_reward": 0.75302224111557, "critic_loss": 2.3172648420333863, "actor_loss": -57.79121011303317, "actor_target_entropy": -1.0, "actor_entropy": 0.615530417811486, "alpha_loss": 0.05194149971488984, "alpha_value": 0.03642778069006053, "duration": 3.8786611557006836, "step": 21500}
{"episode_reward": 148.07053867203487, "episode": 173.0, "batch_reward": 0.761084659576416, "critic_loss": 2.404645800590515, "actor_loss": -57.93399368770539, "actor_target_entropy": -1.0, "actor_entropy": 0.600797730778891, "alpha_loss": 0.051368786820343564, "alpha_value": 0.03622694318274418, "duration": 3.8772003650665283, "step": 21625}
{"episode_reward": 64.77140571835095, "episode": 174.0, "batch_reward": 0.7732500023841858, "critic_loss": 2.4395976552963257, "actor_loss": -58.059882256292525, "actor_target_entropy": -1.0, "actor_entropy": 0.6954090249153876, "alpha_loss": 0.05342233355247205, "alpha_value": 0.03602044961864811, "duration": 3.8753976821899414, "step": 21750}
{"episode_reward": 132.37867409208985, "episode": 175.0, "batch_reward": 0.7729582123756409, "critic_loss": 2.3966368064880372, "actor_loss": -58.19931805323041, "actor_target_entropy": -1.0, "actor_entropy": 0.7522463893133496, "alpha_loss": 0.05401052865717146, "alpha_value": 0.03580955702640697, "duration": 3.883441209793091, "step": 21875}
{"episode_reward": 76.44179608730288, "episode": 176.0, "batch_reward": 0.7762279906272889, "critic_loss": 2.384910464286804, "actor_loss": -58.33017133897351, "actor_target_entropy": -1.0, "actor_entropy": 0.7554490527799053, "alpha_loss": 0.05392965530195544, "alpha_value": 0.03559801194300658, "duration": 3.8748083114624023, "step": 22000}
{"episode_reward": 244.25702854225, "episode": 177.0, "batch_reward": 0.7736737489700317, "critic_loss": 2.4369835090637206, "actor_loss": -58.45723542712984, "actor_target_entropy": -1.0, "actor_entropy": 0.7089800475135682, "alpha_loss": 0.052316952851556596, "alpha_value": 0.03539051560393893, "duration": 3.8852384090423584, "step": 22125}
{"episode_reward": 104.68040092704953, "episode": 178.0, "batch_reward": 0.7784446272850036, "critic_loss": 2.420519669532776, "actor_loss": -58.598492407029674, "actor_target_entropy": -1.0, "actor_entropy": 0.6480945964013377, "alpha_loss": 0.051036969908783515, "alpha_value": 0.03518987211644493, "duration": 3.8641445636749268, "step": 22250}
{"episode_reward": 55.076426465126815, "episode": 179.0, "batch_reward": 0.7862002387046814, "critic_loss": 2.563634985923767, "actor_loss": -58.736665453229634, "actor_target_entropy": -1.0, "actor_entropy": 0.6610742920920962, "alpha_loss": 0.05077508842897794, "alpha_value": 0.03499148114082443, "duration": 3.8825907707214355, "step": 22375}
{"episode_reward": 78.59395761342914, "episode": 180.0, "batch_reward": 0.7634932043552398, "critic_loss": 2.4864486265182495, "actor_loss": -58.84158036016649, "actor_target_entropy": -1.0, "actor_entropy": 0.63675880816675, "alpha_loss": 0.0500894247163688, "alpha_value": 0.034794939909409114, "duration": 3.8742029666900635, "step": 22500}
{"episode_reward": 26.83219840771525, "episode": 181.0, "batch_reward": 0.785926007270813, "critic_loss": 2.5057612466812134, "actor_loss": -58.99250660245381, "actor_target_entropy": -1.0, "actor_entropy": 0.7040331874574933, "alpha_loss": 0.051456418893640006, "alpha_value": 0.03459786825396691, "duration": 3.8809189796447754, "step": 22625}
{"episode_reward": 75.93689464581844, "episode": 182.0, "batch_reward": 0.7674997019767761, "critic_loss": 2.3892769765853883, "actor_loss": -59.098436478645574, "actor_target_entropy": -1.0, "actor_entropy": 0.717240168202308, "alpha_loss": 0.05160395536691912, "alpha_value": 0.03439612100738873, "duration": 3.8697116374969482, "step": 22750}
{"episode_reward": 191.36552336924893, "episode": 183.0, "batch_reward": 0.7670205717086792, "critic_loss": 2.3795300140380857, "actor_loss": -59.22820063999721, "actor_target_entropy": -1.0, "actor_entropy": 0.6987582180235121, "alpha_loss": 0.051081282692769216, "alpha_value": 0.03419635418874463, "duration": 3.8817298412323, "step": 22875}
{"episode_reward": 42.611900864828186, "episode": 184.0, "batch_reward": 0.7707708415985107, "critic_loss": 2.367367702960968, "actor_loss": -59.35480037812264, "actor_target_entropy": -1.0, "actor_entropy": 0.617900421542506, "alpha_loss": 0.0488927352933153, "alpha_value": 0.03400166744046125, "duration": 3.875309944152832, "step": 23000}
{"episode_reward": 20.55092363051619, "episode": 185.0, "batch_reward": 0.7797141032218933, "critic_loss": 2.3747001543045045, "actor_loss": -59.49436993069119, "actor_target_entropy": -1.0, "actor_entropy": 0.5847538709640503, "alpha_loss": 0.047664086674413984, "alpha_value": 0.03381620809423564, "duration": 3.882124423980713, "step": 23125}
{"episode_reward": 86.71718179400929, "episode": 186.0, "batch_reward": 0.765597451210022, "critic_loss": 2.449864691734314, "actor_loss": -59.58652508643366, "actor_target_entropy": -1.0, "actor_entropy": 0.6889056582604686, "alpha_loss": 0.049859287577771375, "alpha_value": 0.03362613161335565, "duration": 3.876408100128174, "step": 23250}
{"episode_reward": 156.20695795943004, "episode": 187.0, "batch_reward": 0.769833487033844, "critic_loss": 2.4295684328079226, "actor_loss": -59.71326561579629, "actor_target_entropy": -1.0, "actor_entropy": 0.7388834896541777, "alpha_loss": 0.05016977700685698, "alpha_value": 0.03343200030451154, "duration": 3.878032684326172, "step": 23375}
{"episode_reward": 106.66493270700832, "episode": 188.0, "batch_reward": 0.7846765551567078, "critic_loss": 2.544470290184021, "actor_loss": -59.86144231980847, "actor_target_entropy": -1.0, "actor_entropy": 0.7912169771809732, "alpha_loss": 0.05095693895653371, "alpha_value": 0.033235760183742316, "duration": 3.872528076171875, "step": 23500}
{"episode_reward": 78.64630368363493, "episode": 189.0, "batch_reward": 0.774868766784668, "critic_loss": 2.380047408103943, "actor_loss": -59.9722167726547, "actor_target_entropy": -1.0, "actor_entropy": 0.7342846298974658, "alpha_loss": 0.049720065402133126, "alpha_value": 0.03304013302810099, "duration": 3.8790905475616455, "step": 23625}
{"episode_reward": 168.42785034371374, "episode": 190.0, "batch_reward": 0.7823617053031922, "critic_loss": 2.432109332084656, "actor_loss": -60.10219955444336, "actor_target_entropy": -1.0, "actor_entropy": 0.6877049207687378, "alpha_loss": 0.048512466311935454, "alpha_value": 0.03285089529846736, "duration": 3.8743984699249268, "step": 23750}
{"episode_reward": 259.99218840368513, "episode": 191.0, "batch_reward": 0.7794775485992431, "critic_loss": 2.458267623901367, "actor_loss": -60.220887562585254, "actor_target_entropy": -1.0, "actor_entropy": 0.7625424994362725, "alpha_loss": 0.04965798876115254, "alpha_value": 0.03266201380870948, "duration": 3.8879940509796143, "step": 23875}
{"episode_reward": 32.59742271269144, "episode": 192.0, "batch_reward": 0.7904306626319886, "critic_loss": 2.483792407989502, "actor_loss": -60.35059055205314, "actor_target_entropy": -1.0, "actor_entropy": 0.8243931224269252, "alpha_loss": 0.05042058289531739, "alpha_value": 0.03246909775309638, "duration": 3.87328839302063, "step": 24000}
{"episode_reward": 19.540540054561433, "episode": 193.0, "batch_reward": 0.7774671936035156, "critic_loss": 2.4122648057937623, "actor_loss": -60.46893437703451, "actor_target_entropy": -1.0, "actor_entropy": 0.8439575093133109, "alpha_loss": 0.05061160175809785, "alpha_value": 0.03227519770375092, "duration": 3.8832600116729736, "step": 24125}
{"episode_reward": 138.84519692074383, "episode": 194.0, "batch_reward": 0.7893013973236084, "critic_loss": 2.5814433841705324, "actor_loss": -60.59430657663653, "actor_target_entropy": -1.0, "actor_entropy": 0.757586790669349, "alpha_loss": 0.04844075621616456, "alpha_value": 0.03208525590040356, "duration": 3.867050886154175, "step": 24250}
{"episode_reward": 30.556111589490047, "episode": 195.0, "batch_reward": 0.7854909839630126, "critic_loss": 2.501667712211609, "actor_loss": -60.721402001759365, "actor_target_entropy": -1.0, "actor_entropy": 0.7564859409180898, "alpha_loss": 0.04809905488103155, "alpha_value": 0.03190156650082275, "duration": 3.8706462383270264, "step": 24375}
{"episode_reward": 68.74704135750204, "episode": 196.0, "batch_reward": 0.7724609999656677, "critic_loss": 2.4714692440032957, "actor_loss": -60.82869345141995, "actor_target_entropy": -1.0, "actor_entropy": 0.7562767805591706, "alpha_loss": 0.047965740003893455, "alpha_value": 0.03171813714799917, "duration": 3.87650728225708, "step": 24500}
{"episode_reward": 37.44273171046696, "episode": 197.0, "batch_reward": 0.764799328327179, "critic_loss": 2.399857048988342, "actor_loss": -60.92518494621156, "actor_target_entropy": -1.0, "actor_entropy": 0.6888385973279438, "alpha_loss": 0.04675547831824848, "alpha_value": 0.0315364939931118, "duration": 3.8803112506866455, "step": 24625}
{"episode_reward": 34.37380687599142, "episode": 198.0, "batch_reward": 0.7714013223648071, "critic_loss": 2.4071101789474487, "actor_loss": -61.04949059024934, "actor_target_entropy": -1.0, "actor_entropy": 0.6507656997249972, "alpha_loss": 0.045644501224160194, "alpha_value": 0.03136099241387567, "duration": 3.882101058959961, "step": 24750}
{"episode_reward": 18.755539253086347, "episode": 199.0, "batch_reward": 0.7646341443061828, "critic_loss": 2.4723715839385987, "actor_loss": -61.14411126999628, "actor_target_entropy": -1.0, "actor_entropy": 0.6399370091302055, "alpha_loss": 0.045334532088230524, "alpha_value": 0.03118740901398347, "duration": 3.877739429473877, "step": 24875}
{"episode_reward": 92.42725961163063, "episode": 200.0, "batch_reward": 0.7616301298141479, "critic_loss": 2.4109024200439455, "actor_loss": -61.24405134877851, "actor_target_entropy": -1.0, "actor_entropy": 0.6136818124401954, "alpha_loss": 0.04423750227978153, "alpha_value": 0.031016317363992678, "duration": 3.8785293102264404, "step": 25000}
{"episode_reward": 28.890023368781872, "episode": 201.0, "batch_reward": 0.760732250213623, "critic_loss": 2.3595851650238036, "actor_loss": -61.34969463045635, "actor_target_entropy": -1.0, "actor_entropy": 0.6294296828527299, "alpha_loss": 0.04450846114565456, "alpha_value": 0.030846489086960187, "duration": 3.8796732425689697, "step": 25125}
{"episode_reward": 82.9743701398452, "episode": 202.0, "batch_reward": 0.7612502770423889, "critic_loss": 2.427637433052063, "actor_loss": -61.45460553323069, "actor_target_entropy": -1.0, "actor_entropy": 0.6053426688717257, "alpha_loss": 0.04379186647072915, "alpha_value": 0.030677543653873894, "duration": 3.8777408599853516, "step": 25250}
{"episode_reward": 19.410162907434135, "episode": 203.0, "batch_reward": 0.7575750966072082, "critic_loss": 2.4295507221221926, "actor_loss": -61.55537238953605, "actor_target_entropy": -1.0, "actor_entropy": 0.6393396457036337, "alpha_loss": 0.04414981266572362, "alpha_value": 0.030508322551545147, "duration": 3.8822100162506104, "step": 25375}
{"episode_reward": 247.51348629227, "episode": 204.0, "batch_reward": 0.7653729953765869, "critic_loss": 2.3938643550872802, "actor_loss": -61.66289040350145, "actor_target_entropy": -1.0, "actor_entropy": 0.5785479737866309, "alpha_loss": 0.04256544328264652, "alpha_value": 0.030340372956837974, "duration": 3.8764736652374268, "step": 25500}
{"episode_reward": 36.71344685724246, "episode": 205.0, "batch_reward": 0.7576034750938415, "critic_loss": 2.363242027282715, "actor_loss": -61.75484884352911, "actor_target_entropy": -1.0, "actor_entropy": 0.5094987191851177, "alpha_loss": 0.04088991401450975, "alpha_value": 0.03018181058886978, "duration": 3.8872227668762207, "step": 25625}
{"episode_reward": 137.85177125775854, "episode": 206.0, "batch_reward": 0.7590535559654236, "critic_loss": 2.433200623512268, "actor_loss": -61.85498902105516, "actor_target_entropy": -1.0, "actor_entropy": 0.6413500578172745, "alpha_loss": 0.04353942031100873, "alpha_value": 0.030018235522113062, "duration": 3.873964786529541, "step": 25750}
{"episode_reward": 35.546882514786866, "episode": 207.0, "batch_reward": 0.7646411819458008, "critic_loss": 2.484127115249634, "actor_loss": -61.955234951443146, "actor_target_entropy": -1.0, "actor_entropy": 0.679665037563869, "alpha_loss": 0.044076135470753626, "alpha_value": 0.029848300069551092, "duration": 3.8820598125457764, "step": 25875}
{"episode_reward": 60.529133835397815, "episode": 208.0, "batch_reward": 0.7690327100753784, "critic_loss": 2.4555767440795897, "actor_loss": -62.06753232402186, "actor_target_entropy": -1.0, "actor_entropy": 0.6815184508600542, "alpha_loss": 0.04370583671956293, "alpha_value": 0.029678547547771116, "duration": 3.878926992416382, "step": 26000}
{"episode_reward": 12.352164008137404, "episode": 209.0, "batch_reward": 0.7488934631347657, "critic_loss": 2.4053093223571778, "actor_loss": -62.14219374883743, "actor_target_entropy": -1.0, "actor_entropy": 0.6657630242998638, "alpha_loss": 0.04307812653363697, "alpha_value": 0.02951088221548009, "duration": 3.8799870014190674, "step": 26125}
{"episode_reward": 25.796190697432497, "episode": 210.0, "batch_reward": 0.7571502122879028, "critic_loss": 2.428363775253296, "actor_loss": -62.24541381097609, "actor_target_entropy": -1.0, "actor_entropy": 0.7085233234590099, "alpha_loss": 0.043568059621799375, "alpha_value": 0.029343570392578167, "duration": 3.87511944770813, "step": 26250}
{"episode_reward": 103.57005197178572, "episode": 211.0, "batch_reward": 0.7504344229698181, "critic_loss": 2.3526729049682618, "actor_loss": -62.328591664632164, "actor_target_entropy": -1.0, "actor_entropy": 0.6764050759966411, "alpha_loss": 0.042980744488655576, "alpha_value": 0.029175655803761726, "duration": 3.870805263519287, "step": 26375}
{"episode_reward": 162.63937076515106, "episode": 212.0, "batch_reward": 0.7675889687538147, "critic_loss": 2.4116366653442385, "actor_loss": -62.445493205901116, "actor_target_entropy": -1.0, "actor_entropy": 0.6460367671905025, "alpha_loss": 0.04192103631794453, "alpha_value": 0.029012017825912298, "duration": 3.8754565715789795, "step": 26500}
{"episode_reward": 89.10274730978401, "episode": 213.0, "batch_reward": 0.7689334139823913, "critic_loss": 2.4268534307479857, "actor_loss": -62.53930942595951, "actor_target_entropy": -1.0, "actor_entropy": 0.6680490573247274, "alpha_loss": 0.04235921126036417, "alpha_value": 0.028849254149012446, "duration": 3.86797833442688, "step": 26625}
{"episode_reward": 100.59007474423638, "episode": 214.0, "batch_reward": 0.7600595498085022, "critic_loss": 2.3987454891204836, "actor_loss": -62.63719810978059, "actor_target_entropy": -1.0, "actor_entropy": 0.6476156519305322, "alpha_loss": 0.04148846882725916, "alpha_value": 0.02868728908938634, "duration": 3.8667056560516357, "step": 26750}
{"episode_reward": 45.15702783724791, "episode": 215.0, "batch_reward": 0.7566624307632446, "critic_loss": 2.4092386960983276, "actor_loss": -62.72377680218409, "actor_target_entropy": -1.0, "actor_entropy": 0.6345082710659693, "alpha_loss": 0.04119358536979509, "alpha_value": 0.028527096781181028, "duration": 3.869328737258911, "step": 26875}
{"episode_reward": 52.061757383360295, "episode": 216.0, "batch_reward": 0.7701083979606629, "critic_loss": 2.4976810312271116, "actor_loss": -62.82491185588221, "actor_target_entropy": -1.0, "actor_entropy": 0.7112890558858072, "alpha_loss": 0.04242100530574398, "alpha_value": 0.028366173822274163, "duration": 3.861772298812866, "step": 27000}
{"episode_reward": 68.27512100309788, "episode": 217.0, "batch_reward": 0.7443062114715576, "critic_loss": 2.3443801670074462, "actor_loss": -62.898767804342604, "actor_target_entropy": -1.0, "actor_entropy": 0.704049581573123, "alpha_loss": 0.04202078194135711, "alpha_value": 0.02820218919093035, "duration": 3.862401247024536, "step": 27125}
{"episode_reward": 17.267628164076942, "episode": 218.0, "batch_reward": 0.7631108717918396, "critic_loss": 2.4836325569152833, "actor_loss": -63.00277494615124, "actor_target_entropy": -1.0, "actor_entropy": 0.533235046171373, "alpha_loss": 0.038809155264208396, "alpha_value": 0.028045026441974423, "duration": 3.8595564365386963, "step": 27250}
{"episode_reward": 112.67898162108662, "episode": 219.0, "batch_reward": 0.7471005098819733, "critic_loss": 2.40881517124176, "actor_loss": -63.075441148546005, "actor_target_entropy": -1.0, "actor_entropy": 0.5098922839240422, "alpha_loss": 0.037722438514705685, "alpha_value": 0.027897953262476353, "duration": 3.8656699657440186, "step": 27375}
{"episode_reward": 29.841720028671364, "episode": 220.0, "batch_reward": 0.7472128469944, "critic_loss": 2.311634943962097, "actor_loss": -63.1601443136892, "actor_target_entropy": -1.0, "actor_entropy": 0.5663858113750335, "alpha_loss": 0.03854630581073223, "alpha_value": 0.02775053207638408, "duration": 3.8636341094970703, "step": 27500}
{"episode_reward": 76.75264238431141, "episode": 221.0, "batch_reward": 0.732182171344757, "critic_loss": 2.2505425596237183, "actor_loss": -63.22748069157676, "actor_target_entropy": -1.0, "actor_entropy": 0.6960142245368351, "alpha_loss": 0.04085687553835294, "alpha_value": 0.027595968942761805, "duration": 3.867521047592163, "step": 27625}
{"episode_reward": 30.050240550330873, "episode": 222.0, "batch_reward": 0.7447339658737182, "critic_loss": 2.3811567153930664, "actor_loss": -63.30501482563634, "actor_target_entropy": -1.0, "actor_entropy": 0.764494284506767, "alpha_loss": 0.041680236016550375, "alpha_value": 0.027434547310548438, "duration": 3.8600523471832275, "step": 27750}
{"episode_reward": 65.22903575040733, "episode": 223.0, "batch_reward": 0.7455394129753112, "critic_loss": 2.387459973335266, "actor_loss": -63.390577709864054, "actor_target_entropy": -1.0, "actor_entropy": 0.7523456774060688, "alpha_loss": 0.041229522180935695, "alpha_value": 0.027273443965138568, "duration": 3.8691530227661133, "step": 27875}
{"episode_reward": 38.43574769275376, "episode": 224.0, "batch_reward": 0.744126139163971, "critic_loss": 2.2890584192276, "actor_loss": -63.46424773431593, "actor_target_entropy": -1.0, "actor_entropy": 0.7464600724558677, "alpha_loss": 0.040838161904004314, "alpha_value": 0.027115091753669184, "duration": 3.866438150405884, "step": 28000}
{"episode_reward": 48.2820130557953, "episode": 225.0, "batch_reward": 0.7358072612285614, "critic_loss": 2.2497763328552245, "actor_loss": -63.53434686812143, "actor_target_entropy": -1.0, "actor_entropy": 0.7765648573163956, "alpha_loss": 0.041241436664547236, "alpha_value": 0.026955872403731887, "duration": 3.870575189590454, "step": 28125}
{"episode_reward": 123.33947776889596, "episode": 226.0, "batch_reward": 0.738403042793274, "critic_loss": 2.374198727607727, "actor_loss": -63.60877935348019, "actor_target_entropy": -1.0, "actor_entropy": 0.7566532819501816, "alpha_loss": 0.040531879651450345, "alpha_value": 0.026798127022782316, "duration": 3.8665223121643066, "step": 28250}
{"episode_reward": 130.44322591158735, "episode": 227.0, "batch_reward": 0.7488915047645569, "critic_loss": 2.4024594736099245, "actor_loss": -63.69535936628069, "actor_target_entropy": -1.0, "actor_entropy": 0.7277279827329848, "alpha_loss": 0.040145570500975565, "alpha_value": 0.02664276690647384, "duration": 3.866281270980835, "step": 28375}
{"episode_reward": 176.08221134920186, "episode": 228.0, "batch_reward": 0.7383111519813538, "critic_loss": 2.3351841373443603, "actor_loss": -63.766853701683786, "actor_target_entropy": -1.0, "actor_entropy": 0.6346845357648788, "alpha_loss": 0.03847736679017544, "alpha_value": 0.026491154294941567, "duration": 3.864071846008301, "step": 28500}
{"episode_reward": 108.37296846117052, "episode": 229.0, "batch_reward": 0.7511158347129822, "critic_loss": 2.4418101835250856, "actor_loss": -63.84647514706566, "actor_target_entropy": -1.0, "actor_entropy": 0.5984313923215109, "alpha_loss": 0.037501576992254405, "alpha_value": 0.026345384323788395, "duration": 3.872638702392578, "step": 28625}
{"episode_reward": 68.02952346536816, "episode": 230.0, "batch_reward": 0.758659869670868, "critic_loss": 2.4907935523986815, "actor_loss": -63.93622170725176, "actor_target_entropy": -1.0, "actor_entropy": 0.5946347367378974, "alpha_loss": 0.03713812372617183, "alpha_value": 0.026201407693008674, "duration": 3.8655529022216797, "step": 28750}
{"episode_reward": 154.74347449763852, "episode": 231.0, "batch_reward": 0.7476281323432923, "critic_loss": 2.3512455224990845, "actor_loss": -64.0037491208031, "actor_target_entropy": -1.0, "actor_entropy": 0.608030048627702, "alpha_loss": 0.03724669747882419, "alpha_value": 0.02605809510245013, "duration": 3.8733363151550293, "step": 28875}
{"episode_reward": 55.0915104932579, "episode": 232.0, "batch_reward": 0.7488314023017884, "critic_loss": 2.3571836462020874, "actor_loss": -64.08159846644247, "actor_target_entropy": -1.0, "actor_entropy": 0.6051800212552471, "alpha_loss": 0.037009344586441596, "alpha_value": 0.02591408881912746, "duration": 3.857898712158203, "step": 29000}
{"episode_reward": 111.74525018830535, "episode": 233.0, "batch_reward": 0.7514949460029602, "critic_loss": 2.4179918451309206, "actor_loss": -64.16208473084465, "actor_target_entropy": -1.0, "actor_entropy": 0.6103227270974053, "alpha_loss": 0.03669422947698169, "alpha_value": 0.025771642238437215, "duration": 3.9026525020599365, "step": 29125}
{"episode_reward": 13.987844023764387, "episode": 234.0, "batch_reward": 0.7476828646659851, "critic_loss": 2.371312252998352, "actor_loss": -64.23236773090977, "actor_target_entropy": -1.0, "actor_entropy": 0.562060252312691, "alpha_loss": 0.0358597501631706, "alpha_value": 0.025630361740245428, "duration": 3.8607001304626465, "step": 29250}
{"episode_reward": 6.220813649088365, "episode": 235.0, "batch_reward": 0.743450304031372, "critic_loss": 2.28050443649292, "actor_loss": -64.30209296090263, "actor_target_entropy": -1.0, "actor_entropy": 0.5017028252283732, "alpha_loss": 0.034327458294611125, "alpha_value": 0.025494369056854992, "duration": 3.8675668239593506, "step": 29375}
{"episode_reward": 78.79946715647642, "episode": 236.0, "batch_reward": 0.7451031346321106, "critic_loss": 2.409125894546509, "actor_loss": -64.37895288775044, "actor_target_entropy": -1.0, "actor_entropy": 0.5236941499094809, "alpha_loss": 0.03480324034969653, "alpha_value": 0.02535984869127513, "duration": 3.877286911010742, "step": 29500}
{"episode_reward": 13.022435173542606, "episode": 237.0, "batch_reward": 0.7454943218231201, "critic_loss": 2.3651158723831176, "actor_loss": -64.45467970106337, "actor_target_entropy": -1.0, "actor_entropy": 0.5233795245488485, "alpha_loss": 0.03433335826747001, "alpha_value": 0.025224320408732192, "duration": 3.8663268089294434, "step": 29625}
{"episode_reward": 84.56965286007427, "episode": 238.0, "batch_reward": 0.7522232193946838, "critic_loss": 2.4070311794281007, "actor_loss": -64.53744789861864, "actor_target_entropy": -1.0, "actor_entropy": 0.4913790956620247, "alpha_loss": 0.033765284675023245, "alpha_value": 0.025090733177900573, "duration": 3.8688290119171143, "step": 29750}
{"episode_reward": 50.81492539646641, "episode": 239.0, "batch_reward": 0.7422388420104981, "critic_loss": 2.3413017797470093, "actor_loss": -64.59103623647539, "actor_target_entropy": -1.0, "actor_entropy": 0.46103112848978195, "alpha_loss": 0.03293506679908624, "alpha_value": 0.024959346971827754, "duration": 3.8673505783081055, "step": 29875}
{"episode_reward": 99.60197373406264, "episode": 240.0, "batch_reward": 0.7351705679893493, "critic_loss": 2.227585331916809, "actor_loss": -64.65662593226278, "actor_target_entropy": -1.0, "actor_entropy": 0.5150004548411216, "alpha_loss": 0.033636616242508736, "alpha_value": 0.024828341524632286, "duration": 3.86338210105896, "step": 30000}
{"episode_reward": 31.138397661763292, "episode": 241.0, "batch_reward": 0.7315568413734436, "critic_loss": 2.261488509178162, "actor_loss": -64.71027350047278, "actor_target_entropy": -1.0, "actor_entropy": 0.5234031998921954, "alpha_loss": 0.03360915385068409, "alpha_value": 0.024694234525882364, "duration": 7.8323845863342285, "step": 30125}
{"episode_reward": 65.47955537992499, "episode": 242.0, "batch_reward": 0.7438859951496124, "critic_loss": 2.3600821352005004, "actor_loss": -64.79559129284274, "actor_target_entropy": -1.0, "actor_entropy": 0.5137488957374327, "alpha_loss": 0.03322074159739479, "alpha_value": 0.024562063871399253, "duration": 3.864654302597046, "step": 30250}
{"episode_reward": 6.784430634575422, "episode": 243.0, "batch_reward": 0.7400716800689697, "critic_loss": 2.282499090194702, "actor_loss": -64.85635799831815, "actor_target_entropy": -1.0, "actor_entropy": 0.5530059470070733, "alpha_loss": 0.03414240148332384, "alpha_value": 0.024427431902378748, "duration": 3.859994888305664, "step": 30375}
{"episode_reward": 26.79441031565295, "episode": 244.0, "batch_reward": 0.7293805246353149, "critic_loss": 2.368857531547546, "actor_loss": -64.89862565071353, "actor_target_entropy": -1.0, "actor_entropy": 0.5448097298222203, "alpha_loss": 0.03363320321565674, "alpha_value": 0.02429244518566148, "duration": 3.8633100986480713, "step": 30500}
{"episode_reward": 48.04726601560415, "episode": 245.0, "batch_reward": 0.7387160193920136, "critic_loss": 2.3744840583801268, "actor_loss": -64.97114659869482, "actor_target_entropy": -1.0, "actor_entropy": 0.6010971845142425, "alpha_loss": 0.03419088099210981, "alpha_value": 0.024157206693249136, "duration": 3.8652594089508057, "step": 30625}
{"episode_reward": 97.59248936738081, "episode": 246.0, "batch_reward": 0.7325387444496155, "critic_loss": 2.2386549882888795, "actor_loss": -65.02595569241431, "actor_target_entropy": -1.0, "actor_entropy": 0.6733958990343155, "alpha_loss": 0.035300781289415974, "alpha_value": 0.02401819145655215, "duration": 3.8568975925445557, "step": 30750}
{"episode_reward": 104.08912317672431, "episode": 247.0, "batch_reward": 0.7153238182067871, "critic_loss": 2.185030764102936, "actor_loss": -65.0588880266462, "actor_target_entropy": -1.0, "actor_entropy": 0.6185857398169381, "alpha_loss": 0.034354123065159434, "alpha_value": 0.023878019984003813, "duration": 3.8613760471343994, "step": 30875}
{"episode_reward": 9.641152860189408, "episode": 248.0, "batch_reward": 0.7252787928581238, "critic_loss": 2.3128547801971435, "actor_loss": -65.12291360670521, "actor_target_entropy": -1.0, "actor_entropy": 0.6064651127784483, "alpha_loss": 0.03367107169282052, "alpha_value": 0.023744540038244208, "duration": 3.8625693321228027, "step": 31000}
{"episode_reward": 36.14181800916761, "episode": 249.0, "batch_reward": 0.7170444803237915, "critic_loss": 2.254034478187561, "actor_loss": -65.1635496351454, "actor_target_entropy": -1.0, "actor_entropy": 0.6885148627417428, "alpha_loss": 0.034684705237547554, "alpha_value": 0.023607765836671953, "duration": 3.866504192352295, "step": 31125}
{"episode_reward": 173.99020289633154, "episode": 250.0, "batch_reward": 0.7177244358062744, "critic_loss": 2.2532469997406004, "actor_loss": -65.20943869313886, "actor_target_entropy": -1.0, "actor_entropy": 0.7651301545481528, "alpha_loss": 0.03568694632380239, "alpha_value": 0.023468515050975684, "duration": 3.856928586959839, "step": 31250}
{"episode_reward": 115.20185991257155, "episode": 251.0, "batch_reward": 0.7253370604515076, "critic_loss": 2.2122818241119386, "actor_loss": -65.2782471671937, "actor_target_entropy": -1.0, "actor_entropy": 0.8088281589841085, "alpha_loss": 0.0360417945517434, "alpha_value": 0.02332590044191486, "duration": 3.871544599533081, "step": 31375}
{"episode_reward": 53.04462771511755, "episode": 252.0, "batch_reward": 0.7220346598625184, "critic_loss": 2.1995709829330443, "actor_loss": -65.32130161408455, "actor_target_entropy": -1.0, "actor_entropy": 0.8253814981829736, "alpha_loss": 0.036050774938156525, "alpha_value": 0.023184121930697722, "duration": 3.8661656379699707, "step": 31500}
{"episode_reward": 136.15624126083287, "episode": 253.0, "batch_reward": 0.7230246591567994, "critic_loss": 2.2618423233032225, "actor_loss": -65.3731421818809, "actor_target_entropy": -1.0, "actor_entropy": 0.8818688790003458, "alpha_loss": 0.03646120990789126, "alpha_value": 0.023041717020028357, "duration": 3.871622085571289, "step": 31625}
{"episode_reward": 50.34097975004516, "episode": 254.0, "batch_reward": 0.737728178024292, "critic_loss": 2.306574613571167, "actor_loss": -65.44451830464024, "actor_target_entropy": -1.0, "actor_entropy": 0.8775712174753989, "alpha_loss": 0.03625050289255957, "alpha_value": 0.022899887866838047, "duration": 3.8672525882720947, "step": 31750}
{"episode_reward": 30.009038859650346, "episode": 255.0, "batch_reward": 0.7342135953903198, "critic_loss": 2.225634943008423, "actor_loss": -65.49625711592417, "actor_target_entropy": -1.0, "actor_entropy": 0.8080627066748483, "alpha_loss": 0.03501368781167363, "alpha_value": 0.022761020886674338, "duration": 3.8638601303100586, "step": 31875}
{"episode_reward": 72.48449251300386, "episode": 256.0, "batch_reward": 0.7201809701919556, "critic_loss": 2.2919008531570433, "actor_loss": -65.54147055841261, "actor_target_entropy": -1.0, "actor_entropy": 0.7116360241366971, "alpha_loss": 0.03365632320844358, "alpha_value": 0.02262800958242036, "duration": 3.870643377304077, "step": 32000}
{"episode_reward": 35.81344178148241, "episode": 257.0, "batch_reward": 0.7273879950046539, "critic_loss": 2.3604395761489867, "actor_loss": -65.58180466909258, "actor_target_entropy": -1.0, "actor_entropy": 0.7333864200682867, "alpha_loss": 0.033696482460650184, "alpha_value": 0.022498594143555293, "duration": 3.8668131828308105, "step": 32125}
{"episode_reward": 220.28331548478857, "episode": 258.0, "batch_reward": 0.7295292453765869, "critic_loss": 2.2757142963409422, "actor_loss": -65.6411015910487, "actor_target_entropy": -1.0, "actor_entropy": 0.748794098054209, "alpha_loss": 0.033777237118732546, "alpha_value": 0.02236812786611057, "duration": 3.866966962814331, "step": 32250}
{"episode_reward": 78.4453985963935, "episode": 259.0, "batch_reward": 0.7246852798461914, "critic_loss": 2.214685933113098, "actor_loss": -65.68423861549014, "actor_target_entropy": -1.0, "actor_entropy": 0.702289795118665, "alpha_loss": 0.03330445304394714, "alpha_value": 0.02223891141472725, "duration": 3.8701345920562744, "step": 32375}
{"episode_reward": 49.40501592148803, "episode": 260.0, "batch_reward": 0.7194107995033264, "critic_loss": 2.250776571273804, "actor_loss": -65.7284678797568, "actor_target_entropy": -1.0, "actor_entropy": 0.6472389505755517, "alpha_loss": 0.03200901570099016, "alpha_value": 0.022113084820154814, "duration": 3.8607258796691895, "step": 32500}
{"episode_reward": 103.97744856638838, "episode": 261.0, "batch_reward": 0.72715656042099, "critic_loss": 2.342243355751038, "actor_loss": -65.78324781145368, "actor_target_entropy": -1.0, "actor_entropy": 0.7691072604012867, "alpha_loss": 0.0334197815566782, "alpha_value": 0.021987991144303495, "duration": 3.8701515197753906, "step": 32625}
{"episode_reward": 77.2160537802176, "episode": 262.0, "batch_reward": 0.7229955534934998, "critic_loss": 2.211153371810913, "actor_loss": -65.8324842145366, "actor_target_entropy": -1.0, "actor_entropy": 0.8944181665297477, "alpha_loss": 0.03466854761204412, "alpha_value": 0.021856601523194838, "duration": 3.8626809120178223, "step": 32750}
{"episode_reward": 55.85275718995427, "episode": 263.0, "batch_reward": 0.7218504629135132, "critic_loss": 2.2803738899230956, "actor_loss": -65.87613920181516, "actor_target_entropy": -1.0, "actor_entropy": 0.9311565539193531, "alpha_loss": 0.03479447949027258, "alpha_value": 0.02172360670076804, "duration": 3.8677830696105957, "step": 32875}
{"episode_reward": 229.04402079723351, "episode": 264.0, "batch_reward": 0.7236995420455933, "critic_loss": 2.2492796411514284, "actor_loss": -65.93072128295898, "actor_target_entropy": -1.0, "actor_entropy": 0.8859476620151151, "alpha_loss": 0.03423547852904566, "alpha_value": 0.02159170217712223, "duration": 3.864124059677124, "step": 33000}
{"episode_reward": 22.582721478060826, "episode": 265.0, "batch_reward": 0.7288315305709839, "critic_loss": 2.2220779418945313, "actor_loss": -65.97701941596137, "actor_target_entropy": -1.0, "actor_entropy": 0.7190326376566811, "alpha_loss": 0.032152958273414585, "alpha_value": 0.021465540908178534, "duration": 3.869109869003296, "step": 33125}
{"episode_reward": 155.26478351277086, "episode": 266.0, "batch_reward": 0.7235923986434937, "critic_loss": 2.3285661153793336, "actor_loss": -66.01902660246819, "actor_target_entropy": -1.0, "actor_entropy": 0.6581358486606229, "alpha_loss": 0.031100276587230545, "alpha_value": 0.02134562930007153, "duration": 3.8685996532440186, "step": 33250}
{"episode_reward": 56.492517210331336, "episode": 267.0, "batch_reward": 0.7175646810531616, "critic_loss": 2.220540678024292, "actor_loss": -66.0658442179362, "actor_target_entropy": -1.0, "actor_entropy": 0.6069532746360415, "alpha_loss": 0.03022049367427826, "alpha_value": 0.021229524010449398, "duration": 3.8670802116394043, "step": 33375}
{"episode_reward": 66.56061319346456, "episode": 268.0, "batch_reward": 0.7368082613945007, "critic_loss": 2.363647602558136, "actor_loss": -66.1200324027769, "actor_target_entropy": -1.0, "actor_entropy": 0.7172637024233418, "alpha_loss": 0.031503742680914944, "alpha_value": 0.021112664052107363, "duration": 3.8550689220428467, "step": 33500}
{"episode_reward": 48.524523470445715, "episode": 269.0, "batch_reward": 0.7219373655319213, "critic_loss": 2.2965021715164187, "actor_loss": -66.16401805574932, "actor_target_entropy": -1.0, "actor_entropy": 0.6995137097343566, "alpha_loss": 0.031038601394920123, "alpha_value": 0.020992892381147373, "duration": 3.8711774349212646, "step": 33625}
{"episode_reward": 61.992336163926524, "episode": 270.0, "batch_reward": 0.7200548622608185, "critic_loss": 2.25964950466156, "actor_loss": -66.19981298139018, "actor_target_entropy": -1.0, "actor_entropy": 0.7020766696622295, "alpha_loss": 0.031079728366626848, "alpha_value": 0.02087477977526402, "duration": 3.865199327468872, "step": 33750}
{"episode_reward": 123.2702781226387, "episode": 271.0, "batch_reward": 0.7343846747875213, "critic_loss": 2.4139826488494873, "actor_loss": -66.2594235132611, "actor_target_entropy": -1.0, "actor_entropy": 0.6899237727362012, "alpha_loss": 0.030743934894128452, "alpha_value": 0.020756952346943396, "duration": 3.8674380779266357, "step": 33875}
{"episode_reward": 10.628497987707728, "episode": 272.0, "batch_reward": 0.7288312182426453, "critic_loss": 2.2992715339660643, "actor_loss": -66.30685006418535, "actor_target_entropy": -1.0, "actor_entropy": 0.7286895359716108, "alpha_loss": 0.031123274636845433, "alpha_value": 0.02064002707874969, "duration": 3.8689255714416504, "step": 34000}
{"episode_reward": 66.09599603953738, "episode": 273.0, "batch_reward": 0.7150453758239746, "critic_loss": 2.2381315031051634, "actor_loss": -66.3297876025003, "actor_target_entropy": -1.0, "actor_entropy": 0.8703074095741151, "alpha_loss": 0.03233305542241959, "alpha_value": 0.020519210391449303, "duration": 3.8678481578826904, "step": 34125}
{"episode_reward": 46.91218901131645, "episode": 274.0, "batch_reward": 0.7202295141220093, "critic_loss": 2.2387069616317747, "actor_loss": -66.38523138723066, "actor_target_entropy": -1.0, "actor_entropy": 0.9180000251339328, "alpha_loss": 0.0326196733381479, "alpha_value": 0.020395902153827968, "duration": 3.8540444374084473, "step": 34250}
{"episode_reward": 156.63577978620452, "episode": 275.0, "batch_reward": 0.7308334393501281, "critic_loss": 2.320097674369812, "actor_loss": -66.436280265687, "actor_target_entropy": -1.0, "actor_entropy": 0.8957825482837738, "alpha_loss": 0.03218383602206669, "alpha_value": 0.020273158205657227, "duration": 3.8596014976501465, "step": 34375}
{"episode_reward": 46.397551163255244, "episode": 276.0, "batch_reward": 0.7352997035980224, "critic_loss": 2.308982334136963, "actor_loss": -66.49181919713175, "actor_target_entropy": -1.0, "actor_entropy": 0.7884174200796312, "alpha_loss": 0.030914205336763013, "alpha_value": 0.02015457429970253, "duration": 3.859218120574951, "step": 34500}
{"episode_reward": 183.72128705190443, "episode": 277.0, "batch_reward": 0.7243929338455201, "critic_loss": 2.3072018089294435, "actor_loss": -66.53062693277995, "actor_target_entropy": -1.0, "actor_entropy": 0.8149793129118662, "alpha_loss": 0.03092135743252815, "alpha_value": 0.020038497487009217, "duration": 3.875072956085205, "step": 34625}
{"episode_reward": 107.55939407602392, "episode": 278.0, "batch_reward": 0.7247040393352508, "critic_loss": 2.2987793779373167, "actor_loss": -66.56662368774414, "actor_target_entropy": -1.0, "actor_entropy": 0.756194487694771, "alpha_loss": 0.030302085853632418, "alpha_value": 0.019922973106716424, "duration": 3.8612730503082275, "step": 34750}
{"episode_reward": 109.25419626621161, "episode": 279.0, "batch_reward": 0.7382171688079834, "critic_loss": 2.3847551050186158, "actor_loss": -66.62612818157862, "actor_target_entropy": -1.0, "actor_entropy": 0.6479959960967775, "alpha_loss": 0.028849003008670278, "alpha_value": 0.019812140564825925, "duration": 3.8690719604492188, "step": 34875}
{"episode_reward": 165.1978956347821, "episode": 280.0, "batch_reward": 0.7179495692253113, "critic_loss": 2.2487187366485597, "actor_loss": -66.65895462036133, "actor_target_entropy": -1.0, "actor_entropy": 0.6278011298948719, "alpha_loss": 0.028249860110302127, "alpha_value": 0.01970498924696194, "duration": 3.8663742542266846, "step": 35000}
{"episode_reward": 28.64637792993317, "episode": 281.0, "batch_reward": 0.719303409576416, "critic_loss": 2.269847285270691, "actor_loss": -66.69367218017578, "actor_target_entropy": -1.0, "actor_entropy": 0.6348408006486439, "alpha_loss": 0.02830361554192172, "alpha_value": 0.01959856116537327, "duration": 3.8670287132263184, "step": 35125}
{"episode_reward": 54.474184089603256, "episode": 282.0, "batch_reward": 0.731082365989685, "critic_loss": 2.30820613861084, "actor_loss": -66.74512223274478, "actor_target_entropy": -1.0, "actor_entropy": 0.5510719860753706, "alpha_loss": 0.02706254000264791, "alpha_value": 0.01949306807101536, "duration": 3.8654770851135254, "step": 35250}
{"episode_reward": 79.65385220148691, "episode": 283.0, "batch_reward": 0.7259201669692993, "critic_loss": 2.3005814247131346, "actor_loss": -66.79073103647383, "actor_target_entropy": -1.0, "actor_entropy": 0.4872050682703654, "alpha_loss": 0.02600880011561371, "alpha_value": 0.019393243040715016, "duration": 3.857866048812866, "step": 35375}
{"episode_reward": 50.249622029174624, "episode": 284.0, "batch_reward": 0.7198568801879883, "critic_loss": 2.2215424184799195, "actor_loss": -66.82461510935137, "actor_target_entropy": -1.0, "actor_entropy": 0.5114147163206532, "alpha_loss": 0.026290423146659327, "alpha_value": 0.019293334236614702, "duration": 3.853729009628296, "step": 35500}
{"episode_reward": 123.32916160672457, "episode": 285.0, "batch_reward": 0.7307462205886841, "critic_loss": 2.3269415578842163, "actor_loss": -66.87782541910808, "actor_target_entropy": -1.0, "actor_entropy": 0.5309058617031763, "alpha_loss": 0.026340333064870228, "alpha_value": 0.019192718915101662, "duration": 3.8646559715270996, "step": 35625}
{"episode_reward": 60.64786715866416, "episode": 286.0, "batch_reward": 0.7062188069820404, "critic_loss": 2.1514690675735473, "actor_loss": -66.89393874137632, "actor_target_entropy": -1.0, "actor_entropy": 0.4987671952093801, "alpha_loss": 0.025745570118869503, "alpha_value": 0.01909282296103695, "duration": 3.8623924255371094, "step": 35750}
{"episode_reward": 79.7711277062925, "episode": 287.0, "batch_reward": 0.725175708770752, "critic_loss": 2.3234384698867796, "actor_loss": -66.93948049393912, "actor_target_entropy": -1.0, "actor_entropy": 0.4989067732341706, "alpha_loss": 0.02563866940400903, "alpha_value": 0.018993602829981554, "duration": 3.870500326156616, "step": 35875}
{"episode_reward": 262.2497043197777, "episode": 288.0, "batch_reward": 0.7372909030914306, "critic_loss": 2.4076628198623657, "actor_loss": -67.00591413436398, "actor_target_entropy": -1.0, "actor_entropy": 0.47463705078248053, "alpha_loss": 0.025259398074159698, "alpha_value": 0.01889498514362696, "duration": 3.860633373260498, "step": 36000}
{"episode_reward": 105.09769689320473, "episode": 289.0, "batch_reward": 0.7373906745910644, "critic_loss": 2.43636722946167, "actor_loss": -67.0455580211821, "actor_target_entropy": -1.0, "actor_entropy": 0.49537828422728036, "alpha_loss": 0.0256994143719711, "alpha_value": 0.018795536594672244, "duration": 3.8699285984039307, "step": 36125}
{"episode_reward": 43.29158750367257, "episode": 290.0, "batch_reward": 0.7223613286018371, "critic_loss": 2.404119878768921, "actor_loss": -67.07087190689579, "actor_target_entropy": -1.0, "actor_entropy": 0.47061794419442454, "alpha_loss": 0.025027317385519703, "alpha_value": 0.01869657739938045, "duration": 3.8527493476867676, "step": 36250}
{"episode_reward": 37.92421917203277, "episode": 291.0, "batch_reward": 0.726113576412201, "critic_loss": 2.3470385389328, "actor_loss": -67.11063808865018, "actor_target_entropy": -1.0, "actor_entropy": 0.44846048998454263, "alpha_loss": 0.02428870940847056, "alpha_value": 0.01860017154078902, "duration": 3.86814022064209, "step": 36375}
{"episode_reward": 115.28390763066014, "episode": 292.0, "batch_reward": 0.7165130980014801, "critic_loss": 2.27594153213501, "actor_loss": -67.14375428230532, "actor_target_entropy": -1.0, "actor_entropy": 0.46096837520599365, "alpha_loss": 0.02442983856364604, "alpha_value": 0.018503941313814314, "duration": 3.867525577545166, "step": 36500}
{"episode_reward": 50.31049586083901, "episode": 293.0, "batch_reward": 0.7214999077320099, "critic_loss": 2.2513416709899903, "actor_loss": -67.18402475024027, "actor_target_entropy": -1.0, "actor_entropy": 0.4264381518439641, "alpha_loss": 0.023842133759033112, "alpha_value": 0.018407790322130396, "duration": 3.868528127670288, "step": 36625}
{"episode_reward": 38.52487397321604, "episode": 294.0, "batch_reward": 0.7257031240463256, "critic_loss": 2.2682273559570314, "actor_loss": -67.23089144306797, "actor_target_entropy": -1.0, "actor_entropy": 0.32250653928326023, "alpha_loss": 0.022379589056776415, "alpha_value": 0.018315973800559344, "duration": 3.8641159534454346, "step": 36750}
{"episode_reward": 64.44086019388503, "episode": 295.0, "batch_reward": 0.7246125612258911, "critic_loss": 2.3207578058242797, "actor_loss": -67.27678062802269, "actor_target_entropy": -1.0, "actor_entropy": 0.2557671278242081, "alpha_loss": 0.020987274627836925, "alpha_value": 0.018229182781580717, "duration": 3.8606395721435547, "step": 36875}
{"episode_reward": 59.205237629482035, "episode": 296.0, "batch_reward": 0.7203160259723663, "critic_loss": 2.345079122543335, "actor_loss": -67.30478225215789, "actor_target_entropy": -1.0, "actor_entropy": 0.22051117881651847, "alpha_loss": 0.020452975535825375, "alpha_value": 0.018145479757581538, "duration": 3.862037420272827, "step": 37000}
{"episode_reward": 67.56481440420119, "episode": 297.0, "batch_reward": 0.6976797828674316, "critic_loss": 2.1862248344421387, "actor_loss": -67.3082746475462, "actor_target_entropy": -1.0, "actor_entropy": 0.29057622523534865, "alpha_loss": 0.02154793066992646, "alpha_value": 0.01806012319267666, "duration": 3.8700547218322754, "step": 37125}
{"episode_reward": 18.71453436149196, "episode": 298.0, "batch_reward": 0.7102727265357971, "critic_loss": 2.224487552642822, "actor_loss": -67.34924611737651, "actor_target_entropy": -1.0, "actor_entropy": 0.45882373086867795, "alpha_loss": 0.0234560813574541, "alpha_value": 0.017968536151383753, "duration": 3.8594720363616943, "step": 37250}
{"episode_reward": 109.12042888197118, "episode": 299.0, "batch_reward": 0.7261359689235687, "critic_loss": 2.2195118017196656, "actor_loss": -67.39686523921905, "actor_target_entropy": -1.0, "actor_entropy": 0.5907121404768929, "alpha_loss": 0.025057090328089775, "alpha_value": 0.017867966538777546, "duration": 3.867548942565918, "step": 37375}
{"episode_reward": 105.06426895981811, "episode": 300.0, "batch_reward": 0.7211553719043732, "critic_loss": 2.315561364173889, "actor_loss": -67.42016872282952, "actor_target_entropy": -1.0, "actor_entropy": 0.6253149009520008, "alpha_loss": 0.025527601911415978, "alpha_value": 0.017763300425761033, "duration": 3.861997604370117, "step": 37500}
{"episode_reward": 96.27219820720424, "episode": 301.0, "batch_reward": 0.7324660863876343, "critic_loss": 2.3023942251205445, "actor_loss": -67.4769301641555, "actor_target_entropy": -1.0, "actor_entropy": 0.5601996940279764, "alpha_loss": 0.024565641901322773, "alpha_value": 0.01765985930325088, "duration": 3.87450909614563, "step": 37625}
{"episode_reward": 53.43599645004204, "episode": 302.0, "batch_reward": 0.7194270298480988, "critic_loss": 2.3496008653640748, "actor_loss": -67.50213056995022, "actor_target_entropy": -1.0, "actor_entropy": 0.4552965356457618, "alpha_loss": 0.022910638201621272, "alpha_value": 0.017562631449105342, "duration": 3.8579015731811523, "step": 37750}
{"episode_reward": 115.34726868009652, "episode": 303.0, "batch_reward": 0.7224358177185058, "critic_loss": 2.226193892478943, "actor_loss": -67.54407210577102, "actor_target_entropy": -1.0, "actor_entropy": 0.5023897280768742, "alpha_loss": 0.023620608159237437, "alpha_value": 0.017467605295006232, "duration": 3.8623387813568115, "step": 37875}
{"episode_reward": 44.057797537683086, "episode": 304.0, "batch_reward": 0.7233327825069428, "critic_loss": 2.3237902450561525, "actor_loss": -67.5728267546623, "actor_target_entropy": -1.0, "actor_entropy": 0.5056378495308661, "alpha_loss": 0.02369244153340978, "alpha_value": 0.017369576807476108, "duration": 3.860377550125122, "step": 38000}
{"episode_reward": 112.71306161282901, "episode": 305.0, "batch_reward": 0.7071599109172821, "critic_loss": 2.211274745941162, "actor_loss": -67.5903067210364, "actor_target_entropy": -1.0, "actor_entropy": 0.5067070873956832, "alpha_loss": 0.023451393174510154, "alpha_value": 0.017272539705819788, "duration": 3.868464469909668, "step": 38125}
{"episode_reward": 103.0803438541534, "episode": 306.0, "batch_reward": 0.7230806741714477, "critic_loss": 2.2235357761383057, "actor_loss": -67.63704213788432, "actor_target_entropy": -1.0, "actor_entropy": 0.5152107400278891, "alpha_loss": 0.023457705133384275, "alpha_value": 0.01717528093178212, "duration": 3.8602311611175537, "step": 38250}
{"episode_reward": 39.21374626115348, "episode": 307.0, "batch_reward": 0.7120776653289795, "critic_loss": 2.253396472454071, "actor_loss": -67.65740288628473, "actor_target_entropy": -1.0, "actor_entropy": 0.44480661551157635, "alpha_loss": 0.02244040124591381, "alpha_value": 0.017080844752071327, "duration": 3.863600492477417, "step": 38375}
{"episode_reward": 27.77437130158216, "episode": 308.0, "batch_reward": 0.7199016103744507, "critic_loss": 2.263036355018616, "actor_loss": -67.68749187838647, "actor_target_entropy": -1.0, "actor_entropy": 0.45084289196998845, "alpha_loss": 0.02233077765953156, "alpha_value": 0.016988443603582922, "duration": 3.8707733154296875, "step": 38500}
{"episode_reward": 25.631860284318893, "episode": 309.0, "batch_reward": 0.711063040971756, "critic_loss": 2.265282199859619, "actor_loss": -67.71322316972037, "actor_target_entropy": -1.0, "actor_entropy": 0.3993449608484904, "alpha_loss": 0.021705994500763832, "alpha_value": 0.016896972613942383, "duration": 3.867323398590088, "step": 38625}
{"episode_reward": 14.537244704697606, "episode": 310.0, "batch_reward": 0.7088683476448059, "critic_loss": 2.2081688899993894, "actor_loss": -67.73689737627583, "actor_target_entropy": -1.0, "actor_entropy": 0.4676085172160979, "alpha_loss": 0.022337997392300638, "alpha_value": 0.016806065047900547, "duration": 3.8655431270599365, "step": 38750}
{"episode_reward": 68.65310882752435, "episode": 311.0, "batch_reward": 0.7056572036743164, "critic_loss": 2.213589412689209, "actor_loss": -67.76073467920698, "actor_target_entropy": -1.0, "actor_entropy": 0.5380181679649959, "alpha_loss": 0.023001550859402097, "alpha_value": 0.01671141502231565, "duration": 3.8660528659820557, "step": 38875}
{"episode_reward": 18.613357865962637, "episode": 312.0, "batch_reward": 0.6988973052501678, "critic_loss": 2.2304988088607787, "actor_loss": -67.77157617384388, "actor_target_entropy": -1.0, "actor_entropy": 0.5945559509338871, "alpha_loss": 0.023561231161077178, "alpha_value": 0.016614701282406708, "duration": 3.8628666400909424, "step": 39000}
{"episode_reward": 29.329340386847473, "episode": 313.0, "batch_reward": 0.7133832893371582, "critic_loss": 2.2678223209381105, "actor_loss": -67.81311459011502, "actor_target_entropy": -1.0, "actor_entropy": 0.6701485183503892, "alpha_loss": 0.02407720753006519, "alpha_value": 0.01651584309878765, "duration": 3.874545097351074, "step": 39125}
{"episode_reward": 43.218620951159195, "episode": 314.0, "batch_reward": 0.716835087299347, "critic_loss": 2.3481078329086302, "actor_loss": -67.83744196737966, "actor_target_entropy": -1.0, "actor_entropy": 0.5672668064794233, "alpha_loss": 0.022822450395793684, "alpha_value": 0.016418504140661105, "duration": 3.8623461723327637, "step": 39250}
{"episode_reward": 138.00929438885484, "episode": 315.0, "batch_reward": 0.7073181467056274, "critic_loss": 2.2106866912841796, "actor_loss": -67.85530405195932, "actor_target_entropy": -1.0, "actor_entropy": 0.6205791916166034, "alpha_loss": 0.02347123548979797, "alpha_value": 0.016323728756435, "duration": 3.8657138347625732, "step": 39375}
{"episode_reward": 76.42625120851778, "episode": 316.0, "batch_reward": 0.7073596897125244, "critic_loss": 2.172216920852661, "actor_loss": -67.88268476916897, "actor_target_entropy": -1.0, "actor_entropy": 0.650871834447307, "alpha_loss": 0.023688573360202775, "alpha_value": 0.016225897273103324, "duration": 3.8628218173980713, "step": 39500}
{"episode_reward": 42.61909855493045, "episode": 317.0, "batch_reward": 0.7075601296424866, "critic_loss": 2.277014958381653, "actor_loss": -67.90245504227896, "actor_target_entropy": -1.0, "actor_entropy": 0.5491350132321554, "alpha_loss": 0.022269925339117883, "alpha_value": 0.01613119490202604, "duration": 3.874648332595825, "step": 39625}
{"episode_reward": 79.10667932572885, "episode": 318.0, "batch_reward": 0.7147183084487915, "critic_loss": 2.220326979637146, "actor_loss": -67.93420434767201, "actor_target_entropy": -1.0, "actor_entropy": 0.4974494480317639, "alpha_loss": 0.021711001443045753, "alpha_value": 0.016041765737981637, "duration": 3.8678815364837646, "step": 39750}
{"episode_reward": 62.88459555342536, "episode": 319.0, "batch_reward": 0.7254983830451965, "critic_loss": 2.291387774467468, "actor_loss": -67.97142525324746, "actor_target_entropy": -1.0, "actor_entropy": 0.4906925038685874, "alpha_loss": 0.021156996665965943, "alpha_value": 0.015953547397029394, "duration": 3.8670668601989746, "step": 39875}
{"episode_reward": 85.8530521929663, "episode": 320.0, "batch_reward": 0.7104357481002808, "critic_loss": 2.293316445350647, "actor_loss": -67.98340052943075, "actor_target_entropy": -1.0, "actor_entropy": 0.5558775817194292, "alpha_loss": 0.022065909248926947, "alpha_value": 0.015864959061713788, "duration": 3.859403133392334, "step": 40000}
{"episode_reward": 49.841986722386174, "episode": 321.0, "batch_reward": 0.7074680833816528, "critic_loss": 2.2694163084030152, "actor_loss": -68.00985112265936, "actor_target_entropy": -1.0, "actor_entropy": 0.6656579384728084, "alpha_loss": 0.023008307057713704, "alpha_value": 0.015772405967865413, "duration": 7.843759298324585, "step": 40125}
{"episode_reward": 217.3703508333324, "episode": 322.0, "batch_reward": 0.7236204710006714, "critic_loss": 2.374188094139099, "actor_loss": -68.04322950301632, "actor_target_entropy": -1.0, "actor_entropy": 0.6996894690298265, "alpha_loss": 0.023112620587550824, "alpha_value": 0.015677633527924204, "duration": 3.8623151779174805, "step": 40250}
{"episode_reward": 62.70813900229692, "episode": 323.0, "batch_reward": 0.7042461705207824, "critic_loss": 2.213871346473694, "actor_loss": -68.05274963378906, "actor_target_entropy": -1.0, "actor_entropy": 0.6709264138388256, "alpha_loss": 0.022803455295543822, "alpha_value": 0.01558392721352253, "duration": 3.871650218963623, "step": 40375}
{"episode_reward": 133.3161457401281, "episode": 324.0, "batch_reward": 0.7044457139968872, "critic_loss": 2.232233262062073, "actor_loss": -68.07239544776178, "actor_target_entropy": -1.0, "actor_entropy": 0.6680810259234521, "alpha_loss": 0.022761607963231303, "alpha_value": 0.01549122855858672, "duration": 3.863327741622925, "step": 40500}
{"episode_reward": 22.838712966175265, "episode": 325.0, "batch_reward": 0.7039232296943665, "critic_loss": 2.2710725135803225, "actor_loss": -68.09256163097564, "actor_target_entropy": -1.0, "actor_entropy": 0.6408701718799652, "alpha_loss": 0.022318596936880597, "alpha_value": 0.015399582209895424, "duration": 3.874985456466675, "step": 40625}
{"episode_reward": 39.277653539259674, "episode": 326.0, "batch_reward": 0.6876722311973572, "critic_loss": 2.1153766775131224, "actor_loss": -68.08468307987336, "actor_target_entropy": -1.0, "actor_entropy": 0.6801079819279332, "alpha_loss": 0.02249356740785222, "alpha_value": 0.01530933867514467, "duration": 3.860440969467163, "step": 40750}
{"episode_reward": 119.11428387729967, "episode": 327.0, "batch_reward": 0.723682457447052, "critic_loss": 2.3233845119476317, "actor_loss": -68.14314451671783, "actor_target_entropy": -1.0, "actor_entropy": 0.7133505249780322, "alpha_loss": 0.022799000025741638, "alpha_value": 0.015217741104885309, "duration": 3.8655269145965576, "step": 40875}
{"episode_reward": 57.476290804623105, "episode": 328.0, "batch_reward": 0.7061161730289459, "critic_loss": 2.264820869445801, "actor_loss": -68.14529062086537, "actor_target_entropy": -1.0, "actor_entropy": 0.6834293219351, "alpha_loss": 0.022293889053886937, "alpha_value": 0.015126904772302092, "duration": 3.8663463592529297, "step": 41000}
{"episode_reward": 142.35477997001865, "episode": 329.0, "batch_reward": 0.7027486963272095, "critic_loss": 2.1997063426971435, "actor_loss": -68.16071210588727, "actor_target_entropy": -1.0, "actor_entropy": 0.5785538677185301, "alpha_loss": 0.021237741505342817, "alpha_value": 0.01503938124621982, "duration": 3.8639564514160156, "step": 41125}
{"episode_reward": 75.73601163647292, "episode": 330.0, "batch_reward": 0.698099184513092, "critic_loss": 2.1622850904464723, "actor_loss": -68.17788597845262, "actor_target_entropy": -1.0, "actor_entropy": 0.5433866631600165, "alpha_loss": 0.020650050993407925, "alpha_value": 0.014955695921451517, "duration": 3.8604788780212402, "step": 41250}
{"episode_reward": 156.78103741278557, "episode": 331.0, "batch_reward": 0.7274768872261047, "critic_loss": 2.3155731372833253, "actor_loss": -68.22872331407335, "actor_target_entropy": -1.0, "actor_entropy": 0.5457478648140317, "alpha_loss": 0.020489603162757934, "alpha_value": 0.014873245822881706, "duration": 3.869384765625, "step": 41375}
{"episode_reward": 14.903141618797322, "episode": 332.0, "batch_reward": 0.7110985336303711, "critic_loss": 2.220885997772217, "actor_loss": -68.2376467797064, "actor_target_entropy": -1.0, "actor_entropy": 0.5747758073191489, "alpha_loss": 0.02073048911387882, "alpha_value": 0.014790614941039499, "duration": 3.863656520843506, "step": 41500}
{"episode_reward": 23.845477419360222, "episode": 333.0, "batch_reward": 0.7155149998664856, "critic_loss": 2.295065469741821, "actor_loss": -68.26907070099361, "actor_target_entropy": -1.0, "actor_entropy": 0.5750906675580948, "alpha_loss": 0.020488186695036433, "alpha_value": 0.014707645488153854, "duration": 3.8784127235412598, "step": 41625}
{"episode_reward": 51.7888806380812, "episode": 334.0, "batch_reward": 0.6942036702632904, "critic_loss": 2.1732272911071777, "actor_loss": -68.26131783762285, "actor_target_entropy": -1.0, "actor_entropy": 0.5977124591027537, "alpha_loss": 0.020752047999731956, "alpha_value": 0.014624844382862757, "duration": 3.865485429763794, "step": 41750}
{"episode_reward": 43.099909306187314, "episode": 335.0, "batch_reward": 0.7078575963973999, "critic_loss": 2.233602773666382, "actor_loss": -68.29302469889323, "actor_target_entropy": -1.0, "actor_entropy": 0.6035010795744639, "alpha_loss": 0.02062875171384168, "alpha_value": 0.01454124378246957, "duration": 3.872678279876709, "step": 41875}
{"episode_reward": 14.251465512990304, "episode": 336.0, "batch_reward": 0.6973812732696533, "critic_loss": 2.1997843885421755, "actor_loss": -68.29454643495622, "actor_target_entropy": -1.0, "actor_entropy": 0.5910742705868136, "alpha_loss": 0.020481708729940075, "alpha_value": 0.014459213970318742, "duration": 3.863111972808838, "step": 42000}
{"episode_reward": 45.8048109075448, "episode": 337.0, "batch_reward": 0.6999195988178253, "critic_loss": 2.182260917186737, "actor_loss": -68.31414419507223, "actor_target_entropy": -1.0, "actor_entropy": 0.6166825994612679, "alpha_loss": 0.020486020823083227, "alpha_value": 0.014376905353680705, "duration": 3.8662562370300293, "step": 42125}
{"episode_reward": 52.12280822384831, "episode": 338.0, "batch_reward": 0.6985018515586853, "critic_loss": 2.2315810260772704, "actor_loss": -68.32461301742062, "actor_target_entropy": -1.0, "actor_entropy": 0.6647008811273882, "alpha_loss": 0.02101094804463848, "alpha_value": 0.014293617068554601, "duration": 3.8586196899414062, "step": 42250}
{"episode_reward": 37.190860164159446, "episode": 339.0, "batch_reward": 0.7172792928218842, "critic_loss": 2.336334617614746, "actor_loss": -68.37149641248915, "actor_target_entropy": -1.0, "actor_entropy": 0.6656006574630737, "alpha_loss": 0.02084868454507419, "alpha_value": 0.014209698991893128, "duration": 3.8669302463531494, "step": 42375}
{"episode_reward": 53.36241771460391, "episode": 340.0, "batch_reward": 0.6906463475227356, "critic_loss": 2.1703622140884398, "actor_loss": -68.34911924792874, "actor_target_entropy": -1.0, "actor_entropy": 0.6488044223477764, "alpha_loss": 0.02050751462698944, "alpha_value": 0.014127123856075409, "duration": 3.8593499660491943, "step": 42500}
{"episode_reward": 56.4923234182898, "episode": 341.0, "batch_reward": 0.7011468245983123, "critic_loss": 2.2366641569137573, "actor_loss": -68.37491341242715, "actor_target_entropy": -1.0, "actor_entropy": 0.6439796799705142, "alpha_loss": 0.02028220809168286, "alpha_value": 0.014045765317859714, "duration": 3.866276264190674, "step": 42625}
{"episode_reward": 64.67470963296921, "episode": 342.0, "batch_reward": 0.6893484191894531, "critic_loss": 2.182854595184326, "actor_loss": -68.38102229948967, "actor_target_entropy": -1.0, "actor_entropy": 0.6301746253044375, "alpha_loss": 0.020096591553620754, "alpha_value": 0.013965267530417037, "duration": 3.866562843322754, "step": 42750}
{"episode_reward": 114.42128674981393, "episode": 343.0, "batch_reward": 0.6986101386547089, "critic_loss": 2.1222531061172485, "actor_loss": -68.39068433973524, "actor_target_entropy": -1.0, "actor_entropy": 0.5935028034543234, "alpha_loss": 0.01950896144031532, "alpha_value": 0.013886310890304471, "duration": 3.8730366230010986, "step": 42875}
{"episode_reward": 44.62798707655766, "episode": 344.0, "batch_reward": 0.6895040247440338, "critic_loss": 2.1372100982666016, "actor_loss": -68.39596090009135, "actor_target_entropy": -1.0, "actor_entropy": 0.5189861828281034, "alpha_loss": 0.01885544424576144, "alpha_value": 0.013809912761437752, "duration": 3.865119218826294, "step": 43000}
{"episode_reward": 69.54017711700084, "episode": 345.0, "batch_reward": 0.704394259929657, "critic_loss": 2.275010711669922, "actor_loss": -68.4232648819212, "actor_target_entropy": -1.0, "actor_entropy": 0.5327875670932588, "alpha_loss": 0.01894705331633015, "alpha_value": 0.013734620154585863, "duration": 3.8678510189056396, "step": 43125}
{"episode_reward": 258.30600449268167, "episode": 346.0, "batch_reward": 0.6831263070106506, "critic_loss": 2.1357636113166807, "actor_loss": -68.40385375484344, "actor_target_entropy": -1.0, "actor_entropy": 0.57098792060729, "alpha_loss": 0.019047886734047243, "alpha_value": 0.013658546625118336, "duration": 3.86224102973938, "step": 43250}
{"episode_reward": 77.93317838526025, "episode": 347.0, "batch_reward": 0.7074675264358521, "critic_loss": 2.266085199356079, "actor_loss": -68.44199165465339, "actor_target_entropy": -1.0, "actor_entropy": 0.5193777708780198, "alpha_loss": 0.018598939868665877, "alpha_value": 0.013582923463120816, "duration": 3.870025873184204, "step": 43375}
{"episode_reward": 52.57440926077162, "episode": 348.0, "batch_reward": 0.7049672574996948, "critic_loss": 2.2135191974639894, "actor_loss": -68.45333603889712, "actor_target_entropy": -1.0, "actor_entropy": 0.5276438997637841, "alpha_loss": 0.018493239016782854, "alpha_value": 0.013509003258917206, "duration": 3.855851411819458, "step": 43500}
{"episode_reward": 38.039402704146, "episode": 349.0, "batch_reward": 0.7015049948692321, "critic_loss": 2.231239559173584, "actor_loss": -68.46393415662978, "actor_target_entropy": -1.0, "actor_entropy": 0.5449455370978703, "alpha_loss": 0.018590775392358264, "alpha_value": 0.013434460531195274, "duration": 3.867910146713257, "step": 43625}
{"episode_reward": 214.65756322705556, "episode": 350.0, "batch_reward": 0.6917889122962951, "critic_loss": 2.1473626985549927, "actor_loss": -68.47062289330268, "actor_target_entropy": -1.0, "actor_entropy": 0.5787930680859473, "alpha_loss": 0.018821506160161188, "alpha_value": 0.013359420249318328, "duration": 3.856382131576538, "step": 43750}
{"episode_reward": 29.83099211658946, "episode": 351.0, "batch_reward": 0.6871859703063965, "critic_loss": 2.1084368686676025, "actor_loss": -68.46920425172836, "actor_target_entropy": -1.0, "actor_entropy": 0.633869384962415, "alpha_loss": 0.019162337044401775, "alpha_value": 0.0132830676192692, "duration": 3.85923433303833, "step": 43875}
{"episode_reward": 109.31645380977635, "episode": 352.0, "batch_reward": 0.6993873510360717, "critic_loss": 2.181589677810669, "actor_loss": -68.49084681849325, "actor_target_entropy": -1.0, "actor_entropy": 0.6183617076566142, "alpha_loss": 0.018955995629151023, "alpha_value": 0.013206274118836556, "duration": 3.863677740097046, "step": 44000}
{"episode_reward": 167.94172962209558, "episode": 353.0, "batch_reward": 0.7246762552261352, "critic_loss": 2.2819797601699827, "actor_loss": -68.54093485029917, "actor_target_entropy": -1.0, "actor_entropy": 0.6277632202420916, "alpha_loss": 0.01897677415538402, "alpha_value": 0.013130747873104582, "duration": 3.857206106185913, "step": 44125}
{"episode_reward": 164.63441858793013, "episode": 354.0, "batch_reward": 0.7096912999153138, "critic_loss": 2.365925230026245, "actor_loss": -68.54311961512411, "actor_target_entropy": -1.0, "actor_entropy": 0.6670110648678195, "alpha_loss": 0.019111014602165067, "alpha_value": 0.013054432649485345, "duration": 3.863553762435913, "step": 44250}
{"episode_reward": 38.27068480348849, "episode": 355.0, "batch_reward": 0.7134012649059296, "critic_loss": 2.262849066734314, "actor_loss": -68.56311301579551, "actor_target_entropy": -1.0, "actor_entropy": 0.631754650010003, "alpha_loss": 0.01877242261691699, "alpha_value": 0.012978379052919367, "duration": 3.864673137664795, "step": 44375}
{"episode_reward": 108.08299761159608, "episode": 356.0, "batch_reward": 0.7036364278793334, "critic_loss": 2.2198251600265504, "actor_loss": -68.57114004319713, "actor_target_entropy": -1.0, "actor_entropy": 0.5476756903433031, "alpha_loss": 0.017790819668481426, "alpha_value": 0.012905227814087856, "duration": 3.8631591796875, "step": 44500}
{"episode_reward": 79.98037041065402, "episode": 357.0, "batch_reward": 0.7054660677909851, "critic_loss": 2.15969402885437, "actor_loss": -68.58828941224114, "actor_target_entropy": -1.0, "actor_entropy": 0.4423637106305077, "alpha_loss": 0.016695517484867382, "alpha_value": 0.012836313476001424, "duration": 3.859299659729004, "step": 44625}
{"episode_reward": 30.994655908721104, "episode": 358.0, "batch_reward": 0.7127633204460144, "critic_loss": 2.357982051849365, "actor_loss": -68.6161385813067, "actor_target_entropy": -1.0, "actor_entropy": 0.3950837389115364, "alpha_loss": 0.016147993474958405, "alpha_value": 0.012770454005690587, "duration": 3.858858823776245, "step": 44750}
{"episode_reward": 71.91779464631306, "episode": 359.0, "batch_reward": 0.6877714982032775, "critic_loss": 2.1478956003189085, "actor_loss": -68.6034421163892, "actor_target_entropy": -1.0, "actor_entropy": 0.38019569525643, "alpha_loss": 0.016249035972924458, "alpha_value": 0.0127051062481242, "duration": 3.8738715648651123, "step": 44875}
{"episode_reward": 12.790328150268847, "episode": 360.0, "batch_reward": 0.7042771348953247, "critic_loss": 2.2461851119995115, "actor_loss": -68.63156127929688, "actor_target_entropy": -1.0, "actor_entropy": 0.414254653838373, "alpha_loss": 0.016205084945766196, "alpha_value": 0.012639711700321354, "duration": 3.8609426021575928, "step": 45000}
{"episode_reward": 50.50362915541435, "episode": 361.0, "batch_reward": 0.6934617204666138, "critic_loss": 2.19059672832489, "actor_loss": -68.63607182578436, "actor_target_entropy": -1.0, "actor_entropy": 0.4539996272041684, "alpha_loss": 0.016605153901591188, "alpha_value": 0.012573022007333524, "duration": 3.8680579662323, "step": 45125}
{"episode_reward": 81.73225779628626, "episode": 362.0, "batch_reward": 0.6889539732933044, "critic_loss": 2.180823822975159, "actor_loss": -68.63307153024981, "actor_target_entropy": -1.0, "actor_entropy": 0.4590032831315071, "alpha_loss": 0.01663089080923988, "alpha_value": 0.012505026470093964, "duration": 3.8619425296783447, "step": 45250}
{"episode_reward": 13.731638697424968, "episode": 363.0, "batch_reward": 0.6769841396808625, "critic_loss": 2.062930860519409, "actor_loss": -68.6307846553742, "actor_target_entropy": -1.0, "actor_entropy": 0.4264772373532492, "alpha_loss": 0.016090201967883678, "alpha_value": 0.012437929616657507, "duration": 3.86773681640625, "step": 45375}
{"episode_reward": 58.97161615833854, "episode": 364.0, "batch_reward": 0.6960226635932922, "critic_loss": 2.1870908336639405, "actor_loss": -68.64492305632561, "actor_target_entropy": -1.0, "actor_entropy": 0.42680851490266863, "alpha_loss": 0.015943517457813985, "alpha_value": 0.012372206338623303, "duration": 3.8612539768218994, "step": 45500}
{"episode_reward": 49.07331078987606, "episode": 365.0, "batch_reward": 0.7063699851036072, "critic_loss": 2.193827260017395, "actor_loss": -68.67917281862289, "actor_target_entropy": -1.0, "actor_entropy": 0.44762228594885933, "alpha_loss": 0.01611963909355894, "alpha_value": 0.01230674384665103, "duration": 3.8682103157043457, "step": 45625}
{"episode_reward": 158.487321983562, "episode": 366.0, "batch_reward": 0.6894084692001343, "critic_loss": 2.098499576091766, "actor_loss": -68.66876602172852, "actor_target_entropy": -1.0, "actor_entropy": 0.499076739434273, "alpha_loss": 0.016368644191853462, "alpha_value": 0.012239241185952635, "duration": 3.866867780685425, "step": 45750}
{"episode_reward": 158.9635838113748, "episode": 367.0, "batch_reward": 0.690470641374588, "critic_loss": 2.1480853123664856, "actor_loss": -68.6710706438337, "actor_target_entropy": -1.0, "actor_entropy": 0.5610037777158949, "alpha_loss": 0.016882035822149307, "alpha_value": 0.0121706345589953, "duration": 3.8688113689422607, "step": 45875}
{"episode_reward": 56.277609457112746, "episode": 368.0, "batch_reward": 0.6989833283424377, "critic_loss": 2.1575662484169005, "actor_loss": -68.69514969856509, "actor_target_entropy": -1.0, "actor_entropy": 0.6087953852068994, "alpha_loss": 0.01724677860376335, "alpha_value": 0.012100244960595192, "duration": 3.8660342693328857, "step": 46000}
{"episode_reward": 115.41004141069283, "episode": 369.0, "batch_reward": 0.6987424547672272, "critic_loss": 2.1629718036651613, "actor_loss": -68.70896257672992, "actor_target_entropy": -1.0, "actor_entropy": 0.6969199880721078, "alpha_loss": 0.017785393972955053, "alpha_value": 0.012028047436649222, "duration": 3.8725500106811523, "step": 46125}
{"episode_reward": 65.22549584506811, "episode": 370.0, "batch_reward": 0.7056365933418274, "critic_loss": 2.1882806091308593, "actor_loss": -68.72191533734721, "actor_target_entropy": -1.0, "actor_entropy": 0.7437485148829799, "alpha_loss": 0.01797116244392049, "alpha_value": 0.011954658501654574, "duration": 3.8648056983947754, "step": 46250}
{"episode_reward": 94.91087775108994, "episode": 371.0, "batch_reward": 0.6886412403583526, "critic_loss": 2.193166784286499, "actor_loss": -68.71387748112754, "actor_target_entropy": -1.0, "actor_entropy": 0.7705146263516138, "alpha_loss": 0.017995326232815547, "alpha_value": 0.011881126698678237, "duration": 3.8679633140563965, "step": 46375}
{"episode_reward": 74.11863679269165, "episode": 372.0, "batch_reward": 0.6993312153816224, "critic_loss": 2.240091209411621, "actor_loss": -68.72502013175718, "actor_target_entropy": -1.0, "actor_entropy": 0.7198985199774465, "alpha_loss": 0.01767838229575465, "alpha_value": 0.0118085512197972, "duration": 3.8591055870056152, "step": 46500}
{"episode_reward": 38.60473844545446, "episode": 373.0, "batch_reward": 0.7002266221046448, "critic_loss": 2.1769230680465697, "actor_loss": -68.75277697850787, "actor_target_entropy": -1.0, "actor_entropy": 0.6490630819683983, "alpha_loss": 0.017008063398183337, "alpha_value": 0.01173858142280768, "duration": 3.8728976249694824, "step": 46625}
{"episode_reward": 250.9196338023551, "episode": 374.0, "batch_reward": 0.7082044813632965, "critic_loss": 2.272498417854309, "actor_loss": -68.76451836862871, "actor_target_entropy": -1.0, "actor_entropy": 0.6178968991002729, "alpha_loss": 0.016626682598143816, "alpha_value": 0.011670436659570998, "duration": 3.860384225845337, "step": 46750}
{"episode_reward": 112.91076663874799, "episode": 375.0, "batch_reward": 0.692398295879364, "critic_loss": 2.1638669538497926, "actor_loss": -68.76265462239583, "actor_target_entropy": -1.0, "actor_entropy": 0.569868907095894, "alpha_loss": 0.01611039417958449, "alpha_value": 0.011604440099242568, "duration": 3.8746283054351807, "step": 46875}
{"episode_reward": 49.15613850640413, "episode": 376.0, "batch_reward": 0.6928218240737916, "critic_loss": 2.199862310409546, "actor_loss": -68.76163458055065, "actor_target_entropy": -1.0, "actor_entropy": 0.5805313087278797, "alpha_loss": 0.016131923579040072, "alpha_value": 0.011539600662616374, "duration": 3.8633406162261963, "step": 47000}
{"episode_reward": 58.50877445592852, "episode": 377.0, "batch_reward": 0.7028720374107361, "critic_loss": 2.2325052976608277, "actor_loss": -68.7996076553587, "actor_target_entropy": -1.0, "actor_entropy": 0.5985857513215807, "alpha_loss": 0.016258152586127086, "alpha_value": 0.011474419928442227, "duration": 3.8695523738861084, "step": 47125}
{"episode_reward": 220.58373239730938, "episode": 378.0, "batch_reward": 0.7081523475646972, "critic_loss": 2.2447598180770876, "actor_loss": -68.80410557408487, "actor_target_entropy": -1.0, "actor_entropy": 0.6375707080287318, "alpha_loss": 0.01642488375786812, "alpha_value": 0.011408396903902666, "duration": 3.8681957721710205, "step": 47250}
{"episode_reward": 21.993264838682702, "episode": 379.0, "batch_reward": 0.7065087065696717, "critic_loss": 2.2294287433624267, "actor_loss": -68.81781308613127, "actor_target_entropy": -1.0, "actor_entropy": 0.6351370149188571, "alpha_loss": 0.01630663140011685, "alpha_value": 0.011342469532612911, "duration": 3.8682548999786377, "step": 47375}
{"episode_reward": 124.7085229773562, "episode": 380.0, "batch_reward": 0.6944566669464112, "critic_loss": 2.1723337230682374, "actor_loss": -68.82225578061995, "actor_target_entropy": -1.0, "actor_entropy": 0.6176193952560425, "alpha_loss": 0.016071841961914492, "alpha_value": 0.011277275087934805, "duration": 3.865600347518921, "step": 47500}
{"episode_reward": 125.28923611990639, "episode": 381.0, "batch_reward": 0.6889127876758575, "critic_loss": 2.1637181797027587, "actor_loss": -68.81649186876085, "actor_target_entropy": -1.0, "actor_entropy": 0.5911370099536957, "alpha_loss": 0.01584983960030571, "alpha_value": 0.011213137192897158, "duration": 3.867466688156128, "step": 47625}
{"episode_reward": 24.019583487335026, "episode": 382.0, "batch_reward": 0.6976289653778076, "critic_loss": 2.195675660133362, "actor_loss": -68.8399921540291, "actor_target_entropy": -1.0, "actor_entropy": 0.5265735233983686, "alpha_loss": 0.015310119056413251, "alpha_value": 0.011150591496723797, "duration": 3.8592369556427, "step": 47750}
{"episode_reward": 174.9166637862359, "episode": 383.0, "batch_reward": 0.7122413983345032, "critic_loss": 2.293395124435425, "actor_loss": -68.85975198897104, "actor_target_entropy": -1.0, "actor_entropy": 0.5339843072588482, "alpha_loss": 0.015171862340399198, "alpha_value": 0.011089376123891383, "duration": 3.872619152069092, "step": 47875}
{"episode_reward": 83.05182587765142, "episode": 384.0, "batch_reward": 0.6917346458435059, "critic_loss": 2.0937809267044067, "actor_loss": -68.8543810690603, "actor_target_entropy": -1.0, "actor_entropy": 0.5815798274932369, "alpha_loss": 0.01533510209992528, "alpha_value": 0.011028065034530398, "duration": 3.863772392272949, "step": 48000}
{"episode_reward": 68.7239536499202, "episode": 385.0, "batch_reward": 0.6922792143821717, "critic_loss": 2.1409081268310546, "actor_loss": -68.86267610580202, "actor_target_entropy": -1.0, "actor_entropy": 0.6022709608078003, "alpha_loss": 0.015560353307851724, "alpha_value": 0.010965790668742958, "duration": 3.8685450553894043, "step": 48125}
{"episode_reward": 96.56955748244037, "episode": 386.0, "batch_reward": 0.6966038899421692, "critic_loss": 2.1304620151519775, "actor_loss": -68.87508183140909, "actor_target_entropy": -1.0, "actor_entropy": 0.6448245240795997, "alpha_loss": 0.015701350545690905, "alpha_value": 0.010902867954784118, "duration": 3.8574612140655518, "step": 48250}
{"episode_reward": 82.48201422256174, "episode": 387.0, "batch_reward": 0.7047507886886597, "critic_loss": 2.2711301183700563, "actor_loss": -68.889649890718, "actor_target_entropy": -1.0, "actor_entropy": 0.6874512585382613, "alpha_loss": 0.015879674607680902, "alpha_value": 0.010839275927822141, "duration": 3.8774161338806152, "step": 48375}
{"episode_reward": 138.21049605650404, "episode": 388.0, "batch_reward": 0.7075982804298401, "critic_loss": 2.2145244636535644, "actor_loss": -68.91122817993164, "actor_target_entropy": -1.0, "actor_entropy": 0.6432024317402993, "alpha_loss": 0.01556328391175597, "alpha_value": 0.01077608561774246, "duration": 3.864119291305542, "step": 48500}
{"episode_reward": 169.08404467136845, "episode": 389.0, "batch_reward": 0.7080787672996521, "critic_loss": 2.2256773071289064, "actor_loss": -68.91797880142454, "actor_target_entropy": -1.0, "actor_entropy": 0.6123521611804054, "alpha_loss": 0.01520626007446221, "alpha_value": 0.010714415566028333, "duration": 3.8729875087738037, "step": 48625}
{"episode_reward": 37.87375411381764, "episode": 390.0, "batch_reward": 0.7076706755161285, "critic_loss": 2.2468476371765136, "actor_loss": -68.93457584996378, "actor_target_entropy": -1.0, "actor_entropy": 0.6212925026493687, "alpha_loss": 0.015192385387396621, "alpha_value": 0.010653602428658135, "duration": 3.8672428131103516, "step": 48750}
{"episode_reward": 190.70665274028218, "episode": 391.0, "batch_reward": 0.7066657938957215, "critic_loss": 2.1804352550506594, "actor_loss": -68.94551304408482, "actor_target_entropy": -1.0, "actor_entropy": 0.557145529323154, "alpha_loss": 0.014591641753675446, "alpha_value": 0.010593616078985927, "duration": 3.8672258853912354, "step": 48875}
{"episode_reward": 68.12283199962224, "episode": 392.0, "batch_reward": 0.7036034097671509, "critic_loss": 2.2235818967819214, "actor_loss": -68.95859847530242, "actor_target_entropy": -1.0, "actor_entropy": 0.5243852561519992, "alpha_loss": 0.014241521021411303, "alpha_value": 0.010536147722331194, "duration": 3.8652775287628174, "step": 49000}
{"episode_reward": 74.88399887749449, "episode": 393.0, "batch_reward": 0.7004157748222352, "critic_loss": 2.1384041662216187, "actor_loss": -68.96603550986639, "actor_target_entropy": -1.0, "actor_entropy": 0.5053521583950709, "alpha_loss": 0.014165376933912436, "alpha_value": 0.010479111606167628, "duration": 3.8556325435638428, "step": 49125}
{"episode_reward": 63.15025669873105, "episode": 394.0, "batch_reward": 0.7146600103378296, "critic_loss": 2.310442868232727, "actor_loss": -68.98893417850617, "actor_target_entropy": -1.0, "actor_entropy": 0.5139202033319781, "alpha_loss": 0.014052273870836343, "alpha_value": 0.010422333496662505, "duration": 3.868133783340454, "step": 49250}
{"episode_reward": 53.772480757860905, "episode": 395.0, "batch_reward": 0.7042382378578186, "critic_loss": 2.172402412414551, "actor_loss": -68.99236733572823, "actor_target_entropy": -1.0, "actor_entropy": 0.4688882695304023, "alpha_loss": 0.013668358503353028, "alpha_value": 0.01036607303027459, "duration": 3.868014335632324, "step": 49375}
{"episode_reward": 32.88357960605337, "episode": 396.0, "batch_reward": 0.7011461508274078, "critic_loss": 2.1729346323013305, "actor_loss": -68.99981135706747, "actor_target_entropy": -1.0, "actor_entropy": 0.4452099530927597, "alpha_loss": 0.013537999272586839, "alpha_value": 0.01031118518537919, "duration": 3.863429546356201, "step": 49500}
{"episode_reward": 226.86233268452003, "episode": 397.0, "batch_reward": 0.7036747455596923, "critic_loss": 2.2013023900985718, "actor_loss": -69.02225118970114, "actor_target_entropy": -1.0, "actor_entropy": 0.4053765119068206, "alpha_loss": 0.013035816243953176, "alpha_value": 0.010257123976058833, "duration": 3.8694496154785156, "step": 49625}
{"episode_reward": 97.76925815771146, "episode": 398.0, "batch_reward": 0.7092965595722198, "critic_loss": 2.252886417388916, "actor_loss": -69.04094486851847, "actor_target_entropy": -1.0, "actor_entropy": 0.3838162614453223, "alpha_loss": 0.012731746875590855, "alpha_value": 0.010204679956166888, "duration": 3.85994291305542, "step": 49750}
{"episode_reward": 86.76043976572923, "episode": 399.0, "batch_reward": 0.698449122428894, "critic_loss": 2.2663347826004028, "actor_loss": -69.02332100035652, "actor_target_entropy": -1.0, "actor_entropy": 0.3266891014008295, "alpha_loss": 0.012366110192877906, "alpha_value": 0.010153010796070411, "duration": 3.8699207305908203, "step": 49875}
{"episode_reward": 71.702581677386, "episode": 400.0, "batch_reward": 0.692393949508667, "critic_loss": 2.080940426826477, "actor_loss": -69.03320657053301, "actor_target_entropy": -1.0, "actor_entropy": 0.21865722056358092, "alpha_loss": 0.011356686512308737, "alpha_value": 0.010103844059992368, "duration": 3.8562302589416504, "step": 50000}
{"episode_reward": 88.11099959573882, "episode": 401.0, "batch_reward": 0.716129298210144, "critic_loss": 2.2713226289749144, "actor_loss": -69.07043723454551, "actor_target_entropy": -1.0, "actor_entropy": 0.1567469873125591, "alpha_loss": 0.01082995439332629, "alpha_value": 0.010057776371460575, "duration": 7.863216876983643, "step": 50125}
{"episode_reward": 26.63651209828416, "episode": 402.0, "batch_reward": 0.7062844965457916, "critic_loss": 2.153368656158447, "actor_loss": -69.07501073037425, "actor_target_entropy": -1.0, "actor_entropy": 0.13415950729000953, "alpha_loss": 0.010614489715906882, "alpha_value": 0.010012852251674167, "duration": 3.858564615249634, "step": 50250}
{"episode_reward": 45.07424125273139, "episode": 403.0, "batch_reward": 0.710224287033081, "critic_loss": 2.243729344367981, "actor_loss": -69.08965785919673, "actor_target_entropy": -1.0, "actor_entropy": 0.20326081722501724, "alpha_loss": 0.011201098029102598, "alpha_value": 0.009966586889883335, "duration": 3.8653903007507324, "step": 50375}
{"episode_reward": 40.424638001741194, "episode": 404.0, "batch_reward": 0.6967807717323303, "critic_loss": 2.079552691459656, "actor_loss": -69.08806363997921, "actor_target_entropy": -1.0, "actor_entropy": 0.30077617783700267, "alpha_loss": 0.011766568321975009, "alpha_value": 0.009917323136998753, "duration": 3.8605527877807617, "step": 50500}
{"episode_reward": 14.606941043289801, "episode": 405.0, "batch_reward": 0.7050454652309418, "critic_loss": 2.128707004547119, "actor_loss": -69.10558088998945, "actor_target_entropy": -1.0, "actor_entropy": 0.38071394912780276, "alpha_loss": 0.012404884507376996, "alpha_value": 0.00986539492036443, "duration": 3.866145610809326, "step": 50625}
{"episode_reward": 66.38645098805767, "episode": 406.0, "batch_reward": 0.6957518124580383, "critic_loss": 2.1097379713058473, "actor_loss": -69.11299563992408, "actor_target_entropy": -1.0, "actor_entropy": 0.48237491807629984, "alpha_loss": 0.012989228561280234, "alpha_value": 0.00981059025340244, "duration": 3.860489845275879, "step": 50750}
{"episode_reward": 40.38291325384936, "episode": 407.0, "batch_reward": 0.7000155780315399, "critic_loss": 2.14079842376709, "actor_loss": -69.11541372632223, "actor_target_entropy": -1.0, "actor_entropy": 0.5296148894325136, "alpha_loss": 0.013349650545962273, "alpha_value": 0.009753589556699017, "duration": 3.8687899112701416, "step": 50875}
{"episode_reward": 131.21742719619553, "episode": 408.0, "batch_reward": 0.6994547901153565, "critic_loss": 2.1383474912643434, "actor_loss": -69.1255752809586, "actor_target_entropy": -1.0, "actor_entropy": 0.5299588672576412, "alpha_loss": 0.013277496361444074, "alpha_value": 0.009696426437256937, "duration": 3.8596978187561035, "step": 51000}
{"episode_reward": 57.601353015482864, "episode": 409.0, "batch_reward": 0.6944562966823578, "critic_loss": 2.1129421129226684, "actor_loss": -69.12971944657583, "actor_target_entropy": -1.0, "actor_entropy": 0.5323913532590109, "alpha_loss": 0.01320522123326858, "alpha_value": 0.009639291599059187, "duration": 3.8677148818969727, "step": 51125}
{"episode_reward": 68.28928344287685, "episode": 410.0, "batch_reward": 0.6855318388938904, "critic_loss": 2.103392467498779, "actor_loss": -69.11366948773784, "actor_target_entropy": -1.0, "actor_entropy": 0.5756433279283585, "alpha_loss": 0.013392999257531858, "alpha_value": 0.009582705024431534, "duration": 3.8659207820892334, "step": 51250}
{"episode_reward": 56.019237943936446, "episode": 411.0, "batch_reward": 0.7031414835453034, "critic_loss": 2.2374695711135866, "actor_loss": -69.13429756770059, "actor_target_entropy": -1.0, "actor_entropy": 0.6546991458014836, "alpha_loss": 0.013772909499941364, "alpha_value": 0.009524635429130525, "duration": 3.8651041984558105, "step": 51375}
{"episode_reward": 35.06697575221095, "episode": 412.0, "batch_reward": 0.7190419840812683, "critic_loss": 2.2793746700286865, "actor_loss": -69.17011162542528, "actor_target_entropy": -1.0, "actor_entropy": 0.6759181522553966, "alpha_loss": 0.013822626758126481, "alpha_value": 0.00946592003858904, "duration": 3.8683853149414062, "step": 51500}
{"episode_reward": 133.99831737843178, "episode": 413.0, "batch_reward": 0.7044734947681427, "critic_loss": 2.1764731459617614, "actor_loss": -69.16772860572452, "actor_target_entropy": -1.0, "actor_entropy": 0.6909812310385326, "alpha_loss": 0.013880155581448759, "alpha_value": 0.009407267044040503, "duration": 3.8633291721343994, "step": 51625}
{"episode_reward": 55.903552538118966, "episode": 414.0, "batch_reward": 0.6957994184494019, "critic_loss": 2.2260962200164793, "actor_loss": -69.16531667401713, "actor_target_entropy": -1.0, "actor_entropy": 0.7092641284388881, "alpha_loss": 0.013844531930742724, "alpha_value": 0.009349087604734367, "duration": 3.858720302581787, "step": 51750}
{"episode_reward": 96.6087097965718, "episode": 415.0, "batch_reward": 0.7011947526931762, "critic_loss": 2.219815581321716, "actor_loss": -69.18627639043899, "actor_target_entropy": -1.0, "actor_entropy": 0.7310411684096806, "alpha_loss": 0.013941931213060069, "alpha_value": 0.009291079870299254, "duration": 3.867753505706787, "step": 51875}
{"episode_reward": 213.0764737754125, "episode": 416.0, "batch_reward": 0.7010998980998993, "critic_loss": 2.0992181763648987, "actor_loss": -69.19060700939548, "actor_target_entropy": -1.0, "actor_entropy": 0.7339754143068867, "alpha_loss": 0.013930895546030614, "alpha_value": 0.009233197659216328, "duration": 3.860816717147827, "step": 52000}
{"episode_reward": 39.75788413541204, "episode": 417.0, "batch_reward": 0.7015649547576904, "critic_loss": 2.129734532356262, "actor_loss": -69.20594133649554, "actor_target_entropy": -1.0, "actor_entropy": 0.6977269781960381, "alpha_loss": 0.013533683685911081, "alpha_value": 0.009176559444670104, "duration": 3.8710756301879883, "step": 52125}
{"episode_reward": 49.71136033094092, "episode": 418.0, "batch_reward": 0.6899415435791015, "critic_loss": 2.0709407482147215, "actor_loss": -69.2005973323699, "actor_target_entropy": -1.0, "actor_entropy": 0.6908880395274009, "alpha_loss": 0.013417666597712425, "alpha_value": 0.00912111803596939, "duration": 3.8598709106445312, "step": 52250}
{"episode_reward": 88.31465805515764, "episode": 419.0, "batch_reward": 0.6878887367248535, "critic_loss": 2.0390443687438964, "actor_loss": -69.19826083713107, "actor_target_entropy": -1.0, "actor_entropy": 0.6772909334727696, "alpha_loss": 0.013271818957513287, "alpha_value": 0.009066433403716554, "duration": 3.8754003047943115, "step": 52375}
{"episode_reward": 25.7539415315444, "episode": 420.0, "batch_reward": 0.6920982565879822, "critic_loss": 2.10338041305542, "actor_loss": -69.19719880627048, "actor_target_entropy": -1.0, "actor_entropy": 0.6498077492560109, "alpha_loss": 0.013147346900715944, "alpha_value": 0.009012807956187542, "duration": 3.8636152744293213, "step": 52500}
{"episode_reward": 118.74036538731411, "episode": 421.0, "batch_reward": 0.7094960458278656, "critic_loss": 2.2398607454299926, "actor_loss": -69.23096308632502, "actor_target_entropy": -1.0, "actor_entropy": 0.6715649063625033, "alpha_loss": 0.013106677149023329, "alpha_value": 0.008959342970644145, "duration": 3.8723254203796387, "step": 52625}
{"episode_reward": 47.8110400050958, "episode": 422.0, "batch_reward": 0.6876962909698486, "critic_loss": 2.101812021255493, "actor_loss": -69.2146580603815, "actor_target_entropy": -1.0, "actor_entropy": 0.6971686463202199, "alpha_loss": 0.013144486043001375, "alpha_value": 0.008906236051346305, "duration": 3.86578106880188, "step": 52750}
{"episode_reward": 60.40493513101367, "episode": 423.0, "batch_reward": 0.6894529604911804, "critic_loss": 2.1259962015151976, "actor_loss": -69.21320609440879, "actor_target_entropy": -1.0, "actor_entropy": 0.7554073655416095, "alpha_loss": 0.013378344313611113, "alpha_value": 0.008852796905723432, "duration": 3.865053415298462, "step": 52875}
{"episode_reward": 93.14305935506015, "episode": 424.0, "batch_reward": 0.692394732952118, "critic_loss": 2.0946968059539794, "actor_loss": -69.2319806006647, "actor_target_entropy": -1.0, "actor_entropy": 0.8242180924261769, "alpha_loss": 0.013617312340366264, "alpha_value": 0.008798358605728585, "duration": 3.858524799346924, "step": 53000}
{"episode_reward": 76.95590490665796, "episode": 425.0, "batch_reward": 0.6939830121994018, "critic_loss": 2.1706708698272705, "actor_loss": -69.22711944580078, "actor_target_entropy": -1.0, "actor_entropy": 0.8716301709886581, "alpha_loss": 0.013792152546109661, "alpha_value": 0.008743620762947423, "duration": 3.8633944988250732, "step": 53125}
{"episode_reward": 155.6316458926342, "episode": 426.0, "batch_reward": 0.6919539799690246, "critic_loss": 2.140881565093994, "actor_loss": -69.23440797867313, "actor_target_entropy": -1.0, "actor_entropy": 0.887248489164537, "alpha_loss": 0.01370825107780195, "alpha_value": 0.008688812471143555, "duration": 3.862305164337158, "step": 53250}
{"episode_reward": 43.751103574899574, "episode": 427.0, "batch_reward": 0.7078656163215638, "critic_loss": 2.2196082482337953, "actor_loss": -69.2540302579365, "actor_target_entropy": -1.0, "actor_entropy": 0.9095685311726162, "alpha_loss": 0.013721349442170726, "alpha_value": 0.008634884098876694, "duration": 3.868748903274536, "step": 53375}
{"episode_reward": 243.4765457182537, "episode": 428.0, "batch_reward": 0.7011474535465241, "critic_loss": 2.1535056848526, "actor_loss": -69.25817575762349, "actor_target_entropy": -1.0, "actor_entropy": 0.915707484368355, "alpha_loss": 0.01370858324451312, "alpha_value": 0.008580917814989144, "duration": 3.8557698726654053, "step": 53500}
{"episode_reward": 117.27190064259645, "episode": 429.0, "batch_reward": 0.7024044210910797, "critic_loss": 2.231380518913269, "actor_loss": -69.26625642322358, "actor_target_entropy": -1.0, "actor_entropy": 0.89008034789373, "alpha_loss": 0.013509019928437376, "alpha_value": 0.008527883812126134, "duration": 3.8721699714660645, "step": 53625}
{"episode_reward": 23.782788969813684, "episode": 430.0, "batch_reward": 0.7024204969406128, "critic_loss": 2.173818039894104, "actor_loss": -69.27167966288906, "actor_target_entropy": -1.0, "actor_entropy": 0.8145100878131005, "alpha_loss": 0.01307833583785161, "alpha_value": 0.00847609177231137, "duration": 3.855743885040283, "step": 53750}
{"episode_reward": 178.21132553646672, "episode": 431.0, "batch_reward": 0.7042082800865174, "critic_loss": 2.1452257642745973, "actor_loss": -69.2859589107453, "actor_target_entropy": -1.0, "actor_entropy": 0.7031787860961187, "alpha_loss": 0.012479427300157055, "alpha_value": 0.008426643289070012, "duration": 3.8805911540985107, "step": 53875}
{"episode_reward": 93.71608233849892, "episode": 432.0, "batch_reward": 0.708485420703888, "critic_loss": 2.253951371192932, "actor_loss": -69.3042696060673, "actor_target_entropy": -1.0, "actor_entropy": 0.5577915599269252, "alpha_loss": 0.011531040417931734, "alpha_value": 0.008380203558341829, "duration": 3.860046148300171, "step": 54000}
{"episode_reward": 23.07303800425114, "episode": 433.0, "batch_reward": 0.7041035442352295, "critic_loss": 2.3253193941116335, "actor_loss": -69.3005842178587, "actor_target_entropy": -1.0, "actor_entropy": 0.48521921558985637, "alpha_loss": 0.011132089894205804, "alpha_value": 0.008336511500435573, "duration": 3.8711633682250977, "step": 54125}
{"episode_reward": 133.12067400428847, "episode": 434.0, "batch_reward": 0.6975719916820526, "critic_loss": 2.2203933115005494, "actor_loss": -69.3073377301616, "actor_target_entropy": -1.0, "actor_entropy": 0.49794065183208835, "alpha_loss": 0.011110203250521613, "alpha_value": 0.00829328156234062, "duration": 3.8631176948547363, "step": 54250}
{"episode_reward": 56.09498002599133, "episode": 435.0, "batch_reward": 0.7076619510650635, "critic_loss": 2.230438594818115, "actor_loss": -69.32335493299696, "actor_target_entropy": -1.0, "actor_entropy": 0.5376505794979277, "alpha_loss": 0.011294232090077704, "alpha_value": 0.00824946424982904, "duration": 3.863023519515991, "step": 54375}
{"episode_reward": 39.580055936445945, "episode": 436.0, "batch_reward": 0.6978807754516602, "critic_loss": 2.2261152067184447, "actor_loss": -69.32092322072675, "actor_target_entropy": -1.0, "actor_entropy": 0.5461671621568741, "alpha_loss": 0.01125585450039756, "alpha_value": 0.00820522532131309, "duration": 3.8645567893981934, "step": 54500}
{"episode_reward": 67.4397259822672, "episode": 437.0, "batch_reward": 0.7165205750465393, "critic_loss": 2.2375943002700804, "actor_loss": -69.34532371399895, "actor_target_entropy": -1.0, "actor_entropy": 0.5557420688962179, "alpha_loss": 0.011339588741224909, "alpha_value": 0.008160747306798112, "duration": 3.864643096923828, "step": 54625}
{"episode_reward": 36.3961805886051, "episode": 438.0, "batch_reward": 0.6981043784618378, "critic_loss": 2.2172091703414916, "actor_loss": -69.34234053088772, "actor_target_entropy": -1.0, "actor_entropy": 0.5621743855937835, "alpha_loss": 0.01127936536326043, "alpha_value": 0.008116188067536164, "duration": 3.866236925125122, "step": 54750}
{"episode_reward": 193.80365051017057, "episode": 439.0, "batch_reward": 0.708996248960495, "critic_loss": 2.206534104347229, "actor_loss": -69.36048041449652, "actor_target_entropy": -1.0, "actor_entropy": 0.5803612924757457, "alpha_loss": 0.011318154411301726, "alpha_value": 0.008071596248124539, "duration": 3.8669190406799316, "step": 54875}
{"episode_reward": 125.88008966048898, "episode": 440.0, "batch_reward": 0.7068654770851135, "critic_loss": 2.2066483964920045, "actor_loss": -69.37201813728579, "actor_target_entropy": -1.0, "actor_entropy": 0.5385768836544406, "alpha_loss": 0.011094642547710289, "alpha_value": 0.008027346481892494, "duration": 3.8627567291259766, "step": 55000}
{"episode_reward": 75.6293386167986, "episode": 441.0, "batch_reward": 0.6979289870262146, "critic_loss": 2.179606695175171, "actor_loss": -69.37109701974052, "actor_target_entropy": -1.0, "actor_entropy": 0.5464908830703251, "alpha_loss": 0.011011676286302861, "alpha_value": 0.007983734327231665, "duration": 3.865271806716919, "step": 55125}
{"episode_reward": 32.62733873742062, "episode": 442.0, "batch_reward": 0.7034308290481568, "critic_loss": 2.230414288520813, "actor_loss": -69.37403918850806, "actor_target_entropy": -1.0, "actor_entropy": 0.5895946448849093, "alpha_loss": 0.011232349946494065, "alpha_value": 0.00793954537971052, "duration": 3.8621761798858643, "step": 55250}
{"episode_reward": 139.25999215064542, "episode": 443.0, "batch_reward": 0.7071443123817444, "critic_loss": 2.198240756034851, "actor_loss": -69.38777136424231, "actor_target_entropy": -1.0, "actor_entropy": 0.6495328498265099, "alpha_loss": 0.011365517027794368, "alpha_value": 0.007894889269342268, "duration": 3.874725103378296, "step": 55375}
{"episode_reward": 60.16604720121168, "episode": 444.0, "batch_reward": 0.7068765029907227, "critic_loss": 2.255860605239868, "actor_loss": -69.40790201002552, "actor_target_entropy": -1.0, "actor_entropy": 0.712249667413773, "alpha_loss": 0.01166336873786584, "alpha_value": 0.007849254738933798, "duration": 3.859217405319214, "step": 55500}
{"episode_reward": 156.88666295214443, "episode": 445.0, "batch_reward": 0.6921511414051056, "critic_loss": 2.1977211446762084, "actor_loss": -69.38537609766401, "actor_target_entropy": -1.0, "actor_entropy": 0.6936880615022447, "alpha_loss": 0.011452913387782045, "alpha_value": 0.007803335207346287, "duration": 3.869584798812866, "step": 55625}
{"episode_reward": 94.07702341748377, "episode": 446.0, "batch_reward": 0.6987803606987, "critic_loss": 2.2018902587890623, "actor_loss": -69.39906729421308, "actor_target_entropy": -1.0, "actor_entropy": 0.629260205453442, "alpha_loss": 0.01110508725527794, "alpha_value": 0.007758797805851786, "duration": 3.8631081581115723, "step": 55750}
{"episode_reward": 89.91492745498869, "episode": 447.0, "batch_reward": 0.7158280506134033, "critic_loss": 2.229839687347412, "actor_loss": -69.42462412516277, "actor_target_entropy": -1.0, "actor_entropy": 0.6188174069873871, "alpha_loss": 0.01097111678904011, "alpha_value": 0.007715165463042059, "duration": 3.865729331970215, "step": 55875}
{"episode_reward": 94.28400866961694, "episode": 448.0, "batch_reward": 0.693209014415741, "critic_loss": 2.077936459541321, "actor_loss": -69.42368255123016, "actor_target_entropy": -1.0, "actor_entropy": 0.5720228110590289, "alpha_loss": 0.010677041440841651, "alpha_value": 0.007672275777883668, "duration": 3.8679745197296143, "step": 56000}
{"episode_reward": 23.20413946808492, "episode": 449.0, "batch_reward": 0.6988208708763123, "critic_loss": 2.1449836506843565, "actor_loss": -69.41746109250992, "actor_target_entropy": -1.0, "actor_entropy": 0.5391699946115888, "alpha_loss": 0.010494631478592517, "alpha_value": 0.0076304084423140985, "duration": 3.869550943374634, "step": 56125}
{"episode_reward": 72.74221004471268, "episode": 450.0, "batch_reward": 0.6993817420005798, "critic_loss": 2.17996249294281, "actor_loss": -69.42422633017263, "actor_target_entropy": -1.0, "actor_entropy": 0.5270133826040453, "alpha_loss": 0.010337962829057247, "alpha_value": 0.007589273818743378, "duration": 3.8657147884368896, "step": 56250}
{"episode_reward": 57.40338518178649, "episode": 451.0, "batch_reward": 0.7039971852302551, "critic_loss": 2.1583647956848147, "actor_loss": -69.44546847873264, "actor_target_entropy": -1.0, "actor_entropy": 0.5326780459237477, "alpha_loss": 0.010356416497083883, "alpha_value": 0.0075482571498476266, "duration": 3.8708925247192383, "step": 56375}
{"episode_reward": 42.36048669509885, "episode": 452.0, "batch_reward": 0.7117848219871521, "critic_loss": 2.1618170976638793, "actor_loss": -69.46236050513482, "actor_target_entropy": -1.0, "actor_entropy": 0.5739672299354307, "alpha_loss": 0.010527743642488796, "alpha_value": 0.007506536692735744, "duration": 3.8697376251220703, "step": 56500}
{"episode_reward": 33.88660585400179, "episode": 453.0, "batch_reward": 0.6939158046245575, "critic_loss": 2.1486695680618286, "actor_loss": -69.44499303424169, "actor_target_entropy": -1.0, "actor_entropy": 0.6074633238807557, "alpha_loss": 0.010681474448314734, "alpha_value": 0.007464467600837471, "duration": 3.867481231689453, "step": 56625}
{"episode_reward": 69.60583644502783, "episode": 454.0, "batch_reward": 0.6971081857681274, "critic_loss": 2.1510450353622437, "actor_loss": -69.45620407596711, "actor_target_entropy": -1.0, "actor_entropy": 0.659938431555225, "alpha_loss": 0.010833486298760098, "alpha_value": 0.007421641126437294, "duration": 3.864339828491211, "step": 56750}
{"episode_reward": 71.35033401915409, "episode": 455.0, "batch_reward": 0.695909737586975, "critic_loss": 2.106323838710785, "actor_loss": -69.45464458162823, "actor_target_entropy": -1.0, "actor_entropy": 0.6995151629523625, "alpha_loss": 0.010873440165250074, "alpha_value": 0.007378335602952716, "duration": 3.8609731197357178, "step": 56875}
{"episode_reward": 37.90706974388958, "episode": 456.0, "batch_reward": 0.7113394360542298, "critic_loss": 2.173499037742615, "actor_loss": -69.47561990061114, "actor_target_entropy": -1.0, "actor_entropy": 0.6858570229622626, "alpha_loss": 0.010798338470199415, "alpha_value": 0.007335358418643366, "duration": 3.859663724899292, "step": 57000}
{"episode_reward": 26.101249304902908, "episode": 457.0, "batch_reward": 0.7067515320777893, "critic_loss": 2.15428457069397, "actor_loss": -69.48278433179098, "actor_target_entropy": -1.0, "actor_entropy": 0.6602827878225417, "alpha_loss": 0.01056905562383315, "alpha_value": 0.007292945780879555, "duration": 3.8742446899414062, "step": 57125}
{"episode_reward": 71.78530920265456, "episode": 458.0, "batch_reward": 0.6918668973445893, "critic_loss": 2.0790354256629944, "actor_loss": -69.47829449561334, "actor_target_entropy": -1.0, "actor_entropy": 0.6345052449933944, "alpha_loss": 0.01039853761152875, "alpha_value": 0.0072514605845671026, "duration": 3.8594613075256348, "step": 57250}
{"episode_reward": 114.88955015920578, "episode": 459.0, "batch_reward": 0.693755407333374, "critic_loss": 2.1615819435119628, "actor_loss": -69.47469463045636, "actor_target_entropy": -1.0, "actor_entropy": 0.6027053821654547, "alpha_loss": 0.01017774607513159, "alpha_value": 0.007210675920850407, "duration": 3.874753713607788, "step": 57375}
{"episode_reward": 19.24255433916771, "episode": 460.0, "batch_reward": 0.6942224371433258, "critic_loss": 2.161851197719574, "actor_loss": -69.48012431975334, "actor_target_entropy": -1.0, "actor_entropy": 0.5680273617467573, "alpha_loss": 0.009972001891583204, "alpha_value": 0.007170899485779806, "duration": 3.861994743347168, "step": 57500}
{"episode_reward": 126.24575570906083, "episode": 461.0, "batch_reward": 0.7088344376087189, "critic_loss": 2.245828453063965, "actor_loss": -69.49597228519501, "actor_target_entropy": -1.0, "actor_entropy": 0.5547327181649586, "alpha_loss": 0.009837332625119459, "alpha_value": 0.0071316688950501484, "duration": 3.8698244094848633, "step": 57625}
{"episode_reward": 59.149641013736755, "episode": 462.0, "batch_reward": 0.6860795774459839, "critic_loss": 2.0563896141052247, "actor_loss": -69.49382006737494, "actor_target_entropy": -1.0, "actor_entropy": 0.5801235668120845, "alpha_loss": 0.00990282904897486, "alpha_value": 0.007092402053410587, "duration": 3.8654136657714844, "step": 57750}
{"episode_reward": 70.14875602981245, "episode": 463.0, "batch_reward": 0.6864226298332214, "critic_loss": 2.1873530225753783, "actor_loss": -69.46434650723896, "actor_target_entropy": -1.0, "actor_entropy": 0.6164931967144921, "alpha_loss": 0.0100459869625786, "alpha_value": 0.007052864409215304, "duration": 3.86043381690979, "step": 57875}
{"episode_reward": 118.51998540026217, "episode": 464.0, "batch_reward": 0.69862286901474, "critic_loss": 2.138757610321045, "actor_loss": -69.49423230078912, "actor_target_entropy": -1.0, "actor_entropy": 0.6648729116685929, "alpha_loss": 0.01019659555787521, "alpha_value": 0.007012538300447774, "duration": 3.8655765056610107, "step": 58000}
{"episode_reward": 23.17536344594682, "episode": 465.0, "batch_reward": 0.6878644795417785, "critic_loss": 2.1663410005569457, "actor_loss": -69.47892361595517, "actor_target_entropy": -1.0, "actor_entropy": 0.7341816179336064, "alpha_loss": 0.010405179024452255, "alpha_value": 0.006971735511590913, "duration": 3.858731508255005, "step": 58125}
{"episode_reward": 18.658891529114072, "episode": 466.0, "batch_reward": 0.6952245366573334, "critic_loss": 2.182170895576477, "actor_loss": -69.48240735453945, "actor_target_entropy": -1.0, "actor_entropy": 0.8077146814715478, "alpha_loss": 0.010640647142164169, "alpha_value": 0.006930109215653181, "duration": 3.862090826034546, "step": 58250}
{"episode_reward": 73.62073320632142, "episode": 467.0, "batch_reward": 0.6766245799064636, "critic_loss": 2.0582529726028445, "actor_loss": -69.4689425513858, "actor_target_entropy": -1.0, "actor_entropy": 0.8986682002506559, "alpha_loss": 0.010940127976475254, "alpha_value": 0.006887536094728466, "duration": 3.869992733001709, "step": 58375}
{"episode_reward": 67.2107947226588, "episode": 468.0, "batch_reward": 0.6969879145622253, "critic_loss": 2.1524289951324462, "actor_loss": -69.46885459653792, "actor_target_entropy": -1.0, "actor_entropy": 0.9383839061183314, "alpha_loss": 0.010961421555088412, "alpha_value": 0.006844536055113828, "duration": 3.8549752235412598, "step": 58500}
{"episode_reward": 111.38497886984703, "episode": 469.0, "batch_reward": 0.7014895553588867, "critic_loss": 2.199082631111145, "actor_loss": -69.48294479127914, "actor_target_entropy": -1.0, "actor_entropy": 0.9260387742330157, "alpha_loss": 0.010869696603289672, "alpha_value": 0.006802042724275922, "duration": 3.8627970218658447, "step": 58625}
{"episode_reward": 68.29056774171603, "episode": 470.0, "batch_reward": 0.6952235732078552, "critic_loss": 2.100476119041443, "actor_loss": -69.48559262675624, "actor_target_entropy": -1.0, "actor_entropy": 0.9332033165039555, "alpha_loss": 0.010814032231968257, "alpha_value": 0.006760016280917645, "duration": 3.855884075164795, "step": 58750}
{"episode_reward": 52.58224140179814, "episode": 471.0, "batch_reward": 0.6860297448635101, "critic_loss": 2.121219317436218, "actor_loss": -69.46969834585039, "actor_target_entropy": -1.0, "actor_entropy": 0.9662110937966241, "alpha_loss": 0.01081131406069275, "alpha_value": 0.006718475658227565, "duration": 3.8688430786132812, "step": 58875}
{"episode_reward": 106.81228218614244, "episode": 472.0, "batch_reward": 0.6934180736541748, "critic_loss": 2.1799999890327455, "actor_loss": -69.4897967923072, "actor_target_entropy": -1.0, "actor_entropy": 0.972418773558832, "alpha_loss": 0.010778090886531337, "alpha_value": 0.0066770735193510625, "duration": 3.8657004833221436, "step": 59000}
{"episode_reward": 137.12798475506528, "episode": 473.0, "batch_reward": 0.6921632771492005, "critic_loss": 2.0672503871917725, "actor_loss": -69.47397940499442, "actor_target_entropy": -1.0, "actor_entropy": 1.0086509632685827, "alpha_loss": 0.01081564961858685, "alpha_value": 0.006636017045026064, "duration": 3.8662967681884766, "step": 59125}
{"episode_reward": 21.786198483646462, "episode": 474.0, "batch_reward": 0.6968309633731842, "critic_loss": 2.1881533060073854, "actor_loss": -69.49072265625, "actor_target_entropy": -1.0, "actor_entropy": 1.0503027862118137, "alpha_loss": 0.010833145855295082, "alpha_value": 0.006594994553763855, "duration": 3.8598129749298096, "step": 59250}
{"episode_reward": 59.51956275514251, "episode": 475.0, "batch_reward": 0.6734498345851898, "critic_loss": 2.0258101148605347, "actor_loss": -69.4577159578838, "actor_target_entropy": -1.0, "actor_entropy": 1.0821241367430914, "alpha_loss": 0.01081201969276345, "alpha_value": 0.006554176693609065, "duration": 3.865692615509033, "step": 59375}
{"episode_reward": 120.64683961984133, "episode": 476.0, "batch_reward": 0.6944902095794677, "critic_loss": 2.072688159942627, "actor_loss": -69.48291950841104, "actor_target_entropy": -1.0, "actor_entropy": 1.0928225094272244, "alpha_loss": 0.010764622910609168, "alpha_value": 0.006513764088525078, "duration": 3.8589155673980713, "step": 59500}
{"episode_reward": 103.07625437539247, "episode": 477.0, "batch_reward": 0.6977717435359955, "critic_loss": 2.1862858390808104, "actor_loss": -69.4801751999628, "actor_target_entropy": -1.0, "actor_entropy": 1.0956378683211312, "alpha_loss": 0.010716072461079983, "alpha_value": 0.006473794601650228, "duration": 3.86063551902771, "step": 59625}
{"episode_reward": 137.83153142023457, "episode": 478.0, "batch_reward": 0.6946934278011322, "critic_loss": 2.0962551107406617, "actor_loss": -69.47730575069305, "actor_target_entropy": -1.0, "actor_entropy": 1.1763476287164996, "alpha_loss": 0.010758674583367763, "alpha_value": 0.006434002569171086, "duration": 3.8612546920776367, "step": 59750}
{"episode_reward": 112.00673786326978, "episode": 479.0, "batch_reward": 0.6916305000782013, "critic_loss": 2.1639041223526, "actor_loss": -69.47630612812345, "actor_target_entropy": -1.0, "actor_entropy": 1.1943504867099581, "alpha_loss": 0.010714909653105432, "alpha_value": 0.006394417815108031, "duration": 3.861191749572754, "step": 59875}
{"episode_reward": 39.59306909618424, "episode": 480.0, "batch_reward": 0.6989289441108704, "critic_loss": 2.2184677619934083, "actor_loss": -69.482420890562, "actor_target_entropy": -1.0, "actor_entropy": 1.1938999429825814, "alpha_loss": 0.010653113690955986, "alpha_value": 0.006355249200935047, "duration": 3.8605637550354004, "step": 60000}
{"episode_reward": 125.24062909694213, "episode": 481.0, "batch_reward": 0.703216336965561, "critic_loss": 2.170759581565857, "actor_loss": -69.49295479910714, "actor_target_entropy": -1.0, "actor_entropy": 1.1862384875615437, "alpha_loss": 0.010578637794842796, "alpha_value": 0.0063165144908877684, "duration": 7.8668577671051025, "step": 60125}
{"episode_reward": 247.81394756327845, "episode": 482.0, "batch_reward": 0.7024997668266296, "critic_loss": 2.1382127237319946, "actor_loss": -69.49965470837009, "actor_target_entropy": -1.0, "actor_entropy": 1.1472822812295729, "alpha_loss": 0.010446886817413953, "alpha_value": 0.006278298076948457, "duration": 3.8708789348602295, "step": 60250}
{"episode_reward": 50.601536613962054, "episode": 483.0, "batch_reward": 0.7033712515830993, "critic_loss": 2.1778161692619324, "actor_loss": -69.5096928429982, "actor_target_entropy": -1.0, "actor_entropy": 1.1410327657820687, "alpha_loss": 0.01041574901827271, "alpha_value": 0.006240593808171893, "duration": 3.8599281311035156, "step": 60375}
{"episode_reward": 86.04448168550897, "episode": 484.0, "batch_reward": 0.6965156216621399, "critic_loss": 2.150355348587036, "actor_loss": -69.50644966863817, "actor_target_entropy": -1.0, "actor_entropy": 1.1727568449512604, "alpha_loss": 0.010360916791063162, "alpha_value": 0.00620314733065191, "duration": 3.8618762493133545, "step": 60500}
{"episode_reward": 77.19362904280135, "episode": 485.0, "batch_reward": 0.6976497206687927, "critic_loss": 2.1008235359191896, "actor_loss": -69.51228671603732, "actor_target_entropy": -1.0, "actor_entropy": 1.1988679359829615, "alpha_loss": 0.01033137882098792, "alpha_value": 0.006165998375348573, "duration": 3.864112615585327, "step": 60625}
{"episode_reward": 109.16931488975602, "episode": 486.0, "batch_reward": 0.7112762401103974, "critic_loss": 2.177222423553467, "actor_loss": -69.53208234233242, "actor_target_entropy": -1.0, "actor_entropy": 1.2519515137518606, "alpha_loss": 0.01029119548958636, "alpha_value": 0.006129115652433159, "duration": 3.8638906478881836, "step": 60750}
{"episode_reward": 123.31597422621506, "episode": 487.0, "batch_reward": 0.7034416103363037, "critic_loss": 2.1627886114120485, "actor_loss": -69.53653256855314, "actor_target_entropy": -1.0, "actor_entropy": 1.30757851260049, "alpha_loss": 0.010253480709497892, "alpha_value": 0.00609245654049123, "duration": 3.867032766342163, "step": 60875}
{"episode_reward": 197.23171766408765, "episode": 488.0, "batch_reward": 0.6844457986354828, "critic_loss": 2.022047124385834, "actor_loss": -69.51911101802703, "actor_target_entropy": -1.0, "actor_entropy": 1.34573100074645, "alpha_loss": 0.010175525045563136, "alpha_value": 0.006056173148340573, "duration": 3.856933355331421, "step": 61000}
{"episode_reward": 256.262083355316, "episode": 489.0, "batch_reward": 0.7069178166389465, "critic_loss": 2.1143746671676635, "actor_loss": -69.55218578520275, "actor_target_entropy": -1.0, "actor_entropy": 1.382110597595336, "alpha_loss": 0.010088638860791449, "alpha_value": 0.00602027769470932, "duration": 3.8637266159057617, "step": 61125}
{"episode_reward": 262.31512756194155, "episode": 490.0, "batch_reward": 0.7076180343627929, "critic_loss": 2.202228983879089, "actor_loss": -69.5663316788212, "actor_target_entropy": -1.0, "actor_entropy": 1.429449439048767, "alpha_loss": 0.009968788423124821, "alpha_value": 0.005984843207828572, "duration": 3.860546350479126, "step": 61250}
{"episode_reward": 95.262318340191, "episode": 491.0, "batch_reward": 0.692723112821579, "critic_loss": 2.0482533369064333, "actor_loss": -69.55619194394066, "actor_target_entropy": -1.0, "actor_entropy": 1.4662550990543668, "alpha_loss": 0.00983924875479369, "alpha_value": 0.005949965183694092, "duration": 3.862865924835205, "step": 61375}
{"episode_reward": 135.70957258700022, "episode": 492.0, "batch_reward": 0.708314359664917, "critic_loss": 2.196732057571411, "actor_loss": -69.56682242116621, "actor_target_entropy": -1.0, "actor_entropy": 1.499794040956805, "alpha_loss": 0.009717991665726709, "alpha_value": 0.005915498373139635, "duration": 3.858301877975464, "step": 61500}
{"episode_reward": 96.48970877855406, "episode": 493.0, "batch_reward": 0.7095530059337616, "critic_loss": 2.239385672569275, "actor_loss": -69.59527660551525, "actor_target_entropy": -1.0, "actor_entropy": 1.5281064188669597, "alpha_loss": 0.009610581773495863, "alpha_value": 0.005881515610901968, "duration": 3.8663454055786133, "step": 61625}
{"episode_reward": 214.87655437797582, "episode": 494.0, "batch_reward": 0.7121046605110168, "critic_loss": 2.22513286113739, "actor_loss": -69.59963829286637, "actor_target_entropy": -1.0, "actor_entropy": 1.5502079725265503, "alpha_loss": 0.009492910977813506, "alpha_value": 0.0058480325682717, "duration": 3.863677501678467, "step": 61750}
{"episode_reward": 146.96950036549933, "episode": 495.0, "batch_reward": 0.7170499076843262, "critic_loss": 2.237200086593628, "actor_loss": -69.61762116447328, "actor_target_entropy": -1.0, "actor_entropy": 1.5733009690330142, "alpha_loss": 0.00932733810669373, "alpha_value": 0.005814944982550409, "duration": 3.859221935272217, "step": 61875}
{"episode_reward": 38.44449837618433, "episode": 496.0, "batch_reward": 0.6890900835990906, "critic_loss": 2.1347677869796753, "actor_loss": -69.60133890951833, "actor_target_entropy": -1.0, "actor_entropy": 1.6080664703922887, "alpha_loss": 0.009268783678811404, "alpha_value": 0.0057823138713349485, "duration": 3.863125801086426, "step": 62000}
{"episode_reward": 105.05782948510448, "episode": 497.0, "batch_reward": 0.7258547892570496, "critic_loss": 2.242484721183777, "actor_loss": -69.63773648701017, "actor_target_entropy": -1.0, "actor_entropy": 1.6140986113321214, "alpha_loss": 0.009163396492127388, "alpha_value": 0.005749998174622981, "duration": 3.865938663482666, "step": 62125}
{"episode_reward": 194.18319758718405, "episode": 498.0, "batch_reward": 0.6979361083507538, "critic_loss": 2.1397247915267945, "actor_loss": -69.62305253551853, "actor_target_entropy": -1.0, "actor_entropy": 1.6745702259002193, "alpha_loss": 0.00877292946942391, "alpha_value": 0.005718268031440369, "duration": 3.8620553016662598, "step": 62250}
{"episode_reward": 109.62503665676843, "episode": 499.0, "batch_reward": 0.7097655227184295, "critic_loss": 2.120641088485718, "actor_loss": -69.66233668251643, "actor_target_entropy": -1.0, "actor_entropy": 1.7572882686342512, "alpha_loss": 0.008461070143514209, "alpha_value": 0.0056879544613077345, "duration": 3.8678300380706787, "step": 62375}
{"episode_reward": 54.3552933251586, "episode": 500.0, "batch_reward": 0.7148207983970642, "critic_loss": 2.2018072271347044, "actor_loss": -69.67017204530778, "actor_target_entropy": -1.0, "actor_entropy": 1.786915829104762, "alpha_loss": 0.00811944123838217, "alpha_value": 0.005658588474388971, "duration": 3.8597898483276367, "step": 62500}
{"episode_reward": 124.06146709090358, "episode": 501.0, "batch_reward": 0.715551480293274, "critic_loss": 2.1952651166915893, "actor_loss": -69.70198010641431, "actor_target_entropy": -1.0, "actor_entropy": 1.8129377989541917, "alpha_loss": 0.008004959273551191, "alpha_value": 0.005630021971062551, "duration": 3.8700671195983887, "step": 62625}
{"episode_reward": 187.31963721973378, "episode": 502.0, "batch_reward": 0.7061329989433288, "critic_loss": 2.172963623046875, "actor_loss": -69.69315288912865, "actor_target_entropy": -1.0, "actor_entropy": 1.8198174853478708, "alpha_loss": 0.007987468691182232, "alpha_value": 0.005601537956132218, "duration": 3.853294849395752, "step": 62750}
{"episode_reward": 201.22512081335398, "episode": 503.0, "batch_reward": 0.7124777393341064, "critic_loss": 2.16679581451416, "actor_loss": -69.7222162882487, "actor_target_entropy": -1.0, "actor_entropy": 1.7946434796802582, "alpha_loss": 0.008035412605201442, "alpha_value": 0.005572658343683385, "duration": 3.8682701587677, "step": 62875}
{"episode_reward": 101.26750205074325, "episode": 504.0, "batch_reward": 0.7138157286643982, "critic_loss": 2.212695731639862, "actor_loss": -69.73802788026872, "actor_target_entropy": -1.0, "actor_entropy": 1.821466403622781, "alpha_loss": 0.007868999374970313, "alpha_value": 0.005543858298327768, "duration": 3.8592307567596436, "step": 63000}
{"episode_reward": 246.92776716872623, "episode": 505.0, "batch_reward": 0.7106534781455993, "critic_loss": 2.145024076461792, "actor_loss": -69.75132073296442, "actor_target_entropy": -1.0, "actor_entropy": 1.872238796854776, "alpha_loss": 0.007519059644509402, "alpha_value": 0.005515936757913705, "duration": 3.8672025203704834, "step": 63125}
{"episode_reward": 119.9469797817914, "episode": 506.0, "batch_reward": 0.7243249568939208, "critic_loss": 2.3031473631858828, "actor_loss": -69.78370321950605, "actor_target_entropy": -1.0, "actor_entropy": 1.8922227621078491, "alpha_loss": 0.0072306971621489335, "alpha_value": 0.005488983298566977, "duration": 3.8598523139953613, "step": 63250}
{"episode_reward": 208.58603505082897, "episode": 507.0, "batch_reward": 0.7219136147499084, "critic_loss": 2.1853808317184447, "actor_loss": -69.81514037601532, "actor_target_entropy": -1.0, "actor_entropy": 1.9422847221768091, "alpha_loss": 0.006995074872282289, "alpha_value": 0.005462808077967274, "duration": 3.858743667602539, "step": 63375}
{"episode_reward": 99.00979922883201, "episode": 508.0, "batch_reward": 0.7144311327934265, "critic_loss": 2.1675700559616087, "actor_loss": -69.83057009789252, "actor_target_entropy": -1.0, "actor_entropy": 2.020914735332612, "alpha_loss": 0.0062400096081077095, "alpha_value": 0.005437948717860717, "duration": 3.865009307861328, "step": 63500}
{"episode_reward": 37.53838364869168, "episode": 509.0, "batch_reward": 0.7326024913787842, "critic_loss": 2.351444053649902, "actor_loss": -69.8870611039419, "actor_target_entropy": -1.0, "actor_entropy": 2.0962319601149786, "alpha_loss": 0.005412005664159854, "alpha_value": 0.005416115960748011, "duration": 3.8642749786376953, "step": 63625}
{"episode_reward": 184.40829092661406, "episode": 510.0, "batch_reward": 0.7231306252479553, "critic_loss": 2.286967420578003, "actor_loss": -69.922668087867, "actor_target_entropy": -1.0, "actor_entropy": 2.1946389136775846, "alpha_loss": 0.004464505826153101, "alpha_value": 0.0053973034109524995, "duration": 3.8571202754974365, "step": 63750}
{"episode_reward": 134.32658697958215, "episode": 511.0, "batch_reward": 0.7093850231170654, "critic_loss": 2.168103416442871, "actor_loss": -69.94147091820126, "actor_target_entropy": -1.0, "actor_entropy": 2.2638461854722767, "alpha_loss": 0.003423324782430889, "alpha_value": 0.005381839666891658, "duration": 3.8605034351348877, "step": 63875}
{"episode_reward": 178.94205224901035, "episode": 512.0, "batch_reward": 0.7292909488677979, "critic_loss": 2.261241255760193, "actor_loss": -70.00152095671623, "actor_target_entropy": -1.0, "actor_entropy": 2.300264773830291, "alpha_loss": 0.003304325032889122, "alpha_value": 0.005368192907839548, "duration": 3.8628804683685303, "step": 64000}
{"episode_reward": 178.78160236322094, "episode": 513.0, "batch_reward": 0.7313398704528808, "critic_loss": 2.2518367948532103, "actor_loss": -70.03565276615204, "actor_target_entropy": -1.0, "actor_entropy": 2.3408382052466985, "alpha_loss": 0.002445120616660764, "alpha_value": 0.005356632554812915, "duration": 3.8696765899658203, "step": 64125}
{"episode_reward": 74.44523201737769, "episode": 514.0, "batch_reward": 0.727387713432312, "critic_loss": 2.2411926012039185, "actor_loss": -70.06376426450667, "actor_target_entropy": -1.0, "actor_entropy": 2.3547207155535297, "alpha_loss": 0.0024822334911028345, "alpha_value": 0.005346187650348378, "duration": 3.8506886959075928, "step": 64250}
{"episode_reward": 68.61225495794834, "episode": 515.0, "batch_reward": 0.7231551637649536, "critic_loss": 2.250130171775818, "actor_loss": -70.10161578466021, "actor_target_entropy": -1.0, "actor_entropy": 2.3835043377346463, "alpha_loss": 0.0020465776989502566, "alpha_value": 0.005336412817749521, "duration": 3.869189500808716, "step": 64375}
{"episode_reward": 145.44101893923337, "episode": 516.0, "batch_reward": 0.7186041159629821, "critic_loss": 2.2339631323814393, "actor_loss": -70.13057573380009, "actor_target_entropy": -1.0, "actor_entropy": 2.4038928554904078, "alpha_loss": 0.0015930781305688734, "alpha_value": 0.005328520256354472, "duration": 3.858987808227539, "step": 64500}
{"episode_reward": 110.09589167046576, "episode": 517.0, "batch_reward": 0.719080180644989, "critic_loss": 2.169802716255188, "actor_loss": -70.18600282214936, "actor_target_entropy": -1.0, "actor_entropy": 2.4377994234599765, "alpha_loss": 0.0009046605757450581, "alpha_value": 0.005322626941253069, "duration": 3.8702774047851562, "step": 64625}
{"episode_reward": 121.87739285268835, "episode": 518.0, "batch_reward": 0.7143933682441711, "critic_loss": 2.1737791118621828, "actor_loss": -70.2133209474625, "actor_target_entropy": -1.0, "actor_entropy": 2.470118676462481, "alpha_loss": 0.00046770055914455426, "alpha_value": 0.0053197006007432174, "duration": 3.8651883602142334, "step": 64750}
{"episode_reward": 157.89496159257035, "episode": 519.0, "batch_reward": 0.7310681295394897, "critic_loss": 2.251525402069092, "actor_loss": -70.26495034354073, "actor_target_entropy": -1.0, "actor_entropy": 2.485151593647306, "alpha_loss": 0.0002583929082094174, "alpha_value": 0.00531760645175143, "duration": 3.870056390762329, "step": 64875}
{"episode_reward": 82.47433212374963, "episode": 520.0, "batch_reward": 0.7263167719841004, "critic_loss": 2.2160303955078127, "actor_loss": -70.2885871394988, "actor_target_entropy": -1.0, "actor_entropy": 2.4953816936862085, "alpha_loss": -2.6319773056574406e-05, "alpha_value": 0.005317663371498685, "duration": 3.8685271739959717, "step": 65000}
{"episode_reward": 141.38553933921497, "episode": 521.0, "batch_reward": 0.7236591396331787, "critic_loss": 2.2025109663009643, "actor_loss": -70.33041745140439, "actor_target_entropy": -1.0, "actor_entropy": 2.499280339195615, "alpha_loss": -5.896146860091932e-06, "alpha_value": 0.005316982800461485, "duration": 3.860208749771118, "step": 65125}
{"episode_reward": 181.72577788255208, "episode": 522.0, "batch_reward": 0.7247385363578797, "critic_loss": 2.2005545043945314, "actor_loss": -70.36817058440178, "actor_target_entropy": -1.0, "actor_entropy": 2.5016454573600524, "alpha_loss": -7.792066894434092e-05, "alpha_value": 0.005317487238504897, "duration": 3.866055965423584, "step": 65250}
{"episode_reward": 165.87705722392786, "episode": 523.0, "batch_reward": 0.737123342037201, "critic_loss": 2.3110385036468504, "actor_loss": -70.42039949931795, "actor_target_entropy": -1.0, "actor_entropy": 2.496502467564174, "alpha_loss": 4.296498105210799e-05, "alpha_value": 0.0053175360885130765, "duration": 3.8535804748535156, "step": 65375}
{"episode_reward": 85.24745530939498, "episode": 524.0, "batch_reward": 0.7087952933311462, "critic_loss": 2.131090372085571, "actor_loss": -70.44379658852854, "actor_target_entropy": -1.0, "actor_entropy": 2.507751234116093, "alpha_loss": -9.210525721784742e-05, "alpha_value": 0.005317344945689737, "duration": 3.849090337753296, "step": 65500}
{"episode_reward": 161.56536276859657, "episode": 525.0, "batch_reward": 0.7435106439590454, "critic_loss": 2.311476767539978, "actor_loss": -70.52010563441685, "actor_target_entropy": -1.0, "actor_entropy": 2.529174214317685, "alpha_loss": -0.0006198148487509037, "alpha_value": 0.0053197713407678844, "duration": 3.857900381088257, "step": 65625}
{"episode_reward": 193.01763222973935, "episode": 526.0, "batch_reward": 0.7435799012184143, "critic_loss": 2.357629147529602, "actor_loss": -70.60149235879221, "actor_target_entropy": -1.0, "actor_entropy": 2.5684760770490094, "alpha_loss": -0.0011684627768831447, "alpha_value": 0.005325052541613372, "duration": 3.8552815914154053, "step": 65750}
{"episode_reward": 161.105390889042, "episode": 527.0, "batch_reward": 0.7297623617649078, "critic_loss": 2.2609753894805906, "actor_loss": -70.62740325927734, "actor_target_entropy": -1.0, "actor_entropy": 2.60839173150441, "alpha_loss": -0.0018908719186641512, "alpha_value": 0.00533442433243621, "duration": 3.8671576976776123, "step": 65875}
{"episode_reward": 196.2563506426108, "episode": 528.0, "batch_reward": 0.7409450573921204, "critic_loss": 2.432387840270996, "actor_loss": -70.71386398807648, "actor_target_entropy": -1.0, "actor_entropy": 2.6354587924095894, "alpha_loss": -0.0025200677060169137, "alpha_value": 0.0053478779557025145, "duration": 3.8530397415161133, "step": 66000}
{"episode_reward": 170.6058122787814, "episode": 529.0, "batch_reward": 0.7365203537940979, "critic_loss": 2.2675169277191163, "actor_loss": -70.76293981642951, "actor_target_entropy": -1.0, "actor_entropy": 2.664477545117575, "alpha_loss": -0.003282648653516339, "alpha_value": 0.005366302670811675, "duration": 3.8600051403045654, "step": 66125}
{"episode_reward": 94.14575836924507, "episode": 530.0, "batch_reward": 0.7352156729698182, "critic_loss": 2.181726474761963, "actor_loss": -70.82701849168346, "actor_target_entropy": -1.0, "actor_entropy": 2.6831003927415416, "alpha_loss": -0.0036736555442574525, "alpha_value": 0.0053886930538745445, "duration": 3.8464293479919434, "step": 66250}
{"episode_reward": 142.48926932386428, "episode": 531.0, "batch_reward": 0.7558524885177612, "critic_loss": 2.316908715248108, "actor_loss": -70.93089754619295, "actor_target_entropy": -1.0, "actor_entropy": 2.712491035461426, "alpha_loss": -0.00402054005849456, "alpha_value": 0.0054144925863922645, "duration": 3.8640224933624268, "step": 66375}
{"episode_reward": 194.20156544499565, "episode": 532.0, "batch_reward": 0.7237533221244812, "critic_loss": 2.2167054681777953, "actor_loss": -70.95615202380765, "actor_target_entropy": -1.0, "actor_entropy": 2.7297985784469114, "alpha_loss": -0.004796659935363418, "alpha_value": 0.0054443110649928525, "duration": 3.8588314056396484, "step": 66500}
{"episode_reward": 223.27691713636935, "episode": 533.0, "batch_reward": 0.7345155987739563, "critic_loss": 2.3321581172943113, "actor_loss": -71.04214404878162, "actor_target_entropy": -1.0, "actor_entropy": 2.7537702984280057, "alpha_loss": -0.0051887954551992676, "alpha_value": 0.005477440072465272, "duration": 3.8443403244018555, "step": 66625}
{"episode_reward": 148.3666189804987, "episode": 534.0, "batch_reward": 0.741347154378891, "critic_loss": 2.2723230476379395, "actor_loss": -71.1203498840332, "actor_target_entropy": -1.0, "actor_entropy": 2.779676837305869, "alpha_loss": -0.006091449276408961, "alpha_value": 0.005515875418600231, "duration": 3.842810869216919, "step": 66750}
{"episode_reward": 153.80426012780816, "episode": 535.0, "batch_reward": 0.7511477484703064, "critic_loss": 2.361132953643799, "actor_loss": -71.22083960639105, "actor_target_entropy": -1.0, "actor_entropy": 2.7967751063997786, "alpha_loss": -0.006502440339693475, "alpha_value": 0.005559633850710711, "duration": 3.841481924057007, "step": 66875}
{"episode_reward": 166.79016051850135, "episode": 536.0, "batch_reward": 0.7379402770996094, "critic_loss": 2.268761263847351, "actor_loss": -71.2771229897776, "actor_target_entropy": -1.0, "actor_entropy": 2.8152517964763026, "alpha_loss": -0.006867972503025685, "alpha_value": 0.005603196007653931, "duration": 3.839542865753174, "step": 67000}
{"episode_reward": 74.76052917607501, "episode": 537.0, "batch_reward": 0.7435537371635437, "critic_loss": 2.2463417921066284, "actor_loss": -71.35452863905165, "actor_target_entropy": -1.0, "actor_entropy": 2.8282048058888267, "alpha_loss": -0.007238733504588406, "alpha_value": 0.005649535810687365, "duration": 3.8470234870910645, "step": 67125}
{"episode_reward": 202.30353064527193, "episode": 538.0, "batch_reward": 0.7473562350273132, "critic_loss": 2.3901675825119018, "actor_loss": -71.44187902635143, "actor_target_entropy": -1.0, "actor_entropy": 2.841768587789228, "alpha_loss": -0.00706429437794272, "alpha_value": 0.005694953953921205, "duration": 3.8377177715301514, "step": 67250}
{"episode_reward": 192.70030893093858, "episode": 539.0, "batch_reward": 0.7387726349830628, "critic_loss": 2.2463666925430297, "actor_loss": -71.52198997376458, "actor_target_entropy": -1.0, "actor_entropy": 2.8675668958633667, "alpha_loss": -0.007938434055725497, "alpha_value": 0.005741469322817204, "duration": 3.8408970832824707, "step": 67375}
{"episode_reward": 216.33625880901664, "episode": 540.0, "batch_reward": 0.7553516211509704, "critic_loss": 2.361415717124939, "actor_loss": -71.60318682270665, "actor_target_entropy": -1.0, "actor_entropy": 2.8799304962158203, "alpha_loss": -0.008572364646580911, "alpha_value": 0.0057929129749598185, "duration": 3.838428497314453, "step": 67500}
{"episode_reward": 181.8891755328517, "episode": 541.0, "batch_reward": 0.7549957187175751, "critic_loss": 2.357003812789917, "actor_loss": -71.7020268515935, "actor_target_entropy": -1.0, "actor_entropy": 2.8895681472051713, "alpha_loss": -0.008572932983201647, "alpha_value": 0.005844410468129573, "duration": 3.8472373485565186, "step": 67625}
{"episode_reward": 115.48344243624554, "episode": 542.0, "batch_reward": 0.7510222988128662, "critic_loss": 2.2885149936676026, "actor_loss": -71.81144099081716, "actor_target_entropy": -1.0, "actor_entropy": 2.912947254796182, "alpha_loss": -0.009816052009081167, "alpha_value": 0.005897812269962354, "duration": 3.8371832370758057, "step": 67750}
{"episode_reward": 164.5855747774524, "episode": 543.0, "batch_reward": 0.752566918373108, "critic_loss": 2.4144885387420656, "actor_loss": -71.90623643663194, "actor_target_entropy": -1.0, "actor_entropy": 2.936449338519384, "alpha_loss": -0.010293392501475792, "alpha_value": 0.005955817359812415, "duration": 3.8443562984466553, "step": 67875}
{"episode_reward": 205.93145344849566, "episode": 544.0, "batch_reward": 0.7482692642211914, "critic_loss": 2.2868435506820677, "actor_loss": -71.99143661991242, "actor_target_entropy": -1.0, "actor_entropy": 2.949645919184531, "alpha_loss": -0.010952930649622314, "alpha_value": 0.006012754040474608, "duration": 3.8338727951049805, "step": 68000}
{"episode_reward": 162.10768697766218, "episode": 545.0, "batch_reward": 0.7491228675842285, "critic_loss": 2.420392074584961, "actor_loss": -72.06917559911334, "actor_target_entropy": -1.0, "actor_entropy": 2.968221376812647, "alpha_loss": -0.010976763301721168, "alpha_value": 0.006070207421589561, "duration": 3.8404541015625, "step": 68125}
{"episode_reward": 183.1200380829513, "episode": 546.0, "batch_reward": 0.7411462507247925, "critic_loss": 2.3596069555282595, "actor_loss": -72.16255471014208, "actor_target_entropy": -1.0, "actor_entropy": 2.9812756507627425, "alpha_loss": -0.01148317098587511, "alpha_value": 0.006127603491094735, "duration": 3.8371195793151855, "step": 68250}
{"episode_reward": 105.79287289921517, "episode": 547.0, "batch_reward": 0.7633499040603637, "critic_loss": 2.409231191635132, "actor_loss": -72.28348432268415, "actor_target_entropy": -1.0, "actor_entropy": 2.993538084484282, "alpha_loss": -0.012099637154726282, "alpha_value": 0.006184904023263639, "duration": 3.8424429893493652, "step": 68375}
{"episode_reward": 177.13180099910832, "episode": 548.0, "batch_reward": 0.7576575665473938, "critic_loss": 2.388244055747986, "actor_loss": -72.3918812659479, "actor_target_entropy": -1.0, "actor_entropy": 3.004244604418355, "alpha_loss": -0.012572044912245004, "alpha_value": 0.006244191050631002, "duration": 3.8330538272857666, "step": 68500}
{"episode_reward": 196.3954331560733, "episode": 549.0, "batch_reward": 0.779235746383667, "critic_loss": 2.500492314338684, "actor_loss": -72.49430023677765, "actor_target_entropy": -1.0, "actor_entropy": 3.0176725690326993, "alpha_loss": -0.012539392736341273, "alpha_value": 0.00630172203334804, "duration": 3.83390212059021, "step": 68625}
{"episode_reward": 162.9101805707014, "episode": 550.0, "batch_reward": 0.7640659995079041, "critic_loss": 2.426630648612976, "actor_loss": -72.59121900989163, "actor_target_entropy": -1.0, "actor_entropy": 3.0261214317814, "alpha_loss": -0.013589698032686306, "alpha_value": 0.00635993261095658, "duration": 3.837233543395996, "step": 68750}
{"episode_reward": 229.64589681428706, "episode": 551.0, "batch_reward": 0.7540513954162598, "critic_loss": 2.322264030456543, "actor_loss": -72.67073131742931, "actor_target_entropy": -1.0, "actor_entropy": 3.0292380348084467, "alpha_loss": -0.013635577323536078, "alpha_value": 0.006419019907338622, "duration": 3.838632345199585, "step": 68875}
{"episode_reward": 194.75428348540922, "episode": 552.0, "batch_reward": 0.7565465455055237, "critic_loss": 2.4185138397216797, "actor_loss": -72.77402484032416, "actor_target_entropy": -1.0, "actor_entropy": 3.036435742532053, "alpha_loss": -0.014598927393014874, "alpha_value": 0.006478818494879612, "duration": 3.8352086544036865, "step": 69000}
{"episode_reward": 129.20006449937114, "episode": 553.0, "batch_reward": 0.7563146090507508, "critic_loss": 2.349238218307495, "actor_loss": -72.91042230999659, "actor_target_entropy": -1.0, "actor_entropy": 3.0480715282379633, "alpha_loss": -0.014828880435772358, "alpha_value": 0.006538124141919481, "duration": 3.847276449203491, "step": 69125}
{"episode_reward": 148.36546441038107, "episode": 554.0, "batch_reward": 0.7754000773429871, "critic_loss": 2.4031909189224243, "actor_loss": -73.02828684160787, "actor_target_entropy": -1.0, "actor_entropy": 3.062965270011656, "alpha_loss": -0.01494782482604346, "alpha_value": 0.00659766007695429, "duration": 3.8292665481567383, "step": 69250}
{"episode_reward": 72.23774279448327, "episode": 555.0, "batch_reward": 0.7629098258018494, "critic_loss": 2.35453692150116, "actor_loss": -73.12164137098524, "actor_target_entropy": -1.0, "actor_entropy": 3.071472652374752, "alpha_loss": -0.014936373761248968, "alpha_value": 0.0066558966152930315, "duration": 3.8437509536743164, "step": 69375}
{"episode_reward": 122.97151800855768, "episode": 556.0, "batch_reward": 0.7704817042350769, "critic_loss": 2.375801095962524, "actor_loss": -73.24745436637632, "actor_target_entropy": -1.0, "actor_entropy": 3.074931836897327, "alpha_loss": -0.016265457646260337, "alpha_value": 0.006715264172432123, "duration": 3.8375649452209473, "step": 69500}
{"episode_reward": 153.86199439180467, "episode": 557.0, "batch_reward": 0.777779435634613, "critic_loss": 2.397647253036499, "actor_loss": -73.3581779116676, "actor_target_entropy": -1.0, "actor_entropy": 3.0806332996913364, "alpha_loss": -0.016298360472160673, "alpha_value": 0.006775248934243279, "duration": 3.843533992767334, "step": 69625}
{"episode_reward": 117.69321570880875, "episode": 558.0, "batch_reward": 0.774847891330719, "critic_loss": 2.4068550729751585, "actor_loss": -73.48654999271515, "actor_target_entropy": -1.0, "actor_entropy": 3.0887462246802544, "alpha_loss": -0.015748994094469854, "alpha_value": 0.006833682475516431, "duration": 3.8338401317596436, "step": 69750}
{"episode_reward": 192.7853960709395, "episode": 559.0, "batch_reward": 0.7560052585601806, "critic_loss": 2.383426052093506, "actor_loss": -73.59148770286923, "actor_target_entropy": -1.0, "actor_entropy": 3.0987141018822077, "alpha_loss": -0.01713172695229924, "alpha_value": 0.006891892511115382, "duration": 3.834188222885132, "step": 69875}
{"episode_reward": 58.93773058250143, "episode": 560.0, "batch_reward": 0.7661541213989258, "critic_loss": 2.4194316854476927, "actor_loss": -73.71445403560516, "actor_target_entropy": -1.0, "actor_entropy": 3.1097258906210623, "alpha_loss": -0.017735230466050488, "alpha_value": 0.006952105855994918, "duration": 3.837181568145752, "step": 70000}
{"episode_reward": 68.26024160904232, "episode": 561.0, "batch_reward": 0.7610515985488892, "critic_loss": 2.3383804292678834, "actor_loss": -73.79134344676184, "actor_target_entropy": -1.0, "actor_entropy": 3.119746662321545, "alpha_loss": -0.017872654729419284, "alpha_value": 0.00701172403096585, "duration": 7.81429648399353, "step": 70125}
{"episode_reward": 101.03793857763416, "episode": 562.0, "batch_reward": 0.7544388995170593, "critic_loss": 2.234233833312988, "actor_loss": -73.90596623574534, "actor_target_entropy": -1.0, "actor_entropy": 3.1233165648675736, "alpha_loss": -0.01850495182518517, "alpha_value": 0.007072825469414195, "duration": 3.8360402584075928, "step": 70250}
{"episode_reward": 177.4942134886849, "episode": 563.0, "batch_reward": 0.763884840965271, "critic_loss": 2.3141249971389772, "actor_loss": -74.02471996489025, "actor_target_entropy": -1.0, "actor_entropy": 3.1278817767188665, "alpha_loss": -0.019038137196311877, "alpha_value": 0.0071346233397850435, "duration": 3.8367700576782227, "step": 70375}
{"episode_reward": 51.30272027706211, "episode": 564.0, "batch_reward": 0.7515244941711425, "critic_loss": 2.3465229330062867, "actor_loss": -74.12177621164629, "actor_target_entropy": -1.0, "actor_entropy": 3.1291600504229145, "alpha_loss": -0.018696015084823294, "alpha_value": 0.007193988272789255, "duration": 3.8419301509857178, "step": 70500}
{"episode_reward": 125.31099517658059, "episode": 565.0, "batch_reward": 0.7643881139755249, "critic_loss": 2.316001788139343, "actor_loss": -74.22740524534196, "actor_target_entropy": -1.0, "actor_entropy": 3.1319366333976624, "alpha_loss": -0.01901491709230911, "alpha_value": 0.007253180844253994, "duration": 3.8408541679382324, "step": 70625}
{"episode_reward": 117.24898085621702, "episode": 566.0, "batch_reward": 0.7746718926429749, "critic_loss": 2.417320571899414, "actor_loss": -74.34727244223318, "actor_target_entropy": -1.0, "actor_entropy": 3.1366512852330364, "alpha_loss": -0.019379272185746702, "alpha_value": 0.007312842941723613, "duration": 3.8342738151550293, "step": 70750}
{"episode_reward": 132.68411175455523, "episode": 567.0, "batch_reward": 0.7815700249671936, "critic_loss": 2.4349012651443482, "actor_loss": -74.46496194506449, "actor_target_entropy": -1.0, "actor_entropy": 3.141613142830985, "alpha_loss": -0.019001611996264683, "alpha_value": 0.007370910461155012, "duration": 3.8407468795776367, "step": 70875}
{"episode_reward": 175.53022385259897, "episode": 568.0, "batch_reward": 0.7606903371810914, "critic_loss": 2.3557020092010497, "actor_loss": -74.55833102810767, "actor_target_entropy": -1.0, "actor_entropy": 3.1451926539021153, "alpha_loss": -0.020148168798656232, "alpha_value": 0.007430072971256157, "duration": 3.8351449966430664, "step": 71000}
{"episode_reward": 214.7116946371708, "episode": 569.0, "batch_reward": 0.7612571172714233, "critic_loss": 2.2929059162139893, "actor_loss": -74.6421881781684, "actor_target_entropy": -1.0, "actor_entropy": 3.1439153883192272, "alpha_loss": -0.019772934180403514, "alpha_value": 0.007489580014543826, "duration": 3.839231491088867, "step": 71125}
{"episode_reward": 190.17278608402933, "episode": 570.0, "batch_reward": 0.7562639455795288, "critic_loss": 2.3519283618927003, "actor_loss": -74.7361600322108, "actor_target_entropy": -1.0, "actor_entropy": 3.1447855580237603, "alpha_loss": -0.01956388469965708, "alpha_value": 0.0075475635032245525, "duration": 3.8343610763549805, "step": 71250}
{"episode_reward": 209.79650146723566, "episode": 571.0, "batch_reward": 0.7839495515823365, "critic_loss": 2.4246473293304445, "actor_loss": -74.87339722164093, "actor_target_entropy": -1.0, "actor_entropy": 3.1438056400844028, "alpha_loss": -0.01987395975147448, "alpha_value": 0.007605142869218331, "duration": 3.847715377807617, "step": 71375}
{"episode_reward": 118.88672126162587, "episode": 572.0, "batch_reward": 0.7731877326965332, "critic_loss": 2.396908805847168, "actor_loss": -74.96223941926033, "actor_target_entropy": -1.0, "actor_entropy": 3.139761232560681, "alpha_loss": -0.020068061583104632, "alpha_value": 0.007662916293102516, "duration": 3.8355724811553955, "step": 71500}
{"episode_reward": 85.25686511908616, "episode": 573.0, "batch_reward": 0.7670645561218262, "critic_loss": 2.3153465366363526, "actor_loss": -75.05711364746094, "actor_target_entropy": -1.0, "actor_entropy": 3.135656856355213, "alpha_loss": -0.01989838983567934, "alpha_value": 0.007720036904552327, "duration": 3.8520805835723877, "step": 71625}
{"episode_reward": 172.5917097924493, "episode": 574.0, "batch_reward": 0.7899337759017945, "critic_loss": 2.4635323095321655, "actor_loss": -75.20994309456118, "actor_target_entropy": -1.0, "actor_entropy": 3.130958341783093, "alpha_loss": -0.02121116617514241, "alpha_value": 0.007779028809399928, "duration": 3.8387417793273926, "step": 71750}
{"episode_reward": 202.655612483889, "episode": 575.0, "batch_reward": 0.7734669218063355, "critic_loss": 2.504595356941223, "actor_loss": -75.30061752077133, "actor_target_entropy": -1.0, "actor_entropy": 3.131998092409164, "alpha_loss": -0.019892099934319656, "alpha_value": 0.007837203332510078, "duration": 3.835634708404541, "step": 71875}
{"episode_reward": 133.53604801097788, "episode": 576.0, "batch_reward": 0.7717484221458435, "critic_loss": 2.3635927629470825, "actor_loss": -75.40379456550845, "actor_target_entropy": -1.0, "actor_entropy": 3.1383686988584456, "alpha_loss": -0.021058123964335648, "alpha_value": 0.007894705950624054, "duration": 3.840555429458618, "step": 72000}
{"episode_reward": 159.97896885539072, "episode": 577.0, "batch_reward": 0.7586712093353272, "critic_loss": 2.3696214733123777, "actor_loss": -75.46357920813182, "actor_target_entropy": -1.0, "actor_entropy": 3.139498650081574, "alpha_loss": -0.021396246236113328, "alpha_value": 0.007953599755043434, "duration": 3.8325958251953125, "step": 72125}
{"episode_reward": 201.13609107942605, "episode": 578.0, "batch_reward": 0.7720150828361512, "critic_loss": 2.3600182371139526, "actor_loss": -75.58905816847279, "actor_target_entropy": -1.0, "actor_entropy": 3.135100995340655, "alpha_loss": -0.02114572861201821, "alpha_value": 0.0080130595387382, "duration": 3.8379054069519043, "step": 72250}
{"episode_reward": 102.3667124745619, "episode": 579.0, "batch_reward": 0.7652698912620545, "critic_loss": 2.3730389385223387, "actor_loss": -75.69088515024336, "actor_target_entropy": -1.0, "actor_entropy": 3.1326898695930603, "alpha_loss": -0.021362777828933702, "alpha_value": 0.008071779156078731, "duration": 3.836014747619629, "step": 72375}
{"episode_reward": 80.54274694699717, "episode": 580.0, "batch_reward": 0.8022013792991638, "critic_loss": 2.5893974895477294, "actor_loss": -75.87818170362904, "actor_target_entropy": -1.0, "actor_entropy": 3.131536791401525, "alpha_loss": -0.02195389848202467, "alpha_value": 0.008131139043144251, "duration": 3.8353469371795654, "step": 72500}
{"episode_reward": 176.25299500941023, "episode": 581.0, "batch_reward": 0.7843587608337402, "critic_loss": 2.5044953317642213, "actor_loss": -75.97390904502264, "actor_target_entropy": -1.0, "actor_entropy": 3.1283604606749518, "alpha_loss": -0.022138193101873472, "alpha_value": 0.00819163681345896, "duration": 3.8427555561065674, "step": 72625}
{"episode_reward": 134.61808246993198, "episode": 582.0, "batch_reward": 0.7784844572544098, "critic_loss": 2.421969825744629, "actor_loss": -76.09529335268083, "actor_target_entropy": -1.0, "actor_entropy": 3.1324208474928334, "alpha_loss": -0.02193473509302543, "alpha_value": 0.008251271953563137, "duration": 3.8379127979278564, "step": 72750}
{"episode_reward": 211.87434653950504, "episode": 583.0, "batch_reward": 0.7696277856826782, "critic_loss": 2.4087687301635743, "actor_loss": -76.15093424963572, "actor_target_entropy": -1.0, "actor_entropy": 3.1358041460551913, "alpha_loss": -0.02196823764178488, "alpha_value": 0.008310548947988558, "duration": 3.8463242053985596, "step": 72875}
{"episode_reward": 164.43863537171296, "episode": 584.0, "batch_reward": 0.7862553791999817, "critic_loss": 2.408531869888306, "actor_loss": -76.28343840568296, "actor_target_entropy": -1.0, "actor_entropy": 3.133247390870125, "alpha_loss": -0.021799181317610127, "alpha_value": 0.008369634297742451, "duration": 3.828559160232544, "step": 73000}
{"episode_reward": 83.30241896318572, "episode": 585.0, "batch_reward": 0.7874704360961914, "critic_loss": 2.362342988014221, "actor_loss": -76.39112805563306, "actor_target_entropy": -1.0, "actor_entropy": 3.124481746128627, "alpha_loss": -0.022165206334893665, "alpha_value": 0.008429010762284778, "duration": 3.8425028324127197, "step": 73125}
{"episode_reward": 140.93539802522176, "episode": 586.0, "batch_reward": 0.7835707983970642, "critic_loss": 2.4053088555335997, "actor_loss": -76.4892210191296, "actor_target_entropy": -1.0, "actor_entropy": 3.1192560657378166, "alpha_loss": -0.022157070542415305, "alpha_value": 0.00848877852047539, "duration": 3.839134454727173, "step": 73250}
{"episode_reward": 171.1288880027758, "episode": 587.0, "batch_reward": 0.7771833653450012, "critic_loss": 2.414596124649048, "actor_loss": -76.5737784249442, "actor_target_entropy": -1.0, "actor_entropy": 3.1123464069669207, "alpha_loss": -0.0219266176933334, "alpha_value": 0.008548182121647556, "duration": 3.845594644546509, "step": 73375}
{"episode_reward": 103.81758850313388, "episode": 588.0, "batch_reward": 0.7811211800575256, "critic_loss": 2.398482757568359, "actor_loss": -76.67437042728547, "actor_target_entropy": -1.0, "actor_entropy": 3.1042322189577165, "alpha_loss": -0.02168149588209006, "alpha_value": 0.008606763789468641, "duration": 3.8488190174102783, "step": 73500}
{"episode_reward": 159.37227705049895, "episode": 589.0, "batch_reward": 0.7801183042526245, "critic_loss": 2.427426429748535, "actor_loss": -76.76782710968502, "actor_target_entropy": -1.0, "actor_entropy": 3.0962997618175687, "alpha_loss": -0.0225945326780516, "alpha_value": 0.008665043337571593, "duration": 3.841740608215332, "step": 73625}
{"episode_reward": 183.55256934180832, "episode": 590.0, "batch_reward": 0.7902814245223999, "critic_loss": 2.4670909156799317, "actor_loss": -76.86408996582031, "actor_target_entropy": -1.0, "actor_entropy": 3.0857023116080993, "alpha_loss": -0.021212538478956107, "alpha_value": 0.008724904724160409, "duration": 3.839702844619751, "step": 73750}
{"episode_reward": 120.89779998142454, "episode": 591.0, "batch_reward": 0.801323914051056, "critic_loss": 2.517101667404175, "actor_loss": -77.00781722295852, "actor_target_entropy": -1.0, "actor_entropy": 3.0654929933093844, "alpha_loss": -0.021476364073654015, "alpha_value": 0.00878150431687583, "duration": 3.8435773849487305, "step": 73875}
{"episode_reward": 83.35604174850326, "episode": 592.0, "batch_reward": 0.7775761556625366, "critic_loss": 2.3613175344467163, "actor_loss": -77.09208125452841, "actor_target_entropy": -1.0, "actor_entropy": 3.0570314007420696, "alpha_loss": -0.021664022558158445, "alpha_value": 0.008839172727322864, "duration": 3.835740804672241, "step": 74000}
{"episode_reward": 198.62957705425228, "episode": 593.0, "batch_reward": 0.7884910917282104, "critic_loss": 2.5111855001449586, "actor_loss": -77.2108159140935, "actor_target_entropy": -1.0, "actor_entropy": 3.041088679480174, "alpha_loss": -0.02147195843004045, "alpha_value": 0.008897173365738559, "duration": 3.836559534072876, "step": 74125}
{"episode_reward": 79.89781093807159, "episode": 594.0, "batch_reward": 0.7950673551559448, "critic_loss": 2.467493559837341, "actor_loss": -77.3027584937311, "actor_target_entropy": -1.0, "actor_entropy": 3.024997541981359, "alpha_loss": -0.02070843219576824, "alpha_value": 0.008954575762800142, "duration": 3.8381142616271973, "step": 74250}
{"episode_reward": 68.68855008363437, "episode": 595.0, "batch_reward": 0.7690123314857483, "critic_loss": 2.31299742603302, "actor_loss": -77.36607942127046, "actor_target_entropy": -1.0, "actor_entropy": 3.021109081449963, "alpha_loss": -0.019924960616562102, "alpha_value": 0.009010162193463036, "duration": 3.8454651832580566, "step": 74375}
{"episode_reward": 196.76560080300246, "episode": 596.0, "batch_reward": 0.7963088855743409, "critic_loss": 2.4208879261016847, "actor_loss": -77.4941883702432, "actor_target_entropy": -1.0, "actor_entropy": 3.0149762553553425, "alpha_loss": -0.02103062037138208, "alpha_value": 0.00906637874048611, "duration": 3.8335556983947754, "step": 74500}
{"episode_reward": 166.79556358063815, "episode": 597.0, "batch_reward": 0.80625834274292, "critic_loss": 2.4677465829849243, "actor_loss": -77.60102166069879, "actor_target_entropy": -1.0, "actor_entropy": 3.003211626930842, "alpha_loss": -0.021142434077485214, "alpha_value": 0.009123978515326356, "duration": 3.8482751846313477, "step": 74625}
{"episode_reward": 143.60743809284884, "episode": 598.0, "batch_reward": 0.7828401174545289, "critic_loss": 2.443991590499878, "actor_loss": -77.66200539373583, "actor_target_entropy": -1.0, "actor_entropy": 2.991683913815406, "alpha_loss": -0.02029658406372032, "alpha_value": 0.009181915050124653, "duration": 3.83217716217041, "step": 74750}
{"episode_reward": 55.20614904807153, "episode": 599.0, "batch_reward": 0.7949710230827332, "critic_loss": 2.42470481967926, "actor_loss": -77.77942257835751, "actor_target_entropy": -1.0, "actor_entropy": 2.9764650889805386, "alpha_loss": -0.020477666490016474, "alpha_value": 0.009237555006154557, "duration": 3.837397336959839, "step": 74875}
{"episode_reward": 166.42310234618077, "episode": 600.0, "batch_reward": 0.7897840309143066, "critic_loss": 2.4052221336364745, "actor_loss": -77.87983863584456, "actor_target_entropy": -1.0, "actor_entropy": 2.9557867203989336, "alpha_loss": -0.019314203967129993, "alpha_value": 0.00929466788330734, "duration": 3.839339256286621, "step": 75000}
{"episode_reward": 98.88411328700445, "episode": 601.0, "batch_reward": 0.7935002160072326, "critic_loss": 2.5163263750076292, "actor_loss": -77.97472938658699, "actor_target_entropy": -1.0, "actor_entropy": 2.94735466487824, "alpha_loss": -0.019172566809824536, "alpha_value": 0.009348397394761504, "duration": 3.8470916748046875, "step": 75125}
{"episode_reward": 114.74003608897236, "episode": 602.0, "batch_reward": 0.793792580127716, "critic_loss": 2.479701962471008, "actor_loss": -78.0563577221286, "actor_target_entropy": -1.0, "actor_entropy": 2.9244683173394974, "alpha_loss": -0.01921419934519837, "alpha_value": 0.009403053574229513, "duration": 3.8350045680999756, "step": 75250}
{"episode_reward": 120.88980677983217, "episode": 603.0, "batch_reward": 0.7757030181884765, "critic_loss": 2.4217185802459715, "actor_loss": -78.13262188623823, "actor_target_entropy": -1.0, "actor_entropy": 2.898241255018446, "alpha_loss": -0.018435938978597285, "alpha_value": 0.009457916454190498, "duration": 3.8425185680389404, "step": 75375}
{"episode_reward": 193.63647883959658, "episode": 604.0, "batch_reward": 0.7879877939224244, "critic_loss": 2.379972751617432, "actor_loss": -78.23280703636908, "actor_target_entropy": -1.0, "actor_entropy": 2.8751777372052594, "alpha_loss": -0.017841772596922614, "alpha_value": 0.00951001878780507, "duration": 3.827528476715088, "step": 75500}
{"episode_reward": 30.608919822185623, "episode": 605.0, "batch_reward": 0.7837715539932251, "critic_loss": 2.3172818393707275, "actor_loss": -78.29696885366289, "actor_target_entropy": -1.0, "actor_entropy": 2.854036422002883, "alpha_loss": -0.017358539300778554, "alpha_value": 0.009561742873524981, "duration": 3.8397765159606934, "step": 75625}
{"episode_reward": 153.0172134118479, "episode": 606.0, "batch_reward": 0.7898162355422974, "critic_loss": 2.4457457427978517, "actor_loss": -78.3944337906376, "actor_target_entropy": -1.0, "actor_entropy": 2.844888456406132, "alpha_loss": -0.01730473985474917, "alpha_value": 0.00961358623875875, "duration": 3.8374459743499756, "step": 75750}
{"episode_reward": 138.7408320985273, "episode": 607.0, "batch_reward": 0.7851024599075317, "critic_loss": 2.462421417236328, "actor_loss": -78.47518521263486, "actor_target_entropy": -1.0, "actor_entropy": 2.8233305461822993, "alpha_loss": -0.01750266571189203, "alpha_value": 0.009665660950482527, "duration": 3.847458839416504, "step": 75875}
{"episode_reward": 115.53257227481717, "episode": 608.0, "batch_reward": 0.7869191045761108, "critic_loss": 2.3301992216110228, "actor_loss": -78.55596050139397, "actor_target_entropy": -1.0, "actor_entropy": 2.8201198731699297, "alpha_loss": -0.016075852927902052, "alpha_value": 0.0097173568584485, "duration": 3.8373186588287354, "step": 76000}
{"episode_reward": 73.7255609924113, "episode": 609.0, "batch_reward": 0.7999350514411926, "critic_loss": 2.4060459156036376, "actor_loss": -78.68957979716951, "actor_target_entropy": -1.0, "actor_entropy": 2.8107588329012434, "alpha_loss": -0.017103860080833474, "alpha_value": 0.009768128344525926, "duration": 3.8445703983306885, "step": 76125}
{"episode_reward": 198.73657272867754, "episode": 610.0, "batch_reward": 0.7848770442008972, "critic_loss": 2.3908763189315794, "actor_loss": -78.74827181908393, "actor_target_entropy": -1.0, "actor_entropy": 2.784054463909518, "alpha_loss": -0.016281658558235053, "alpha_value": 0.009821206853486638, "duration": 3.836601495742798, "step": 76250}
{"episode_reward": 112.56279678025325, "episode": 611.0, "batch_reward": 0.7818043375015259, "critic_loss": 2.3093548107147215, "actor_loss": -78.84928470187717, "actor_target_entropy": -1.0, "actor_entropy": 2.7699921017601374, "alpha_loss": -0.016095471878846485, "alpha_value": 0.009873215394884548, "duration": 3.843531370162964, "step": 76375}
{"episode_reward": 166.0021546559346, "episode": 612.0, "batch_reward": 0.7955430498123169, "critic_loss": 2.429832592964172, "actor_loss": -78.96279021232358, "actor_target_entropy": -1.0, "actor_entropy": 2.7356027326276227, "alpha_loss": -0.01550500700250268, "alpha_value": 0.009923148813824497, "duration": 3.8389930725097656, "step": 76500}
{"episode_reward": 139.30928058629428, "episode": 613.0, "batch_reward": 0.7949577097892762, "critic_loss": 2.5265615167617796, "actor_loss": -79.06084514799572, "actor_target_entropy": -1.0, "actor_entropy": 2.723587596227252, "alpha_loss": -0.01561167309178956, "alpha_value": 0.009974672085321929, "duration": 3.8437108993530273, "step": 76625}
{"episode_reward": 149.9856211534979, "episode": 614.0, "batch_reward": 0.7863246774673462, "critic_loss": 2.3552250385284426, "actor_loss": -79.14266044862809, "actor_target_entropy": -1.0, "actor_entropy": 2.709079311740014, "alpha_loss": -0.015692338114604354, "alpha_value": 0.010025886888132713, "duration": 3.8359124660491943, "step": 76750}
{"episode_reward": 100.05222195079851, "episode": 615.0, "batch_reward": 0.8078545331954956, "critic_loss": 2.46502085018158, "actor_loss": -79.2550295875186, "actor_target_entropy": -1.0, "actor_entropy": 2.692657531253875, "alpha_loss": -0.014052805409485858, "alpha_value": 0.01007615752623297, "duration": 3.8427774906158447, "step": 76875}
{"episode_reward": 145.57024839778472, "episode": 616.0, "batch_reward": 0.8002455406188965, "critic_loss": 2.5255288619995118, "actor_loss": -79.34939538278887, "actor_target_entropy": -1.0, "actor_entropy": 2.6914886505373063, "alpha_loss": -0.015493375354356343, "alpha_value": 0.010126828768170214, "duration": 3.8295071125030518, "step": 77000}
{"episode_reward": 73.94893471279232, "episode": 617.0, "batch_reward": 0.7907228169441223, "critic_loss": 2.4513348064422606, "actor_loss": -79.42362733871218, "actor_target_entropy": -1.0, "actor_entropy": 2.6954842067900158, "alpha_loss": -0.01509540125225035, "alpha_value": 0.010178575122984451, "duration": 3.842029571533203, "step": 77125}
{"episode_reward": 132.72573089649464, "episode": 618.0, "batch_reward": 0.806713900566101, "critic_loss": 2.479008790016174, "actor_loss": -79.51360850180349, "actor_target_entropy": -1.0, "actor_entropy": 2.6751780202311854, "alpha_loss": -0.015298707365629173, "alpha_value": 0.010233568351568604, "duration": 3.8372344970703125, "step": 77250}
{"episode_reward": 195.29889469619133, "episode": 619.0, "batch_reward": 0.7947550435066223, "critic_loss": 2.4890717334747317, "actor_loss": -79.6177976093595, "actor_target_entropy": -1.0, "actor_entropy": 2.662787301199777, "alpha_loss": -0.015114792097832948, "alpha_value": 0.010287601952628308, "duration": 3.83750057220459, "step": 77375}
{"episode_reward": 191.94127616391344, "episode": 620.0, "batch_reward": 0.8014593272209167, "critic_loss": 2.4665012111663818, "actor_loss": -79.70898326750725, "actor_target_entropy": -1.0, "actor_entropy": 2.640159576169906, "alpha_loss": -0.015045899680004485, "alpha_value": 0.010342021520701714, "duration": 3.838010549545288, "step": 77500}
{"episode_reward": 191.73908793066028, "episode": 621.0, "batch_reward": 0.8074134635925293, "critic_loss": 2.4508787517547606, "actor_loss": -79.80120050339471, "actor_target_entropy": -1.0, "actor_entropy": 2.6285521794879245, "alpha_loss": -0.015846137748292043, "alpha_value": 0.010397809350895773, "duration": 3.8368499279022217, "step": 77625}
{"episode_reward": 111.87789844759673, "episode": 622.0, "batch_reward": 0.8039518313407898, "critic_loss": 2.4577315425872803, "actor_loss": -79.89894830026934, "actor_target_entropy": -1.0, "actor_entropy": 2.603954053694202, "alpha_loss": -0.014463313269398866, "alpha_value": 0.010454025498035795, "duration": 3.8347551822662354, "step": 77750}
{"episode_reward": 145.1664831441267, "episode": 623.0, "batch_reward": 0.7952520389556885, "critic_loss": 2.3530347146987913, "actor_loss": -79.99467468261719, "actor_target_entropy": -1.0, "actor_entropy": 2.5660436569698275, "alpha_loss": -0.014212628072571187, "alpha_value": 0.010507674161856531, "duration": 3.844010829925537, "step": 77875}
{"episode_reward": 175.9668738371288, "episode": 624.0, "batch_reward": 0.7995219459533691, "critic_loss": 2.4977652225494387, "actor_loss": -80.07551316292056, "actor_target_entropy": -1.0, "actor_entropy": 2.535443582842427, "alpha_loss": -0.01353967674977837, "alpha_value": 0.010560321405208293, "duration": 3.833559989929199, "step": 78000}
{"episode_reward": 124.70870507983793, "episode": 625.0, "batch_reward": 0.8100829186439514, "critic_loss": 2.4768173828125, "actor_loss": -80.20468066987537, "actor_target_entropy": -1.0, "actor_entropy": 2.5093156420995317, "alpha_loss": -0.014204614411389071, "alpha_value": 0.010615253934222609, "duration": 3.836064338684082, "step": 78125}
{"episode_reward": 112.19929990453288, "episode": 626.0, "batch_reward": 0.7920243520736694, "critic_loss": 2.3717275762557986, "actor_loss": -80.2855110168457, "actor_target_entropy": -1.0, "actor_entropy": 2.471656184042654, "alpha_loss": -0.013585584320788902, "alpha_value": 0.010668594702310484, "duration": 3.8434431552886963, "step": 78250}
{"episode_reward": 90.84938111899233, "episode": 627.0, "batch_reward": 0.793027355670929, "critic_loss": 2.4072240533828735, "actor_loss": -80.38117169576978, "actor_target_entropy": -1.0, "actor_entropy": 2.4335024546063138, "alpha_loss": -0.013078622741713411, "alpha_value": 0.010722086001508315, "duration": 3.8407554626464844, "step": 78375}
{"episode_reward": 132.48849796326525, "episode": 628.0, "batch_reward": 0.8108920888900757, "critic_loss": 2.479916275024414, "actor_loss": -80.45177890408424, "actor_target_entropy": -1.0, "actor_entropy": 2.411649703979492, "alpha_loss": -0.014328195931269758, "alpha_value": 0.010775826764263578, "duration": 3.8430168628692627, "step": 78500}
{"episode_reward": 167.90902440223022, "episode": 629.0, "batch_reward": 0.8217595362663269, "critic_loss": 2.548263472557068, "actor_loss": -80.58976612393818, "actor_target_entropy": -1.0, "actor_entropy": 2.3790470607697016, "alpha_loss": -0.013354872870776389, "alpha_value": 0.010833790334503287, "duration": 3.842650890350342, "step": 78625}
{"episode_reward": 94.66556117064019, "episode": 630.0, "batch_reward": 0.7987430119514465, "critic_loss": 2.3711793842315676, "actor_loss": -80.68264868951613, "actor_target_entropy": -1.0, "actor_entropy": 2.3091835668010097, "alpha_loss": -0.012594576294143353, "alpha_value": 0.010887632757647262, "duration": 3.8392891883850098, "step": 78750}
{"episode_reward": 77.9094883637001, "episode": 631.0, "batch_reward": 0.8054838147163391, "critic_loss": 2.4153756380081175, "actor_loss": -80.75525871155754, "actor_target_entropy": -1.0, "actor_entropy": 2.22936943599156, "alpha_loss": -0.013193930913176801, "alpha_value": 0.010942574611869555, "duration": 3.8488082885742188, "step": 78875}
{"episode_reward": 63.49934498225856, "episode": 632.0, "batch_reward": 0.805436671257019, "critic_loss": 2.38656067943573, "actor_loss": -80.87314150410313, "actor_target_entropy": -1.0, "actor_entropy": 2.1650978826707408, "alpha_loss": -0.0132394953060054, "alpha_value": 0.010998605094811575, "duration": 3.8373732566833496, "step": 79000}
{"episode_reward": 103.84245017066408, "episode": 633.0, "batch_reward": 0.8020545706748963, "critic_loss": 2.4692213020324707, "actor_loss": -80.96993522038535, "actor_target_entropy": -1.0, "actor_entropy": 2.06383876951914, "alpha_loss": -0.013532714785209723, "alpha_value": 0.011055333366163817, "duration": 3.8470005989074707, "step": 79125}
{"episode_reward": 44.83974603973835, "episode": 634.0, "batch_reward": 0.8095462393760681, "critic_loss": 2.4576546869277953, "actor_loss": -81.11402253181704, "actor_target_entropy": -1.0, "actor_entropy": 1.8969414041888328, "alpha_loss": -0.014638152686999209, "alpha_value": 0.011118024169213914, "duration": 3.83609938621521, "step": 79250}
{"episode_reward": 86.70050187447067, "episode": 635.0, "batch_reward": 0.8011009664535522, "critic_loss": 2.486729169845581, "actor_loss": -81.2008522881402, "actor_target_entropy": -1.0, "actor_entropy": 1.6786979361185952, "alpha_loss": -0.01682216561739407, "alpha_value": 0.011185873556631218, "duration": 3.8492772579193115, "step": 79375}
{"episode_reward": 74.95477140814938, "episode": 636.0, "batch_reward": 0.7956599197387695, "critic_loss": 2.2996628580093383, "actor_loss": -81.33848547166393, "actor_target_entropy": -1.0, "actor_entropy": 1.4584020222387006, "alpha_loss": -0.019765782545530988, "alpha_value": 0.011266867198285796, "duration": 3.842141628265381, "step": 79500}
{"episode_reward": 73.48811917658576, "episode": 637.0, "batch_reward": 0.7942433524131775, "critic_loss": 2.317866470336914, "actor_loss": -81.4346428522988, "actor_target_entropy": -1.0, "actor_entropy": 1.2580854041235787, "alpha_loss": -0.022521012595721653, "alpha_value": 0.011359059012841259, "duration": 3.845653772354126, "step": 79625}
{"episode_reward": 75.39598587949969, "episode": 638.0, "batch_reward": 0.7998028206825256, "critic_loss": 2.3624767122268677, "actor_loss": -81.54656564035723, "actor_target_entropy": -1.0, "actor_entropy": 1.1190907147622877, "alpha_loss": -0.02530564346741284, "alpha_value": 0.011462480876868054, "duration": 3.842519998550415, "step": 79750}
{"episode_reward": 74.18490210422141, "episode": 639.0, "batch_reward": 0.8181337265968323, "critic_loss": 2.5474032402038573, "actor_loss": -81.68508693150112, "actor_target_entropy": -1.0, "actor_entropy": 1.0261235634485881, "alpha_loss": -0.02665169903683284, "alpha_value": 0.011571043115493564, "duration": 3.8469061851501465, "step": 79875}
{"episode_reward": 72.2526014241053, "episode": 640.0, "batch_reward": 0.8186739745140076, "critic_loss": 2.3937184886932372, "actor_loss": -81.78697844474546, "actor_target_entropy": -1.0, "actor_entropy": 0.9522950764625303, "alpha_loss": -0.027714184845887845, "alpha_value": 0.011681105824886817, "duration": 3.8407139778137207, "step": 80000}
{"episode_reward": 74.94218922810533, "episode": 641.0, "batch_reward": 0.7979578828811645, "critic_loss": 2.33305969619751, "actor_loss": -81.85071115645151, "actor_target_entropy": -1.0, "actor_entropy": 0.903418118991549, "alpha_loss": -0.028801478238569364, "alpha_value": 0.011792254503802349, "duration": 7.8278584480285645, "step": 80125}
{"episode_reward": 75.74829418826704, "episode": 642.0, "batch_reward": 0.7893861904144287, "critic_loss": 2.316573401451111, "actor_loss": -81.9407712874874, "actor_target_entropy": -1.0, "actor_entropy": 0.8728405621743971, "alpha_loss": -0.029162802853651585, "alpha_value": 0.011902373840639554, "duration": 3.8396244049072266, "step": 80250}
{"episode_reward": 73.47775737821033, "episode": 643.0, "batch_reward": 0.7900654726028442, "critic_loss": 2.4539220752716067, "actor_loss": -82.03196776859345, "actor_target_entropy": -1.0, "actor_entropy": 0.8482848595059107, "alpha_loss": -0.03019334656733369, "alpha_value": 0.01201224816312318, "duration": 3.8445885181427, "step": 80375}
{"episode_reward": 74.17265994229373, "episode": 644.0, "batch_reward": 0.7843872256278992, "critic_loss": 2.251743827819824, "actor_loss": -82.11535398421749, "actor_target_entropy": -1.0, "actor_entropy": 0.8400884020713068, "alpha_loss": -0.02966493223944018, "alpha_value": 0.012120538634983661, "duration": 3.837711811065674, "step": 80500}
{"episode_reward": 76.23646559380153, "episode": 645.0, "batch_reward": 0.8117785654067993, "critic_loss": 2.4558760213851927, "actor_loss": -82.21253059023903, "actor_target_entropy": -1.0, "actor_entropy": 0.8323050623848325, "alpha_loss": -0.030016793499863338, "alpha_value": 0.01222589585493305, "duration": 3.8413381576538086, "step": 80625}
{"episode_reward": 74.13060753438458, "episode": 646.0, "batch_reward": 0.7871167345046997, "critic_loss": 2.291503779411316, "actor_loss": -82.28673725743448, "actor_target_entropy": -1.0, "actor_entropy": 0.8323266929195773, "alpha_loss": -0.03037290157930505, "alpha_value": 0.01233030001952831, "duration": 3.8439106941223145, "step": 80750}
{"episode_reward": 76.74997230610201, "episode": 647.0, "batch_reward": 0.811650857925415, "critic_loss": 2.435892568588257, "actor_loss": -82.37260909307571, "actor_target_entropy": -1.0, "actor_entropy": 0.8287788743064517, "alpha_loss": -0.030354141715973143, "alpha_value": 0.012433732417692364, "duration": 3.8442459106445312, "step": 80875}
{"episode_reward": 72.88701720448934, "episode": 648.0, "batch_reward": 0.7975582680702209, "critic_loss": 2.425463779449463, "actor_loss": -82.42698669433594, "actor_target_entropy": -1.0, "actor_entropy": 0.8262856429623019, "alpha_loss": -0.03033606756118036, "alpha_value": 0.012535514498174959, "duration": 3.840132713317871, "step": 81000}
{"episode_reward": 74.56493426563274, "episode": 649.0, "batch_reward": 0.8022029914855957, "critic_loss": 2.4394439516067505, "actor_loss": -82.48816148061601, "actor_target_entropy": -1.0, "actor_entropy": 0.8281219743546986, "alpha_loss": -0.03042315671013461, "alpha_value": 0.012636021511193907, "duration": 3.8403544425964355, "step": 81125}
{"episode_reward": 76.28884259315724, "episode": 650.0, "batch_reward": 0.8038265383243561, "critic_loss": 2.473927568435669, "actor_loss": -82.55632252846995, "actor_target_entropy": -1.0, "actor_entropy": 0.8272121837062221, "alpha_loss": -0.03045888915057144, "alpha_value": 0.012735723076212414, "duration": 3.8416802883148193, "step": 81250}
{"episode_reward": 75.5554553830822, "episode": 651.0, "batch_reward": 0.8044571394920349, "critic_loss": 2.4579611682891844, "actor_loss": -82.6106912522089, "actor_target_entropy": -1.0, "actor_entropy": 0.8304105505110726, "alpha_loss": -0.030266233675536654, "alpha_value": 0.012834253109255737, "duration": 3.8501076698303223, "step": 81375}
{"episode_reward": 73.76645112646536, "episode": 652.0, "batch_reward": 0.7888800601959228, "critic_loss": 2.415705153465271, "actor_loss": -82.66599938177293, "actor_target_entropy": -1.0, "actor_entropy": 0.8399137873803416, "alpha_loss": -0.030022842839600578, "alpha_value": 0.01293156595389644, "duration": 3.8330326080322266, "step": 81500}
{"episode_reward": 76.12462434831423, "episode": 653.0, "batch_reward": 0.792375916481018, "critic_loss": 2.3806785545349123, "actor_loss": -82.71441202315073, "actor_target_entropy": -1.0, "actor_entropy": 0.8298410707049899, "alpha_loss": -0.030081142715754964, "alpha_value": 0.01302711867079102, "duration": 3.8484606742858887, "step": 81625}
{"episode_reward": 72.93587028316735, "episode": 654.0, "batch_reward": 0.7882444562911988, "critic_loss": 2.3502830810546875, "actor_loss": -82.80978418165638, "actor_target_entropy": -1.0, "actor_entropy": 0.8246176665829074, "alpha_loss": -0.030147793883037184, "alpha_value": 0.013123089983249497, "duration": 3.837317943572998, "step": 81750}
{"episode_reward": 76.02979121004306, "episode": 655.0, "batch_reward": 0.7876870269775391, "critic_loss": 2.212080849647522, "actor_loss": -82.80276658799913, "actor_target_entropy": -1.0, "actor_entropy": 0.8182597557703654, "alpha_loss": -0.03006649859959171, "alpha_value": 0.01321838149540414, "duration": 3.84586501121521, "step": 81875}
{"episode_reward": 73.97543578495095, "episode": 656.0, "batch_reward": 0.7944615831375123, "critic_loss": 2.362601887702942, "actor_loss": -82.90692261726626, "actor_target_entropy": -1.0, "actor_entropy": 0.8070960698589202, "alpha_loss": -0.030691210751331622, "alpha_value": 0.013314211694473263, "duration": 3.8382959365844727, "step": 82000}
{"episode_reward": 74.19580448329611, "episode": 657.0, "batch_reward": 0.7895741124153137, "critic_loss": 2.35151620388031, "actor_loss": -82.92135038829986, "actor_target_entropy": -1.0, "actor_entropy": 0.8051557105685038, "alpha_loss": -0.030185192498186277, "alpha_value": 0.013410234160104796, "duration": 3.841440439224243, "step": 82125}
{"episode_reward": 73.87997893566043, "episode": 658.0, "batch_reward": 0.7916896872520447, "critic_loss": 2.315661660194397, "actor_loss": -82.99099436113912, "actor_target_entropy": -1.0, "actor_entropy": 0.8105268363029726, "alpha_loss": -0.030379266688419927, "alpha_value": 0.013505579577213727, "duration": 3.843961000442505, "step": 82250}
{"episode_reward": 72.2401380068457, "episode": 659.0, "batch_reward": 0.7912920579910279, "critic_loss": 2.3386024646759034, "actor_loss": -83.03869786338201, "actor_target_entropy": -1.0, "actor_entropy": 0.8033670868192401, "alpha_loss": -0.030374546697925008, "alpha_value": 0.013600328439545476, "duration": 3.83612322807312, "step": 82375}
{"episode_reward": 73.68736632548674, "episode": 660.0, "batch_reward": 0.8053780999183655, "critic_loss": 2.435737973213196, "actor_loss": -83.13571868404266, "actor_target_entropy": -1.0, "actor_entropy": 0.799273802388099, "alpha_loss": -0.030319059928578716, "alpha_value": 0.01369565966308424, "duration": 3.8410041332244873, "step": 82500}
{"episode_reward": 72.54594100257493, "episode": 661.0, "batch_reward": 0.778042106628418, "critic_loss": 2.2239253692626955, "actor_loss": -83.11566367981926, "actor_target_entropy": -1.0, "actor_entropy": 0.7981426318486532, "alpha_loss": -0.030150621331163814, "alpha_value": 0.013790598400846642, "duration": 3.844417095184326, "step": 82625}
{"episode_reward": 72.17827488292086, "episode": 662.0, "batch_reward": 0.7969081788063049, "critic_loss": 2.3108442726135254, "actor_loss": -83.18151031001922, "actor_target_entropy": -1.0, "actor_entropy": 0.8053507535688339, "alpha_loss": -0.030174410751750393, "alpha_value": 0.01388545721165761, "duration": 3.8304903507232666, "step": 82750}
{"episode_reward": 70.7377690788815, "episode": 663.0, "batch_reward": 0.7845927233695984, "critic_loss": 2.293997975349426, "actor_loss": -83.22844732375373, "actor_target_entropy": -1.0, "actor_entropy": 0.8142867939812797, "alpha_loss": -0.029748678000436887, "alpha_value": 0.013979249091356831, "duration": 3.844330310821533, "step": 82875}
{"episode_reward": 74.37757819542374, "episode": 664.0, "batch_reward": 0.7925891437530518, "critic_loss": 2.295860361099243, "actor_loss": -83.22989752984816, "actor_target_entropy": -1.0, "actor_entropy": 0.8224990175616357, "alpha_loss": -0.0298053017787395, "alpha_value": 0.01407266142899216, "duration": 3.836487293243408, "step": 83000}
{"episode_reward": 76.70593668881973, "episode": 665.0, "batch_reward": 0.7780876579284668, "critic_loss": 2.278685983657837, "actor_loss": -83.24103013295976, "actor_target_entropy": -1.0, "actor_entropy": 0.8219370633836777, "alpha_loss": -0.028978314694194568, "alpha_value": 0.014165278865179187, "duration": 3.841712236404419, "step": 83125}
{"episode_reward": 75.77845851963225, "episode": 666.0, "batch_reward": 0.7822653927803039, "critic_loss": 2.242423858642578, "actor_loss": -83.31667266353485, "actor_target_entropy": -1.0, "actor_entropy": 0.8160787897725259, "alpha_loss": -0.028882638641422795, "alpha_value": 0.014256738233269218, "duration": 3.8372437953948975, "step": 83250}
{"episode_reward": 71.73913643464358, "episode": 667.0, "batch_reward": 0.7862792630195617, "critic_loss": 2.2570036697387694, "actor_loss": -83.29175991482205, "actor_target_entropy": -1.0, "actor_entropy": 0.8166082037819756, "alpha_loss": -0.028692230552671446, "alpha_value": 0.014348556414077276, "duration": 3.8459296226501465, "step": 83375}
{"episode_reward": 74.19765557042923, "episode": 668.0, "batch_reward": 0.7854683380126953, "critic_loss": 2.2967370700836183, "actor_loss": -83.2993892546623, "actor_target_entropy": -1.0, "actor_entropy": 0.8245712134145922, "alpha_loss": -0.02850171581151024, "alpha_value": 0.014439643862110395, "duration": 3.836608409881592, "step": 83500}
{"episode_reward": 72.75949332804822, "episode": 669.0, "batch_reward": 0.7897972521781922, "critic_loss": 2.342550901412964, "actor_loss": -83.33071039593409, "actor_target_entropy": -1.0, "actor_entropy": 0.8263050128543188, "alpha_loss": -0.028236164962725033, "alpha_value": 0.014530516939830644, "duration": 3.8485817909240723, "step": 83625}
{"episode_reward": 74.79902156782319, "episode": 670.0, "batch_reward": 0.7984790601730347, "critic_loss": 2.3723657627105714, "actor_loss": -83.33219306699691, "actor_target_entropy": -1.0, "actor_entropy": 0.8232251328806723, "alpha_loss": -0.027727192778500817, "alpha_value": 0.014621106948725907, "duration": 3.8381142616271973, "step": 83750}
{"episode_reward": 74.7025611656973, "episode": 671.0, "batch_reward": 0.7832548937797547, "critic_loss": 2.21850691986084, "actor_loss": -83.33596535334512, "actor_target_entropy": -1.0, "actor_entropy": 0.8339367385894533, "alpha_loss": -0.02703395459268774, "alpha_value": 0.014710631209214873, "duration": 3.842806816101074, "step": 83875}
{"episode_reward": 75.64321205658837, "episode": 672.0, "batch_reward": 0.7950941729545593, "critic_loss": 2.3148230676651003, "actor_loss": -83.35056046516665, "actor_target_entropy": -1.0, "actor_entropy": 0.824726446982353, "alpha_loss": -0.026636386590619242, "alpha_value": 0.014798215931917326, "duration": 3.837618827819824, "step": 84000}
{"episode_reward": 72.68905393537798, "episode": 673.0, "batch_reward": 0.7940503258705139, "critic_loss": 2.3544035892486574, "actor_loss": -83.35633850097656, "actor_target_entropy": -1.0, "actor_entropy": 0.8187747701765999, "alpha_loss": -0.027225448202992244, "alpha_value": 0.014887382531158887, "duration": 3.8432180881500244, "step": 84125}
{"episode_reward": 73.16158458954547, "episode": 674.0, "batch_reward": 0.7914162421226502, "critic_loss": 2.3800221881866457, "actor_loss": -83.36656755016696, "actor_target_entropy": -1.0, "actor_entropy": 0.8258362316316173, "alpha_loss": -0.026277428853415673, "alpha_value": 0.014976838889670106, "duration": 3.8410632610321045, "step": 84250}
{"episode_reward": 72.31228901457258, "episode": 675.0, "batch_reward": 0.7769618129730225, "critic_loss": 2.252519012451172, "actor_loss": -83.38108123294892, "actor_target_entropy": -1.0, "actor_entropy": 0.8331214984258016, "alpha_loss": -0.026053455820868886, "alpha_value": 0.015065318035770167, "duration": 3.845623731613159, "step": 84375}
{"episode_reward": 73.57777899350906, "episode": 676.0, "batch_reward": 0.7906499972343445, "critic_loss": 2.3849115743637084, "actor_loss": -83.38859570410943, "actor_target_entropy": -1.0, "actor_entropy": 0.8298877170008998, "alpha_loss": -0.02615486911588138, "alpha_value": 0.015154009287620946, "duration": 3.8353471755981445, "step": 84500}
{"episode_reward": 73.16492658123963, "episode": 677.0, "batch_reward": 0.8054365983009338, "critic_loss": 2.412585338592529, "actor_loss": -83.38993714347718, "actor_target_entropy": -1.0, "actor_entropy": 0.8292333531001258, "alpha_loss": -0.02551599062742695, "alpha_value": 0.015242299151516106, "duration": 3.8522696495056152, "step": 84625}
{"episode_reward": 69.27487350472349, "episode": 678.0, "batch_reward": 0.7821306219100952, "critic_loss": 2.181723317146301, "actor_loss": -83.39963273079165, "actor_target_entropy": -1.0, "actor_entropy": 0.827644859590838, "alpha_loss": -0.025347640737891197, "alpha_value": 0.015330713111301394, "duration": 3.839282274246216, "step": 84750}
{"episode_reward": 76.87145863847269, "episode": 679.0, "batch_reward": 0.7849304780960084, "critic_loss": 2.234590587615967, "actor_loss": -83.37098282102555, "actor_target_entropy": -1.0, "actor_entropy": 0.8291071199235462, "alpha_loss": -0.02490334035385223, "alpha_value": 0.01541864187166692, "duration": 3.8461267948150635, "step": 84875}
{"episode_reward": 73.5952823131687, "episode": 680.0, "batch_reward": 0.7753527202606201, "critic_loss": 2.266259427070618, "actor_loss": -83.35834552395728, "actor_target_entropy": -1.0, "actor_entropy": 0.8252661497362198, "alpha_loss": -0.024608715076840693, "alpha_value": 0.015505791294045767, "duration": 3.839185953140259, "step": 85000}
{"episode_reward": 75.13002711691462, "episode": 681.0, "batch_reward": 0.7919681243896485, "critic_loss": 2.3454179878234864, "actor_loss": -83.3361352587503, "actor_target_entropy": -1.0, "actor_entropy": 0.8441687557432387, "alpha_loss": -0.023667566892173555, "alpha_value": 0.015593197702143898, "duration": 3.8405799865722656, "step": 85125}
{"episode_reward": 73.52775857479763, "episode": 682.0, "batch_reward": 0.7816349635124207, "critic_loss": 2.2801435737609865, "actor_loss": -83.35685225455991, "actor_target_entropy": -1.0, "actor_entropy": 0.8309988860161074, "alpha_loss": -0.023706196807324886, "alpha_value": 0.015678480142305565, "duration": 3.84371280670166, "step": 85250}
{"episode_reward": 74.84765061785083, "episode": 683.0, "batch_reward": 0.7876304216384887, "critic_loss": 2.3134819421768187, "actor_loss": -83.33034091525607, "actor_target_entropy": -1.0, "actor_entropy": 0.8290861693639604, "alpha_loss": -0.02305290224178443, "alpha_value": 0.015764488697661557, "duration": 3.8394744396209717, "step": 85375}
{"episode_reward": 72.7924977639902, "episode": 684.0, "batch_reward": 0.7749480514526367, "critic_loss": 2.231201825141907, "actor_loss": -83.27638527654833, "actor_target_entropy": -1.0, "actor_entropy": 0.8445684563729071, "alpha_loss": -0.02227470308782593, "alpha_value": 0.0158492888124893, "duration": 3.834913492202759, "step": 85500}
{"episode_reward": 73.41954225748142, "episode": 685.0, "batch_reward": 0.780209391117096, "critic_loss": 2.327231077194214, "actor_loss": -83.3042252555726, "actor_target_entropy": -1.0, "actor_entropy": 0.8460969641095116, "alpha_loss": -0.022260559988873347, "alpha_value": 0.015933432923447313, "duration": 3.842283248901367, "step": 85625}
{"episode_reward": 74.71091773976777, "episode": 686.0, "batch_reward": 0.7835379447937012, "critic_loss": 2.2712088708877562, "actor_loss": -83.27020718974453, "actor_target_entropy": -1.0, "actor_entropy": 0.8461953017019457, "alpha_loss": -0.02147197504077227, "alpha_value": 0.016016594980940844, "duration": 3.8318817615509033, "step": 85750}
{"episode_reward": 76.39741519231458, "episode": 687.0, "batch_reward": 0.7965061388015747, "critic_loss": 2.3149716863632204, "actor_loss": -83.27859920925565, "actor_target_entropy": -1.0, "actor_entropy": 0.8411931859122382, "alpha_loss": -0.021022103682515166, "alpha_value": 0.01609941522045871, "duration": 3.845543622970581, "step": 85875}
{"episode_reward": 72.20427894966778, "episode": 688.0, "batch_reward": 0.784891101360321, "critic_loss": 2.246926033973694, "actor_loss": -83.27807063441122, "actor_target_entropy": -1.0, "actor_entropy": 0.8342208285485545, "alpha_loss": -0.021326725401224628, "alpha_value": 0.016182759619706204, "duration": 3.8359553813934326, "step": 86000}
{"episode_reward": 73.42262762642912, "episode": 689.0, "batch_reward": 0.7809358692169189, "critic_loss": 2.263464035987854, "actor_loss": -83.26136828225756, "actor_target_entropy": -1.0, "actor_entropy": 0.8328833069120135, "alpha_loss": -0.020912577324206868, "alpha_value": 0.016267656540655432, "duration": 3.8431882858276367, "step": 86125}
{"episode_reward": 75.26844444204428, "episode": 690.0, "batch_reward": 0.7905172533988952, "critic_loss": 2.29679487991333, "actor_loss": -83.24575510332662, "actor_target_entropy": -1.0, "actor_entropy": 0.8416919285251249, "alpha_loss": -0.020660441549074267, "alpha_value": 0.016351617349630573, "duration": 3.8380868434906006, "step": 86250}
{"episode_reward": 72.56415516193746, "episode": 691.0, "batch_reward": 0.7911701946258545, "critic_loss": 2.2854951829910277, "actor_loss": -83.20059143550812, "actor_target_entropy": -1.0, "actor_entropy": 0.8671313562090435, "alpha_loss": -0.01969208402766122, "alpha_value": 0.016435233562737236, "duration": 3.8411519527435303, "step": 86375}
{"episode_reward": 73.23111781360413, "episode": 692.0, "batch_reward": 0.7648247103691102, "critic_loss": 2.140722371101379, "actor_loss": -83.17026864328692, "actor_target_entropy": -1.0, "actor_entropy": 0.8891744344465194, "alpha_loss": -0.019042831139578935, "alpha_value": 0.01651612625639068, "duration": 3.8401026725769043, "step": 86500}
{"episode_reward": 72.60145932443966, "episode": 693.0, "batch_reward": 0.7898443470001221, "critic_loss": 2.1740167484283446, "actor_loss": -83.15775165860614, "actor_target_entropy": -1.0, "actor_entropy": 0.9056297351443579, "alpha_loss": -0.018702119115799193, "alpha_value": 0.01659716494968825, "duration": 3.840445041656494, "step": 86625}
{"episode_reward": 69.45263787439659, "episode": 694.0, "batch_reward": 0.7749423041343689, "critic_loss": 2.2694651675224304, "actor_loss": -83.14209538121378, "actor_target_entropy": -1.0, "actor_entropy": 0.899127810232101, "alpha_loss": -0.01751127726428451, "alpha_value": 0.016674599336693578, "duration": 3.8351662158966064, "step": 86750}
{"episode_reward": 72.28155106328525, "episode": 695.0, "batch_reward": 0.7816395349502564, "critic_loss": 2.2836907920837404, "actor_loss": -83.11319611564515, "actor_target_entropy": -1.0, "actor_entropy": 0.8755362847494701, "alpha_loss": -0.01876156854014548, "alpha_value": 0.016754840891460187, "duration": 3.8431708812713623, "step": 86875}
{"episode_reward": 72.97429542311274, "episode": 696.0, "batch_reward": 0.7805944509506225, "critic_loss": 2.2000061140060425, "actor_loss": -83.07253831432712, "actor_target_entropy": -1.0, "actor_entropy": 0.8969045646729008, "alpha_loss": -0.017666482847304113, "alpha_value": 0.016838096711273245, "duration": 3.842148780822754, "step": 87000}
{"episode_reward": 72.20608375841941, "episode": 697.0, "batch_reward": 0.7677476906776428, "critic_loss": 2.322731351852417, "actor_loss": -83.0322989811973, "actor_target_entropy": -1.0, "actor_entropy": 0.8856114300470503, "alpha_loss": -0.01722174406879478, "alpha_value": 0.01691732055522455, "duration": 3.8451504707336426, "step": 87125}
{"episode_reward": 72.7454876748012, "episode": 698.0, "batch_reward": 0.7925764832496643, "critic_loss": 2.3387827253341675, "actor_loss": -83.0224124539283, "actor_target_entropy": -1.0, "actor_entropy": 0.9164856979923863, "alpha_loss": -0.015971139238606536, "alpha_value": 0.01699505282340116, "duration": 3.841801166534424, "step": 87250}
{"episode_reward": 71.51155323550238, "episode": 699.0, "batch_reward": 0.7687517194747925, "critic_loss": 2.2340344524383546, "actor_loss": -82.99668823726593, "actor_target_entropy": -1.0, "actor_entropy": 0.9049947242888193, "alpha_loss": -0.01583424976302518, "alpha_value": 0.017070241081306527, "duration": 3.8442788124084473, "step": 87375}
{"episode_reward": 72.58673887591411, "episode": 700.0, "batch_reward": 0.7710491189956665, "critic_loss": 2.192303053855896, "actor_loss": -82.92950119510773, "actor_target_entropy": -1.0, "actor_entropy": 0.9248229957395985, "alpha_loss": -0.015381569598591136, "alpha_value": 0.017144920273071344, "duration": 3.8346166610717773, "step": 87500}
{"episode_reward": 74.30050636231272, "episode": 701.0, "batch_reward": 0.7762212209701538, "critic_loss": 2.2621106634140014, "actor_loss": -82.90262119353764, "actor_target_entropy": -1.0, "actor_entropy": 0.9546618253465683, "alpha_loss": -0.014334067347503844, "alpha_value": 0.017219492741837678, "duration": 3.8465404510498047, "step": 87625}
{"episode_reward": 73.8136474216168, "episode": 702.0, "batch_reward": 0.7867946214675904, "critic_loss": 2.2509095573425295, "actor_loss": -82.89115745790544, "actor_target_entropy": -1.0, "actor_entropy": 0.9658842432883478, "alpha_loss": -0.013170983905213015, "alpha_value": 0.017288266954304708, "duration": 3.833761215209961, "step": 87750}
{"episode_reward": 73.35342012944481, "episode": 703.0, "batch_reward": 0.7896783919334411, "critic_loss": 2.178756878852844, "actor_loss": -82.87152438693576, "actor_target_entropy": -1.0, "actor_entropy": 0.9361999318713233, "alpha_loss": -0.013215877485298922, "alpha_value": 0.017356511591587624, "duration": 3.8395557403564453, "step": 87875}
{"episode_reward": 71.09157860759139, "episode": 704.0, "batch_reward": 0.7866667923927307, "critic_loss": 2.2377953090667724, "actor_loss": -82.83081559211978, "actor_target_entropy": -1.0, "actor_entropy": 0.9495834112167358, "alpha_loss": -0.012512031807413986, "alpha_value": 0.017424030628791515, "duration": 3.8393542766571045, "step": 88000}
{"episode_reward": 73.9679312746399, "episode": 705.0, "batch_reward": 0.7813692212104797, "critic_loss": 2.233976372718811, "actor_loss": -82.79413798498729, "actor_target_entropy": -1.0, "actor_entropy": 0.9761628669405741, "alpha_loss": -0.011227386567505106, "alpha_value": 0.017489228587559014, "duration": 3.845470428466797, "step": 88125}
{"episode_reward": 75.83875938049295, "episode": 706.0, "batch_reward": 0.7613955793380738, "critic_loss": 2.0901241550445557, "actor_loss": -82.74478432439989, "actor_target_entropy": -1.0, "actor_entropy": 0.999005998334577, "alpha_loss": -0.01063577457511377, "alpha_value": 0.017548770002599183, "duration": 3.8404438495635986, "step": 88250}
{"episode_reward": 71.28598302954524, "episode": 707.0, "batch_reward": 0.7910496621131897, "critic_loss": 2.391877083778381, "actor_loss": -82.72790926978702, "actor_target_entropy": -1.0, "actor_entropy": 1.0152893842212738, "alpha_loss": -0.009354264534536808, "alpha_value": 0.01760646696627389, "duration": 3.8436472415924072, "step": 88375}
{"episode_reward": 76.1552040282873, "episode": 708.0, "batch_reward": 0.7816190767288208, "critic_loss": 2.20428112411499, "actor_loss": -82.7194943581858, "actor_target_entropy": -1.0, "actor_entropy": 0.9915957950776623, "alpha_loss": -0.0091066216944807, "alpha_value": 0.0176588741602894, "duration": 3.843519687652588, "step": 88500}
{"episode_reward": 75.11013421929827, "episode": 709.0, "batch_reward": 0.7727708930969238, "critic_loss": 2.201487750053406, "actor_loss": -82.66208079504588, "actor_target_entropy": -1.0, "actor_entropy": 0.9480582362129575, "alpha_loss": -0.010695571981606975, "alpha_value": 0.017718916069223486, "duration": 3.8440911769866943, "step": 88625}
{"episode_reward": 73.73775710570676, "episode": 710.0, "batch_reward": 0.7842560544013977, "critic_loss": 2.205144193649292, "actor_loss": -82.65117288404896, "actor_target_entropy": -1.0, "actor_entropy": 0.931542323481652, "alpha_loss": -0.009773459518328309, "alpha_value": 0.017780952634220876, "duration": 3.841994047164917, "step": 88750}
{"episode_reward": 76.53328824733717, "episode": 711.0, "batch_reward": 0.7726305813789368, "critic_loss": 2.195434803009033, "actor_loss": -82.57998705667163, "actor_target_entropy": -1.0, "actor_entropy": 0.9342341063514589, "alpha_loss": -0.009658859495724004, "alpha_value": 0.017841993115207497, "duration": 3.8476202487945557, "step": 88875}
{"episode_reward": 74.41111806668992, "episode": 712.0, "batch_reward": 0.7872287659645081, "critic_loss": 2.2681388330459593, "actor_loss": -82.5762710571289, "actor_target_entropy": -1.0, "actor_entropy": 0.9585011274583878, "alpha_loss": -0.008704774667538943, "alpha_value": 0.017901292695084992, "duration": 3.840879201889038, "step": 89000}
{"episode_reward": 77.54589256294025, "episode": 713.0, "batch_reward": 0.795561550617218, "critic_loss": 2.320581198692322, "actor_loss": -82.58430820041232, "actor_target_entropy": -1.0, "actor_entropy": 0.9479856964141603, "alpha_loss": -0.008767250888345261, "alpha_value": 0.017959393467608335, "duration": 3.848870277404785, "step": 89125}
{"episode_reward": 75.40622525702578, "episode": 714.0, "batch_reward": 0.7763480248451233, "critic_loss": 2.1791612973213197, "actor_loss": -82.51504024382561, "actor_target_entropy": -1.0, "actor_entropy": 0.9522690503827987, "alpha_loss": -0.008769910455861639, "alpha_value": 0.01802003246619291, "duration": 3.841167688369751, "step": 89250}
{"episode_reward": 74.30307192915284, "episode": 715.0, "batch_reward": 0.780547116279602, "critic_loss": 2.1922703771591188, "actor_loss": -82.48580944727338, "actor_target_entropy": -1.0, "actor_entropy": 0.9889625840716891, "alpha_loss": -0.007333787734664622, "alpha_value": 0.01807616436430965, "duration": 3.851222276687622, "step": 89375}
{"episode_reward": 72.22041511992829, "episode": 716.0, "batch_reward": 0.7655714516639709, "critic_loss": 2.1995264744758605, "actor_loss": -82.44171770157352, "actor_target_entropy": -1.0, "actor_entropy": 0.9889113556954169, "alpha_loss": -0.007438459061837244, "alpha_value": 0.018127800653838785, "duration": 3.838322877883911, "step": 89500}
{"episode_reward": 76.013045881496, "episode": 717.0, "batch_reward": 0.7771943740844727, "critic_loss": 2.2236669158935545, "actor_loss": -82.42074621291388, "actor_target_entropy": -1.0, "actor_entropy": 1.0103265387671334, "alpha_loss": -0.006177113631681081, "alpha_value": 0.018178845946156322, "duration": 3.8456225395202637, "step": 89625}
{"episode_reward": 74.45504212341181, "episode": 718.0, "batch_reward": 0.7692881798744202, "critic_loss": 2.119343074798584, "actor_loss": -82.3595932991274, "actor_target_entropy": -1.0, "actor_entropy": 1.0277648933472172, "alpha_loss": -0.005659695906234124, "alpha_value": 0.018223273353809844, "duration": 3.8290839195251465, "step": 89750}
{"episode_reward": 75.8945171827442, "episode": 719.0, "batch_reward": 0.7699076147079468, "critic_loss": 2.1765429472923277, "actor_loss": -82.31394776843842, "actor_target_entropy": -1.0, "actor_entropy": 1.0617777979563152, "alpha_loss": -0.005070284214554473, "alpha_value": 0.01826499466318412, "duration": 3.8349928855895996, "step": 89875}
{"episode_reward": 71.33428548314714, "episode": 720.0, "batch_reward": 0.7738065190315246, "critic_loss": 2.262417610168457, "actor_loss": -82.3038966271185, "actor_target_entropy": -1.0, "actor_entropy": 1.0714053838483748, "alpha_loss": -0.0041300562710779145, "alpha_value": 0.018300726406071798, "duration": 3.8424808979034424, "step": 90000}
{"episode_reward": 75.59810300660435, "episode": 721.0, "batch_reward": 0.7691913833618164, "critic_loss": 2.2178699131011963, "actor_loss": -82.27797263009208, "actor_target_entropy": -1.0, "actor_entropy": 1.0607135125568934, "alpha_loss": -0.0038092814456109725, "alpha_value": 0.018333557058610967, "duration": 7.819676160812378, "step": 90125}
{"episode_reward": 75.04611217544233, "episode": 722.0, "batch_reward": 0.7704463605880737, "critic_loss": 2.1504321041107177, "actor_loss": -82.2195900947817, "actor_target_entropy": -1.0, "actor_entropy": 1.0521710957250288, "alpha_loss": -0.004617401654080999, "alpha_value": 0.0183702877676624, "duration": 3.837956666946411, "step": 90250}
{"episode_reward": 73.55902363012743, "episode": 723.0, "batch_reward": 0.7758182401657104, "critic_loss": 2.139210961341858, "actor_loss": -82.18379841153583, "actor_target_entropy": -1.0, "actor_entropy": 1.0957209136750963, "alpha_loss": -0.002874230924395046, "alpha_value": 0.018403733106625738, "duration": 3.84321665763855, "step": 90375}
{"episode_reward": 71.34555994905072, "episode": 724.0, "batch_reward": 0.7760139012336731, "critic_loss": 2.2212636976242064, "actor_loss": -82.13730559810516, "actor_target_entropy": -1.0, "actor_entropy": 1.132995609314211, "alpha_loss": -0.0015494164160167378, "alpha_value": 0.018423125565290386, "duration": 3.8419010639190674, "step": 90500}
{"episode_reward": 79.83728915240441, "episode": 725.0, "batch_reward": 0.7934467644691467, "critic_loss": 2.324364142417908, "actor_loss": -82.11683642675006, "actor_target_entropy": -1.0, "actor_entropy": 1.180584879148574, "alpha_loss": -0.00029009193669827214, "alpha_value": 0.018431575462615944, "duration": 3.8411669731140137, "step": 90625}
{"episode_reward": 69.09644521819679, "episode": 726.0, "batch_reward": 0.7694928021430969, "critic_loss": 2.138028573036194, "actor_loss": -82.05967134045017, "actor_target_entropy": -1.0, "actor_entropy": 1.2324715775828208, "alpha_loss": 0.0009126191528799433, "alpha_value": 0.018430736057023528, "duration": 3.846694231033325, "step": 90750}
{"episode_reward": 63.59298187438756, "episode": 727.0, "batch_reward": 0.7788086724281311, "critic_loss": 2.165619661331177, "actor_loss": -82.0533915928432, "actor_target_entropy": -1.0, "actor_entropy": 1.2591297531884813, "alpha_loss": 0.0013046607149705765, "alpha_value": 0.018419134834798775, "duration": 3.839768648147583, "step": 90875}
{"episode_reward": 75.22766132660477, "episode": 728.0, "batch_reward": 0.7661908435821533, "critic_loss": 2.127214642524719, "actor_loss": -81.97498690697455, "actor_target_entropy": -1.0, "actor_entropy": 1.29385325601024, "alpha_loss": 0.002395511788856839, "alpha_value": 0.01839921427511409, "duration": 3.8448104858398438, "step": 91000}
{"episode_reward": 74.49106317711262, "episode": 729.0, "batch_reward": 0.7753686690330506, "critic_loss": 2.191198191642761, "actor_loss": -81.92764657641214, "actor_target_entropy": -1.0, "actor_entropy": 1.3719997122174217, "alpha_loss": 0.0047447636080462305, "alpha_value": 0.018363330225542346, "duration": 3.84789776802063, "step": 91125}
{"episode_reward": 68.54589164415863, "episode": 730.0, "batch_reward": 0.7633236422538757, "critic_loss": 2.1441497130393983, "actor_loss": -81.90854275611139, "actor_target_entropy": -1.0, "actor_entropy": 1.4229764669172225, "alpha_loss": 0.005273099738030484, "alpha_value": 0.018310304483057507, "duration": 3.841005563735962, "step": 91250}
{"episode_reward": 72.6811333540687, "episode": 731.0, "batch_reward": 0.7719396667480469, "critic_loss": 2.2316716890335084, "actor_loss": -81.85889725458054, "actor_target_entropy": -1.0, "actor_entropy": 1.4549524689477586, "alpha_loss": 0.006034637467810027, "alpha_value": 0.018248351956541908, "duration": 3.8502094745635986, "step": 91375}
{"episode_reward": 246.37198164815814, "episode": 732.0, "batch_reward": 0.7607796897888184, "critic_loss": 2.101426432609558, "actor_loss": -81.81603167133946, "actor_target_entropy": -1.0, "actor_entropy": 1.5322596834551903, "alpha_loss": 0.0067656951263592, "alpha_value": 0.01818096642374039, "duration": 3.8364250659942627, "step": 91500}
{"episode_reward": 71.97657949161771, "episode": 733.0, "batch_reward": 0.7686814665794373, "critic_loss": 2.1497128524780273, "actor_loss": -81.78502994113498, "actor_target_entropy": -1.0, "actor_entropy": 1.572872557337322, "alpha_loss": 0.007798306211563093, "alpha_value": 0.01809852575011327, "duration": 3.851912260055542, "step": 91625}
{"episode_reward": 85.12875909717333, "episode": 734.0, "batch_reward": 0.7752610530853271, "critic_loss": 2.2506064586639405, "actor_loss": -81.74430613363943, "actor_target_entropy": -1.0, "actor_entropy": 1.6355760828141244, "alpha_loss": 0.008816947724910514, "alpha_value": 0.01800469438286126, "duration": 3.84055233001709, "step": 91750}
{"episode_reward": 119.59781422923626, "episode": 735.0, "batch_reward": 0.7788881797790528, "critic_loss": 2.202813753128052, "actor_loss": -81.72878931439112, "actor_target_entropy": -1.0, "actor_entropy": 1.7675888292373172, "alpha_loss": 0.008537891812415587, "alpha_value": 0.017908044366308083, "duration": 3.8451945781707764, "step": 91875}
{"episode_reward": 135.7090111296419, "episode": 736.0, "batch_reward": 0.7794280238151551, "critic_loss": 2.1816110172271728, "actor_loss": -81.7088861773091, "actor_target_entropy": -1.0, "actor_entropy": 1.8899239455499957, "alpha_loss": 0.008916582397726034, "alpha_value": 0.01780956870017123, "duration": 3.840977668762207, "step": 92000}
{"episode_reward": 132.81688893601876, "episode": 737.0, "batch_reward": 0.7802391920089722, "critic_loss": 2.2070685777664183, "actor_loss": -81.6852532038613, "actor_target_entropy": -1.0, "actor_entropy": 2.007723808288574, "alpha_loss": 0.008598316307013323, "alpha_value": 0.017710447102980052, "duration": 3.8401994705200195, "step": 92125}
{"episode_reward": 75.41447045879292, "episode": 738.0, "batch_reward": 0.7627337403297424, "critic_loss": 2.1212034254074097, "actor_loss": -81.66752403013167, "actor_target_entropy": -1.0, "actor_entropy": 2.1015610541066816, "alpha_loss": 0.007362417337830148, "alpha_value": 0.017623344286143986, "duration": 3.8386456966400146, "step": 92250}
{"episode_reward": 187.49807209765692, "episode": 739.0, "batch_reward": 0.7583076214790344, "critic_loss": 2.066353488922119, "actor_loss": -81.62871999589224, "actor_target_entropy": -1.0, "actor_entropy": 2.1983484237913102, "alpha_loss": 0.004956025807630448, "alpha_value": 0.01755122473294551, "duration": 3.842050313949585, "step": 92375}
{"episode_reward": 66.4807404481693, "episode": 740.0, "batch_reward": 0.7586747403144837, "critic_loss": 2.1287565422058106, "actor_loss": -81.61258919008317, "actor_target_entropy": -1.0, "actor_entropy": 2.272006142523981, "alpha_loss": 0.0023918951750778023, "alpha_value": 0.017507650325435477, "duration": 3.8388118743896484, "step": 92500}
{"episode_reward": 234.98853480466306, "episode": 741.0, "batch_reward": 0.7616530287265778, "critic_loss": 2.1442988481521605, "actor_loss": -81.59444270058283, "actor_target_entropy": -1.0, "actor_entropy": 2.3250785857912093, "alpha_loss": 0.0013710404506012323, "alpha_value": 0.017489047089005037, "duration": 3.843531608581543, "step": 92625}
{"episode_reward": 168.37390267454248, "episode": 742.0, "batch_reward": 0.7765767226219177, "critic_loss": 2.0921734800338747, "actor_loss": -81.59735759612053, "actor_target_entropy": -1.0, "actor_entropy": 2.365231344776769, "alpha_loss": 0.0008135718052207883, "alpha_value": 0.017473051057699956, "duration": 3.840400457382202, "step": 92750}
{"episode_reward": 141.4636895472661, "episode": 743.0, "batch_reward": 0.778250449180603, "critic_loss": 2.178656545639038, "actor_loss": -81.58339606391058, "actor_target_entropy": -1.0, "actor_entropy": 2.405758645799425, "alpha_loss": -0.00046076350808439275, "alpha_value": 0.017472166202241755, "duration": 3.84084153175354, "step": 92875}
{"episode_reward": 178.83210510236572, "episode": 744.0, "batch_reward": 0.7698712697029114, "critic_loss": 2.114181933403015, "actor_loss": -81.57124316307807, "actor_target_entropy": -1.0, "actor_entropy": 2.4280668843177056, "alpha_loss": -0.0013894091591223955, "alpha_value": 0.01748194088559952, "duration": 3.842102527618408, "step": 93000}
{"episode_reward": 185.34653653708105, "episode": 745.0, "batch_reward": 0.7737855458259583, "critic_loss": 2.1500882110595705, "actor_loss": -81.56719643729073, "actor_target_entropy": -1.0, "actor_entropy": 2.4483567646571567, "alpha_loss": -0.0023494010988903778, "alpha_value": 0.017503690287957594, "duration": 3.845578193664551, "step": 93125}
{"episode_reward": 110.54402439230857, "episode": 746.0, "batch_reward": 0.7846297407150269, "critic_loss": 2.20273663520813, "actor_loss": -81.57393400130734, "actor_target_entropy": -1.0, "actor_entropy": 2.4705514907836914, "alpha_loss": -0.003436224766999423, "alpha_value": 0.017547105214049712, "duration": 3.834139347076416, "step": 93250}
{"episode_reward": 144.53288413719326, "episode": 747.0, "batch_reward": 0.7934415555000305, "critic_loss": 2.326959372520447, "actor_loss": -81.58460768442305, "actor_target_entropy": -1.0, "actor_entropy": 2.492887330433679, "alpha_loss": -0.004718188383054757, "alpha_value": 0.017596327452112558, "duration": 3.8430376052856445, "step": 93375}
{"episode_reward": 207.38844870256693, "episode": 748.0, "batch_reward": 0.7779784436225892, "critic_loss": 2.1391013765335085, "actor_loss": -81.56910459456905, "actor_target_entropy": -1.0, "actor_entropy": 2.504207887957173, "alpha_loss": -0.00439175229703617, "alpha_value": 0.017662758340728925, "duration": 3.8381967544555664, "step": 93500}
{"episode_reward": 91.31645099903552, "episode": 749.0, "batch_reward": 0.7893667879104614, "critic_loss": 2.2626412382125856, "actor_loss": -81.58640652611142, "actor_target_entropy": -1.0, "actor_entropy": 2.519705651298402, "alpha_loss": -0.004966812527051107, "alpha_value": 0.017727716859608427, "duration": 3.8403842449188232, "step": 93625}
{"episode_reward": 54.420705225978104, "episode": 750.0, "batch_reward": 0.7840328335762023, "critic_loss": 2.2776795263290404, "actor_loss": -81.58839244227255, "actor_target_entropy": -1.0, "actor_entropy": 2.5298725558865454, "alpha_loss": -0.004312587490740923, "alpha_value": 0.017790445069391408, "duration": 3.8402059078216553, "step": 93750}
{"episode_reward": 202.1224507253588, "episode": 751.0, "batch_reward": 0.7811998953819275, "critic_loss": 2.12659979057312, "actor_loss": -81.58759404742528, "actor_target_entropy": -1.0, "actor_entropy": 2.5380269610692583, "alpha_loss": -0.005445601409375076, "alpha_value": 0.017856109681578188, "duration": 3.8363699913024902, "step": 93875}
{"episode_reward": 78.96476538723918, "episode": 752.0, "batch_reward": 0.7936196217536926, "critic_loss": 2.2054334192276, "actor_loss": -81.60842021819084, "actor_target_entropy": -1.0, "actor_entropy": 2.5438747559824297, "alpha_loss": -0.00570099878748278, "alpha_value": 0.017943101056244835, "duration": 3.838803768157959, "step": 94000}
{"episode_reward": 189.96812690623094, "episode": 753.0, "batch_reward": 0.7937168970108032, "critic_loss": 2.2316004400253298, "actor_loss": -81.60545833527095, "actor_target_entropy": -1.0, "actor_entropy": 2.549496287391299, "alpha_loss": -0.0056893150340617885, "alpha_value": 0.018020504271704825, "duration": 3.844440221786499, "step": 94125}
{"episode_reward": 83.94401636866405, "episode": 754.0, "batch_reward": 0.7865591912269593, "critic_loss": 2.232029937744141, "actor_loss": -81.60337386592742, "actor_target_entropy": -1.0, "actor_entropy": 2.5502295186442714, "alpha_loss": -0.005693292340560396, "alpha_value": 0.01811208687339989, "duration": 3.8370978832244873, "step": 94250}
{"episode_reward": 175.19134633622966, "episode": 755.0, "batch_reward": 0.7811381993293762, "critic_loss": 2.222531087875366, "actor_loss": -81.60430133153521, "actor_target_entropy": -1.0, "actor_entropy": 2.559442792619978, "alpha_loss": -0.005065191172189005, "alpha_value": 0.018186405412694447, "duration": 3.8375415802001953, "step": 94375}
{"episode_reward": 183.73584621078422, "episode": 756.0, "batch_reward": 0.781196141242981, "critic_loss": 2.1623545780181885, "actor_loss": -81.61441212315714, "actor_target_entropy": -1.0, "actor_entropy": 2.5615553240622244, "alpha_loss": -0.004942736364976172, "alpha_value": 0.01825703284112554, "duration": 3.8328144550323486, "step": 94500}
{"episode_reward": 210.51059081529058, "episode": 757.0, "batch_reward": 0.7660746083259583, "critic_loss": 2.1694647607803343, "actor_loss": -81.6037081763858, "actor_target_entropy": -1.0, "actor_entropy": 2.562889961969285, "alpha_loss": -0.005190637641741584, "alpha_value": 0.018336483045344232, "duration": 3.844510316848755, "step": 94625}
{"episode_reward": 89.60943981227057, "episode": 758.0, "batch_reward": 0.76989763879776, "critic_loss": 2.1536055965423584, "actor_loss": -81.59955670756679, "actor_target_entropy": -1.0, "actor_entropy": 2.5598388333474436, "alpha_loss": -0.0046284350382554676, "alpha_value": 0.018412906440363037, "duration": 3.828819990158081, "step": 94750}
{"episode_reward": 140.63773783272987, "episode": 759.0, "batch_reward": 0.7984197402000427, "critic_loss": 2.2949028806686402, "actor_loss": -81.62974729992095, "actor_target_entropy": -1.0, "actor_entropy": 2.5578632808866955, "alpha_loss": -0.00532802249885179, "alpha_value": 0.01848651159409217, "duration": 3.8432564735412598, "step": 94875}
{"episode_reward": 52.95767959345008, "episode": 760.0, "batch_reward": 0.794132119178772, "critic_loss": 2.238246614456177, "actor_loss": -81.65389583956811, "actor_target_entropy": -1.0, "actor_entropy": 2.555755384506718, "alpha_loss": -0.004188954986015995, "alpha_value": 0.018564275982568143, "duration": 3.8293097019195557, "step": 95000}
{"episode_reward": 201.1245738413359, "episode": 761.0, "batch_reward": 0.787172691822052, "critic_loss": 2.2111727056503296, "actor_loss": -81.65383923242963, "actor_target_entropy": -1.0, "actor_entropy": 2.554293405442011, "alpha_loss": -0.0033897400015063346, "alpha_value": 0.018623201447341142, "duration": 3.8354930877685547, "step": 95125}
{"episode_reward": 85.98304554138491, "episode": 762.0, "batch_reward": 0.7785251321792602, "critic_loss": 2.2157294626235964, "actor_loss": -81.65763621176443, "actor_target_entropy": -1.0, "actor_entropy": 2.547507070725964, "alpha_loss": -0.0036712008577230717, "alpha_value": 0.018681472488335377, "duration": 3.8388001918792725, "step": 95250}
{"episode_reward": 158.14026389837557, "episode": 763.0, "batch_reward": 0.7915912752151489, "critic_loss": 2.2446965494155884, "actor_loss": -81.67246888175843, "actor_target_entropy": -1.0, "actor_entropy": 2.539049920581636, "alpha_loss": -0.0030769482938691026, "alpha_value": 0.018732966802795434, "duration": 3.8385610580444336, "step": 95375}
{"episode_reward": 101.22475834814401, "episode": 764.0, "batch_reward": 0.7870662951469422, "critic_loss": 2.2272093811035156, "actor_loss": -81.69328357327369, "actor_target_entropy": -1.0, "actor_entropy": 2.5382410326311664, "alpha_loss": -0.002712752630618671, "alpha_value": 0.018781641947051654, "duration": 3.827127456665039, "step": 95500}
{"episode_reward": 92.07414038790219, "episode": 765.0, "batch_reward": 0.7913355870246888, "critic_loss": 2.195648491859436, "actor_loss": -81.72094181605748, "actor_target_entropy": -1.0, "actor_entropy": 2.5330424233088418, "alpha_loss": -0.003091339727804538, "alpha_value": 0.018827087899773467, "duration": 3.840726375579834, "step": 95625}
{"episode_reward": 184.00128793569195, "episode": 766.0, "batch_reward": 0.78860324716568, "critic_loss": 2.2765311126708982, "actor_loss": -81.73662333334646, "actor_target_entropy": -1.0, "actor_entropy": 2.524259167332803, "alpha_loss": -0.0017573467452049016, "alpha_value": 0.01886813169082605, "duration": 3.8389270305633545, "step": 95750}
{"episode_reward": 70.8560004205826, "episode": 767.0, "batch_reward": 0.7862848038673401, "critic_loss": 2.2270967874526977, "actor_loss": -81.75384218730623, "actor_target_entropy": -1.0, "actor_entropy": 2.5196423152136425, "alpha_loss": -0.0005324805526816774, "alpha_value": 0.018891325870354792, "duration": 3.84161114692688, "step": 95875}
{"episode_reward": 171.00554932892175, "episode": 768.0, "batch_reward": 0.7860016431808472, "critic_loss": 2.2198239889144897, "actor_loss": -81.78201761553365, "actor_target_entropy": -1.0, "actor_entropy": 2.5154952387655936, "alpha_loss": -0.002064255530938446, "alpha_value": 0.018911771323943966, "duration": 3.8316781520843506, "step": 96000}
{"episode_reward": 208.48041396160139, "episode": 769.0, "batch_reward": 0.7955894474983215, "critic_loss": 2.290939935684204, "actor_loss": -81.80478038485089, "actor_target_entropy": -1.0, "actor_entropy": 2.5172352866520957, "alpha_loss": -0.00048551790782117417, "alpha_value": 0.018934430371576983, "duration": 3.8433308601379395, "step": 96125}
{"episode_reward": 148.99238380494842, "episode": 770.0, "batch_reward": 0.7934516181945801, "critic_loss": 2.2801729497909546, "actor_loss": -81.82949730657762, "actor_target_entropy": -1.0, "actor_entropy": 2.511772878708378, "alpha_loss": -0.001203387105394335, "alpha_value": 0.018953434082250257, "duration": 3.836350440979004, "step": 96250}
{"episode_reward": 244.99120932234084, "episode": 771.0, "batch_reward": 0.796864513874054, "critic_loss": 2.2241542196273802, "actor_loss": -81.85715884254093, "actor_target_entropy": -1.0, "actor_entropy": 2.50144100189209, "alpha_loss": 0.0005001952647164996, "alpha_value": 0.01895529217438388, "duration": 3.851247549057007, "step": 96375}
{"episode_reward": 37.326289602816956, "episode": 772.0, "batch_reward": 0.7905736346244812, "critic_loss": 2.194044273376465, "actor_loss": -81.87513043803554, "actor_target_entropy": -1.0, "actor_entropy": 2.492171133718183, "alpha_loss": 0.0002544382361755256, "alpha_value": 0.01895472244515724, "duration": 3.837705373764038, "step": 96500}
{"episode_reward": 202.05939627499146, "episode": 773.0, "batch_reward": 0.7957699699401856, "critic_loss": 2.24433403301239, "actor_loss": -81.91422526041667, "actor_target_entropy": -1.0, "actor_entropy": 2.483996860564701, "alpha_loss": 0.0012379261990269972, "alpha_value": 0.018941939004818876, "duration": 3.8340015411376953, "step": 96625}
{"episode_reward": 179.07839409799314, "episode": 774.0, "batch_reward": 0.7924774885177612, "critic_loss": 2.199429087638855, "actor_loss": -81.91112469088647, "actor_target_entropy": -1.0, "actor_entropy": 2.469684616211922, "alpha_loss": 0.0023275623407830754, "alpha_value": 0.01890755164333631, "duration": 3.8356714248657227, "step": 96750}
{"episode_reward": 156.13331006335142, "episode": 775.0, "batch_reward": 0.798634506225586, "critic_loss": 2.2370241813659666, "actor_loss": -81.95568121047248, "actor_target_entropy": -1.0, "actor_entropy": 2.4483907033526706, "alpha_loss": 0.0021771658276621667, "alpha_value": 0.018861465696843615, "duration": 3.8392531871795654, "step": 96875}
{"episode_reward": 168.71585962377446, "episode": 776.0, "batch_reward": 0.8007042918205262, "critic_loss": 2.217182213783264, "actor_loss": -81.98339585335025, "actor_target_entropy": -1.0, "actor_entropy": 2.4305868610259025, "alpha_loss": 0.0031807000416466187, "alpha_value": 0.018814172280615386, "duration": 3.8487131595611572, "step": 97000}
{"episode_reward": 155.18633296998289, "episode": 777.0, "batch_reward": 0.7858374676704407, "critic_loss": 2.262053270339966, "actor_loss": -82.01049550374348, "actor_target_entropy": -1.0, "actor_entropy": 2.4272496056935142, "alpha_loss": 0.004418399585928354, "alpha_value": 0.01873022573494765, "duration": 3.8306422233581543, "step": 97125}
{"episode_reward": 81.98198331341258, "episode": 778.0, "batch_reward": 0.796466142654419, "critic_loss": 2.252942144393921, "actor_loss": -82.05647314748457, "actor_target_entropy": -1.0, "actor_entropy": 2.4282649101749545, "alpha_loss": 0.0037893654934446058, "alpha_value": 0.018653663793781975, "duration": 3.838972568511963, "step": 97250}
{"episode_reward": 172.59006933812438, "episode": 779.0, "batch_reward": 0.8019741706848145, "critic_loss": 2.2986331090927123, "actor_loss": -82.07725403800843, "actor_target_entropy": -1.0, "actor_entropy": 2.417262849353609, "alpha_loss": 0.004471765421811373, "alpha_value": 0.018569694802481374, "duration": 3.841738224029541, "step": 97375}
{"episode_reward": 202.37871084263017, "episode": 780.0, "batch_reward": 0.7997376708984375, "critic_loss": 2.29082154750824, "actor_loss": -82.12281356319305, "actor_target_entropy": -1.0, "actor_entropy": 2.407130010666386, "alpha_loss": 0.004106698758644803, "alpha_value": 0.018486560791107994, "duration": 3.834728240966797, "step": 97500}
{"episode_reward": 108.82877305506555, "episode": 781.0, "batch_reward": 0.8062808837890625, "critic_loss": 2.3531140880584718, "actor_loss": -82.15819852314299, "actor_target_entropy": -1.0, "actor_entropy": 2.3944530638437422, "alpha_loss": 0.005926333032437556, "alpha_value": 0.018383294633612088, "duration": 3.8478431701660156, "step": 97625}
{"episode_reward": 189.40852188016308, "episode": 782.0, "batch_reward": 0.8070741839408875, "critic_loss": 2.3535631351470947, "actor_loss": -82.2180672922442, "actor_target_entropy": -1.0, "actor_entropy": 2.385460284448439, "alpha_loss": 0.005474960491541893, "alpha_value": 0.018275559148175975, "duration": 3.825521469116211, "step": 97750}
{"episode_reward": 154.1151403169926, "episode": 783.0, "batch_reward": 0.7971435470581054, "critic_loss": 2.249775379180908, "actor_loss": -82.23912665957496, "actor_target_entropy": -1.0, "actor_entropy": 2.387212965223524, "alpha_loss": 0.005685428032718066, "alpha_value": 0.018162017062779902, "duration": 3.8374247550964355, "step": 97875}
{"episode_reward": 113.15269145821453, "episode": 784.0, "batch_reward": 0.7995496668815613, "critic_loss": 2.2613007545471193, "actor_loss": -82.28961255473476, "actor_target_entropy": -1.0, "actor_entropy": 2.393397608110982, "alpha_loss": 0.005197611460912853, "alpha_value": 0.018062870134096055, "duration": 3.834137439727783, "step": 98000}
{"episode_reward": 179.86236699758226, "episode": 785.0, "batch_reward": 0.7986151247024537, "critic_loss": 2.186074546813965, "actor_loss": -82.32490951295883, "actor_target_entropy": -1.0, "actor_entropy": 2.394796114119272, "alpha_loss": 0.005450032195002432, "alpha_value": 0.01796295464929431, "duration": 3.840148687362671, "step": 98125}
{"episode_reward": 203.5136814138551, "episode": 786.0, "batch_reward": 0.8020853981971741, "critic_loss": 2.268176718711853, "actor_loss": -82.37596622590095, "actor_target_entropy": -1.0, "actor_entropy": 2.399874641049293, "alpha_loss": 0.003262455244698832, "alpha_value": 0.017882113859960927, "duration": 3.8385682106018066, "step": 98250}
{"episode_reward": 149.53209531924838, "episode": 787.0, "batch_reward": 0.7992640080451965, "critic_loss": 2.220386707305908, "actor_loss": -82.38711729503814, "actor_target_entropy": -1.0, "actor_entropy": 2.3873921500311956, "alpha_loss": 0.005211933264656673, "alpha_value": 0.017805996459922042, "duration": 3.840730667114258, "step": 98375}
{"episode_reward": 117.19553762338097, "episode": 788.0, "batch_reward": 0.7969283542633057, "critic_loss": 2.2616272506713866, "actor_loss": -82.43586041850429, "actor_target_entropy": -1.0, "actor_entropy": 2.3865094646330802, "alpha_loss": 0.00451257417538023, "alpha_value": 0.01771356310566281, "duration": 3.8381454944610596, "step": 98500}
{"episode_reward": 140.02316107804876, "episode": 789.0, "batch_reward": 0.8004190068244934, "critic_loss": 2.2703974056243896, "actor_loss": -82.46226888989645, "actor_target_entropy": -1.0, "actor_entropy": 2.37681832389226, "alpha_loss": 0.005152139354900029, "alpha_value": 0.017629366060898183, "duration": 3.8461456298828125, "step": 98625}
{"episode_reward": 117.91353800104201, "episode": 790.0, "batch_reward": 0.7948525500297546, "critic_loss": 2.1995294723510743, "actor_loss": -82.49150048532793, "actor_target_entropy": -1.0, "actor_entropy": 2.3644666056479178, "alpha_loss": 0.004647898470847717, "alpha_value": 0.01753959941653772, "duration": 3.838670253753662, "step": 98750}
{"episode_reward": 152.0428153405487, "episode": 791.0, "batch_reward": 0.8083381896018982, "critic_loss": 2.2760483837127685, "actor_loss": -82.54197959294395, "actor_target_entropy": -1.0, "actor_entropy": 2.349145420013912, "alpha_loss": 0.005927920853811508, "alpha_value": 0.017441319540191166, "duration": 3.8362226486206055, "step": 98875}
{"episode_reward": 173.86178851474233, "episode": 792.0, "batch_reward": 0.8042045588493347, "critic_loss": 2.199379200935364, "actor_loss": -82.58878732496693, "actor_target_entropy": -1.0, "actor_entropy": 2.3311487320930726, "alpha_loss": 0.005470051891132889, "alpha_value": 0.017340245551988546, "duration": 3.837926149368286, "step": 99000}
{"episode_reward": 106.85788962994607, "episode": 793.0, "batch_reward": 0.8007505111694336, "critic_loss": 2.2404414567947386, "actor_loss": -82.62316289023748, "actor_target_entropy": -1.0, "actor_entropy": 2.303302325899639, "alpha_loss": 0.007048329501043236, "alpha_value": 0.01722953403398474, "duration": 3.841161012649536, "step": 99125}
{"episode_reward": 192.43526127802127, "episode": 794.0, "batch_reward": 0.8016837630271911, "critic_loss": 2.320376742362976, "actor_loss": -82.67437510336599, "actor_target_entropy": -1.0, "actor_entropy": 2.2741668608880814, "alpha_loss": 0.007215239993867374, "alpha_value": 0.017103114209728407, "duration": 3.833639621734619, "step": 99250}
{"episode_reward": 139.22702933949202, "episode": 795.0, "batch_reward": 0.7943436489105224, "critic_loss": 2.1546796255111693, "actor_loss": -82.69354732452877, "actor_target_entropy": -1.0, "actor_entropy": 2.260678291320801, "alpha_loss": 0.00768809116053735, "alpha_value": 0.016978452652391444, "duration": 3.8388254642486572, "step": 99375}
{"episode_reward": 128.6406185373193, "episode": 796.0, "batch_reward": 0.8127660641670227, "critic_loss": 2.3441825428009033, "actor_loss": -82.74660418110508, "actor_target_entropy": -1.0, "actor_entropy": 2.2511339649077384, "alpha_loss": 0.008482945406989705, "alpha_value": 0.016845978056314843, "duration": 3.8321692943573, "step": 99500}
{"episode_reward": 120.34970702125293, "episode": 797.0, "batch_reward": 0.7964548077583313, "critic_loss": 2.256984380722046, "actor_loss": -82.78430539085751, "actor_target_entropy": -1.0, "actor_entropy": 2.2324668490697466, "alpha_loss": 0.0077655520253179094, "alpha_value": 0.01672128938642928, "duration": 3.8443374633789062, "step": 99625}
{"episode_reward": 188.66208904664384, "episode": 798.0, "batch_reward": 0.8216117906570435, "critic_loss": 2.309901865005493, "actor_loss": -82.8407365122149, "actor_target_entropy": -1.0, "actor_entropy": 2.2120122601909022, "alpha_loss": 0.008555145470440508, "alpha_value": 0.01659451251043737, "duration": 3.8377315998077393, "step": 99750}
{"episode_reward": 182.88828265946134, "episode": 799.0, "batch_reward": 0.8094681158065796, "critic_loss": 2.296422660827637, "actor_loss": -82.89259435260107, "actor_target_entropy": -1.0, "actor_entropy": 2.2030522634112644, "alpha_loss": 0.008243064525433712, "alpha_value": 0.016469684185162054, "duration": 3.8433918952941895, "step": 99875}
{"episode_reward": 125.82095438101187, "episode": 800.0, "batch_reward": 0.8101880159378052, "critic_loss": 2.266456563949585, "actor_loss": -82.9299547749181, "actor_target_entropy": -1.0, "actor_entropy": 2.2037182777158675, "alpha_loss": 0.007919169434781877, "alpha_value": 0.016346781270182163, "duration": 3.8336591720581055, "step": 100000}
{"episode_reward": 83.83162972060393, "episode": 801.0, "batch_reward": 0.8079270143508911, "critic_loss": 2.2590214948654177, "actor_loss": -83.00525628952752, "actor_target_entropy": -1.0, "actor_entropy": 2.192892483302525, "alpha_loss": 0.006846151048583644, "alpha_value": 0.016246032218903715, "duration": 7.822153806686401, "step": 100125}
{"episode_reward": 67.35727430228866, "episode": 802.0, "batch_reward": 0.8028039331436158, "critic_loss": 2.2955600299835206, "actor_loss": -83.0505965448195, "actor_target_entropy": -1.0, "actor_entropy": 2.1539578437805176, "alpha_loss": 0.007589351175533187, "alpha_value": 0.016139976815846026, "duration": 3.835566520690918, "step": 100250}
{"episode_reward": 179.45118878103943, "episode": 803.0, "batch_reward": 0.8160441460609436, "critic_loss": 2.3080335631370543, "actor_loss": -83.1174586462596, "actor_target_entropy": -1.0, "actor_entropy": 2.114325765579466, "alpha_loss": 0.00815046613755089, "alpha_value": 0.016032035516418373, "duration": 3.8417816162109375, "step": 100375}
{"episode_reward": 132.29056431147745, "episode": 804.0, "batch_reward": 0.8057704486846924, "critic_loss": 2.218741794586182, "actor_loss": -83.11918111001292, "actor_target_entropy": -1.0, "actor_entropy": 2.1030665366880354, "alpha_loss": 0.008060015144667799, "alpha_value": 0.015921330863080254, "duration": 3.8384180068969727, "step": 100500}
{"episode_reward": 53.662155669157784, "episode": 805.0, "batch_reward": 0.7929148240089416, "critic_loss": 2.2755666360855105, "actor_loss": -83.14611223008897, "actor_target_entropy": -1.0, "actor_entropy": 2.1237846404787093, "alpha_loss": 0.007429243689070323, "alpha_value": 0.01581413298219711, "duration": 3.8390820026397705, "step": 100625}
{"episode_reward": 144.8626504043024, "episode": 806.0, "batch_reward": 0.7978734731674194, "critic_loss": 2.2441599311828613, "actor_loss": -83.19063383533108, "actor_target_entropy": -1.0, "actor_entropy": 2.1126852650796213, "alpha_loss": 0.007149539806226629, "alpha_value": 0.015718994684421197, "duration": 3.8468263149261475, "step": 100750}
{"episode_reward": 199.46927715352416, "episode": 807.0, "batch_reward": 0.811271023273468, "critic_loss": 2.265815810203552, "actor_loss": -83.2454344734313, "actor_target_entropy": -1.0, "actor_entropy": 2.11256590343657, "alpha_loss": 0.006808389552004103, "alpha_value": 0.01562763542261421, "duration": 3.8408193588256836, "step": 100875}
{"episode_reward": 191.56049886066586, "episode": 808.0, "batch_reward": 0.8016346645355225, "critic_loss": 2.245881363868713, "actor_loss": -83.30857246152816, "actor_target_entropy": -1.0, "actor_entropy": 2.067870017020933, "alpha_loss": 0.006829917397079689, "alpha_value": 0.015539421075142397, "duration": 3.8365237712860107, "step": 101000}
{"episode_reward": 139.18424412903053, "episode": 809.0, "batch_reward": 0.8060132260322571, "critic_loss": 2.218551058769226, "actor_loss": -83.35344574943421, "actor_target_entropy": -1.0, "actor_entropy": 2.006368981467353, "alpha_loss": 0.006689740045528326, "alpha_value": 0.015448692833246873, "duration": 3.843583822250366, "step": 101125}
{"episode_reward": 212.46277519303953, "episode": 810.0, "batch_reward": 0.824372058391571, "critic_loss": 2.306917356491089, "actor_loss": -83.42737320930728, "actor_target_entropy": -1.0, "actor_entropy": 1.9703418093342935, "alpha_loss": 0.006903390294962352, "alpha_value": 0.015359394133205808, "duration": 3.8279335498809814, "step": 101250}
{"episode_reward": 130.84848996332283, "episode": 811.0, "batch_reward": 0.8089089002609253, "critic_loss": 2.2610877113342287, "actor_loss": -83.50690326993427, "actor_target_entropy": -1.0, "actor_entropy": 1.921017467029511, "alpha_loss": 0.006342895434326714, "alpha_value": 0.01527691104445924, "duration": 3.84421706199646, "step": 101375}
{"episode_reward": 60.65317719703202, "episode": 812.0, "batch_reward": 0.8165799536705017, "critic_loss": 2.2565456371307375, "actor_loss": -83.55416550174836, "actor_target_entropy": -1.0, "actor_entropy": 1.8426641071996381, "alpha_loss": 0.00555067122801237, "alpha_value": 0.015197545045016974, "duration": 3.834467887878418, "step": 101500}
{"episode_reward": 143.81246512225252, "episode": 813.0, "batch_reward": 0.8270740604400635, "critic_loss": 2.3593391218185427, "actor_loss": -83.64547136094835, "actor_target_entropy": -1.0, "actor_entropy": 1.7840448125960335, "alpha_loss": 0.004363450905426391, "alpha_value": 0.015132538973729978, "duration": 3.8465945720672607, "step": 101625}
{"episode_reward": 85.73165781308111, "episode": 814.0, "batch_reward": 0.8116554470062256, "critic_loss": 2.30240030002594, "actor_loss": -83.68146071895477, "actor_target_entropy": -1.0, "actor_entropy": 1.698501790723493, "alpha_loss": 0.003703262251351149, "alpha_value": 0.015077394039505988, "duration": 3.8357272148132324, "step": 101750}
{"episode_reward": 137.22302411883976, "episode": 815.0, "batch_reward": 0.8258999800682068, "critic_loss": 2.351016953468323, "actor_loss": -83.82140301901197, "actor_target_entropy": -1.0, "actor_entropy": 1.5740434271948678, "alpha_loss": 0.002119080816757762, "alpha_value": 0.015039292794164761, "duration": 3.842195749282837, "step": 101875}
{"episode_reward": 120.79057131338925, "episode": 816.0, "batch_reward": 0.8064536890983581, "critic_loss": 2.2149251766204836, "actor_loss": -83.93187639790196, "actor_target_entropy": -1.0, "actor_entropy": 1.356341504281567, "alpha_loss": -0.0008431476237620377, "alpha_value": 0.0150270734970795, "duration": 3.8397295475006104, "step": 102000}
{"episode_reward": 72.03708043184714, "episode": 817.0, "batch_reward": 0.8234402532577515, "critic_loss": 2.27627654838562, "actor_loss": -84.03591022794208, "actor_target_entropy": -1.0, "actor_entropy": 1.0687052427776276, "alpha_loss": -0.005849454012359419, "alpha_value": 0.015072148231289648, "duration": 3.836574077606201, "step": 102125}
{"episode_reward": 74.23208612740038, "episode": 818.0, "batch_reward": 0.8012542643547058, "critic_loss": 2.183769262313843, "actor_loss": -84.11725554927703, "actor_target_entropy": -1.0, "actor_entropy": 0.811858396376333, "alpha_loss": -0.011527235274233164, "alpha_value": 0.015191011129772862, "duration": 3.842532157897949, "step": 102250}
{"episode_reward": 73.73187938567462, "episode": 819.0, "batch_reward": 0.795954083442688, "critic_loss": 2.193891568183899, "actor_loss": -84.23245796324714, "actor_target_entropy": -1.0, "actor_entropy": 0.619846088545663, "alpha_loss": -0.016219533447708403, "alpha_value": 0.01537702088833099, "duration": 3.840836524963379, "step": 102375}
{"episode_reward": 72.0745886382181, "episode": 820.0, "batch_reward": 0.801547999382019, "critic_loss": 2.288870906829834, "actor_loss": -84.29307322348318, "actor_target_entropy": -1.0, "actor_entropy": 0.5084718158168178, "alpha_loss": -0.019125262590786143, "alpha_value": 0.01558975702248019, "duration": 3.835120916366577, "step": 102500}
{"episode_reward": 74.43498174321444, "episode": 821.0, "batch_reward": 0.8185132899284363, "critic_loss": 2.2791605825424193, "actor_loss": -84.37741343180339, "actor_target_entropy": -1.0, "actor_entropy": 0.4513775375154283, "alpha_loss": -0.021410345203346677, "alpha_value": 0.015809515585280803, "duration": 3.843101739883423, "step": 102625}
{"episode_reward": 75.46990446050425, "episode": 822.0, "batch_reward": 0.8287107429504394, "critic_loss": 2.3218364210128786, "actor_loss": -84.50845595329038, "actor_target_entropy": -1.0, "actor_entropy": 0.431660040732353, "alpha_loss": -0.023245042580510338, "alpha_value": 0.016026688307407715, "duration": 3.835625171661377, "step": 102750}
{"episode_reward": 71.7254285030736, "episode": 823.0, "batch_reward": 0.8015566787719727, "critic_loss": 2.2729963245391844, "actor_loss": -84.56536744132875, "actor_target_entropy": -1.0, "actor_entropy": 0.44254810280270046, "alpha_loss": -0.023900219431472202, "alpha_value": 0.016233815812638008, "duration": 3.8423171043395996, "step": 102875}
{"episode_reward": 72.054890019621, "episode": 824.0, "batch_reward": 0.797169234752655, "critic_loss": 2.19175581741333, "actor_loss": -84.59443738383632, "actor_target_entropy": -1.0, "actor_entropy": 0.4444560581637967, "alpha_loss": -0.02471917098568332, "alpha_value": 0.016431597251470347, "duration": 3.840414047241211, "step": 103000}
{"episode_reward": 72.42050797048952, "episode": 825.0, "batch_reward": 0.8032264184951782, "critic_loss": 2.2467993907928467, "actor_loss": -84.66832006545295, "actor_target_entropy": -1.0, "actor_entropy": 0.458192403354342, "alpha_loss": -0.025525719962186284, "alpha_value": 0.016622779752372665, "duration": 3.8481831550598145, "step": 103125}
{"episode_reward": 73.07114198757088, "episode": 826.0, "batch_reward": 0.8194262623786926, "critic_loss": 2.296880958557129, "actor_loss": -84.77358713457662, "actor_target_entropy": -1.0, "actor_entropy": 0.47054323457902475, "alpha_loss": -0.025998446789960706, "alpha_value": 0.01680532930501024, "duration": 3.831833600997925, "step": 103250}
{"episode_reward": 74.7914991402075, "episode": 827.0, "batch_reward": 0.8075325202941894, "critic_loss": 2.2558348598480227, "actor_loss": -84.83444601391989, "actor_target_entropy": -1.0, "actor_entropy": 0.4846186429735214, "alpha_loss": -0.026838804225599956, "alpha_value": 0.016985429921393087, "duration": 3.8521456718444824, "step": 103375}
{"episode_reward": 74.23809765456136, "episode": 828.0, "batch_reward": 0.7957209782600403, "critic_loss": 2.171238074302673, "actor_loss": -84.91394116801601, "actor_target_entropy": -1.0, "actor_entropy": 0.5002458057095928, "alpha_loss": -0.027455481249959238, "alpha_value": 0.017160413625155472, "duration": 3.840822696685791, "step": 103500}
{"episode_reward": 75.57427045353118, "episode": 829.0, "batch_reward": 0.8007030372619629, "critic_loss": 2.195991189002991, "actor_loss": -84.93476916116381, "actor_target_entropy": -1.0, "actor_entropy": 0.5220538718359811, "alpha_loss": -0.02791460712869016, "alpha_value": 0.017333095042767387, "duration": 3.8361685276031494, "step": 103625}
{"episode_reward": 72.68453823463304, "episode": 830.0, "batch_reward": 0.8094941654205322, "critic_loss": 2.214339089393616, "actor_loss": -85.01450187929215, "actor_target_entropy": -1.0, "actor_entropy": 0.547037543789033, "alpha_loss": -0.02820009801296457, "alpha_value": 0.01750148033558303, "duration": 3.840179443359375, "step": 103750}
{"episode_reward": 71.63909552299118, "episode": 831.0, "batch_reward": 0.8023762350082397, "critic_loss": 2.283749342441559, "actor_loss": -85.02852981809586, "actor_target_entropy": -1.0, "actor_entropy": 0.5676814506924341, "alpha_loss": -0.0285103042269983, "alpha_value": 0.017665166876426882, "duration": 3.8421313762664795, "step": 103875}
{"episode_reward": 74.25031559694831, "episode": 832.0, "batch_reward": 0.8076319932937622, "critic_loss": 2.2537832832336426, "actor_loss": -85.10482320477885, "actor_target_entropy": -1.0, "actor_entropy": 0.5924225814880864, "alpha_loss": -0.028510916887992812, "alpha_value": 0.017826462355391128, "duration": 3.8444623947143555, "step": 104000}
{"episode_reward": 74.11319692658851, "episode": 833.0, "batch_reward": 0.7984314608573914, "critic_loss": 2.1815568151474, "actor_loss": -85.16492256285652, "actor_target_entropy": -1.0, "actor_entropy": 0.6072046056626335, "alpha_loss": -0.029248042179951594, "alpha_value": 0.017985090872196456, "duration": 3.846693992614746, "step": 104125}
{"episode_reward": 70.52652468665278, "episode": 834.0, "batch_reward": 0.8164046239852906, "critic_loss": 2.2285572938919067, "actor_loss": -85.24089517901021, "actor_target_entropy": -1.0, "actor_entropy": 0.6211416221434071, "alpha_loss": -0.028793850102491917, "alpha_value": 0.018142166617508112, "duration": 3.8362042903900146, "step": 104250}
{"episode_reward": 73.67835834210634, "episode": 835.0, "batch_reward": 0.8153746604919434, "critic_loss": 2.2460685367584228, "actor_loss": -85.3238032507518, "actor_target_entropy": -1.0, "actor_entropy": 0.6298086699985322, "alpha_loss": -0.02973048510177741, "alpha_value": 0.01829681193959049, "duration": 3.845513343811035, "step": 104375}
{"episode_reward": 74.16929794078193, "episode": 836.0, "batch_reward": 0.8199448781013489, "critic_loss": 2.294564999580383, "actor_loss": -85.34119390672252, "actor_target_entropy": -1.0, "actor_entropy": 0.6515089504180416, "alpha_loss": -0.030419420090413863, "alpha_value": 0.018452691032252205, "duration": 3.837373733520508, "step": 104500}
{"episode_reward": 73.54835842548617, "episode": 837.0, "batch_reward": 0.8018071961402893, "critic_loss": 2.238563049316406, "actor_loss": -85.37112886943514, "actor_target_entropy": -1.0, "actor_entropy": 0.6795700334367298, "alpha_loss": -0.029748423675459528, "alpha_value": 0.018606872050777094, "duration": 3.858691453933716, "step": 104625}
{"episode_reward": 75.53773475629991, "episode": 838.0, "batch_reward": 0.8152311367988586, "critic_loss": 2.326342225074768, "actor_loss": -85.37490537089687, "actor_target_entropy": -1.0, "actor_entropy": 0.6970945981241041, "alpha_loss": -0.030048538059476885, "alpha_value": 0.01875730706281998, "duration": 3.839343786239624, "step": 104750}
{"episode_reward": 73.01148967276609, "episode": 839.0, "batch_reward": 0.8070534796714782, "critic_loss": 2.2485849590301514, "actor_loss": -85.43753330291264, "actor_target_entropy": -1.0, "actor_entropy": 0.72125710570623, "alpha_loss": -0.030159007343981, "alpha_value": 0.018906626328047803, "duration": 3.849461078643799, "step": 104875}
{"episode_reward": 72.05359184666882, "episode": 840.0, "batch_reward": 0.7997361092567444, "critic_loss": 2.204791467666626, "actor_loss": -85.47276429207095, "actor_target_entropy": -1.0, "actor_entropy": 0.7293494939804077, "alpha_loss": -0.030226722359657288, "alpha_value": 0.01905568821838514, "duration": 3.844832420349121, "step": 105000}
{"episode_reward": 74.87484545999912, "episode": 841.0, "batch_reward": 0.8214401559829712, "critic_loss": 2.2949023885726927, "actor_loss": -85.49994199238127, "actor_target_entropy": -1.0, "actor_entropy": 0.7483379594863407, "alpha_loss": -0.029879752457851454, "alpha_value": 0.019202056621746864, "duration": 3.842397928237915, "step": 105125}
{"episode_reward": 73.44821054885864, "episode": 842.0, "batch_reward": 0.807141791343689, "critic_loss": 2.278001238822937, "actor_loss": -85.55167598109091, "actor_target_entropy": -1.0, "actor_entropy": 0.750319084813518, "alpha_loss": -0.030567348514112733, "alpha_value": 0.019347598186116696, "duration": 3.8410701751708984, "step": 105250}
{"episode_reward": 74.29109119463104, "episode": 843.0, "batch_reward": 0.7993660068511963, "critic_loss": 2.1426563205718994, "actor_loss": -85.58443281385634, "actor_target_entropy": -1.0, "actor_entropy": 0.7597032898948306, "alpha_loss": -0.030890233341663603, "alpha_value": 0.019495627976164293, "duration": 3.840543746948242, "step": 105375}
{"episode_reward": 72.60634008686951, "episode": 844.0, "batch_reward": 0.8041200575828552, "critic_loss": 2.31320152759552, "actor_loss": -85.60176086425781, "actor_target_entropy": -1.0, "actor_entropy": 0.7568310960646598, "alpha_loss": -0.0305062782980742, "alpha_value": 0.019641349879191333, "duration": 3.8390865325927734, "step": 105500}
{"episode_reward": 73.93492092035038, "episode": 845.0, "batch_reward": 0.7985173382759094, "critic_loss": 2.2412567510604857, "actor_loss": -85.62034655374194, "actor_target_entropy": -1.0, "actor_entropy": 0.759328253685482, "alpha_loss": -0.031223805532568975, "alpha_value": 0.019787384376443964, "duration": 3.845944881439209, "step": 105625}
{"episode_reward": 76.27035750363264, "episode": 846.0, "batch_reward": 0.8202732534408569, "critic_loss": 2.298232135772705, "actor_loss": -85.64230691232989, "actor_target_entropy": -1.0, "actor_entropy": 0.7841210557568458, "alpha_loss": -0.030747849133706862, "alpha_value": 0.01993401110420644, "duration": 3.837061882019043, "step": 105750}
{"episode_reward": 73.12525361678591, "episode": 847.0, "batch_reward": 0.8011140394210815, "critic_loss": 2.1513328008651733, "actor_loss": -85.60436248779297, "actor_target_entropy": -1.0, "actor_entropy": 0.8187098749100216, "alpha_loss": -0.030101553463037053, "alpha_value": 0.020076608265257964, "duration": 3.8451614379882812, "step": 105875}
{"episode_reward": 70.17092813996086, "episode": 848.0, "batch_reward": 0.7933056674003601, "critic_loss": 2.2340949716567993, "actor_loss": -85.59055094565115, "actor_target_entropy": -1.0, "actor_entropy": 0.8641127347946167, "alpha_loss": -0.029497323377478506, "alpha_value": 0.02021751244202253, "duration": 3.8321754932403564, "step": 106000}
{"episode_reward": 73.17091529456894, "episode": 849.0, "batch_reward": 0.800929756641388, "critic_loss": 2.1990225572586057, "actor_loss": -85.61285388280474, "actor_target_entropy": -1.0, "actor_entropy": 0.8669325832336668, "alpha_loss": -0.029145208497842152, "alpha_value": 0.020354833782123476, "duration": 3.841578960418701, "step": 106125}
{"episode_reward": 72.77450006786077, "episode": 850.0, "batch_reward": 0.7993444952964782, "critic_loss": 2.1805970153808594, "actor_loss": -85.63063504618984, "actor_target_entropy": -1.0, "actor_entropy": 0.8588857843029883, "alpha_loss": -0.029517989515537215, "alpha_value": 0.020492944736608475, "duration": 3.836383581161499, "step": 106250}
{"episode_reward": 74.23894708969169, "episode": 851.0, "batch_reward": 0.812716082572937, "critic_loss": 2.2259951181411743, "actor_loss": -85.65731072804284, "actor_target_entropy": -1.0, "actor_entropy": 0.8598744396179442, "alpha_loss": -0.029289775690625585, "alpha_value": 0.0206312960109828, "duration": 3.8477976322174072, "step": 106375}
{"episode_reward": 75.74462583754674, "episode": 852.0, "batch_reward": 0.8029475588798523, "critic_loss": 2.2615882387161257, "actor_loss": -85.65124856272051, "actor_target_entropy": -1.0, "actor_entropy": 0.8466896280165641, "alpha_loss": -0.029041078031784105, "alpha_value": 0.020767121561334232, "duration": 3.8325397968292236, "step": 106500}
{"episode_reward": 73.25582978312566, "episode": 853.0, "batch_reward": 0.8182695698738098, "critic_loss": 2.2474653759002687, "actor_loss": -85.69298638237848, "actor_target_entropy": -1.0, "actor_entropy": 0.8420077297422621, "alpha_loss": -0.02888639581700166, "alpha_value": 0.020904431847507295, "duration": 3.8404953479766846, "step": 106625}
{"episode_reward": 75.56368162448165, "episode": 854.0, "batch_reward": 0.7929270401000976, "critic_loss": 2.088440893650055, "actor_loss": -85.67152232508505, "actor_target_entropy": -1.0, "actor_entropy": 0.8483241335038216, "alpha_loss": -0.029053717911724123, "alpha_value": 0.02104176122371753, "duration": 3.8420097827911377, "step": 106750}
{"episode_reward": 73.79401437689418, "episode": 855.0, "batch_reward": 0.7985335693359376, "critic_loss": 2.1290315742492676, "actor_loss": -85.68412526448567, "actor_target_entropy": -1.0, "actor_entropy": 0.8498357155966381, "alpha_loss": -0.028423812861243885, "alpha_value": 0.021178537073568517, "duration": 3.8397326469421387, "step": 106875}
{"episode_reward": 76.57342610601472, "episode": 856.0, "batch_reward": 0.7977320337295533, "critic_loss": 2.1320821294784547, "actor_loss": -85.68513328798356, "actor_target_entropy": -1.0, "actor_entropy": 0.8577533421977874, "alpha_loss": -0.02859911866365902, "alpha_value": 0.02131442093196194, "duration": 3.839522123336792, "step": 107000}
{"episode_reward": 72.60118861767077, "episode": 857.0, "batch_reward": 0.7924834260940552, "critic_loss": 2.263543138504028, "actor_loss": -85.70286644829645, "actor_target_entropy": -1.0, "actor_entropy": 0.8547921578089396, "alpha_loss": -0.028047015535689536, "alpha_value": 0.021451767628354507, "duration": 3.8422305583953857, "step": 107125}
{"episode_reward": 73.90531790347279, "episode": 858.0, "batch_reward": 0.8150355186462402, "critic_loss": 2.1817733373641968, "actor_loss": -85.7437512797694, "actor_target_entropy": -1.0, "actor_entropy": 0.8698153226606308, "alpha_loss": -0.02771049641793774, "alpha_value": 0.021585839456468234, "duration": 3.839001417160034, "step": 107250}
{"episode_reward": 74.1965860215937, "episode": 859.0, "batch_reward": 0.8081166105270385, "critic_loss": 2.195716442108154, "actor_loss": -85.69071415492466, "actor_target_entropy": -1.0, "actor_entropy": 0.9037889923368182, "alpha_loss": -0.02599540293689758, "alpha_value": 0.02171691999783073, "duration": 3.83508563041687, "step": 107375}
{"episode_reward": 77.19048390760565, "episode": 860.0, "batch_reward": 0.8054620280265808, "critic_loss": 2.163041088104248, "actor_loss": -85.71075636340726, "actor_target_entropy": -1.0, "actor_entropy": 0.8953006229092998, "alpha_loss": -0.026188144460320473, "alpha_value": 0.02184422810579814, "duration": 3.8390698432922363, "step": 107500}
{"episode_reward": 74.751934029563, "episode": 861.0, "batch_reward": 0.7979982419013977, "critic_loss": 2.1661084623336793, "actor_loss": -85.70809318905785, "actor_target_entropy": -1.0, "actor_entropy": 0.8794134552516635, "alpha_loss": -0.026174271242722633, "alpha_value": 0.02197413047756484, "duration": 3.8409414291381836, "step": 107625}
{"episode_reward": 76.51983474559697, "episode": 862.0, "batch_reward": 0.8006312198638916, "critic_loss": 2.1561074285507202, "actor_loss": -85.6987061039094, "actor_target_entropy": -1.0, "actor_entropy": 0.8806999152706515, "alpha_loss": -0.025062204518866156, "alpha_value": 0.02210255175462335, "duration": 3.833561420440674, "step": 107750}
{"episode_reward": 74.48264107559898, "episode": 863.0, "batch_reward": 0.7979478011131287, "critic_loss": 2.14374666595459, "actor_loss": -85.67208983406188, "actor_target_entropy": -1.0, "actor_entropy": 0.8810770265639775, "alpha_loss": -0.02485808159505564, "alpha_value": 0.02222838741290089, "duration": 3.848524808883667, "step": 107875}
{"episode_reward": 74.05603633547592, "episode": 864.0, "batch_reward": 0.7966496143341064, "critic_loss": 2.2245297956466676, "actor_loss": -85.65392364994172, "actor_target_entropy": -1.0, "actor_entropy": 0.8947493376270417, "alpha_loss": -0.024224279929072626, "alpha_value": 0.022353020500525147, "duration": 3.8409364223480225, "step": 108000}
{"episode_reward": 73.86610399315607, "episode": 865.0, "batch_reward": 0.7963597302436829, "critic_loss": 2.2115392570495604, "actor_loss": -85.65457383413164, "actor_target_entropy": -1.0, "actor_entropy": 0.8786181362848433, "alpha_loss": -0.02372188177255411, "alpha_value": 0.022476388059253047, "duration": 3.8460049629211426, "step": 108125}
{"episode_reward": 71.3445983454368, "episode": 866.0, "batch_reward": 0.7967167420387268, "critic_loss": 2.173327447891235, "actor_loss": -85.63170476113596, "actor_target_entropy": -1.0, "actor_entropy": 0.8910610637357158, "alpha_loss": -0.024197745587556593, "alpha_value": 0.022603132998579065, "duration": 3.8456411361694336, "step": 108250}
{"episode_reward": 72.03242585835773, "episode": 867.0, "batch_reward": 0.7931928706169128, "critic_loss": 2.1714169616699217, "actor_loss": -85.63141607859778, "actor_target_entropy": -1.0, "actor_entropy": 0.9240563729452709, "alpha_loss": -0.02198162048108994, "alpha_value": 0.022723779493881113, "duration": 3.841146945953369, "step": 108375}
{"episode_reward": 72.59066847022572, "episode": 868.0, "batch_reward": 0.8080461621284485, "critic_loss": 2.209297884941101, "actor_loss": -85.60729180612871, "actor_target_entropy": -1.0, "actor_entropy": 0.9121796738716864, "alpha_loss": -0.02194805509380756, "alpha_value": 0.022843039508631185, "duration": 3.840226411819458, "step": 108500}
{"episode_reward": 73.4649696257939, "episode": 869.0, "batch_reward": 0.7923546328544616, "critic_loss": 2.1105752964019775, "actor_loss": -85.58248235308935, "actor_target_entropy": -1.0, "actor_entropy": 0.941511110653953, "alpha_loss": -0.02045862650173524, "alpha_value": 0.02295869836259031, "duration": 3.8400721549987793, "step": 108625}
{"episode_reward": 72.02395035959576, "episode": 870.0, "batch_reward": 0.7853587093353271, "critic_loss": 2.076896944999695, "actor_loss": -85.57003415015436, "actor_target_entropy": -1.0, "actor_entropy": 0.9239421698354906, "alpha_loss": -0.02044164707824107, "alpha_value": 0.02307124276952197, "duration": 3.8377420902252197, "step": 108750}
{"episode_reward": 74.57662447076517, "episode": 871.0, "batch_reward": 0.7926452612876892, "critic_loss": 2.1645490913391114, "actor_loss": -85.53587813604446, "actor_target_entropy": -1.0, "actor_entropy": 0.9188119362271021, "alpha_loss": -0.019757709495486723, "alpha_value": 0.023184496821619015, "duration": 3.844348430633545, "step": 108875}
{"episode_reward": 75.57640387205561, "episode": 872.0, "batch_reward": 0.7909163413047791, "critic_loss": 2.1630169982910155, "actor_loss": -85.48136729578817, "actor_target_entropy": -1.0, "actor_entropy": 0.9533047868359473, "alpha_loss": -0.01835179010466222, "alpha_value": 0.023294480965313422, "duration": 3.8381245136260986, "step": 109000}
{"episode_reward": 75.12833368489186, "episode": 873.0, "batch_reward": 0.7783157620429992, "critic_loss": 2.0150676584243774, "actor_loss": -85.44213031587147, "actor_target_entropy": -1.0, "actor_entropy": 0.9376223598207746, "alpha_loss": -0.01842673374192109, "alpha_value": 0.02340115741658974, "duration": 3.846734046936035, "step": 109125}
{"episode_reward": 72.44087140928276, "episode": 874.0, "batch_reward": 0.7898656282424926, "critic_loss": 2.0952696132659914, "actor_loss": -85.42071877756426, "actor_target_entropy": -1.0, "actor_entropy": 0.945787295218437, "alpha_loss": -0.01780763689068056, "alpha_value": 0.02350870480831002, "duration": 3.833806037902832, "step": 109250}
{"episode_reward": 70.82235907785835, "episode": 875.0, "batch_reward": 0.7966887755393982, "critic_loss": 2.2255906496047975, "actor_loss": -85.3942357623388, "actor_target_entropy": -1.0, "actor_entropy": 0.9641329314973619, "alpha_loss": -0.0168353778324903, "alpha_value": 0.0236130998191654, "duration": 3.841684579849243, "step": 109375}
{"episode_reward": 69.47340427564741, "episode": 876.0, "batch_reward": 0.7891901979446411, "critic_loss": 2.1094089965820313, "actor_loss": -85.34436293571225, "actor_target_entropy": -1.0, "actor_entropy": 0.9881580452765187, "alpha_loss": -0.015938416288624847, "alpha_value": 0.023714813464317214, "duration": 3.836918830871582, "step": 109500}
{"episode_reward": 74.7750290428631, "episode": 877.0, "batch_reward": 0.8051108922958374, "critic_loss": 2.203602648735046, "actor_loss": -85.36268337189205, "actor_target_entropy": -1.0, "actor_entropy": 1.0049131654557728, "alpha_loss": -0.014538056483226163, "alpha_value": 0.023809502881659964, "duration": 3.843147039413452, "step": 109625}
{"episode_reward": 76.15519436920978, "episode": 878.0, "batch_reward": 0.8021562604904174, "critic_loss": 2.217783624649048, "actor_loss": -85.3253814943375, "actor_target_entropy": -1.0, "actor_entropy": 0.9696909881407215, "alpha_loss": -0.015128844718058263, "alpha_value": 0.02390441169933911, "duration": 3.8369011878967285, "step": 109750}
{"episode_reward": 72.2878014111883, "episode": 879.0, "batch_reward": 0.800866660118103, "critic_loss": 2.1815500030517576, "actor_loss": -85.26517038496713, "actor_target_entropy": -1.0, "actor_entropy": 1.011020268712725, "alpha_loss": -0.013760639524589929, "alpha_value": 0.024002746438607905, "duration": 3.8419511318206787, "step": 109875}
{"episode_reward": 75.55109312307816, "episode": 880.0, "batch_reward": 0.8046795425415039, "critic_loss": 2.201945291519165, "actor_loss": -85.2604003414031, "actor_target_entropy": -1.0, "actor_entropy": 1.031462227144549, "alpha_loss": -0.012404701942878385, "alpha_value": 0.02408996804424957, "duration": 3.8404862880706787, "step": 110000}
{"episode_reward": 75.44771187596564, "episode": 881.0, "batch_reward": 0.7926790862083435, "critic_loss": 2.0599875974655153, "actor_loss": -85.2156972733755, "actor_target_entropy": -1.0, "actor_entropy": 1.0562863595901975, "alpha_loss": -0.01126911500764508, "alpha_value": 0.024170666583127418, "duration": 7.8320276737213135, "step": 110125}
{"episode_reward": 74.51894495066686, "episode": 882.0, "batch_reward": 0.7870898494720459, "critic_loss": 2.1284666690826417, "actor_loss": -85.1950447328629, "actor_target_entropy": -1.0, "actor_entropy": 1.049842622972304, "alpha_loss": -0.011416338481790116, "alpha_value": 0.02425127596999057, "duration": 3.8436710834503174, "step": 110250}
{"episode_reward": 76.27195524452627, "episode": 883.0, "batch_reward": 0.7987520313262939, "critic_loss": 2.089210985183716, "actor_loss": -85.14695558093842, "actor_target_entropy": -1.0, "actor_entropy": 1.0619024114003257, "alpha_loss": -0.010265762230292672, "alpha_value": 0.024331787495955496, "duration": 3.8480913639068604, "step": 110375}
{"episode_reward": 74.04805388686287, "episode": 884.0, "batch_reward": 0.7971221513748169, "critic_loss": 2.1310939254760743, "actor_loss": -85.12354869227255, "actor_target_entropy": -1.0, "actor_entropy": 1.072183459035812, "alpha_loss": -0.010452699565869425, "alpha_value": 0.0244067325090598, "duration": 3.8405754566192627, "step": 110500}
{"episode_reward": 73.5076061205839, "episode": 885.0, "batch_reward": 0.7910050225257873, "critic_loss": 2.155929560661316, "actor_loss": -85.05713362920852, "actor_target_entropy": -1.0, "actor_entropy": 1.0644639957518804, "alpha_loss": -0.009173196592619495, "alpha_value": 0.024484349728888348, "duration": 3.842122793197632, "step": 110625}
{"episode_reward": 74.56844161338242, "episode": 886.0, "batch_reward": 0.7973600206375122, "critic_loss": 2.1020870304107664, "actor_loss": -85.05827183877268, "actor_target_entropy": -1.0, "actor_entropy": 1.075599689637461, "alpha_loss": -0.009488306699260589, "alpha_value": 0.024555238012713934, "duration": 3.8414576053619385, "step": 110750}
{"episode_reward": 73.25946693210959, "episode": 887.0, "batch_reward": 0.7917637486457825, "critic_loss": 2.1260472745895385, "actor_loss": -84.98528992183624, "actor_target_entropy": -1.0, "actor_entropy": 1.0902955513151864, "alpha_loss": -0.009164974370616533, "alpha_value": 0.024632480764020612, "duration": 3.8421428203582764, "step": 110875}
{"episode_reward": 73.40507737494275, "episode": 888.0, "batch_reward": 0.8026702342033386, "critic_loss": 2.235122657299042, "actor_loss": -84.96275797197896, "actor_target_entropy": -1.0, "actor_entropy": 1.1122991231180006, "alpha_loss": -0.007834517359433154, "alpha_value": 0.024704089256122632, "duration": 3.8350918292999268, "step": 111000}
{"episode_reward": 73.55485612450346, "episode": 889.0, "batch_reward": 0.7902545213699341, "critic_loss": 2.1133061714172365, "actor_loss": -84.88924202086433, "actor_target_entropy": -1.0, "actor_entropy": 1.17486610299065, "alpha_loss": -0.004684912589644747, "alpha_value": 0.024758057258156555, "duration": 3.8420827388763428, "step": 111125}
{"episode_reward": 73.01011458115468, "episode": 890.0, "batch_reward": 0.7930569314956665, "critic_loss": 2.2341727991104126, "actor_loss": -84.90335673670614, "actor_target_entropy": -1.0, "actor_entropy": 1.1882712187305573, "alpha_loss": -0.004547525142815204, "alpha_value": 0.024798113400502104, "duration": 3.840569019317627, "step": 111250}
{"episode_reward": 72.51848018735915, "episode": 891.0, "batch_reward": 0.7965011692047119, "critic_loss": 2.2126555709838867, "actor_loss": -84.83575076148624, "actor_target_entropy": -1.0, "actor_entropy": 1.2196590654433719, "alpha_loss": -0.0038459718639459756, "alpha_value": 0.024836920614054563, "duration": 3.8510403633117676, "step": 111375}
{"episode_reward": 74.84544661202322, "episode": 892.0, "batch_reward": 0.7883807907104492, "critic_loss": 2.0579024600982665, "actor_loss": -84.78857963315902, "actor_target_entropy": -1.0, "actor_entropy": 1.2710777444224204, "alpha_loss": -0.0007356772149514948, "alpha_value": 0.02485521000838093, "duration": 3.840299129486084, "step": 111500}
{"episode_reward": 76.02349587039951, "episode": 893.0, "batch_reward": 0.7863437900543213, "critic_loss": 2.097847231388092, "actor_loss": -84.7466301085457, "actor_target_entropy": -1.0, "actor_entropy": 1.2912215145807417, "alpha_loss": -0.0004811768571565312, "alpha_value": 0.024862670172100348, "duration": 3.8444905281066895, "step": 111625}
{"episode_reward": 84.94684779845268, "episode": 894.0, "batch_reward": 0.8086838102340699, "critic_loss": 2.1119504451751707, "actor_loss": -84.70794850011026, "actor_target_entropy": -1.0, "actor_entropy": 1.3186299454781316, "alpha_loss": 0.0005403884326017672, "alpha_value": 0.02486513048026353, "duration": 3.839813232421875, "step": 111750}
{"episode_reward": 71.3078912272329, "episode": 895.0, "batch_reward": 0.79423091173172, "critic_loss": 2.150570034980774, "actor_loss": -84.63737257700117, "actor_target_entropy": -1.0, "actor_entropy": 1.3843359284930759, "alpha_loss": 0.003024990297114802, "alpha_value": 0.024843574279075922, "duration": 3.844623327255249, "step": 111875}
{"episode_reward": 72.0218527944872, "episode": 896.0, "batch_reward": 0.7821972560882569, "critic_loss": 2.078270121574402, "actor_loss": -84.59156048682428, "actor_target_entropy": -1.0, "actor_entropy": 1.4425442641781223, "alpha_loss": 0.0035083111856252917, "alpha_value": 0.024810311142226562, "duration": 3.8429715633392334, "step": 112000}
{"episode_reward": 64.66772616323505, "episode": 897.0, "batch_reward": 0.7884300951957702, "critic_loss": 2.08023139667511, "actor_loss": -84.58275870671348, "actor_target_entropy": -1.0, "actor_entropy": 1.4598059446092635, "alpha_loss": 0.00573231680374149, "alpha_value": 0.02475971451293268, "duration": 3.8440520763397217, "step": 112125}
{"episode_reward": 166.36183406321928, "episode": 898.0, "batch_reward": 0.8086891107559204, "critic_loss": 2.1363859720230103, "actor_loss": -84.55409634497857, "actor_target_entropy": -1.0, "actor_entropy": 1.4595110531776183, "alpha_loss": 0.006241145932431062, "alpha_value": 0.02469710899198393, "duration": 3.8435661792755127, "step": 112250}
{"episode_reward": 81.2006510690634, "episode": 899.0, "batch_reward": 0.8006973495483398, "critic_loss": 2.2073097448349, "actor_loss": -84.52529447040861, "actor_target_entropy": -1.0, "actor_entropy": 1.4936423396307326, "alpha_loss": 0.0066182994013947866, "alpha_value": 0.02462452533436545, "duration": 3.8459525108337402, "step": 112375}
{"episode_reward": 79.389897426221, "episode": 900.0, "batch_reward": 0.7963989996910095, "critic_loss": 2.1561451778411866, "actor_loss": -84.49583201254568, "actor_target_entropy": -1.0, "actor_entropy": 1.4996040598038705, "alpha_loss": 0.007014755213129965, "alpha_value": 0.02454602846033431, "duration": 3.84355092048645, "step": 112500}
{"episode_reward": 86.81718963792426, "episode": 901.0, "batch_reward": 0.7832487239837647, "critic_loss": 2.1113212633132936, "actor_loss": -84.44643801734561, "actor_target_entropy": -1.0, "actor_entropy": 1.5233394702275593, "alpha_loss": 0.008345486902971827, "alpha_value": 0.024460030047865407, "duration": 3.850090265274048, "step": 112625}
{"episode_reward": 76.99140749307804, "episode": 902.0, "batch_reward": 0.7898463110923767, "critic_loss": 2.079238510131836, "actor_loss": -84.41001695202243, "actor_target_entropy": -1.0, "actor_entropy": 1.5511298064262635, "alpha_loss": 0.009135190100829688, "alpha_value": 0.024356051880915795, "duration": 3.840277671813965, "step": 112750}
{"episode_reward": 88.71518932090025, "episode": 903.0, "batch_reward": 0.788263846874237, "critic_loss": 2.0798938398361204, "actor_loss": -84.36886499798487, "actor_target_entropy": -1.0, "actor_entropy": 1.5725733306672838, "alpha_loss": 0.008808882557787001, "alpha_value": 0.0242509256469622, "duration": 3.8479533195495605, "step": 112875}
{"episode_reward": 50.18916042187549, "episode": 904.0, "batch_reward": 0.8017518796920776, "critic_loss": 2.216134530067444, "actor_loss": -84.32416497507403, "actor_target_entropy": -1.0, "actor_entropy": 1.598902706177004, "alpha_loss": 0.010233544888192668, "alpha_value": 0.024137638537266606, "duration": 3.8313515186309814, "step": 113000}
{"episode_reward": 51.63681120877031, "episode": 905.0, "batch_reward": 0.7898641548156738, "critic_loss": 2.0823426723480223, "actor_loss": -84.286865234375, "actor_target_entropy": -1.0, "actor_entropy": 1.6452433287151276, "alpha_loss": 0.010924233042354148, "alpha_value": 0.024010064382498475, "duration": 3.846430540084839, "step": 113125}
{"episode_reward": 95.50723258803416, "episode": 906.0, "batch_reward": 0.7878283460140229, "critic_loss": 1.9949911456108094, "actor_loss": -84.24418553998393, "actor_target_entropy": -1.0, "actor_entropy": 1.6852890329976236, "alpha_loss": 0.011769184279405782, "alpha_value": 0.023876483127174303, "duration": 3.8342576026916504, "step": 113250}
{"episode_reward": 142.04543018581376, "episode": 907.0, "batch_reward": 0.8004277420043945, "critic_loss": 2.1080384731292723, "actor_loss": -84.21060543968564, "actor_target_entropy": -1.0, "actor_entropy": 1.7363984414509364, "alpha_loss": 0.012641302849506103, "alpha_value": 0.023729460009602108, "duration": 3.841491222381592, "step": 113375}
{"episode_reward": 127.69716193681882, "episode": 908.0, "batch_reward": 0.7794831895828247, "critic_loss": 2.101417209625244, "actor_loss": -84.16224818075857, "actor_target_entropy": -1.0, "actor_entropy": 1.767621644081608, "alpha_loss": 0.012869444540551594, "alpha_value": 0.023581203985050415, "duration": 3.843062400817871, "step": 113500}
{"episode_reward": 92.58573568348896, "episode": 909.0, "batch_reward": 0.786868112564087, "critic_loss": 2.0798483057022095, "actor_loss": -84.14052315363809, "actor_target_entropy": -1.0, "actor_entropy": 1.7766161438018557, "alpha_loss": 0.012934529370376988, "alpha_value": 0.023430352059622208, "duration": 3.831101179122925, "step": 113625}
{"episode_reward": 56.494739460320204, "episode": 910.0, "batch_reward": 0.7840624446868897, "critic_loss": 2.049484832763672, "actor_loss": -84.1093019054782, "actor_target_entropy": -1.0, "actor_entropy": 1.7831157138270717, "alpha_loss": 0.013035753749371055, "alpha_value": 0.023280803088651582, "duration": 3.829287528991699, "step": 113750}
{"episode_reward": 163.49729982322086, "episode": 911.0, "batch_reward": 0.7803232822418212, "critic_loss": 2.027997025489807, "actor_loss": -84.06248801095145, "actor_target_entropy": -1.0, "actor_entropy": 1.7935898966259427, "alpha_loss": 0.013383950602026686, "alpha_value": 0.02312968361336757, "duration": 3.842703104019165, "step": 113875}
{"episode_reward": 87.17849505847389, "episode": 912.0, "batch_reward": 0.7899829511642456, "critic_loss": 2.122864819526672, "actor_loss": -84.03500132406911, "actor_target_entropy": -1.0, "actor_entropy": 1.7917237320253927, "alpha_loss": 0.012860474916505478, "alpha_value": 0.02298042337146464, "duration": 3.8381733894348145, "step": 114000}
{"episode_reward": 147.4923243376543, "episode": 913.0, "batch_reward": 0.7858682599067688, "critic_loss": 2.088916899204254, "actor_loss": -83.99871002681671, "actor_target_entropy": -1.0, "actor_entropy": 1.7999900201010326, "alpha_loss": 0.013612928475061107, "alpha_value": 0.022836207578053984, "duration": 3.842270851135254, "step": 114125}
{"episode_reward": 70.57469839212516, "episode": 914.0, "batch_reward": 0.7864385619163513, "critic_loss": 2.0524482078552246, "actor_loss": -83.95738392491495, "actor_target_entropy": -1.0, "actor_entropy": 1.8217801009455035, "alpha_loss": 0.013821029502357687, "alpha_value": 0.022683289929028433, "duration": 3.8329577445983887, "step": 114250}
{"episode_reward": 186.22929779587952, "episode": 915.0, "batch_reward": 0.7890961728096009, "critic_loss": 2.131636556625366, "actor_loss": -83.90983339339968, "actor_target_entropy": -1.0, "actor_entropy": 1.8293251177621266, "alpha_loss": 0.01424232694423861, "alpha_value": 0.02253052398509288, "duration": 3.848052501678467, "step": 114375}
{"episode_reward": 84.81738983716049, "episode": 916.0, "batch_reward": 0.8007461557388306, "critic_loss": 2.058010223388672, "actor_loss": -83.88817522602696, "actor_target_entropy": -1.0, "actor_entropy": 1.8546742047033002, "alpha_loss": 0.01348440078718047, "alpha_value": 0.02238439125915343, "duration": 3.8568174839019775, "step": 114500}
{"episode_reward": 141.3724029917613, "episode": 917.0, "batch_reward": 0.7944700155258179, "critic_loss": 2.1302706127166746, "actor_loss": -83.8724838741242, "actor_target_entropy": -1.0, "actor_entropy": 1.86519626019493, "alpha_loss": 0.013577068017588722, "alpha_value": 0.022241104552372992, "duration": 3.8325867652893066, "step": 114625}
{"episode_reward": 129.11508450866071, "episode": 918.0, "batch_reward": 0.7994324202537537, "critic_loss": 2.0998752336502076, "actor_loss": -83.82595837500787, "actor_target_entropy": -1.0, "actor_entropy": 1.873193698544656, "alpha_loss": 0.015233362784549113, "alpha_value": 0.022089501753299594, "duration": 3.838480234146118, "step": 114750}
{"episode_reward": 112.83984345605057, "episode": 919.0, "batch_reward": 0.7998428359031677, "critic_loss": 2.1318774747848512, "actor_loss": -83.80740634978764, "actor_target_entropy": -1.0, "actor_entropy": 1.8897880845599704, "alpha_loss": 0.014755865780725366, "alpha_value": 0.021935593748381124, "duration": 3.8430943489074707, "step": 114875}
{"episode_reward": 157.67144528510883, "episode": 920.0, "batch_reward": 0.7850318055152893, "critic_loss": 2.013697581768036, "actor_loss": -83.76601065358808, "actor_target_entropy": -1.0, "actor_entropy": 1.8781521743343723, "alpha_loss": 0.014609005084381468, "alpha_value": 0.02178792767791253, "duration": 3.8422305583953857, "step": 115000}
{"episode_reward": 142.5917235951458, "episode": 921.0, "batch_reward": 0.7961772274971008, "critic_loss": 2.1127184638977052, "actor_loss": -83.74489993140811, "actor_target_entropy": -1.0, "actor_entropy": 1.8730590627306984, "alpha_loss": 0.016247732816116203, "alpha_value": 0.021633646073397468, "duration": 3.8435802459716797, "step": 115125}
{"episode_reward": 131.25835464461264, "episode": 922.0, "batch_reward": 0.7647943172454834, "critic_loss": 2.0147849588394164, "actor_loss": -83.6638541683074, "actor_target_entropy": -1.0, "actor_entropy": 1.8851581888814126, "alpha_loss": 0.015677533518042294, "alpha_value": 0.021475852819211494, "duration": 3.836928129196167, "step": 115250}
{"episode_reward": 127.19980850857048, "episode": 923.0, "batch_reward": 0.8125143113136292, "critic_loss": 2.1486681308746336, "actor_loss": -83.68599289182633, "actor_target_entropy": -1.0, "actor_entropy": 1.88977517211248, "alpha_loss": 0.01621439563672221, "alpha_value": 0.02132363304236762, "duration": 3.8380744457244873, "step": 115375}
{"episode_reward": 82.17646714922466, "episode": 924.0, "batch_reward": 0.7925247287750244, "critic_loss": 2.1529669389724733, "actor_loss": -83.65998077392578, "actor_target_entropy": -1.0, "actor_entropy": 1.8663392259228615, "alpha_loss": 0.015853908754164172, "alpha_value": 0.021172611395064725, "duration": 3.8366904258728027, "step": 115500}
{"episode_reward": 93.00484149263694, "episode": 925.0, "batch_reward": 0.7860042471885681, "critic_loss": 2.030997211456299, "actor_loss": -83.61140623546783, "actor_target_entropy": -1.0, "actor_entropy": 1.8612552237889124, "alpha_loss": 0.015798119665493094, "alpha_value": 0.021023849964517866, "duration": 3.845440626144409, "step": 115625}
{"episode_reward": 96.80847426316062, "episode": 926.0, "batch_reward": 0.7874028334617614, "critic_loss": 2.0545037813186644, "actor_loss": -83.55784139325542, "actor_target_entropy": -1.0, "actor_entropy": 1.8644978961636942, "alpha_loss": 0.015278912682626997, "alpha_value": 0.020881620915218228, "duration": 3.836871385574341, "step": 115750}
{"episode_reward": 54.45368671383164, "episode": 927.0, "batch_reward": 0.7870874981880188, "critic_loss": 2.0243668718338013, "actor_loss": -83.52879212394593, "actor_target_entropy": -1.0, "actor_entropy": 1.8788709205294412, "alpha_loss": 0.015819258751377227, "alpha_value": 0.020741416653421923, "duration": 3.8461952209472656, "step": 115875}
{"episode_reward": 59.386140357525676, "episode": 928.0, "batch_reward": 0.7955910506248474, "critic_loss": 2.093535367965698, "actor_loss": -83.51808646417433, "actor_target_entropy": -1.0, "actor_entropy": 1.8843318608499342, "alpha_loss": 0.0160582686564134, "alpha_value": 0.020601626917175295, "duration": 3.83823299407959, "step": 116000}
{"episode_reward": 87.76471037923697, "episode": 929.0, "batch_reward": 0.7903672118186951, "critic_loss": 2.0606057262420654, "actor_loss": -83.48729705810547, "actor_target_entropy": -1.0, "actor_entropy": 1.8699361426489693, "alpha_loss": 0.016223451906135156, "alpha_value": 0.020458545591288957, "duration": 3.8458824157714844, "step": 116125}
{"episode_reward": 69.59606296246083, "episode": 930.0, "batch_reward": 0.7880514836311341, "critic_loss": 2.0701176404953, "actor_loss": -83.45194367439517, "actor_target_entropy": -1.0, "actor_entropy": 1.8678553835038216, "alpha_loss": 0.016071805963292718, "alpha_value": 0.0203206515736508, "duration": 3.8362009525299072, "step": 116250}
{"episode_reward": 191.04604623345818, "episode": 931.0, "batch_reward": 0.7918031868934632, "critic_loss": 2.0534361886978147, "actor_loss": -83.43042403932601, "actor_target_entropy": -1.0, "actor_entropy": 1.8729973312408206, "alpha_loss": 0.016847840805966702, "alpha_value": 0.020180988194254023, "duration": 3.8329217433929443, "step": 116375}
{"episode_reward": 236.63756995252834, "episode": 932.0, "batch_reward": 0.7908436660766601, "critic_loss": 2.1194895582199096, "actor_loss": -83.39654614848476, "actor_target_entropy": -1.0, "actor_entropy": 1.8893916414630028, "alpha_loss": 0.016174944403070594, "alpha_value": 0.020043447955815516, "duration": 3.829454183578491, "step": 116500}
{"episode_reward": 22.44361436591229, "episode": 933.0, "batch_reward": 0.796391128540039, "critic_loss": 2.061130518913269, "actor_loss": -83.37879059806703, "actor_target_entropy": -1.0, "actor_entropy": 1.9002401582778445, "alpha_loss": 0.015989816481513635, "alpha_value": 0.01990749350113101, "duration": 3.8401408195495605, "step": 116625}
{"episode_reward": 170.12329664012444, "episode": 934.0, "batch_reward": 0.7926289510726928, "critic_loss": 2.0645770807266235, "actor_loss": -83.34891596148091, "actor_target_entropy": -1.0, "actor_entropy": 1.9090610204204437, "alpha_loss": 0.016421236969049898, "alpha_value": 0.019776818085274726, "duration": 3.841581106185913, "step": 116750}
{"episode_reward": 211.98473155823066, "episode": 935.0, "batch_reward": 0.7981270689964295, "critic_loss": 2.057768481254578, "actor_loss": -83.33097936236669, "actor_target_entropy": -1.0, "actor_entropy": 1.9260783138729276, "alpha_loss": 0.015743171470978902, "alpha_value": 0.019646879604595432, "duration": 3.8429391384124756, "step": 116875}
{"episode_reward": 91.26371518694815, "episode": 936.0, "batch_reward": 0.8030383968353272, "critic_loss": 2.106866269111633, "actor_loss": -83.29771423339844, "actor_target_entropy": -1.0, "actor_entropy": 1.9486913258029568, "alpha_loss": 0.01642777437284108, "alpha_value": 0.019518500960133408, "duration": 3.8354854583740234, "step": 117000}
{"episode_reward": 149.4541978129, "episode": 937.0, "batch_reward": 0.7999902758598327, "critic_loss": 2.1125181741714476, "actor_loss": -83.28004564557757, "actor_target_entropy": -1.0, "actor_entropy": 1.9739375965935844, "alpha_loss": 0.01571648752701188, "alpha_value": 0.019391310794333615, "duration": 3.845212459564209, "step": 117125}
{"episode_reward": 115.91373616116748, "episode": 938.0, "batch_reward": 0.8032731986045838, "critic_loss": 2.1492075242996216, "actor_loss": -83.26375161447832, "actor_target_entropy": -1.0, "actor_entropy": 1.9750155825768747, "alpha_loss": 0.014719822158616397, "alpha_value": 0.0192717312394077, "duration": 3.8304758071899414, "step": 117250}
{"episode_reward": 154.89812503388887, "episode": 939.0, "batch_reward": 0.80107572555542, "critic_loss": 2.143144238948822, "actor_loss": -83.22815244160002, "actor_target_entropy": -1.0, "actor_entropy": 1.982731442602854, "alpha_loss": 0.014065753239842634, "alpha_value": 0.019160433261853228, "duration": 3.846667528152466, "step": 117375}
{"episode_reward": 194.52162755831745, "episode": 940.0, "batch_reward": 0.8002501411437988, "critic_loss": 2.1134970149993895, "actor_loss": -83.20164354385868, "actor_target_entropy": -1.0, "actor_entropy": 1.9843628675706926, "alpha_loss": 0.014931035633649557, "alpha_value": 0.01904772143759814, "duration": 3.8341660499572754, "step": 117500}
{"episode_reward": 84.78763826244813, "episode": 941.0, "batch_reward": 0.7906245369911193, "critic_loss": 2.117069408416748, "actor_loss": -83.17552693684895, "actor_target_entropy": -1.0, "actor_entropy": 1.9976071119308472, "alpha_loss": 0.015237205055734468, "alpha_value": 0.018930551348961485, "duration": 3.842627763748169, "step": 117625}
{"episode_reward": 114.30231992375144, "episode": 942.0, "batch_reward": 0.7921893258094788, "critic_loss": 2.076644384384155, "actor_loss": -83.15867787022745, "actor_target_entropy": -1.0, "actor_entropy": 1.9865171736286533, "alpha_loss": 0.015325303737735075, "alpha_value": 0.018814763881672608, "duration": 3.8347349166870117, "step": 117750}
{"episode_reward": 153.07768940035302, "episode": 943.0, "batch_reward": 0.8004071955680847, "critic_loss": 2.0867153573036195, "actor_loss": -83.14552948966859, "actor_target_entropy": -1.0, "actor_entropy": 1.9681138708477928, "alpha_loss": 0.015515011321339343, "alpha_value": 0.01869695627663183, "duration": 3.843310832977295, "step": 117875}
{"episode_reward": 86.47929302458883, "episode": 944.0, "batch_reward": 0.7812769532203674, "critic_loss": 2.0519699382781984, "actor_loss": -83.10988924580235, "actor_target_entropy": -1.0, "actor_entropy": 1.9567476741729244, "alpha_loss": 0.015788402536042755, "alpha_value": 0.018577944665905666, "duration": 3.842125177383423, "step": 118000}
{"episode_reward": 194.12786832168337, "episode": 945.0, "batch_reward": 0.8093692178726196, "critic_loss": 2.1267268447875978, "actor_loss": -83.10649774944972, "actor_target_entropy": -1.0, "actor_entropy": 1.9481591440382457, "alpha_loss": 0.015913522181411583, "alpha_value": 0.018457364174533593, "duration": 3.8414626121520996, "step": 118125}
{"episode_reward": 59.31565244217681, "episode": 946.0, "batch_reward": 0.7911431369781494, "critic_loss": 2.1692205381393435, "actor_loss": -83.07120956913117, "actor_target_entropy": -1.0, "actor_entropy": 1.9572955600676998, "alpha_loss": 0.015776388662596865, "alpha_value": 0.018341461369076217, "duration": 3.838937997817993, "step": 118250}
{"episode_reward": 90.20818075508012, "episode": 947.0, "batch_reward": 0.7961083474159241, "critic_loss": 2.0845007009506227, "actor_loss": -83.04419684031653, "actor_target_entropy": -1.0, "actor_entropy": 1.9641621926474193, "alpha_loss": 0.015385375860782842, "alpha_value": 0.01822641466219393, "duration": 3.8428080081939697, "step": 118375}
{"episode_reward": 97.27567956972617, "episode": 948.0, "batch_reward": 0.785660053730011, "critic_loss": 2.0840019311904907, "actor_loss": -82.99739542315083, "actor_target_entropy": -1.0, "actor_entropy": 1.972588296859495, "alpha_loss": 0.014592459605586144, "alpha_value": 0.018114990564322128, "duration": 3.836491107940674, "step": 118500}
{"episode_reward": 138.26503603807197, "episode": 949.0, "batch_reward": 0.8054554982185363, "critic_loss": 2.0876914129257202, "actor_loss": -83.02043805803571, "actor_target_entropy": -1.0, "actor_entropy": 1.9686543771198817, "alpha_loss": 0.015435271999902196, "alpha_value": 0.018006488831782585, "duration": 3.846733331680298, "step": 118625}
{"episode_reward": 175.40158154173878, "episode": 950.0, "batch_reward": 0.7782331552505494, "critic_loss": 2.0986189832687376, "actor_loss": -82.9635860073951, "actor_target_entropy": -1.0, "actor_entropy": 1.9614272309887795, "alpha_loss": 0.015413629679730343, "alpha_value": 0.017895099447309333, "duration": 3.8356070518493652, "step": 118750}
{"episode_reward": 111.47426390070795, "episode": 951.0, "batch_reward": 0.8011104121208191, "critic_loss": 2.1444026136398318, "actor_loss": -82.96365961952814, "actor_target_entropy": -1.0, "actor_entropy": 1.9584274310914298, "alpha_loss": 0.015451461808489901, "alpha_value": 0.017784162630765068, "duration": 3.835926055908203, "step": 118875}
{"episode_reward": 104.75511427283466, "episode": 952.0, "batch_reward": 0.7978238410949707, "critic_loss": 2.070011782646179, "actor_loss": -82.94235192575762, "actor_target_entropy": -1.0, "actor_entropy": 1.9588824741301998, "alpha_loss": 0.015046609505530327, "alpha_value": 0.017675722871094243, "duration": 3.8393242359161377, "step": 119000}
{"episode_reward": 106.46136286404263, "episode": 953.0, "batch_reward": 0.8080450081825257, "critic_loss": 2.1653753232955935, "actor_loss": -82.93062325129434, "actor_target_entropy": -1.0, "actor_entropy": 1.95165016726842, "alpha_loss": 0.015592185558662527, "alpha_value": 0.0175663385786355, "duration": 3.846953868865967, "step": 119125}
{"episode_reward": 146.8070536252501, "episode": 954.0, "batch_reward": 0.7998149313926697, "critic_loss": 2.0740614709854124, "actor_loss": -82.90616103141538, "actor_target_entropy": -1.0, "actor_entropy": 1.9633991833656066, "alpha_loss": 0.015864680265827526, "alpha_value": 0.017454113112052843, "duration": 3.834444284439087, "step": 119250}
{"episode_reward": 196.16522129425917, "episode": 955.0, "batch_reward": 0.8115559358596802, "critic_loss": 2.1544751176834107, "actor_loss": -82.90160612076048, "actor_target_entropy": -1.0, "actor_entropy": 1.9692673323646424, "alpha_loss": 0.014713425041427688, "alpha_value": 0.017347491466619503, "duration": 3.84075665473938, "step": 119375}
{"episode_reward": 203.2253237788912, "episode": 956.0, "batch_reward": 0.7999905395507813, "critic_loss": 2.129552089214325, "actor_loss": -82.8877786205661, "actor_target_entropy": -1.0, "actor_entropy": 1.964765860188392, "alpha_loss": 0.01507005203635462, "alpha_value": 0.017245153458862593, "duration": 3.840188503265381, "step": 119500}
{"episode_reward": 226.64761023269065, "episode": 957.0, "batch_reward": 0.8178162178993225, "critic_loss": 2.172153739929199, "actor_loss": -82.8942133585612, "actor_target_entropy": -1.0, "actor_entropy": 1.9618977005519564, "alpha_loss": 0.01525341005374988, "alpha_value": 0.017138414650233084, "duration": 3.8411192893981934, "step": 119625}
{"episode_reward": 161.92106182607054, "episode": 958.0, "batch_reward": 0.8014989485740661, "critic_loss": 2.1657525386810303, "actor_loss": -82.8614156169276, "actor_target_entropy": -1.0, "actor_entropy": 1.9633217819275395, "alpha_loss": 0.015121850109989605, "alpha_value": 0.017034691014752728, "duration": 3.8451430797576904, "step": 119750}
{"episode_reward": 129.56364266903853, "episode": 959.0, "batch_reward": 0.8076511220932007, "critic_loss": 2.0784289665222166, "actor_loss": -82.86418963235522, "actor_target_entropy": -1.0, "actor_entropy": 1.9574137509815277, "alpha_loss": 0.015114250637236096, "alpha_value": 0.016931266038584136, "duration": 3.8422255516052246, "step": 119875}
{"episode_reward": 40.6007861007196, "episode": 960.0, "batch_reward": 0.8062798113822937, "critic_loss": 2.0684098997116087, "actor_loss": -82.8420773167764, "actor_target_entropy": -1.0, "actor_entropy": 1.9685445177939631, "alpha_loss": 0.015232571611000646, "alpha_value": 0.01682813029285772, "duration": 3.84182071685791, "step": 120000}
{"episode_reward": 149.40060878613855, "episode": 961.0, "batch_reward": 0.8021076006889343, "critic_loss": 2.0512650079727175, "actor_loss": -82.82787310887896, "actor_target_entropy": -1.0, "actor_entropy": 1.9714187610717047, "alpha_loss": 0.014585857456993489, "alpha_value": 0.016726532288102943, "duration": 7.821545839309692, "step": 120125}
{"episode_reward": 127.75784924649659, "episode": 962.0, "batch_reward": 0.8052663707733154, "critic_loss": 2.13118595123291, "actor_loss": -82.8060924160865, "actor_target_entropy": -1.0, "actor_entropy": 1.9688329273654568, "alpha_loss": 0.01451260797799595, "alpha_value": 0.016628078654177935, "duration": 3.8419582843780518, "step": 120250}
{"episode_reward": 143.64781658733352, "episode": 963.0, "batch_reward": 0.8124879336357117, "critic_loss": 2.1389381074905396, "actor_loss": -82.80859011695499, "actor_target_entropy": -1.0, "actor_entropy": 1.9774344024204074, "alpha_loss": 0.014848724185001282, "alpha_value": 0.01652844890824339, "duration": 3.8369109630584717, "step": 120375}
{"episode_reward": 177.30511226911548, "episode": 964.0, "batch_reward": 0.7961151666641235, "critic_loss": 2.060896048545837, "actor_loss": -82.77244580176568, "actor_target_entropy": -1.0, "actor_entropy": 1.9847533510577293, "alpha_loss": 0.01418258712416695, "alpha_value": 0.016431458645758172, "duration": 3.8391640186309814, "step": 120500}
{"episode_reward": 127.13073027833896, "episode": 965.0, "batch_reward": 0.8135137162208557, "critic_loss": 2.125745400428772, "actor_loss": -82.78282831585597, "actor_target_entropy": -1.0, "actor_entropy": 1.996980729557219, "alpha_loss": 0.013658086857980206, "alpha_value": 0.016338778471810915, "duration": 3.842816114425659, "step": 120625}
{"episode_reward": 144.96661384669665, "episode": 966.0, "batch_reward": 0.7989989552497864, "critic_loss": 2.0269258794784544, "actor_loss": -82.76747832759735, "actor_target_entropy": -1.0, "actor_entropy": 1.9916967768822946, "alpha_loss": 0.01416914261156513, "alpha_value": 0.016245695953631414, "duration": 3.8341636657714844, "step": 120750}
{"episode_reward": 92.70825971221625, "episode": 967.0, "batch_reward": 0.8043327355384826, "critic_loss": 2.1190716104507445, "actor_loss": -82.74930342416914, "actor_target_entropy": -1.0, "actor_entropy": 1.999608380453927, "alpha_loss": 0.012970516140321417, "alpha_value": 0.01615551943275305, "duration": 3.8429861068725586, "step": 120875}
{"episode_reward": 188.92304933821094, "episode": 968.0, "batch_reward": 0.798422634601593, "critic_loss": 2.049613995552063, "actor_loss": -82.74159400693831, "actor_target_entropy": -1.0, "actor_entropy": 1.9909860126433834, "alpha_loss": 0.014127775771363128, "alpha_value": 0.016064408038206617, "duration": 3.828702688217163, "step": 121000}
{"episode_reward": 128.62606166687502, "episode": 969.0, "batch_reward": 0.8005248370170593, "critic_loss": 2.1507373938560486, "actor_loss": -82.72837647937592, "actor_target_entropy": -1.0, "actor_entropy": 1.9895267505494376, "alpha_loss": 0.01333985279595095, "alpha_value": 0.015972667167704853, "duration": 3.844724178314209, "step": 121125}
{"episode_reward": 81.85006982328923, "episode": 970.0, "batch_reward": 0.8030232753753662, "critic_loss": 2.1503616991043093, "actor_loss": -82.71992997200259, "actor_target_entropy": -1.0, "actor_entropy": 1.9898242219801872, "alpha_loss": 0.013999771371844315, "alpha_value": 0.015882159149475997, "duration": 3.836329936981201, "step": 121250}
{"episode_reward": 158.18198873643823, "episode": 971.0, "batch_reward": 0.8076239948272705, "critic_loss": 2.072474057197571, "actor_loss": -82.71026780870226, "actor_target_entropy": -1.0, "actor_entropy": 2.007032422792344, "alpha_loss": 0.013293395469349528, "alpha_value": 0.015790735595808396, "duration": 3.842228412628174, "step": 121375}
{"episode_reward": 180.0574052753939, "episode": 972.0, "batch_reward": 0.8042025675773621, "critic_loss": 2.142499363899231, "actor_loss": -82.70317754437846, "actor_target_entropy": -1.0, "actor_entropy": 2.0066729207192697, "alpha_loss": 0.013407630755776358, "alpha_value": 0.015702230434791867, "duration": 3.837822914123535, "step": 121500}
{"episode_reward": 102.52729105458383, "episode": 973.0, "batch_reward": 0.8121648945808411, "critic_loss": 2.1850751543045046, "actor_loss": -82.69298468695746, "actor_target_entropy": -1.0, "actor_entropy": 2.0055144627889, "alpha_loss": 0.01368372995288126, "alpha_value": 0.015612189552159109, "duration": 3.837480068206787, "step": 121625}
{"episode_reward": 200.49984835685567, "episode": 974.0, "batch_reward": 0.801298710823059, "critic_loss": 2.0931128578186033, "actor_loss": -82.68349013790008, "actor_target_entropy": -1.0, "actor_entropy": 1.9993394632493295, "alpha_loss": 0.013685108192505376, "alpha_value": 0.015522561902283797, "duration": 3.839233875274658, "step": 121750}
{"episode_reward": 158.96526413847405, "episode": 975.0, "batch_reward": 0.8199218854904174, "critic_loss": 2.18394189453125, "actor_loss": -82.6969718327598, "actor_target_entropy": -1.0, "actor_entropy": 1.9902738559813726, "alpha_loss": 0.013469767305881732, "alpha_value": 0.01543257784929741, "duration": 3.836477756500244, "step": 121875}
{"episode_reward": 146.0968769372804, "episode": 976.0, "batch_reward": 0.8239129433631897, "critic_loss": 2.1457025089263917, "actor_loss": -82.7150013831354, "actor_target_entropy": -1.0, "actor_entropy": 1.9758539238283712, "alpha_loss": 0.01353957672272959, "alpha_value": 0.015342562771641921, "duration": 3.839986562728882, "step": 122000}
{"episode_reward": 38.41705069609905, "episode": 977.0, "batch_reward": 0.8194864110946656, "critic_loss": 2.160156180381775, "actor_loss": -82.69518074156746, "actor_target_entropy": -1.0, "actor_entropy": 1.9527886273368957, "alpha_loss": 0.0136626349052503, "alpha_value": 0.015253401635730366, "duration": 3.8430874347686768, "step": 122125}
{"episode_reward": 26.913705166466826, "episode": 978.0, "batch_reward": 0.8050399146080017, "critic_loss": 2.1380243759155273, "actor_loss": -82.68715310865834, "actor_target_entropy": -1.0, "actor_entropy": 1.9450805302589171, "alpha_loss": 0.01386285672384885, "alpha_value": 0.015164296894286026, "duration": 3.8355650901794434, "step": 122250}
{"episode_reward": 94.67838368797156, "episode": 979.0, "batch_reward": 0.8068850026130676, "critic_loss": 2.1038726329803468, "actor_loss": -82.65607767256479, "actor_target_entropy": -1.0, "actor_entropy": 1.9443880130374243, "alpha_loss": 0.013805683450921187, "alpha_value": 0.01507293043961909, "duration": 3.8443593978881836, "step": 122375}
{"episode_reward": 21.526058586626323, "episode": 980.0, "batch_reward": 0.8028270092010498, "critic_loss": 2.12629203414917, "actor_loss": -82.65835374401462, "actor_target_entropy": -1.0, "actor_entropy": 1.94191780782515, "alpha_loss": 0.013512513870673796, "alpha_value": 0.0149838813785079, "duration": 3.8342769145965576, "step": 122500}
{"episode_reward": 171.32169010143264, "episode": 981.0, "batch_reward": 0.8093499817848205, "critic_loss": 2.1229209394454958, "actor_loss": -82.65629141671317, "actor_target_entropy": -1.0, "actor_entropy": 1.9347761415299916, "alpha_loss": 0.01375420367906964, "alpha_value": 0.014895475930956673, "duration": 3.846214771270752, "step": 122625}
{"episode_reward": 58.45023688903036, "episode": 982.0, "batch_reward": 0.7878995547294617, "critic_loss": 1.9994768877029419, "actor_loss": -82.63880268219978, "actor_target_entropy": -1.0, "actor_entropy": 1.9428522856004777, "alpha_loss": 0.01329646882180485, "alpha_value": 0.014808082654664536, "duration": 3.832747220993042, "step": 122750}
{"episode_reward": 71.62688048442924, "episode": 983.0, "batch_reward": 0.8178366870880127, "critic_loss": 2.1358994007110597, "actor_loss": -82.6452376350524, "actor_target_entropy": -1.0, "actor_entropy": 1.945481741239154, "alpha_loss": 0.012924424446527921, "alpha_value": 0.014723663163669035, "duration": 3.8443338871002197, "step": 122875}
{"episode_reward": 208.0923679688221, "episode": 984.0, "batch_reward": 0.7937860369682312, "critic_loss": 1.998442193031311, "actor_loss": -82.6190302448888, "actor_target_entropy": -1.0, "actor_entropy": 1.9478245127585627, "alpha_loss": 0.01310202969057906, "alpha_value": 0.014639870362392162, "duration": 3.8405685424804688, "step": 123000}
{"episode_reward": 62.46415559178488, "episode": 985.0, "batch_reward": 0.8062391562461853, "critic_loss": 2.160338912963867, "actor_loss": -82.60720970517113, "actor_target_entropy": -1.0, "actor_entropy": 1.9478713917353796, "alpha_loss": 0.01280439498701266, "alpha_value": 0.014556942510038503, "duration": 3.8436524868011475, "step": 123125}
{"episode_reward": 241.73346410280655, "episode": 986.0, "batch_reward": 0.7914669351577759, "critic_loss": 2.0693851985931397, "actor_loss": -82.57771941154233, "actor_target_entropy": -1.0, "actor_entropy": 1.9629695838497532, "alpha_loss": 0.01284578739995918, "alpha_value": 0.014474082089857674, "duration": 3.8443965911865234, "step": 123250}
{"episode_reward": 171.90902849748446, "episode": 987.0, "batch_reward": 0.8126778974533081, "critic_loss": 2.0976230521202086, "actor_loss": -82.59449126228454, "actor_target_entropy": -1.0, "actor_entropy": 1.9758689687365578, "alpha_loss": 0.012215474391326545, "alpha_value": 0.014393342567780494, "duration": 3.834792375564575, "step": 123375}
{"episode_reward": 89.57571857166266, "episode": 988.0, "batch_reward": 0.809010922908783, "critic_loss": 2.090883444786072, "actor_loss": -82.58196972262475, "actor_target_entropy": -1.0, "actor_entropy": 1.9743815429749028, "alpha_loss": 0.01279075367135867, "alpha_value": 0.01431336990210813, "duration": 3.83473801612854, "step": 123500}
{"episode_reward": 172.48588294239198, "episode": 989.0, "batch_reward": 0.798874319076538, "critic_loss": 2.0712036428451537, "actor_loss": -82.55725630502852, "actor_target_entropy": -1.0, "actor_entropy": 1.9833540405545915, "alpha_loss": 0.01235038090852045, "alpha_value": 0.014233113653158137, "duration": 3.8428666591644287, "step": 123625}
{"episode_reward": 152.6664859998974, "episode": 990.0, "batch_reward": 0.8013837013244629, "critic_loss": 2.037676652908325, "actor_loss": -82.56014903899163, "actor_target_entropy": -1.0, "actor_entropy": 1.9750911843392156, "alpha_loss": 0.012481378045894446, "alpha_value": 0.01415394988595919, "duration": 3.8346970081329346, "step": 123750}
{"episode_reward": 171.75887102460987, "episode": 991.0, "batch_reward": 0.8288067970275879, "critic_loss": 2.1866047887802122, "actor_loss": -82.57858167375836, "actor_target_entropy": -1.0, "actor_entropy": 1.9772321780522664, "alpha_loss": 0.012302379360392926, "alpha_value": 0.014073535312054257, "duration": 3.8441848754882812, "step": 123875}
{"episode_reward": 112.4861342310431, "episode": 992.0, "batch_reward": 0.8041162223815917, "critic_loss": 2.0904441604614257, "actor_loss": -82.54276558660692, "actor_target_entropy": -1.0, "actor_entropy": 1.9872967235503658, "alpha_loss": 0.011921244200258967, "alpha_value": 0.013994538343160615, "duration": 3.830687999725342, "step": 124000}
{"episode_reward": 192.67390183995312, "episode": 993.0, "batch_reward": 0.8050965008735657, "critic_loss": 2.1085264587402346, "actor_loss": -82.54195609925286, "actor_target_entropy": -1.0, "actor_entropy": 1.9929232086454118, "alpha_loss": 0.012043252239920317, "alpha_value": 0.013918138541968814, "duration": 3.8483121395111084, "step": 124125}
{"episode_reward": 226.00157770760694, "episode": 994.0, "batch_reward": 0.810998812675476, "critic_loss": 2.149927391052246, "actor_loss": -82.54408067272556, "actor_target_entropy": -1.0, "actor_entropy": 1.975933232615071, "alpha_loss": 0.01163701107725501, "alpha_value": 0.013842505193648717, "duration": 3.832148551940918, "step": 124250}
{"episode_reward": 193.82489549075666, "episode": 995.0, "batch_reward": 0.8103710918426513, "critic_loss": 2.069393772125244, "actor_loss": -82.52771977015904, "actor_target_entropy": -1.0, "actor_entropy": 1.9775933481398082, "alpha_loss": 0.011819173677987049, "alpha_value": 0.013766220958493329, "duration": 3.84017014503479, "step": 124375}
{"episode_reward": 136.99419574882396, "episode": 996.0, "batch_reward": 0.797413079738617, "critic_loss": 2.017671257019043, "actor_loss": -82.51564431959584, "actor_target_entropy": -1.0, "actor_entropy": 1.9857071022833548, "alpha_loss": 0.011774211220683591, "alpha_value": 0.013690450407425357, "duration": 3.834092378616333, "step": 124500}
{"episode_reward": 110.44229867608749, "episode": 997.0, "batch_reward": 0.8102644329071045, "critic_loss": 2.100095211982727, "actor_loss": -82.50013103182354, "actor_target_entropy": -1.0, "actor_entropy": 1.9829042393063743, "alpha_loss": 0.011844471843528843, "alpha_value": 0.013615157511692181, "duration": 3.8398807048797607, "step": 124625}
{"episode_reward": 166.84958822785836, "episode": 998.0, "batch_reward": 0.8042587041854858, "critic_loss": 2.153849401473999, "actor_loss": -82.49677362749654, "actor_target_entropy": -1.0, "actor_entropy": 1.9843188754973873, "alpha_loss": 0.011527575620059525, "alpha_value": 0.013539484696831765, "duration": 3.8424758911132812, "step": 124750}
{"episode_reward": 59.7727359476777, "episode": 999.0, "batch_reward": 0.8240957245826721, "critic_loss": 2.1262660059928895, "actor_loss": -82.52448938763331, "actor_target_entropy": -1.0, "actor_entropy": 1.9737941518662467, "alpha_loss": 0.011632596172155842, "alpha_value": 0.013465285147667502, "duration": 3.8390064239501953, "step": 124875}
{"episode_reward": 195.09930488989758, "episode": 1000.0, "batch_reward": 0.8128669819831849, "critic_loss": 2.1039964332580565, "actor_loss": -82.50009635186964, "actor_target_entropy": -1.0, "actor_entropy": 1.9704400224070395, "alpha_loss": 0.012113556701449616, "alpha_value": 0.013388673795980292, "duration": 3.8366549015045166, "step": 125000}
{"episode_reward": 62.98684682339366, "episode": 1001.0, "batch_reward": 0.8036897296905517, "critic_loss": 2.080330189704895, "actor_loss": -82.48504880874876, "actor_target_entropy": -1.0, "actor_entropy": 1.9736923206420172, "alpha_loss": 0.01168718889710449, "alpha_value": 0.013311043361756342, "duration": 3.842305898666382, "step": 125125}
{"episode_reward": 170.37762053415366, "episode": 1002.0, "batch_reward": 0.8204794445037842, "critic_loss": 2.0954073066711425, "actor_loss": -82.48915149319556, "actor_target_entropy": -1.0, "actor_entropy": 1.9712519068871774, "alpha_loss": 0.011773657098773026, "alpha_value": 0.013235815340348754, "duration": 3.834172248840332, "step": 125250}
{"episode_reward": 131.10289073172441, "episode": 1003.0, "batch_reward": 0.8220055236816406, "critic_loss": 2.235789973258972, "actor_loss": -82.49341256277901, "actor_target_entropy": -1.0, "actor_entropy": 1.9677666425704956, "alpha_loss": 0.011645740629839045, "alpha_value": 0.013161052581055516, "duration": 3.843449354171753, "step": 125375}
{"episode_reward": 133.10498413831158, "episode": 1004.0, "batch_reward": 0.8154583883285522, "critic_loss": 2.1246560773849485, "actor_loss": -82.48364836169827, "actor_target_entropy": -1.0, "actor_entropy": 1.9687384520807574, "alpha_loss": 0.011657686288198155, "alpha_value": 0.01308538657454732, "duration": 3.8325629234313965, "step": 125500}
{"episode_reward": 141.11513941731215, "episode": 1005.0, "batch_reward": 0.8128102278709411, "critic_loss": 2.098817464828491, "actor_loss": -82.48232983785962, "actor_target_entropy": -1.0, "actor_entropy": 1.9675038220390442, "alpha_loss": 0.01138785732762208, "alpha_value": 0.013012815181204002, "duration": 3.840062141418457, "step": 125625}
{"episode_reward": 99.8934995077356, "episode": 1006.0, "batch_reward": 0.8138669109344483, "critic_loss": 2.1724305591583253, "actor_loss": -82.4869742854949, "actor_target_entropy": -1.0, "actor_entropy": 1.9541636167034027, "alpha_loss": 0.01134687103331089, "alpha_value": 0.01293923922070038, "duration": 3.835718870162964, "step": 125750}
{"episode_reward": 127.0491226338435, "episode": 1007.0, "batch_reward": 0.8213514347076416, "critic_loss": 2.122103314399719, "actor_loss": -82.49303920685298, "actor_target_entropy": -1.0, "actor_entropy": 1.943148100186908, "alpha_loss": 0.011374702765828087, "alpha_value": 0.012866643086644917, "duration": 3.843658924102783, "step": 125875}
{"episode_reward": 99.26980238456564, "episode": 1008.0, "batch_reward": 0.8114068050384522, "critic_loss": 2.1232688159942628, "actor_loss": -82.48128324939358, "actor_target_entropy": -1.0, "actor_entropy": 1.9479596576383036, "alpha_loss": 0.01152282899936601, "alpha_value": 0.012792386138376603, "duration": 3.833240509033203, "step": 126000}
{"episode_reward": 114.13880009874806, "episode": 1009.0, "batch_reward": 0.8109806752204896, "critic_loss": 2.0550083684921265, "actor_loss": -82.46648310101222, "actor_target_entropy": -1.0, "actor_entropy": 1.9464796478786166, "alpha_loss": 0.011151874238359076, "alpha_value": 0.012720063026058263, "duration": 3.8430016040802, "step": 126125}
{"episode_reward": 168.034366982173, "episode": 1010.0, "batch_reward": 0.8086833844184875, "critic_loss": 2.1898131685256956, "actor_loss": -82.46516787621283, "actor_target_entropy": -1.0, "actor_entropy": 1.9670815506289083, "alpha_loss": 0.011151059425526088, "alpha_value": 0.012649715028806139, "duration": 3.837871551513672, "step": 126250}
{"episode_reward": 85.88855713310967, "episode": 1011.0, "batch_reward": 0.8254099125862122, "critic_loss": 2.173779384613037, "actor_loss": -82.47820645286923, "actor_target_entropy": -1.0, "actor_entropy": 1.9740113776827615, "alpha_loss": 0.010970818152325966, "alpha_value": 0.012578785844151544, "duration": 3.8403406143188477, "step": 126375}
{"episode_reward": 142.57923020080673, "episode": 1012.0, "batch_reward": 0.8169659790992737, "critic_loss": 2.170287913322449, "actor_loss": -82.48007226759388, "actor_target_entropy": -1.0, "actor_entropy": 1.9650781116177958, "alpha_loss": 0.010872886681388463, "alpha_value": 0.012508487548044792, "duration": 3.842533588409424, "step": 126500}
{"episode_reward": 183.08170156514623, "episode": 1013.0, "batch_reward": 0.8065933589935302, "critic_loss": 2.0928174648284914, "actor_loss": -82.47279055156405, "actor_target_entropy": -1.0, "actor_entropy": 1.9521610944990129, "alpha_loss": 0.011123811973938866, "alpha_value": 0.012438576051549645, "duration": 3.840944528579712, "step": 126625}
{"episode_reward": 184.56929702161048, "episode": 1014.0, "batch_reward": 0.8040751848220825, "critic_loss": 2.0975477113723753, "actor_loss": -82.45393691524383, "actor_target_entropy": -1.0, "actor_entropy": 1.9493494379904963, "alpha_loss": 0.010831689619789682, "alpha_value": 0.012368613309584843, "duration": 3.835597515106201, "step": 126750}
{"episode_reward": 195.9049191364095, "episode": 1015.0, "batch_reward": 0.8170106263160706, "critic_loss": 2.1983855414390563, "actor_loss": -82.46367657373823, "actor_target_entropy": -1.0, "actor_entropy": 1.9491842076891945, "alpha_loss": 0.010784782151440306, "alpha_value": 0.012299523613206471, "duration": 3.847172737121582, "step": 126875}
{"episode_reward": 59.5988605122477, "episode": 1016.0, "batch_reward": 0.8165357785224915, "critic_loss": 2.122516468048096, "actor_loss": -82.4639137021957, "actor_target_entropy": -1.0, "actor_entropy": 1.9651739405047508, "alpha_loss": 0.010688740429618666, "alpha_value": 0.012232014850837932, "duration": 3.8364264965057373, "step": 127000}
{"episode_reward": 137.2500637383811, "episode": 1017.0, "batch_reward": 0.8032481608390808, "critic_loss": 2.0924406995773315, "actor_loss": -82.46343497624473, "actor_target_entropy": -1.0, "actor_entropy": 1.9485963961434742, "alpha_loss": 0.010694292706570454, "alpha_value": 0.01216282342277646, "duration": 3.842695713043213, "step": 127125}
{"episode_reward": 108.9992568560014, "episode": 1018.0, "batch_reward": 0.8199446797370911, "critic_loss": 2.1511950759887695, "actor_loss": -82.47279923962009, "actor_target_entropy": -1.0, "actor_entropy": 1.9446020318615822, "alpha_loss": 0.01053389291008634, "alpha_value": 0.012095160080978311, "duration": 3.8376150131225586, "step": 127250}
{"episode_reward": 165.1229694891644, "episode": 1019.0, "batch_reward": 0.8143444361686707, "critic_loss": 2.1496826915740965, "actor_loss": -82.45195903475323, "actor_target_entropy": -1.0, "actor_entropy": 1.9537154019825043, "alpha_loss": 0.010684840115053313, "alpha_value": 0.012027017819111682, "duration": 3.846691370010376, "step": 127375}
{"episode_reward": 74.65663529296842, "episode": 1020.0, "batch_reward": 0.8310163831710815, "critic_loss": 2.176462990760803, "actor_loss": -82.48646016274729, "actor_target_entropy": -1.0, "actor_entropy": 1.958248003836601, "alpha_loss": 0.009907948634316844, "alpha_value": 0.011961379255937885, "duration": 3.840055227279663, "step": 127500}
{"episode_reward": 117.43825499802408, "episode": 1021.0, "batch_reward": 0.8188212676048279, "critic_loss": 2.1025658445358277, "actor_loss": -82.46601165287079, "actor_target_entropy": -1.0, "actor_entropy": 1.971269624573844, "alpha_loss": 0.010305468924343586, "alpha_value": 0.0118971929409328, "duration": 3.841137409210205, "step": 127625}
{"episode_reward": 161.7136171300958, "episode": 1022.0, "batch_reward": 0.8063134965896607, "critic_loss": 2.047794714927673, "actor_loss": -82.47018826392389, "actor_target_entropy": -1.0, "actor_entropy": 1.964222127391446, "alpha_loss": 0.010476205896045412, "alpha_value": 0.01183122511968178, "duration": 3.8384740352630615, "step": 127750}
{"episode_reward": 33.72785214770434, "episode": 1023.0, "batch_reward": 0.8090067310333252, "critic_loss": 2.140200284957886, "actor_loss": -82.4630124531095, "actor_target_entropy": -1.0, "actor_entropy": 1.9485931869537112, "alpha_loss": 0.009936506194727761, "alpha_value": 0.011765373334318386, "duration": 3.839597225189209, "step": 127875}
{"episode_reward": 235.83794503195173, "episode": 1024.0, "batch_reward": 0.8320869011878967, "critic_loss": 2.2085249700546266, "actor_loss": -82.49395653509325, "actor_target_entropy": -1.0, "actor_entropy": 1.9443138683995893, "alpha_loss": 0.010486601258537943, "alpha_value": 0.011699940325518224, "duration": 3.8296737670898438, "step": 128000}
{"episode_reward": 170.5019700846461, "episode": 1025.0, "batch_reward": 0.8171706647872925, "critic_loss": 2.0772083749771117, "actor_loss": -82.49598354763455, "actor_target_entropy": -1.0, "actor_entropy": 1.9452849815762232, "alpha_loss": 0.010152871432226328, "alpha_value": 0.01163409129503651, "duration": 3.840956449508667, "step": 128125}
{"episode_reward": 134.76713937137515, "episode": 1026.0, "batch_reward": 0.8044274940490722, "critic_loss": 2.1265402488708496, "actor_loss": -82.4800321517452, "actor_target_entropy": -1.0, "actor_entropy": 1.941142132205348, "alpha_loss": 0.009931695715133701, "alpha_value": 0.011569491928815399, "duration": 3.835012435913086, "step": 128250}
{"episode_reward": 194.91910699007082, "episode": 1027.0, "batch_reward": 0.8290516819953918, "critic_loss": 2.1587708950042725, "actor_loss": -82.51047031463139, "actor_target_entropy": -1.0, "actor_entropy": 1.9328069857188634, "alpha_loss": 0.009915237669788655, "alpha_value": 0.01150591216285161, "duration": 3.8462178707122803, "step": 128375}
{"episode_reward": 110.28919129181249, "episode": 1028.0, "batch_reward": 0.8247107939720154, "critic_loss": 2.1595174951553346, "actor_loss": -82.50832206972184, "actor_target_entropy": -1.0, "actor_entropy": 1.9242033227797477, "alpha_loss": 0.009964254534532946, "alpha_value": 0.011443001376115721, "duration": 3.8359549045562744, "step": 128500}
{"episode_reward": 17.941591810780675, "episode": 1029.0, "batch_reward": 0.8313646025657654, "critic_loss": 2.15731449508667, "actor_loss": -82.528321523515, "actor_target_entropy": -1.0, "actor_entropy": 1.9227963421079848, "alpha_loss": 0.010005905721632262, "alpha_value": 0.011378786734168587, "duration": 3.848790168762207, "step": 128625}
{"episode_reward": 240.88167979615673, "episode": 1030.0, "batch_reward": 0.8099713940620422, "critic_loss": 2.096126461982727, "actor_loss": -82.50311353129726, "actor_target_entropy": -1.0, "actor_entropy": 1.9240602254867554, "alpha_loss": 0.009605094377372054, "alpha_value": 0.011315368801293088, "duration": 3.8359994888305664, "step": 128750}
{"episode_reward": 189.81542502322532, "episode": 1031.0, "batch_reward": 0.8171423163414001, "critic_loss": 2.1012383956909177, "actor_loss": -82.51989806644501, "actor_target_entropy": -1.0, "actor_entropy": 1.921474367853195, "alpha_loss": 0.009727467435397326, "alpha_value": 0.011253573625528954, "duration": 3.849458694458008, "step": 128875}
{"episode_reward": 158.26654555999454, "episode": 1032.0, "batch_reward": 0.8239849071502685, "critic_loss": 2.0923933086395263, "actor_loss": -82.52132218883884, "actor_target_entropy": -1.0, "actor_entropy": 1.9044225485094133, "alpha_loss": 0.009622697425525515, "alpha_value": 0.01119117909293067, "duration": 3.841996669769287, "step": 129000}
{"episode_reward": 67.65119365480894, "episode": 1033.0, "batch_reward": 0.8026486158370971, "critic_loss": 2.1009661216735838, "actor_loss": -82.49263593885634, "actor_target_entropy": -1.0, "actor_entropy": 1.9079182356122941, "alpha_loss": 0.00969418603926897, "alpha_value": 0.011129343627565909, "duration": 3.839780330657959, "step": 129125}
{"episode_reward": 130.69528781326767, "episode": 1034.0, "batch_reward": 0.8320720338821411, "critic_loss": 2.2339462108612063, "actor_loss": -82.54403871105563, "actor_target_entropy": -1.0, "actor_entropy": 1.9005433859363678, "alpha_loss": 0.009595786131197406, "alpha_value": 0.011067578665634252, "duration": 3.8355162143707275, "step": 129250}
{"episode_reward": 221.71407383192462, "episode": 1035.0, "batch_reward": 0.8254920582771301, "critic_loss": 2.1529390020370482, "actor_loss": -82.5291260007828, "actor_target_entropy": -1.0, "actor_entropy": 1.8855801101714846, "alpha_loss": 0.00980552143254687, "alpha_value": 0.011005046982820546, "duration": 3.840811014175415, "step": 129375}
{"episode_reward": 169.6998252414108, "episode": 1036.0, "batch_reward": 0.8181175737380981, "critic_loss": 2.2105368957519533, "actor_loss": -82.54324057794386, "actor_target_entropy": -1.0, "actor_entropy": 1.8746129966551257, "alpha_loss": 0.00939081450774064, "alpha_value": 0.010943792134170354, "duration": 3.8455963134765625, "step": 129500}
{"episode_reward": 92.71965315501981, "episode": 1037.0, "batch_reward": 0.8425927157402039, "critic_loss": 2.1672736082077027, "actor_loss": -82.56298028855096, "actor_target_entropy": -1.0, "actor_entropy": 1.8755985914714752, "alpha_loss": 0.009467679726344252, "alpha_value": 0.010883087808751794, "duration": 3.841649055480957, "step": 129625}
{"episode_reward": 41.64167756255005, "episode": 1038.0, "batch_reward": 0.8174962329864502, "critic_loss": 2.121662706375122, "actor_loss": -82.55649923509166, "actor_target_entropy": -1.0, "actor_entropy": 1.8923077467949159, "alpha_loss": 0.009141765700112428, "alpha_value": 0.01082313518399366, "duration": 3.8343560695648193, "step": 129750}
{"episode_reward": 111.16465161238996, "episode": 1039.0, "batch_reward": 0.8283360495567321, "critic_loss": 2.1597908372879027, "actor_loss": -82.56451779320126, "actor_target_entropy": -1.0, "actor_entropy": 1.8868184335648068, "alpha_loss": 0.009259126304338375, "alpha_value": 0.010763865215092348, "duration": 3.8448615074157715, "step": 129875}
{"episode_reward": 194.94994261189117, "episode": 1040.0, "batch_reward": 0.8188124928474426, "critic_loss": 2.1707216329574583, "actor_loss": -82.56536262266097, "actor_target_entropy": -1.0, "actor_entropy": 1.8875504193767425, "alpha_loss": 0.009315640177397479, "alpha_value": 0.01070429487413645, "duration": 3.835627794265747, "step": 130000}
{"episode_reward": 180.46247241732388, "episode": 1041.0, "batch_reward": 0.8253298206329346, "critic_loss": 2.1740635805130006, "actor_loss": -82.57770017593626, "actor_target_entropy": -1.0, "actor_entropy": 1.882504979769389, "alpha_loss": 0.00913338184297558, "alpha_value": 0.010644873662704038, "duration": 7.820262670516968, "step": 130125}
{"episode_reward": 106.57417280804655, "episode": 1042.0, "batch_reward": 0.8258120484352112, "critic_loss": 2.1977845811843872, "actor_loss": -82.5970230102539, "actor_target_entropy": -1.0, "actor_entropy": 1.8735163481004777, "alpha_loss": 0.008862104552287248, "alpha_value": 0.01058677949622282, "duration": 3.8382022380828857, "step": 130250}
{"episode_reward": 96.45101240460133, "episode": 1043.0, "batch_reward": 0.8328474864959717, "critic_loss": 2.31365362739563, "actor_loss": -82.59053996252635, "actor_target_entropy": -1.0, "actor_entropy": 1.877954121619936, "alpha_loss": 0.009261460346539341, "alpha_value": 0.010527859330563735, "duration": 3.837703227996826, "step": 130375}
{"episode_reward": 176.88144269366228, "episode": 1044.0, "batch_reward": 0.8240100469589233, "critic_loss": 2.2728868389129637, "actor_loss": -82.62640331637475, "actor_target_entropy": -1.0, "actor_entropy": 1.8593119690495152, "alpha_loss": 0.008802580549531886, "alpha_value": 0.010470442134081673, "duration": 3.835902690887451, "step": 130500}
{"episode_reward": 95.61186455041242, "episode": 1045.0, "batch_reward": 0.8211052594184876, "critic_loss": 2.1358265075683596, "actor_loss": -82.63108922564794, "actor_target_entropy": -1.0, "actor_entropy": 1.8465888178537762, "alpha_loss": 0.008707765955477953, "alpha_value": 0.010413126736384047, "duration": 3.835965156555176, "step": 130625}
{"episode_reward": 120.37213125446895, "episode": 1046.0, "batch_reward": 0.8298068680763244, "critic_loss": 2.0844996213912963, "actor_loss": -82.64082594840757, "actor_target_entropy": -1.0, "actor_entropy": 1.8254631911554644, "alpha_loss": 0.008757218973891388, "alpha_value": 0.010357069317985398, "duration": 3.825181484222412, "step": 130750}
{"episode_reward": 141.00672369466406, "episode": 1047.0, "batch_reward": 0.8187025480270386, "critic_loss": 2.117914791107178, "actor_loss": -82.65236239963107, "actor_target_entropy": -1.0, "actor_entropy": 1.8208725206435672, "alpha_loss": 0.008796670296717258, "alpha_value": 0.010300289904704414, "duration": 3.841970443725586, "step": 130875}
{"episode_reward": 54.14732999843431, "episode": 1048.0, "batch_reward": 0.8357968649864197, "critic_loss": 2.1997457151412965, "actor_loss": -82.6683105960969, "actor_target_entropy": -1.0, "actor_entropy": 1.8085356258576917, "alpha_loss": 0.008669147598406961, "alpha_value": 0.010244072945015262, "duration": 3.8359687328338623, "step": 131000}
{"episode_reward": 188.3074719957625, "episode": 1049.0, "batch_reward": 0.8404881620407104, "critic_loss": 2.297865372657776, "actor_loss": -82.68708159431579, "actor_target_entropy": -1.0, "actor_entropy": 1.8127352112815494, "alpha_loss": 0.008364442403295211, "alpha_value": 0.010188248553444546, "duration": 3.8399314880371094, "step": 131125}
{"episode_reward": 66.54338168828339, "episode": 1050.0, "batch_reward": 0.8363216662406922, "critic_loss": 2.152425926208496, "actor_loss": -82.69873551399478, "actor_target_entropy": -1.0, "actor_entropy": 1.7988614459191599, "alpha_loss": 0.008071260188796347, "alpha_value": 0.010135557250190158, "duration": 3.8366591930389404, "step": 131250}
{"episode_reward": 52.345238009624246, "episode": 1051.0, "batch_reward": 0.8448867087364197, "critic_loss": 2.245150644302368, "actor_loss": -82.71887848869203, "actor_target_entropy": -1.0, "actor_entropy": 1.7946080423536754, "alpha_loss": 0.008272056815229238, "alpha_value": 0.010082245404491822, "duration": 3.8401763439178467, "step": 131375}
{"episode_reward": 135.52148553304343, "episode": 1052.0, "batch_reward": 0.829539608001709, "critic_loss": 2.219800973892212, "actor_loss": -82.73887831164944, "actor_target_entropy": -1.0, "actor_entropy": 1.7923425743656773, "alpha_loss": 0.00831999668040343, "alpha_value": 0.010027403637997123, "duration": 3.838176727294922, "step": 131500}
{"episode_reward": 89.00798022636636, "episode": 1053.0, "batch_reward": 0.8296649775505066, "critic_loss": 2.106781888961792, "actor_loss": -82.75305163671099, "actor_target_entropy": -1.0, "actor_entropy": 1.77925820010049, "alpha_loss": 0.008400210223737218, "alpha_value": 0.0099726651239814, "duration": 3.844005823135376, "step": 131625}
{"episode_reward": 153.37483796685575, "episode": 1054.0, "batch_reward": 0.8271186761856079, "critic_loss": 2.1853825483322145, "actor_loss": -82.74808699084866, "actor_target_entropy": -1.0, "actor_entropy": 1.765017036468752, "alpha_loss": 0.008227188966327136, "alpha_value": 0.009918153784895268, "duration": 3.8383142948150635, "step": 131750}
{"episode_reward": 127.6889323594287, "episode": 1055.0, "batch_reward": 0.835774564743042, "critic_loss": 2.166213210105896, "actor_loss": -82.7728518531436, "actor_target_entropy": -1.0, "actor_entropy": 1.755534840008569, "alpha_loss": 0.007940981906676104, "alpha_value": 0.009865022206571553, "duration": 3.837252378463745, "step": 131875}
{"episode_reward": 124.22422513646893, "episode": 1056.0, "batch_reward": 0.813963773727417, "critic_loss": 2.157219418525696, "actor_loss": -82.75402081397272, "actor_target_entropy": -1.0, "actor_entropy": 1.7448374417520338, "alpha_loss": 0.008038486894820967, "alpha_value": 0.009811908135078823, "duration": 3.8351542949676514, "step": 132000}
{"episode_reward": 156.15697859158882, "episode": 1057.0, "batch_reward": 0.820222779750824, "critic_loss": 2.167925630569458, "actor_loss": -82.75036039806548, "actor_target_entropy": -1.0, "actor_entropy": 1.7404174369478982, "alpha_loss": 0.008029026858922508, "alpha_value": 0.00975931378543793, "duration": 3.8480470180511475, "step": 132125}
{"episode_reward": 122.79611393745763, "episode": 1058.0, "batch_reward": 0.8380046720504761, "critic_loss": 2.2657144002914427, "actor_loss": -82.7526609359249, "actor_target_entropy": -1.0, "actor_entropy": 1.7610770079397386, "alpha_loss": 0.007932236575851999, "alpha_value": 0.00970644411678364, "duration": 3.832216739654541, "step": 132250}
{"episode_reward": 138.8672958075849, "episode": 1059.0, "batch_reward": 0.8267333431243896, "critic_loss": 2.180391138076782, "actor_loss": -82.76758369566902, "actor_target_entropy": -1.0, "actor_entropy": 1.7908554852954925, "alpha_loss": 0.007803002727173623, "alpha_value": 0.009654224956729116, "duration": 3.8404924869537354, "step": 132375}
{"episode_reward": 57.288905737633996, "episode": 1060.0, "batch_reward": 0.8335777072906494, "critic_loss": 2.1350492429733277, "actor_loss": -82.80113158687469, "actor_target_entropy": -1.0, "actor_entropy": 1.7879570876398394, "alpha_loss": 0.007549243025301445, "alpha_value": 0.009603159707333699, "duration": 3.8379697799682617, "step": 132500}
{"episode_reward": 69.80301741540498, "episode": 1061.0, "batch_reward": 0.8351131281852722, "critic_loss": 2.236506336212158, "actor_loss": -82.80081019325861, "actor_target_entropy": -1.0, "actor_entropy": 1.7744778546075972, "alpha_loss": 0.007345955715411239, "alpha_value": 0.009553878723429802, "duration": 3.842954397201538, "step": 132625}
{"episode_reward": 89.11405032128842, "episode": 1062.0, "batch_reward": 0.8305376310348511, "critic_loss": 2.119059941291809, "actor_loss": -82.80669747629473, "actor_target_entropy": -1.0, "actor_entropy": 1.7775020176364529, "alpha_loss": 0.007516048690905014, "alpha_value": 0.009504451109043924, "duration": 3.840254783630371, "step": 132750}
{"episode_reward": 55.41497280112837, "episode": 1063.0, "batch_reward": 0.8218448739051819, "critic_loss": 2.1219408960342405, "actor_loss": -82.80701470753503, "actor_target_entropy": -1.0, "actor_entropy": 1.7657321615824624, "alpha_loss": 0.007688504429386248, "alpha_value": 0.00945367849720185, "duration": 3.8473799228668213, "step": 132875}
{"episode_reward": 113.65835746150675, "episode": 1064.0, "batch_reward": 0.8271879506111145, "critic_loss": 2.119933253288269, "actor_loss": -82.81658701742849, "actor_target_entropy": -1.0, "actor_entropy": 1.7611692220933977, "alpha_loss": 0.0072527230536985786, "alpha_value": 0.009403472086277728, "duration": 3.84161639213562, "step": 133000}
{"episode_reward": 165.69056690615983, "episode": 1065.0, "batch_reward": 0.8351377882957458, "critic_loss": 2.282676778793335, "actor_loss": -82.85093240889292, "actor_target_entropy": -1.0, "actor_entropy": 1.747592261859349, "alpha_loss": 0.006964254917369949, "alpha_value": 0.0093554505531271, "duration": 3.843536138534546, "step": 133125}
{"episode_reward": 90.2847237877777, "episode": 1066.0, "batch_reward": 0.813073459148407, "critic_loss": 2.0940499458312987, "actor_loss": -82.8220080714072, "actor_target_entropy": -1.0, "actor_entropy": 1.7111892584831483, "alpha_loss": 0.007110340415590232, "alpha_value": 0.00930758484529188, "duration": 3.8343334197998047, "step": 133250}
{"episode_reward": 72.81198820751855, "episode": 1067.0, "batch_reward": 0.8404334440231324, "critic_loss": 2.183418249130249, "actor_loss": -82.87670171828498, "actor_target_entropy": -1.0, "actor_entropy": 1.7058989982756356, "alpha_loss": 0.006988787129225712, "alpha_value": 0.00925936938781544, "duration": 3.8324036598205566, "step": 133375}
{"episode_reward": 89.42911106333541, "episode": 1068.0, "batch_reward": 0.8239923667907715, "critic_loss": 2.089970888137817, "actor_loss": -82.86566642022902, "actor_target_entropy": -1.0, "actor_entropy": 1.6829237668744979, "alpha_loss": 0.0068390444071302495, "alpha_value": 0.009211851104773405, "duration": 3.8349268436431885, "step": 133500}
{"episode_reward": 83.97328167270318, "episode": 1069.0, "batch_reward": 0.8194714741706848, "critic_loss": 2.1368586263656617, "actor_loss": -82.87352522592695, "actor_target_entropy": -1.0, "actor_entropy": 1.6610942587019906, "alpha_loss": 0.0068908144113799885, "alpha_value": 0.00916502273678863, "duration": 3.8515405654907227, "step": 133625}
{"episode_reward": 90.47403899490018, "episode": 1070.0, "batch_reward": 0.8220216526985168, "critic_loss": 2.1369923610687254, "actor_loss": -82.87351042224515, "actor_target_entropy": -1.0, "actor_entropy": 1.6526065526470062, "alpha_loss": 0.006651150235425561, "alpha_value": 0.009118466848590778, "duration": 3.83876371383667, "step": 133750}
{"episode_reward": 83.12128578781417, "episode": 1071.0, "batch_reward": 0.8200514235496521, "critic_loss": 2.1403918809890747, "actor_loss": -82.9004894438244, "actor_target_entropy": -1.0, "actor_entropy": 1.63106912469107, "alpha_loss": 0.0058995504227895585, "alpha_value": 0.009074973792891221, "duration": 3.839898109436035, "step": 133875}
{"episode_reward": 109.40927367393894, "episode": 1072.0, "batch_reward": 0.8369150061607361, "critic_loss": 2.2041944999694825, "actor_loss": -82.91818631079889, "actor_target_entropy": -1.0, "actor_entropy": 1.5821270519687283, "alpha_loss": 0.006469296595652497, "alpha_value": 0.009031349427693845, "duration": 3.8403804302215576, "step": 134000}
{"episode_reward": 59.79213246632251, "episode": 1073.0, "batch_reward": 0.8261055717468262, "critic_loss": 2.1960826749801634, "actor_loss": -82.89120652940538, "actor_target_entropy": -1.0, "actor_entropy": 1.571043122382391, "alpha_loss": 0.006104716188496067, "alpha_value": 0.008987318941292372, "duration": 3.8477659225463867, "step": 134125}
{"episode_reward": 73.42656429421872, "episode": 1074.0, "batch_reward": 0.820570152759552, "critic_loss": 2.094365466117859, "actor_loss": -82.90715962071573, "actor_target_entropy": -1.0, "actor_entropy": 1.5596443799234205, "alpha_loss": 0.006078947786121599, "alpha_value": 0.00894449297586561, "duration": 3.8448543548583984, "step": 134250}
{"episode_reward": 112.32039522806109, "episode": 1075.0, "batch_reward": 0.8383465714454651, "critic_loss": 2.1870107975006103, "actor_loss": -82.95076654827784, "actor_target_entropy": -1.0, "actor_entropy": 1.5368990992742873, "alpha_loss": 0.0058093993991081205, "alpha_value": 0.0089017381821281, "duration": 3.8391225337982178, "step": 134375}
{"episode_reward": 143.84150221275652, "episode": 1076.0, "batch_reward": 0.8303645277023315, "critic_loss": 2.137842872619629, "actor_loss": -82.93005051151398, "actor_target_entropy": -1.0, "actor_entropy": 1.491755489380129, "alpha_loss": 0.005584892561478961, "alpha_value": 0.00886045834323102, "duration": 3.8440237045288086, "step": 134500}
{"episode_reward": 115.85569906575074, "episode": 1077.0, "batch_reward": 0.8262645344734192, "critic_loss": 2.1331199102401732, "actor_loss": -82.94444032699343, "actor_target_entropy": -1.0, "actor_entropy": 1.4777528842290242, "alpha_loss": 0.005270241815153332, "alpha_value": 0.008821796059517419, "duration": 3.8388397693634033, "step": 134625}
{"episode_reward": 110.52216878570025, "episode": 1078.0, "batch_reward": 0.8263029375076294, "critic_loss": 2.1839962749481203, "actor_loss": -82.95455194288685, "actor_target_entropy": -1.0, "actor_entropy": 1.449566706534355, "alpha_loss": 0.005484319840287489, "alpha_value": 0.008782067253214211, "duration": 3.835883617401123, "step": 134750}
{"episode_reward": 140.55126933214038, "episode": 1079.0, "batch_reward": 0.8207071013450623, "critic_loss": 2.096968786239624, "actor_loss": -82.95273129902189, "actor_target_entropy": -1.0, "actor_entropy": 1.4141404458454676, "alpha_loss": 0.0048900331289226575, "alpha_value": 0.008744185930545247, "duration": 3.843207836151123, "step": 134875}
{"episode_reward": 75.80567647261502, "episode": 1080.0, "batch_reward": 0.8335167393684387, "critic_loss": 2.096430438995361, "actor_loss": -82.96313501173451, "actor_target_entropy": -1.0, "actor_entropy": 1.3873053096955823, "alpha_loss": 0.004570731198445203, "alpha_value": 0.008708148717069049, "duration": 3.833773136138916, "step": 135000}
{"episode_reward": 78.10917116292764, "episode": 1081.0, "batch_reward": 0.8185423612594604, "critic_loss": 2.099834260940552, "actor_loss": -82.96238696385943, "actor_target_entropy": -1.0, "actor_entropy": 1.3539324582569183, "alpha_loss": 0.0044372907233616666, "alpha_value": 0.00867360871680064, "duration": 3.836798906326294, "step": 135125}
{"episode_reward": 88.05563161117192, "episode": 1082.0, "batch_reward": 0.817977388381958, "critic_loss": 2.185396222114563, "actor_loss": -82.96817373460338, "actor_target_entropy": -1.0, "actor_entropy": 1.3234589215247863, "alpha_loss": 0.0039205846016205125, "alpha_value": 0.008641408731381547, "duration": 3.8389596939086914, "step": 135250}
{"episode_reward": 85.47029981492174, "episode": 1083.0, "batch_reward": 0.815827799320221, "critic_loss": 2.0430974283218384, "actor_loss": -82.95193348233661, "actor_target_entropy": -1.0, "actor_entropy": 1.2873933750485618, "alpha_loss": 0.003955699476627781, "alpha_value": 0.008610721192395135, "duration": 3.8483567237854004, "step": 135375}
{"episode_reward": 134.2990147505266, "episode": 1084.0, "batch_reward": 0.8164195699691772, "critic_loss": 2.0865431308746336, "actor_loss": -82.96792430262411, "actor_target_entropy": -1.0, "actor_entropy": 1.2446202501173942, "alpha_loss": 0.003333641611407661, "alpha_value": 0.00858132550337996, "duration": 3.84077787399292, "step": 135500}
{"episode_reward": 74.53778258797229, "episode": 1085.0, "batch_reward": 0.8221389226913453, "critic_loss": 2.12198264503479, "actor_loss": -82.98550293937562, "actor_target_entropy": -1.0, "actor_entropy": 1.2040929813233634, "alpha_loss": 0.003050496783255348, "alpha_value": 0.008554976844960508, "duration": 3.847322940826416, "step": 135625}
{"episode_reward": 73.52077613916786, "episode": 1086.0, "batch_reward": 0.8230918507575988, "critic_loss": 2.0934583530426027, "actor_loss": -82.99817374444777, "actor_target_entropy": -1.0, "actor_entropy": 1.1478640840899559, "alpha_loss": 0.002526642268827756, "alpha_value": 0.008531946347907602, "duration": 3.83896803855896, "step": 135750}
{"episode_reward": 83.51937517819857, "episode": 1087.0, "batch_reward": 0.8111702771186828, "critic_loss": 2.1211225242614744, "actor_loss": -83.00132376050192, "actor_target_entropy": -1.0, "actor_entropy": 1.0850834486976502, "alpha_loss": 0.0019832216161635836, "alpha_value": 0.008513213239096994, "duration": 3.843447685241699, "step": 135875}
{"episode_reward": 75.58572080257575, "episode": 1088.0, "batch_reward": 0.8203153014183044, "critic_loss": 2.0653773946762084, "actor_loss": -83.02355563256049, "actor_target_entropy": -1.0, "actor_entropy": 1.0411266396122594, "alpha_loss": 0.0013820274600162051, "alpha_value": 0.008498322710473018, "duration": 3.849914312362671, "step": 136000}
{"episode_reward": 65.45413623823988, "episode": 1089.0, "batch_reward": 0.8328173303604126, "critic_loss": 2.1149340319633483, "actor_loss": -83.03525640094091, "actor_target_entropy": -1.0, "actor_entropy": 0.9976880985593038, "alpha_loss": 0.0009049771118923904, "alpha_value": 0.008487674990395256, "duration": 3.8463571071624756, "step": 136125}
{"episode_reward": 74.92384142557444, "episode": 1090.0, "batch_reward": 0.8288903355598449, "critic_loss": 2.1171144409179687, "actor_loss": -83.046567732288, "actor_target_entropy": -1.0, "actor_entropy": 0.9604716954692718, "alpha_loss": 0.0005577225212266879, "alpha_value": 0.008481126129894373, "duration": 3.8400914669036865, "step": 136250}
{"episode_reward": 76.50396224310188, "episode": 1091.0, "batch_reward": 0.823142641544342, "critic_loss": 2.1545315437316894, "actor_loss": -83.04193321106926, "actor_target_entropy": -1.0, "actor_entropy": 0.9367708497577243, "alpha_loss": 0.00033016879751812667, "alpha_value": 0.00847660774431483, "duration": 3.843018054962158, "step": 136375}
{"episode_reward": 73.62339464504502, "episode": 1092.0, "batch_reward": 0.8286841945648193, "critic_loss": 2.1784942975044252, "actor_loss": -83.06144825104744, "actor_target_entropy": -1.0, "actor_entropy": 0.9242755866819813, "alpha_loss": 0.00022238093116621097, "alpha_value": 0.008473854080375194, "duration": 3.8424556255340576, "step": 136500}
{"episode_reward": 73.30437328797956, "episode": 1093.0, "batch_reward": 0.8355680770874023, "critic_loss": 2.068033658981323, "actor_loss": -83.08744121733166, "actor_target_entropy": -1.0, "actor_entropy": 0.9022133104384892, "alpha_loss": -0.0001074939449724283, "alpha_value": 0.008473758755588014, "duration": 3.846269369125366, "step": 136625}
{"episode_reward": 76.0668341084732, "episode": 1094.0, "batch_reward": 0.8263785057067871, "critic_loss": 2.167163412094116, "actor_loss": -83.06572895665323, "actor_target_entropy": -1.0, "actor_entropy": 0.8879402414444955, "alpha_loss": -0.00020815693419389128, "alpha_value": 0.00847491970271282, "duration": 3.837958812713623, "step": 136750}
{"episode_reward": 74.2013028349823, "episode": 1095.0, "batch_reward": 0.8160289449691772, "critic_loss": 2.1573730907440187, "actor_loss": -83.06265537322514, "actor_target_entropy": -1.0, "actor_entropy": 0.8813833073964195, "alpha_loss": -0.000189884859580724, "alpha_value": 0.00847741190767439, "duration": 3.8504409790039062, "step": 136875}
{"episode_reward": 74.92986170846352, "episode": 1096.0, "batch_reward": 0.8227895131111145, "critic_loss": 2.152678207397461, "actor_loss": -83.06796806089339, "actor_target_entropy": -1.0, "actor_entropy": 0.8672932386398315, "alpha_loss": -0.00038240580925635333, "alpha_value": 0.008480206362004958, "duration": 3.8392446041107178, "step": 137000}
{"episode_reward": 70.59787350014199, "episode": 1097.0, "batch_reward": 0.8220208821296692, "critic_loss": 2.087109941482544, "actor_loss": -83.07385907854352, "actor_target_entropy": -1.0, "actor_entropy": 0.8749664416388859, "alpha_loss": -0.0003799893915244851, "alpha_value": 0.008485242970630351, "duration": 3.8496899604797363, "step": 137125}
{"episode_reward": 78.74186036036959, "episode": 1098.0, "batch_reward": 0.8153491787910462, "critic_loss": 2.1052880735397337, "actor_loss": -83.07606014128655, "actor_target_entropy": -1.0, "actor_entropy": 0.8779721144706972, "alpha_loss": -0.0006621832637334123, "alpha_value": 0.008490595817123811, "duration": 3.8439676761627197, "step": 137250}
{"episode_reward": 76.62995414532617, "episode": 1099.0, "batch_reward": 0.8357872424125672, "critic_loss": 2.2033730783462526, "actor_loss": -83.11010754297651, "actor_target_entropy": -1.0, "actor_entropy": 0.8653739463715326, "alpha_loss": -0.0005583447655515065, "alpha_value": 0.008497746660514654, "duration": 3.843919038772583, "step": 137375}
{"episode_reward": 78.72604608862571, "episode": 1100.0, "batch_reward": 0.8268403449058532, "critic_loss": 2.185289885520935, "actor_loss": -83.10736686952653, "actor_target_entropy": -1.0, "actor_entropy": 0.8542536650934527, "alpha_loss": -0.0008500111000631155, "alpha_value": 0.008506704015700025, "duration": 3.8459908962249756, "step": 137500}
{"episode_reward": 72.03128013085478, "episode": 1101.0, "batch_reward": 0.8174539394378663, "critic_loss": 2.060766693115234, "actor_loss": -83.10913945758153, "actor_target_entropy": -1.0, "actor_entropy": 0.8536045910820128, "alpha_loss": -0.0008694537005679209, "alpha_value": 0.008518556553026694, "duration": 3.845848321914673, "step": 137625}
{"episode_reward": 73.75775469701516, "episode": 1102.0, "batch_reward": 0.8374268221855163, "critic_loss": 2.139058129310608, "actor_loss": -83.14162395846459, "actor_target_entropy": -1.0, "actor_entropy": 0.841175252391446, "alpha_loss": -0.001011969604728473, "alpha_value": 0.008529919948014338, "duration": 3.8419508934020996, "step": 137750}
{"episode_reward": 72.11436745641544, "episode": 1103.0, "batch_reward": 0.8182097935676574, "critic_loss": 2.1156483726501465, "actor_loss": -83.13528490823413, "actor_target_entropy": -1.0, "actor_entropy": 0.8270756271150377, "alpha_loss": -0.0008217020852801701, "alpha_value": 0.008542084044773213, "duration": 3.8470115661621094, "step": 137875}
{"episode_reward": 73.65543524696005, "episode": 1104.0, "batch_reward": 0.8206713118553162, "critic_loss": 2.0549887104034426, "actor_loss": -83.11934477283108, "actor_target_entropy": -1.0, "actor_entropy": 0.8211997901239703, "alpha_loss": -0.001039137279745304, "alpha_value": 0.008555610493344025, "duration": 3.835066556930542, "step": 138000}
{"episode_reward": 77.29223131457798, "episode": 1105.0, "batch_reward": 0.8201525297164917, "critic_loss": 2.0388855781555177, "actor_loss": -83.11334385947576, "actor_target_entropy": -1.0, "actor_entropy": 0.8243168289699252, "alpha_loss": -0.0011218602682227297, "alpha_value": 0.008571740967287432, "duration": 3.852924108505249, "step": 138125}
{"episode_reward": 76.37094172295275, "episode": 1106.0, "batch_reward": 0.8140494074821473, "critic_loss": 2.1091895427703857, "actor_loss": -83.09513067430065, "actor_target_entropy": -1.0, "actor_entropy": 0.839791517103872, "alpha_loss": -0.0008938871349880262, "alpha_value": 0.008587326834973487, "duration": 3.8383634090423584, "step": 138250}
{"episode_reward": 73.6680320702949, "episode": 1107.0, "batch_reward": 0.8272906765937805, "critic_loss": 2.116628638267517, "actor_loss": -83.13189406622024, "actor_target_entropy": -1.0, "actor_entropy": 0.8484753218908159, "alpha_loss": -0.0009072604422856655, "alpha_value": 0.008600222689123043, "duration": 3.850437879562378, "step": 138375}
{"episode_reward": 76.5385960339307, "episode": 1108.0, "batch_reward": 0.8187453413009643, "critic_loss": 2.0871962118148804, "actor_loss": -83.12704098609186, "actor_target_entropy": -1.0, "actor_entropy": 0.8389530220339375, "alpha_loss": -0.000987706400337629, "alpha_value": 0.00861522335654584, "duration": 3.83980655670166, "step": 138500}
{"episode_reward": 75.47555437317637, "episode": 1109.0, "batch_reward": 0.8093546724319458, "critic_loss": 2.0383974189758303, "actor_loss": -83.10589163643974, "actor_target_entropy": -1.0, "actor_entropy": 0.8364174876894269, "alpha_loss": -0.0010410277279175168, "alpha_value": 0.008630987758936925, "duration": 3.8481805324554443, "step": 138625}
{"episode_reward": 71.4754442274165, "episode": 1110.0, "batch_reward": 0.8166428108215332, "critic_loss": 2.027539325714111, "actor_loss": -83.08754890195785, "actor_target_entropy": -1.0, "actor_entropy": 0.8471188737500098, "alpha_loss": -0.000953632990844668, "alpha_value": 0.008647726644599153, "duration": 3.8480982780456543, "step": 138750}
{"episode_reward": 75.36649979003391, "episode": 1111.0, "batch_reward": 0.8314554052352905, "critic_loss": 2.158852385520935, "actor_loss": -83.08453441801525, "actor_target_entropy": -1.0, "actor_entropy": 0.8771607251394362, "alpha_loss": -0.000552136220254137, "alpha_value": 0.008662451071225609, "duration": 3.8467345237731934, "step": 138875}
{"episode_reward": 74.03192190046137, "episode": 1112.0, "batch_reward": 0.828101674079895, "critic_loss": 2.1191790585517882, "actor_loss": -83.10754972888577, "actor_target_entropy": -1.0, "actor_entropy": 0.8993583533071703, "alpha_loss": -0.0005027344809458291, "alpha_value": 0.008670967034345776, "duration": 3.8433475494384766, "step": 139000}
{"episode_reward": 76.41442066431838, "episode": 1113.0, "batch_reward": 0.820980634689331, "critic_loss": 2.078643780231476, "actor_loss": -83.09329780699714, "actor_target_entropy": -1.0, "actor_entropy": 0.8896304860947624, "alpha_loss": -0.000397194725034448, "alpha_value": 0.008679792198439854, "duration": 3.8461990356445312, "step": 139125}
{"episode_reward": 73.8313478018923, "episode": 1114.0, "batch_reward": 0.8186617908477783, "critic_loss": 2.024994821071625, "actor_loss": -83.10436261084772, "actor_target_entropy": -1.0, "actor_entropy": 0.892634795558068, "alpha_loss": -0.0002520109419786041, "alpha_value": 0.008684620748043173, "duration": 3.8407680988311768, "step": 139250}
{"episode_reward": 75.13794644811817, "episode": 1115.0, "batch_reward": 0.8228933062553406, "critic_loss": 2.125968314170837, "actor_loss": -83.11720191107855, "actor_target_entropy": -1.0, "actor_entropy": 0.867277117002578, "alpha_loss": -0.0007744052450612395, "alpha_value": 0.008694755082751967, "duration": 3.8463451862335205, "step": 139375}
{"episode_reward": 74.35519717092474, "episode": 1116.0, "batch_reward": 0.812252583026886, "critic_loss": 2.088103991508484, "actor_loss": -83.07300862958354, "actor_target_entropy": -1.0, "actor_entropy": 0.8732536415899953, "alpha_loss": -0.0007860005295491822, "alpha_value": 0.008710865015643835, "duration": 3.8395063877105713, "step": 139500}
{"episode_reward": 80.5087301858866, "episode": 1117.0, "batch_reward": 0.8145249328613281, "critic_loss": 2.033634530067444, "actor_loss": -83.0874976506309, "actor_target_entropy": -1.0, "actor_entropy": 0.8776855487672109, "alpha_loss": -0.0006695132774655663, "alpha_value": 0.008723479449685795, "duration": 3.8518784046173096, "step": 139625}
{"episode_reward": 74.87133347510365, "episode": 1118.0, "batch_reward": 0.8125383129119873, "critic_loss": 2.034548599243164, "actor_loss": -83.09817381828061, "actor_target_entropy": -1.0, "actor_entropy": 0.8660703051474786, "alpha_loss": -0.000798075927436472, "alpha_value": 0.00873781797435561, "duration": 3.8412933349609375, "step": 139750}
{"episode_reward": 75.36940185332614, "episode": 1119.0, "batch_reward": 0.8171707682609558, "critic_loss": 2.053497757911682, "actor_loss": -83.10656374976749, "actor_target_entropy": -1.0, "actor_entropy": 0.8503175027786739, "alpha_loss": -0.0010245946665120768, "alpha_value": 0.00876010920391926, "duration": 3.8502955436706543, "step": 139875}
{"episode_reward": 72.76204667260289, "episode": 1120.0, "batch_reward": 0.8136862463951111, "critic_loss": 2.047572458744049, "actor_loss": -83.08700450774163, "actor_target_entropy": -1.0, "actor_entropy": 0.8703046498760101, "alpha_loss": -0.0007342868393020433, "alpha_value": 0.008781058890773104, "duration": 3.8398542404174805, "step": 140000}
{"episode_reward": 74.12223399664609, "episode": 1121.0, "batch_reward": 0.8188594355583191, "critic_loss": 2.0927380466461183, "actor_loss": -83.10461934407552, "actor_target_entropy": -1.0, "actor_entropy": 0.8716533922013783, "alpha_loss": -0.0007925237289219652, "alpha_value": 0.008796000912984088, "duration": 7.825408220291138, "step": 140125}
{"episode_reward": 74.38937637279221, "episode": 1122.0, "batch_reward": 0.808825300693512, "critic_loss": 2.113340054512024, "actor_loss": -83.06879055884576, "actor_target_entropy": -1.0, "actor_entropy": 0.8823788589046847, "alpha_loss": -0.0006611620533916603, "alpha_value": 0.008814026994852594, "duration": 3.835280656814575, "step": 140250}
{"episode_reward": 75.5194854011755, "episode": 1123.0, "batch_reward": 0.827555166721344, "critic_loss": 2.1457884435653685, "actor_loss": -83.10657973516555, "actor_target_entropy": -1.0, "actor_entropy": 0.9026792635993351, "alpha_loss": -0.0004244606705412032, "alpha_value": 0.008826824913139743, "duration": 3.8540420532226562, "step": 140375}
{"episode_reward": 74.57171866658646, "episode": 1124.0, "batch_reward": 0.8288714594841003, "critic_loss": 2.124457102775574, "actor_loss": -83.08117761919576, "actor_target_entropy": -1.0, "actor_entropy": 0.9178740785967919, "alpha_loss": -0.0003063680032350784, "alpha_value": 0.008835556527704036, "duration": 3.8392767906188965, "step": 140500}
{"episode_reward": 76.57968310725454, "episode": 1125.0, "batch_reward": 0.8202536044120788, "critic_loss": 2.0754615364074707, "actor_loss": -83.0933093116397, "actor_target_entropy": -1.0, "actor_entropy": 0.9330902875415863, "alpha_loss": -0.00012046369871342673, "alpha_value": 0.008841740282999885, "duration": 3.850477695465088, "step": 140625}
{"episode_reward": 76.11069706542477, "episode": 1126.0, "batch_reward": 0.8087118916511535, "critic_loss": 2.008593436717987, "actor_loss": -83.07704322568831, "actor_target_entropy": -1.0, "actor_entropy": 0.9379720111047068, "alpha_loss": -9.123603494146899e-06, "alpha_value": 0.008841853017362714, "duration": 3.841125965118408, "step": 140750}
{"episode_reward": 74.34904747951362, "episode": 1127.0, "batch_reward": 0.8230030679702759, "critic_loss": 2.097668089866638, "actor_loss": -83.07060265919519, "actor_target_entropy": -1.0, "actor_entropy": 0.9586856194904873, "alpha_loss": 0.0002432474351417835, "alpha_value": 0.008841914121022636, "duration": 3.8480491638183594, "step": 140875}
{"episode_reward": 67.68268320349344, "episode": 1128.0, "batch_reward": 0.8181801190376282, "critic_loss": 2.103197757720947, "actor_loss": -83.05963208598476, "actor_target_entropy": -1.0, "actor_entropy": 0.9731942338328208, "alpha_loss": 0.00043625735246854264, "alpha_value": 0.008832053181340336, "duration": 3.8456993103027344, "step": 141000}
{"episode_reward": 71.2620718646512, "episode": 1129.0, "batch_reward": 0.8107896633148194, "critic_loss": 2.0490593423843384, "actor_loss": -83.07393137613933, "actor_target_entropy": -1.0, "actor_entropy": 0.9637387007001846, "alpha_loss": 0.0004065718660260447, "alpha_value": 0.008818289773776833, "duration": 3.8478078842163086, "step": 141125}
{"episode_reward": 72.75231461382954, "episode": 1130.0, "batch_reward": 0.8214155616760254, "critic_loss": 2.0316856060028075, "actor_loss": -83.07451075892294, "actor_target_entropy": -1.0, "actor_entropy": 0.9455930071492349, "alpha_loss": 0.00043303015157899577, "alpha_value": 0.008807147427202717, "duration": 3.8480515480041504, "step": 141250}
{"episode_reward": 73.93278141245564, "episode": 1131.0, "batch_reward": 0.8127136988639831, "critic_loss": 2.024099807739258, "actor_loss": -83.04513755677239, "actor_target_entropy": -1.0, "actor_entropy": 0.9697232189632597, "alpha_loss": 0.0006670301717970269, "alpha_value": 0.008791961260123642, "duration": 3.83970308303833, "step": 141375}
{"episode_reward": 74.55414343715614, "episode": 1132.0, "batch_reward": 0.812445686340332, "critic_loss": 2.0934287452697755, "actor_loss": -83.0423315725019, "actor_target_entropy": -1.0, "actor_entropy": 0.9827737539045273, "alpha_loss": 0.0008387578968869357, "alpha_value": 0.008770387103658302, "duration": 3.841541051864624, "step": 141500}
{"episode_reward": 75.34318687618027, "episode": 1133.0, "batch_reward": 0.8310155367851257, "critic_loss": 2.127559783935547, "actor_loss": -83.02764383951823, "actor_target_entropy": -1.0, "actor_entropy": 1.0003777174722581, "alpha_loss": 0.001113965655335166, "alpha_value": 0.008741306913257236, "duration": 3.847302198410034, "step": 141625}
{"episode_reward": 74.93696676782568, "episode": 1134.0, "batch_reward": 0.8132107057571412, "critic_loss": 2.0019537506103515, "actor_loss": -83.00907208842617, "actor_target_entropy": -1.0, "actor_entropy": 1.0383127158687961, "alpha_loss": 0.0014231688645292794, "alpha_value": 0.008703403598245474, "duration": 3.8377013206481934, "step": 141750}
{"episode_reward": 77.08925706858624, "episode": 1135.0, "batch_reward": 0.8005526113510132, "critic_loss": 1.9787884674072265, "actor_loss": -82.97690134199838, "actor_target_entropy": -1.0, "actor_entropy": 1.0681903646105813, "alpha_loss": 0.0016383208511840728, "alpha_value": 0.008656315458756229, "duration": 3.849698305130005, "step": 141875}
{"episode_reward": 86.96181473082108, "episode": 1136.0, "batch_reward": 0.8204516649246216, "critic_loss": 2.125892875671387, "actor_loss": -83.00778456657163, "actor_target_entropy": -1.0, "actor_entropy": 1.0755101365427817, "alpha_loss": 0.0019557393691596397, "alpha_value": 0.00860443507615485, "duration": 3.8384857177734375, "step": 142000}
{"episode_reward": 75.1257397140137, "episode": 1137.0, "batch_reward": 0.8211531138420105, "critic_loss": 2.085465802192688, "actor_loss": -82.9802972702753, "actor_target_entropy": -1.0, "actor_entropy": 1.0744067165586684, "alpha_loss": 0.0022829779486600605, "alpha_value": 0.008542045020918487, "duration": 3.850468873977661, "step": 142125}
{"episode_reward": 81.58786018717234, "episode": 1138.0, "batch_reward": 0.8127714824676514, "critic_loss": 1.9919247093200683, "actor_loss": -82.9832286219443, "actor_target_entropy": -1.0, "actor_entropy": 1.064507657481778, "alpha_loss": 0.001827198731329953, "alpha_value": 0.008483323177505542, "duration": 3.8428516387939453, "step": 142250}
{"episode_reward": 85.7343926775641, "episode": 1139.0, "batch_reward": 0.8129925246238708, "critic_loss": 2.0609513635635377, "actor_loss": -82.96053834945437, "actor_target_entropy": -1.0, "actor_entropy": 1.0602860091224549, "alpha_loss": 0.001996544089504621, "alpha_value": 0.008431418106499845, "duration": 3.849053382873535, "step": 142375}
{"episode_reward": 72.24711064186853, "episode": 1140.0, "batch_reward": 0.8170030403137207, "critic_loss": 2.0435852117538453, "actor_loss": -82.96871948242188, "actor_target_entropy": -1.0, "actor_entropy": 1.0566826212790705, "alpha_loss": 0.002199714646614607, "alpha_value": 0.008371549285886863, "duration": 3.84139084815979, "step": 142500}
{"episode_reward": 75.15670471335937, "episode": 1141.0, "batch_reward": 0.8081148986816407, "critic_loss": 2.0153221139907838, "actor_loss": -82.95138561914838, "actor_target_entropy": -1.0, "actor_entropy": 1.0279545575853377, "alpha_loss": 0.0016324923113672182, "alpha_value": 0.008320532862472285, "duration": 3.841552495956421, "step": 142625}
{"episode_reward": 76.3102019394089, "episode": 1142.0, "batch_reward": 0.8098783521652222, "critic_loss": 2.075933235168457, "actor_loss": -82.94625066941784, "actor_target_entropy": -1.0, "actor_entropy": 1.0220050081129997, "alpha_loss": 0.0017459376089860716, "alpha_value": 0.008275842617887011, "duration": 3.8441379070281982, "step": 142750}
{"episode_reward": 83.56037894578448, "episode": 1143.0, "batch_reward": 0.8056246156692505, "critic_loss": 2.0170532131195067, "actor_loss": -82.93408457438152, "actor_target_entropy": -1.0, "actor_entropy": 1.004615725032867, "alpha_loss": 0.0017264967360201158, "alpha_value": 0.008228351399178697, "duration": 3.8471972942352295, "step": 142875}
{"episode_reward": 75.93886984885094, "episode": 1144.0, "batch_reward": 0.8149202928543091, "critic_loss": 2.1209294528961182, "actor_loss": -82.92178012478736, "actor_target_entropy": -1.0, "actor_entropy": 0.9944024278271583, "alpha_loss": 0.0015443377450273762, "alpha_value": 0.008186584649339728, "duration": 3.8444414138793945, "step": 143000}
{"episode_reward": 72.6561238278476, "episode": 1145.0, "batch_reward": 0.8222608213424683, "critic_loss": 2.0501251974105834, "actor_loss": -82.93078322637649, "actor_target_entropy": -1.0, "actor_entropy": 0.9837347079837133, "alpha_loss": 0.001312124742345611, "alpha_value": 0.008148015430903422, "duration": 3.8493826389312744, "step": 143125}
{"episode_reward": 73.80971153833944, "episode": 1146.0, "batch_reward": 0.8043079433441163, "critic_loss": 2.01219621181488, "actor_loss": -82.92408924718058, "actor_target_entropy": -1.0, "actor_entropy": 0.9698491750224945, "alpha_loss": 0.00121625106253158, "alpha_value": 0.00811335711274318, "duration": 3.839325428009033, "step": 143250}
{"episode_reward": 74.90586488931316, "episode": 1147.0, "batch_reward": 0.827106616973877, "critic_loss": 2.0557107162475585, "actor_loss": -82.91966792515346, "actor_target_entropy": -1.0, "actor_entropy": 0.941132456537277, "alpha_loss": 0.0012250414491438912, "alpha_value": 0.008081950281667116, "duration": 3.8548545837402344, "step": 143375}
{"episode_reward": 74.94634648827507, "episode": 1148.0, "batch_reward": 0.8116977190971375, "critic_loss": 2.0820973320007323, "actor_loss": -82.92045113348192, "actor_target_entropy": -1.0, "actor_entropy": 0.9302013035743467, "alpha_loss": 0.0009153503760312413, "alpha_value": 0.008050778871423286, "duration": 3.839606285095215, "step": 143500}
{"episode_reward": 75.05384458697714, "episode": 1149.0, "batch_reward": 0.8152695789337158, "critic_loss": 2.0483848838806153, "actor_loss": -82.88733927408855, "actor_target_entropy": -1.0, "actor_entropy": 0.937187151303367, "alpha_loss": 0.0008859224690240808, "alpha_value": 0.00802810806796626, "duration": 3.850998878479004, "step": 143625}
{"episode_reward": 85.71107620444926, "episode": 1150.0, "batch_reward": 0.8175530743598938, "critic_loss": 2.063832360267639, "actor_loss": -82.89590626378214, "actor_target_entropy": -1.0, "actor_entropy": 0.9519523997460643, "alpha_loss": 0.0012242273052482145, "alpha_value": 0.00799773546933224, "duration": 3.835965156555176, "step": 143750}
{"episode_reward": 74.6803465137813, "episode": 1151.0, "batch_reward": 0.8188387160301208, "critic_loss": 2.059435128211975, "actor_loss": -82.89473482162234, "actor_target_entropy": -1.0, "actor_entropy": 0.957432506576417, "alpha_loss": 0.00134822306553981, "alpha_value": 0.007961345319579299, "duration": 3.8407251834869385, "step": 143875}
{"episode_reward": 76.64884970996638, "episode": 1152.0, "batch_reward": 0.804292959690094, "critic_loss": 1.9778785400390626, "actor_loss": -82.86760957779423, "actor_target_entropy": -1.0, "actor_entropy": 0.9312512374693348, "alpha_loss": 0.0009286905793311646, "alpha_value": 0.007927990705666505, "duration": 3.843935966491699, "step": 144000}
{"episode_reward": 73.88652051714789, "episode": 1153.0, "batch_reward": 0.811765730381012, "critic_loss": 2.045990433692932, "actor_loss": -82.85719529409258, "actor_target_entropy": -1.0, "actor_entropy": 0.9496578356576344, "alpha_loss": 0.0010985724913466367, "alpha_value": 0.0079002983677937, "duration": 3.845048427581787, "step": 144125}
{"episode_reward": 74.03144138839154, "episode": 1154.0, "batch_reward": 0.8006867122650146, "critic_loss": 2.0226457386016845, "actor_loss": -82.83247338571856, "actor_target_entropy": -1.0, "actor_entropy": 0.9572771480006557, "alpha_loss": 0.0012481896970242697, "alpha_value": 0.007866325104006788, "duration": 3.843888759613037, "step": 144250}
{"episode_reward": 74.28511708140891, "episode": 1155.0, "batch_reward": 0.8193744220733643, "critic_loss": 2.106987176895142, "actor_loss": -82.83634319002667, "actor_target_entropy": -1.0, "actor_entropy": 0.9742428026502095, "alpha_loss": 0.0015679788339184597, "alpha_value": 0.007826028593867633, "duration": 3.848050355911255, "step": 144375}
{"episode_reward": 76.05013295832829, "episode": 1156.0, "batch_reward": 0.8105144400596619, "critic_loss": 2.0134031457901003, "actor_loss": -82.81365056191721, "actor_target_entropy": -1.0, "actor_entropy": 0.9998140681174493, "alpha_loss": 0.001784220385044107, "alpha_value": 0.0077783912057387055, "duration": 3.8654940128326416, "step": 144500}
{"episode_reward": 76.4349176747916, "episode": 1157.0, "batch_reward": 0.8130437064170838, "critic_loss": 2.0620350675582886, "actor_loss": -82.7870625087193, "actor_target_entropy": -1.0, "actor_entropy": 1.0118192055868724, "alpha_loss": 0.0019755674399516824, "alpha_value": 0.007727807624778862, "duration": 3.8465347290039062, "step": 144625}
{"episode_reward": 86.36948554529795, "episode": 1158.0, "batch_reward": 0.8128967771530151, "critic_loss": 2.123460974693298, "actor_loss": -82.79848615584835, "actor_target_entropy": -1.0, "actor_entropy": 1.0302936069426998, "alpha_loss": 0.0020625656494127225, "alpha_value": 0.007669708911681305, "duration": 3.8384854793548584, "step": 144750}
{"episode_reward": 66.0261315151102, "episode": 1159.0, "batch_reward": 0.8299090628623962, "critic_loss": 2.0881806945800783, "actor_loss": -82.80718388633123, "actor_target_entropy": -1.0, "actor_entropy": 1.018366013254438, "alpha_loss": 0.0017554581979297042, "alpha_value": 0.007619888952559693, "duration": 3.8415956497192383, "step": 144875}
{"episode_reward": 100.85156380675667, "episode": 1160.0, "batch_reward": 0.8192256851196289, "critic_loss": 2.028657693862915, "actor_loss": -82.81026864820912, "actor_target_entropy": -1.0, "actor_entropy": 1.0058227546753422, "alpha_loss": 0.0017746996130764245, "alpha_value": 0.007572673768883863, "duration": 3.8391358852386475, "step": 145000}
{"episode_reward": 74.15612335792378, "episode": 1161.0, "batch_reward": 0.8064506945610046, "critic_loss": 2.0494061727523802, "actor_loss": -82.76397705078125, "actor_target_entropy": -1.0, "actor_entropy": 1.000884875418648, "alpha_loss": 0.001841547409264696, "alpha_value": 0.007524945431474136, "duration": 3.8466687202453613, "step": 145125}
{"episode_reward": 78.87443002054955, "episode": 1162.0, "batch_reward": 0.8074837794303894, "critic_loss": 2.0548882513046265, "actor_loss": -82.77519004575667, "actor_target_entropy": -1.0, "actor_entropy": 1.0122451820681173, "alpha_loss": 0.0018869014715047314, "alpha_value": 0.0074760013771770165, "duration": 3.8401637077331543, "step": 145250}
{"episode_reward": 95.35522616216898, "episode": 1163.0, "batch_reward": 0.8146166262626648, "critic_loss": 2.0105151405334474, "actor_loss": -82.74019477480934, "actor_target_entropy": -1.0, "actor_entropy": 1.0060099666080777, "alpha_loss": 0.0018811997567628703, "alpha_value": 0.007430593146539332, "duration": 3.847639799118042, "step": 145375}
{"episode_reward": 79.69993315762837, "episode": 1164.0, "batch_reward": 0.8187873845100403, "critic_loss": 2.0426295614242553, "actor_loss": -82.74437959732548, "actor_target_entropy": -1.0, "actor_entropy": 1.0409651148703791, "alpha_loss": 0.002239186479616159, "alpha_value": 0.007379789778619346, "duration": 3.844059944152832, "step": 145500}
{"episode_reward": 67.41771290449647, "episode": 1165.0, "batch_reward": 0.8082743473052979, "critic_loss": 2.0783634481430053, "actor_loss": -82.71904391334171, "actor_target_entropy": -1.0, "actor_entropy": 1.039756277250865, "alpha_loss": 0.002161645177116115, "alpha_value": 0.00732527516208145, "duration": 3.836921215057373, "step": 145625}
{"episode_reward": 73.0820557110459, "episode": 1166.0, "batch_reward": 0.810144196510315, "critic_loss": 2.0386995058059694, "actor_loss": -82.71881337319651, "actor_target_entropy": -1.0, "actor_entropy": 1.0374187231063843, "alpha_loss": 0.002130651904735714, "alpha_value": 0.007273244913739099, "duration": 3.8401989936828613, "step": 145750}
{"episode_reward": 75.72576384067862, "episode": 1167.0, "batch_reward": 0.8161566319465637, "critic_loss": 2.0560537633895875, "actor_loss": -82.69211142403739, "actor_target_entropy": -1.0, "actor_entropy": 1.0538365367859128, "alpha_loss": 0.002225117247906469, "alpha_value": 0.007223052892703825, "duration": 3.842700958251953, "step": 145875}
{"episode_reward": 139.35007574854114, "episode": 1168.0, "batch_reward": 0.8180076003074646, "critic_loss": 2.036993724822998, "actor_loss": -82.68025687433058, "actor_target_entropy": -1.0, "actor_entropy": 1.0651039961845643, "alpha_loss": 0.0022708934895138465, "alpha_value": 0.007171353901611159, "duration": 3.841446876525879, "step": 146000}
{"episode_reward": 75.16096573450999, "episode": 1169.0, "batch_reward": 0.8055086274147034, "critic_loss": 1.948288685798645, "actor_loss": -82.66968536376953, "actor_target_entropy": -1.0, "actor_entropy": 1.0708755784564548, "alpha_loss": 0.0024559483142747056, "alpha_value": 0.007118043879498038, "duration": 3.8491618633270264, "step": 146125}
{"episode_reward": 76.78449359051733, "episode": 1170.0, "batch_reward": 0.8119815416336059, "critic_loss": 2.016309868812561, "actor_loss": -82.65461423320156, "actor_target_entropy": -1.0, "actor_entropy": 1.0793738095991072, "alpha_loss": 0.0024665789622362825, "alpha_value": 0.007064534916141402, "duration": 3.8390822410583496, "step": 146250}
{"episode_reward": 89.403259350829, "episode": 1171.0, "batch_reward": 0.8144593172073364, "critic_loss": 1.95042391872406, "actor_loss": -82.64278363424634, "actor_target_entropy": -1.0, "actor_entropy": 1.0847610310902671, "alpha_loss": 0.0025213194959279564, "alpha_value": 0.007012798203248086, "duration": 3.847952127456665, "step": 146375}
{"episode_reward": 85.1769275961685, "episode": 1172.0, "batch_reward": 0.8145328412055969, "critic_loss": 2.0211228771209715, "actor_loss": -82.62368331416961, "actor_target_entropy": -1.0, "actor_entropy": 1.1135422375894362, "alpha_loss": 0.0027263300444540237, "alpha_value": 0.006957449999632181, "duration": 3.838745594024658, "step": 146500}
{"episode_reward": 74.10265977748737, "episode": 1173.0, "batch_reward": 0.8177597742080689, "critic_loss": 2.0285143194198607, "actor_loss": -82.62750110928974, "actor_target_entropy": -1.0, "actor_entropy": 1.1277527752376737, "alpha_loss": 0.002894663525420049, "alpha_value": 0.006901636806512511, "duration": 3.847510814666748, "step": 146625}
{"episode_reward": 88.34731193436441, "episode": 1174.0, "batch_reward": 0.813619622707367, "critic_loss": 2.033139889717102, "actor_loss": -82.59820187476373, "actor_target_entropy": -1.0, "actor_entropy": 1.1158203348036735, "alpha_loss": 0.0027342443504641133, "alpha_value": 0.00684685249612636, "duration": 3.8409337997436523, "step": 146750}
{"episode_reward": 72.8948762314974, "episode": 1175.0, "batch_reward": 0.8131212749481201, "critic_loss": 2.0147573652267456, "actor_loss": -82.6101554991707, "actor_target_entropy": -1.0, "actor_entropy": 1.1235073956232222, "alpha_loss": 0.0028627358029581725, "alpha_value": 0.0067938337775153455, "duration": 3.8485560417175293, "step": 146875}
{"episode_reward": 85.92360075052277, "episode": 1176.0, "batch_reward": 0.8238882479667664, "critic_loss": 2.1416821756362916, "actor_loss": -82.59834904824534, "actor_target_entropy": -1.0, "actor_entropy": 1.1245297193527222, "alpha_loss": 0.003036096601957275, "alpha_value": 0.006740647998261049, "duration": 3.8442859649658203, "step": 147000}
{"episode_reward": 74.80199439579178, "episode": 1177.0, "batch_reward": 0.8147880897521973, "critic_loss": 2.0800192546844483, "actor_loss": -82.5667263212658, "actor_target_entropy": -1.0, "actor_entropy": 1.1514431957214597, "alpha_loss": 0.003041443132263209, "alpha_value": 0.006686977943546991, "duration": 3.838589906692505, "step": 147125}
{"episode_reward": 91.4244071958328, "episode": 1178.0, "batch_reward": 0.8171169204711914, "critic_loss": 2.0480613584518435, "actor_loss": -82.58068859961725, "actor_target_entropy": -1.0, "actor_entropy": 1.1543457931087864, "alpha_loss": 0.003235850000618807, "alpha_value": 0.006633311338785885, "duration": 3.8450865745544434, "step": 147250}
{"episode_reward": 96.03036259267883, "episode": 1179.0, "batch_reward": 0.8089948267936706, "critic_loss": 1.9166600646972656, "actor_loss": -82.54504019116598, "actor_target_entropy": -1.0, "actor_entropy": 1.1639630926979914, "alpha_loss": 0.00311896400082679, "alpha_value": 0.006580211031341289, "duration": 3.845059871673584, "step": 147375}
{"episode_reward": 93.33494870416948, "episode": 1180.0, "batch_reward": 0.8089099173545837, "critic_loss": 1.9996591510772705, "actor_loss": -82.52565014746881, "actor_target_entropy": -1.0, "actor_entropy": 1.1849801501920145, "alpha_loss": 0.0033188119095059173, "alpha_value": 0.006529017167520022, "duration": 3.8419532775878906, "step": 147500}
{"episode_reward": 77.52982261123744, "episode": 1181.0, "batch_reward": 0.7936840386390686, "critic_loss": 1.9472795486450196, "actor_loss": -82.50572749546596, "actor_target_entropy": -1.0, "actor_entropy": 1.1824226095562889, "alpha_loss": 0.003280374458030103, "alpha_value": 0.006476724354321278, "duration": 3.849949598312378, "step": 147625}
{"episode_reward": 60.23427518083598, "episode": 1182.0, "batch_reward": 0.8141578330993652, "critic_loss": 2.075710053443909, "actor_loss": -82.50631381619361, "actor_target_entropy": -1.0, "actor_entropy": 1.180235251303642, "alpha_loss": 0.0032820518770735833, "alpha_value": 0.006426980745663546, "duration": 3.8397960662841797, "step": 147750}
{"episode_reward": 92.6073854577291, "episode": 1183.0, "batch_reward": 0.8073835554122925, "critic_loss": 2.0074521255493165, "actor_loss": -82.48328896174355, "actor_target_entropy": -1.0, "actor_entropy": 1.2059275479543776, "alpha_loss": 0.0034143649640360047, "alpha_value": 0.006377436775189961, "duration": 3.8538436889648438, "step": 147875}
{"episode_reward": 120.983296829588, "episode": 1184.0, "batch_reward": 0.8036554656028747, "critic_loss": 2.0120973558425903, "actor_loss": -82.45776404103925, "actor_target_entropy": -1.0, "actor_entropy": 1.2267304428162114, "alpha_loss": 0.0035136757388470633, "alpha_value": 0.006327751417342804, "duration": 3.84047532081604, "step": 148000}
{"episode_reward": 104.87308295468628, "episode": 1185.0, "batch_reward": 0.8208437495231629, "critic_loss": 2.0877258615493774, "actor_loss": -82.48282683841767, "actor_target_entropy": -1.0, "actor_entropy": 1.219331940015157, "alpha_loss": 0.003420658003065794, "alpha_value": 0.006278529500797342, "duration": 3.8519952297210693, "step": 148125}
{"episode_reward": 88.89195627397481, "episode": 1186.0, "batch_reward": 0.8111332888603211, "critic_loss": 1.9577544527053834, "actor_loss": -82.45486314835087, "actor_target_entropy": -1.0, "actor_entropy": 1.223214783976155, "alpha_loss": 0.0034669829690228064, "alpha_value": 0.006231514761929468, "duration": 3.8400092124938965, "step": 148250}
{"episode_reward": 144.90207360999818, "episode": 1187.0, "batch_reward": 0.8026819472312927, "critic_loss": 1.9957853469848632, "actor_loss": -82.42595624166822, "actor_target_entropy": -1.0, "actor_entropy": 1.2374480281557356, "alpha_loss": 0.0035393229087016414, "alpha_value": 0.006185340045993291, "duration": 3.844794511795044, "step": 148375}
{"episode_reward": 77.50304233534591, "episode": 1188.0, "batch_reward": 0.8188515801429749, "critic_loss": 2.0634077806472777, "actor_loss": -82.43575951360887, "actor_target_entropy": -1.0, "actor_entropy": 1.2633599965803084, "alpha_loss": 0.0036038763843657027, "alpha_value": 0.006138054350340337, "duration": 3.840252637863159, "step": 148500}
{"episode_reward": 77.78289913022653, "episode": 1189.0, "batch_reward": 0.8149812130928039, "critic_loss": 1.984875732421875, "actor_loss": -82.4295883178711, "actor_target_entropy": -1.0, "actor_entropy": 1.2659642071951003, "alpha_loss": 0.0037908028951653887, "alpha_value": 0.0060913022093828815, "duration": 3.840291976928711, "step": 148625}
{"episode_reward": 88.37064081308692, "episode": 1190.0, "batch_reward": 0.8133385791778565, "critic_loss": 2.0522676134109497, "actor_loss": -82.40151571458385, "actor_target_entropy": -1.0, "actor_entropy": 1.2734654526556692, "alpha_loss": 0.00375706308911885, "alpha_value": 0.006043944876603418, "duration": 3.8522913455963135, "step": 148750}
{"episode_reward": 79.50012190893499, "episode": 1191.0, "batch_reward": 0.7999990935325623, "critic_loss": 1.96987144947052, "actor_loss": -82.37763286772228, "actor_target_entropy": -1.0, "actor_entropy": 1.298414534992642, "alpha_loss": 0.0039886595784789985, "alpha_value": 0.005997666793710173, "duration": 3.8470537662506104, "step": 148875}
{"episode_reward": 101.59750105803457, "episode": 1192.0, "batch_reward": 0.8056463112831116, "critic_loss": 1.9806315803527832, "actor_loss": -82.37112488285187, "actor_target_entropy": -1.0, "actor_entropy": 1.31595770389803, "alpha_loss": 0.003863125111937763, "alpha_value": 0.0059515334270110595, "duration": 3.84138560295105, "step": 149000}
{"episode_reward": 217.94577344441353, "episode": 1193.0, "batch_reward": 0.7992696189880371, "critic_loss": 1.9246116399765014, "actor_loss": -82.35550399053665, "actor_target_entropy": -1.0, "actor_entropy": 1.290853668772985, "alpha_loss": 0.003701865654586563, "alpha_value": 0.005907773157567642, "duration": 3.847996950149536, "step": 149125}
{"episode_reward": 82.83698117003112, "episode": 1194.0, "batch_reward": 0.8150746335983277, "critic_loss": 2.0605130376815795, "actor_loss": -82.33460481705204, "actor_target_entropy": -1.0, "actor_entropy": 1.2786818819661294, "alpha_loss": 0.0036821282081936878, "alpha_value": 0.005866069760522315, "duration": 3.8433098793029785, "step": 149250}
{"episode_reward": 76.92829286232731, "episode": 1195.0, "batch_reward": 0.8153532552719116, "critic_loss": 1.97653182888031, "actor_loss": -82.31352936275421, "actor_target_entropy": -1.0, "actor_entropy": 1.3226854252436804, "alpha_loss": 0.0037410312576130742, "alpha_value": 0.005824429410780301, "duration": 3.8410418033599854, "step": 149375}
{"episode_reward": 83.77927807375526, "episode": 1196.0, "batch_reward": 0.815138916015625, "critic_loss": 1.9872605495452882, "actor_loss": -82.32850142448179, "actor_target_entropy": -1.0, "actor_entropy": 1.3509552440335673, "alpha_loss": 0.004054312188658983, "alpha_value": 0.005782220934801259, "duration": 3.8338522911071777, "step": 149500}
{"episode_reward": 81.55268446465031, "episode": 1197.0, "batch_reward": 0.8217733139991761, "critic_loss": 1.9866186542510986, "actor_loss": -82.31412905738468, "actor_target_entropy": -1.0, "actor_entropy": 1.365876729526217, "alpha_loss": 0.004000906887952061, "alpha_value": 0.0057396212260168245, "duration": 3.849950075149536, "step": 149625}
{"episode_reward": 74.22904852890919, "episode": 1198.0, "batch_reward": 0.8078234887123108, "critic_loss": 1.9593859100341797, "actor_loss": -82.29416767243416, "actor_target_entropy": -1.0, "actor_entropy": 1.3993966694801085, "alpha_loss": 0.004210873792368558, "alpha_value": 0.00569659043762968, "duration": 3.8367230892181396, "step": 149750}
{"episode_reward": 138.31015229114433, "episode": 1199.0, "batch_reward": 0.7999114603996277, "critic_loss": 1.9750705556869508, "actor_loss": -82.27379063197544, "actor_target_entropy": -1.0, "actor_entropy": 1.4140702221128676, "alpha_loss": 0.003987654552070631, "alpha_value": 0.00565489251228508, "duration": 3.851475715637207, "step": 149875}
{"episode_reward": 97.10197815355741, "episode": 1200.0, "batch_reward": 0.8043719296455383, "critic_loss": 1.9851091222763062, "actor_loss": -82.2689571995889, "actor_target_entropy": -1.0, "actor_entropy": 1.413415958804469, "alpha_loss": 0.004152754152704391, "alpha_value": 0.005614014461346384, "duration": 3.8379697799682617, "step": 150000}
{"episode_reward": 138.32890677752107, "episode": 1201.0, "batch_reward": 0.8079001593589783, "critic_loss": 1.9587646551132203, "actor_loss": -82.23755415659102, "actor_target_entropy": -1.0, "actor_entropy": 1.4420904450946384, "alpha_loss": 0.004084621519145984, "alpha_value": 0.0055735657191895395, "duration": 7.828731536865234, "step": 150125}
{"episode_reward": 75.87688088786781, "episode": 1202.0, "batch_reward": 0.8267643003463745, "critic_loss": 2.0735296988487244, "actor_loss": -82.24418074084866, "actor_target_entropy": -1.0, "actor_entropy": 1.4757646168431928, "alpha_loss": 0.0042276263815320785, "alpha_value": 0.005533550213024993, "duration": 3.8392932415008545, "step": 150250}
{"episode_reward": 76.45452195363775, "episode": 1203.0, "batch_reward": 0.8025242171287537, "critic_loss": 1.9939332962036134, "actor_loss": -82.22567204066685, "actor_target_entropy": -1.0, "actor_entropy": 1.5009371155784244, "alpha_loss": 0.0042726641949561855, "alpha_value": 0.00549325592006902, "duration": 3.8458642959594727, "step": 150375}
{"episode_reward": 71.8501211651365, "episode": 1204.0, "batch_reward": 0.8043197560310363, "critic_loss": 2.0136448078155516, "actor_loss": -82.21950457173008, "actor_target_entropy": -1.0, "actor_entropy": 1.5046026668240946, "alpha_loss": 0.004192914652277625, "alpha_value": 0.005454155132628742, "duration": 3.8402693271636963, "step": 150500}
{"episode_reward": 130.7677797684382, "episode": 1205.0, "batch_reward": 0.8172813954353333, "critic_loss": 1.956518726348877, "actor_loss": -82.21342020186167, "actor_target_entropy": -1.0, "actor_entropy": 1.5123242139816284, "alpha_loss": 0.004140055734693768, "alpha_value": 0.005415929060097772, "duration": 3.8445537090301514, "step": 150625}
{"episode_reward": 94.43283326166483, "episode": 1206.0, "batch_reward": 0.8119581189155579, "critic_loss": 2.0772840385437013, "actor_loss": -82.21358268491683, "actor_target_entropy": -1.0, "actor_entropy": 1.521843591044026, "alpha_loss": 0.0041075272019952536, "alpha_value": 0.005378799803746495, "duration": 3.837232828140259, "step": 150750}
{"episode_reward": 86.51153399291702, "episode": 1207.0, "batch_reward": 0.812096652507782, "critic_loss": 2.0044855132102968, "actor_loss": -82.19752962627108, "actor_target_entropy": -1.0, "actor_entropy": 1.5298515974529205, "alpha_loss": 0.004086636904893177, "alpha_value": 0.005342627737551596, "duration": 3.8386573791503906, "step": 150875}
{"episode_reward": 70.2200239662133, "episode": 1208.0, "batch_reward": 0.8090912857055664, "critic_loss": 1.9320761070251464, "actor_loss": -82.18602568103421, "actor_target_entropy": -1.0, "actor_entropy": 1.5502872659314064, "alpha_loss": 0.0040224290813409514, "alpha_value": 0.005307049890212968, "duration": 3.843817949295044, "step": 151000}
{"episode_reward": 89.39025140556258, "episode": 1209.0, "batch_reward": 0.8141549010276794, "critic_loss": 1.9421725854873657, "actor_loss": -82.18830774700831, "actor_target_entropy": -1.0, "actor_entropy": 1.5726074056019859, "alpha_loss": 0.004133706202819234, "alpha_value": 0.005271649611042919, "duration": 3.8457798957824707, "step": 151125}
{"episode_reward": 176.40482934659653, "episode": 1210.0, "batch_reward": 0.7995138969421387, "critic_loss": 1.9427867393493652, "actor_loss": -82.15831978090348, "actor_target_entropy": -1.0, "actor_entropy": 1.5860862616569764, "alpha_loss": 0.004069429003603516, "alpha_value": 0.005236971733905357, "duration": 3.844736337661743, "step": 151250}
{"episode_reward": 70.15871746923315, "episode": 1211.0, "batch_reward": 0.8104270796775818, "critic_loss": 1.9634219751358033, "actor_loss": -82.15091378348214, "actor_target_entropy": -1.0, "actor_entropy": 1.6120148178130862, "alpha_loss": 0.004150712352600836, "alpha_value": 0.005202104454742551, "duration": 3.851041316986084, "step": 151375}
{"episode_reward": 76.92510006852798, "episode": 1212.0, "batch_reward": 0.8094513249397278, "critic_loss": 1.9986411948204041, "actor_loss": -82.14724288448211, "actor_target_entropy": -1.0, "actor_entropy": 1.6483779761099047, "alpha_loss": 0.004023948440238113, "alpha_value": 0.0051676840326393405, "duration": 3.8345470428466797, "step": 151500}
{"episode_reward": 91.47277190081441, "episode": 1213.0, "batch_reward": 0.8018555970191955, "critic_loss": 1.898395736694336, "actor_loss": -82.1205567859468, "actor_target_entropy": -1.0, "actor_entropy": 1.6630488369199965, "alpha_loss": 0.0041210166777351075, "alpha_value": 0.005134326625768918, "duration": 3.84153413772583, "step": 151625}
{"episode_reward": 123.81084079953055, "episode": 1214.0, "batch_reward": 0.816498221874237, "critic_loss": 2.0305247592926023, "actor_loss": -82.11921236591954, "actor_target_entropy": -1.0, "actor_entropy": 1.7089711196960942, "alpha_loss": 0.003988514507880374, "alpha_value": 0.005100909977144561, "duration": 3.8375866413116455, "step": 151750}
{"episode_reward": 149.1357125418331, "episode": 1215.0, "batch_reward": 0.8048139343261719, "critic_loss": 1.9673265857696534, "actor_loss": -82.1091061546689, "actor_target_entropy": -1.0, "actor_entropy": 1.7347695959938898, "alpha_loss": 0.003944106263271164, "alpha_value": 0.005068840117800317, "duration": 3.8475594520568848, "step": 151875}
{"episode_reward": 78.17998433049169, "episode": 1216.0, "batch_reward": 0.8123361206054688, "critic_loss": 1.977189794063568, "actor_loss": -82.10556879351216, "actor_target_entropy": -1.0, "actor_entropy": 1.7480400954523394, "alpha_loss": 0.004052423999734944, "alpha_value": 0.0050366563383068075, "duration": 3.8376078605651855, "step": 152000}
{"episode_reward": 191.01654381277078, "episode": 1217.0, "batch_reward": 0.7967141318321228, "critic_loss": 2.0062139558792116, "actor_loss": -82.08220781598773, "actor_target_entropy": -1.0, "actor_entropy": 1.7622968299048287, "alpha_loss": 0.0038327252869272514, "alpha_value": 0.005005185403686021, "duration": 3.8451836109161377, "step": 152125}
{"episode_reward": 116.42902926801398, "episode": 1218.0, "batch_reward": 0.8127448711395263, "critic_loss": 2.049945983886719, "actor_loss": -82.07936551493984, "actor_target_entropy": -1.0, "actor_entropy": 1.794257321665364, "alpha_loss": 0.0038383328017868824, "alpha_value": 0.004974694560117495, "duration": 3.841641426086426, "step": 152250}
{"episode_reward": 93.39283152873843, "episode": 1219.0, "batch_reward": 0.807272641658783, "critic_loss": 1.9878641357421876, "actor_loss": -82.05393618629093, "actor_target_entropy": -1.0, "actor_entropy": 1.830655917288765, "alpha_loss": 0.003899331509490453, "alpha_value": 0.004944250611200031, "duration": 3.8418679237365723, "step": 152375}
{"episode_reward": 164.45509499486764, "episode": 1220.0, "batch_reward": 0.8099395723342896, "critic_loss": 1.954741729736328, "actor_loss": -82.04406615226499, "actor_target_entropy": -1.0, "actor_entropy": 1.8743148349946546, "alpha_loss": 0.0037158468227472996, "alpha_value": 0.004914532585936143, "duration": 3.8459248542785645, "step": 152500}
{"episode_reward": 173.4207043092137, "episode": 1221.0, "batch_reward": 0.8310436191558838, "critic_loss": 2.0527934331893922, "actor_loss": -82.06741938515314, "actor_target_entropy": -1.0, "actor_entropy": 1.9270239198018635, "alpha_loss": 0.0036520258198300052, "alpha_value": 0.004885649251899447, "duration": 3.8430631160736084, "step": 152625}
{"episode_reward": 175.7234507993133, "episode": 1222.0, "batch_reward": 0.804361656665802, "critic_loss": 1.9372846956253051, "actor_loss": -82.02173688334804, "actor_target_entropy": -1.0, "actor_entropy": 1.9678454745200373, "alpha_loss": 0.0032283197731650887, "alpha_value": 0.004858931278017492, "duration": 3.835733413696289, "step": 152750}
{"episode_reward": 132.63429298364036, "episode": 1223.0, "batch_reward": 0.8152342410087585, "critic_loss": 1.964652545928955, "actor_loss": -82.02434878879123, "actor_target_entropy": -1.0, "actor_entropy": 2.005329800030542, "alpha_loss": 0.003276274676272084, "alpha_value": 0.00483347917184825, "duration": 3.845571279525757, "step": 152875}
{"episode_reward": 131.69488797668055, "episode": 1224.0, "batch_reward": 0.8145920405387879, "critic_loss": 2.028860269546509, "actor_loss": -82.02806977302798, "actor_target_entropy": -1.0, "actor_entropy": 2.0404697848904516, "alpha_loss": 0.002996074959575649, "alpha_value": 0.004809361421328143, "duration": 3.8375751972198486, "step": 153000}
{"episode_reward": 44.49194450959524, "episode": 1225.0, "batch_reward": 0.8123980731964111, "critic_loss": 1.995452473640442, "actor_loss": -82.02169121636285, "actor_target_entropy": -1.0, "actor_entropy": 2.054489605010502, "alpha_loss": 0.0028885433428166877, "alpha_value": 0.004786377797550068, "duration": 3.8452236652374268, "step": 153125}
{"episode_reward": 124.41536624520128, "episode": 1226.0, "batch_reward": 0.8310213227272034, "critic_loss": 2.0477844915390016, "actor_loss": -82.03674427155525, "actor_target_entropy": -1.0, "actor_entropy": 2.0650059330847954, "alpha_loss": 0.002684469909347113, "alpha_value": 0.004763589994572038, "duration": 3.8321328163146973, "step": 153250}
{"episode_reward": 127.24001832278509, "episode": 1227.0, "batch_reward": 0.818984393119812, "critic_loss": 2.00674507522583, "actor_loss": -82.02825346447173, "actor_target_entropy": -1.0, "actor_entropy": 2.0813904565478127, "alpha_loss": 0.002844736926139347, "alpha_value": 0.004742094441796773, "duration": 3.8436386585235596, "step": 153375}
{"episode_reward": 79.78701116073256, "episode": 1228.0, "batch_reward": 0.8067438626289367, "critic_loss": 1.9682096834182738, "actor_loss": -82.00997580251386, "actor_target_entropy": -1.0, "actor_entropy": 2.095402394571612, "alpha_loss": 0.002842600444226616, "alpha_value": 0.004718949781719035, "duration": 3.8353805541992188, "step": 153500}
{"episode_reward": 111.80206387637409, "episode": 1229.0, "batch_reward": 0.8152552843093872, "critic_loss": 1.9772029037475587, "actor_loss": -82.023435320173, "actor_target_entropy": -1.0, "actor_entropy": 2.117777430821979, "alpha_loss": 0.002603285678935843, "alpha_value": 0.004696848947639596, "duration": 3.8417892456054688, "step": 153625}
{"episode_reward": 148.2782158057013, "episode": 1230.0, "batch_reward": 0.7971780252456665, "critic_loss": 1.957654405593872, "actor_loss": -81.98676755351406, "actor_target_entropy": -1.0, "actor_entropy": 2.1335987737101894, "alpha_loss": 0.002751055816676648, "alpha_value": 0.004674920523488187, "duration": 3.8386857509613037, "step": 153750}
{"episode_reward": 140.41935920722108, "episode": 1231.0, "batch_reward": 0.8007235398292541, "critic_loss": 1.9770707921981812, "actor_loss": -81.96746135893322, "actor_target_entropy": -1.0, "actor_entropy": 2.1539060350448365, "alpha_loss": 0.0022748245659934743, "alpha_value": 0.004654084109495742, "duration": 3.8417794704437256, "step": 153875}
{"episode_reward": 155.16590020340809, "episode": 1232.0, "batch_reward": 0.8216564331054688, "critic_loss": 1.9737042274475098, "actor_loss": -81.98220812889838, "actor_target_entropy": -1.0, "actor_entropy": 2.1670007859506915, "alpha_loss": 0.002264942956014326, "alpha_value": 0.004635294467046932, "duration": 3.8401670455932617, "step": 154000}
{"episode_reward": 197.0524730820992, "episode": 1233.0, "batch_reward": 0.803908103942871, "critic_loss": 1.9822219190597534, "actor_loss": -81.96644773937408, "actor_target_entropy": -1.0, "actor_entropy": 2.1869913736979165, "alpha_loss": 0.0023273972832294743, "alpha_value": 0.00461636444045753, "duration": 3.8399457931518555, "step": 154125}
{"episode_reward": 29.64824871656805, "episode": 1234.0, "batch_reward": 0.8162887897491455, "critic_loss": 2.076691234111786, "actor_loss": -81.96306942355248, "actor_target_entropy": -1.0, "actor_entropy": 2.2050054457879837, "alpha_loss": 0.002248886221599194, "alpha_value": 0.004596462876269889, "duration": 3.8365638256073, "step": 154250}
{"episode_reward": 141.91373282097908, "episode": 1235.0, "batch_reward": 0.8002226452827453, "critic_loss": 1.9163233528137207, "actor_loss": -81.94494737897601, "actor_target_entropy": -1.0, "actor_entropy": 2.2186166823856412, "alpha_loss": 0.001987244260297822, "alpha_value": 0.0045781616042242694, "duration": 3.842132806777954, "step": 154375}
{"episode_reward": 81.36610662492572, "episode": 1236.0, "batch_reward": 0.8206860775947571, "critic_loss": 1.9719710178375245, "actor_loss": -81.95965477728075, "actor_target_entropy": -1.0, "actor_entropy": 2.224190773502473, "alpha_loss": 0.0019043045908948707, "alpha_value": 0.0045614403745586046, "duration": 3.8324406147003174, "step": 154500}
{"episode_reward": 68.2702701502622, "episode": 1237.0, "batch_reward": 0.8010300183296204, "critic_loss": 1.9528503351211548, "actor_loss": -81.9364978850834, "actor_target_entropy": -1.0, "actor_entropy": 2.23652836633107, "alpha_loss": 0.0017652659370223918, "alpha_value": 0.004545104093973709, "duration": 3.8471648693084717, "step": 154625}
{"episode_reward": 157.5733009337876, "episode": 1238.0, "batch_reward": 0.8090378503799438, "critic_loss": 1.9442784566879272, "actor_loss": -81.94666585614604, "actor_target_entropy": -1.0, "actor_entropy": 2.2473850711699455, "alpha_loss": 0.0017305818830444027, "alpha_value": 0.004529628622723335, "duration": 3.8326261043548584, "step": 154750}
{"episode_reward": 113.69233214138566, "episode": 1239.0, "batch_reward": 0.807496292591095, "critic_loss": 1.9326493520736694, "actor_loss": -81.93379332527282, "actor_target_entropy": -1.0, "actor_entropy": 2.2664205460321334, "alpha_loss": 0.0016205148112642326, "alpha_value": 0.00451424587064604, "duration": 3.840712308883667, "step": 154875}
{"episode_reward": 65.28940608238433, "episode": 1240.0, "batch_reward": 0.815367235660553, "critic_loss": 1.9970307722091676, "actor_loss": -81.93902292559224, "actor_target_entropy": -1.0, "actor_entropy": 2.2788127007022982, "alpha_loss": 0.00133308888677763, "alpha_value": 0.004499821126344081, "duration": 3.832603693008423, "step": 155000}
{"episode_reward": 123.29540964435279, "episode": 1241.0, "batch_reward": 0.7912615113258362, "critic_loss": 1.8865650930404663, "actor_loss": -81.9114022633386, "actor_target_entropy": -1.0, "actor_entropy": 2.286343604799301, "alpha_loss": 0.0013046109356403734, "alpha_value": 0.0044879432700401616, "duration": 3.8411591053009033, "step": 155125}
{"episode_reward": 61.91659091834754, "episode": 1242.0, "batch_reward": 0.8060963282585144, "critic_loss": 1.969676074028015, "actor_loss": -81.91266361359627, "actor_target_entropy": -1.0, "actor_entropy": 2.2860745460756364, "alpha_loss": 0.0012773050283055541, "alpha_value": 0.004475300023584467, "duration": 3.8320627212524414, "step": 155250}
{"episode_reward": 51.03047468597587, "episode": 1243.0, "batch_reward": 0.816584816455841, "critic_loss": 2.005082597732544, "actor_loss": -81.9215575929672, "actor_target_entropy": -1.0, "actor_entropy": 2.2946131569998607, "alpha_loss": 0.0014965842553739629, "alpha_value": 0.004460812320496124, "duration": 3.8412177562713623, "step": 155375}
{"episode_reward": 163.00218425621514, "episode": 1244.0, "batch_reward": 0.8160826201438904, "critic_loss": 2.0214182424545286, "actor_loss": -81.91262620495212, "actor_target_entropy": -1.0, "actor_entropy": 2.31318816831035, "alpha_loss": 0.0012682721752489375, "alpha_value": 0.004447875464392323, "duration": 3.8386850357055664, "step": 155500}
{"episode_reward": 76.72433474260849, "episode": 1245.0, "batch_reward": 0.8102470564842225, "critic_loss": 1.9577455673217774, "actor_loss": -81.90096525161985, "actor_target_entropy": -1.0, "actor_entropy": 2.334186765882704, "alpha_loss": 0.0010974230515005598, "alpha_value": 0.004436270848046371, "duration": 3.8324625492095947, "step": 155625}
{"episode_reward": 128.20932920005998, "episode": 1246.0, "batch_reward": 0.8051698775291443, "critic_loss": 1.9234800634384155, "actor_loss": -81.89256089733493, "actor_target_entropy": -1.0, "actor_entropy": 2.3430852274740896, "alpha_loss": 0.000919440118577181, "alpha_value": 0.004425259536967849, "duration": 3.835665464401245, "step": 155750}
{"episode_reward": 136.12931316111505, "episode": 1247.0, "batch_reward": 0.8306284103393554, "critic_loss": 2.071652862548828, "actor_loss": -81.91482604496063, "actor_target_entropy": -1.0, "actor_entropy": 2.3593213368975925, "alpha_loss": 0.0009313724294770509, "alpha_value": 0.00441573517840802, "duration": 3.842308521270752, "step": 155875}
{"episode_reward": 121.25106653816165, "episode": 1248.0, "batch_reward": 0.8123902463912964, "critic_loss": 1.9325191144943237, "actor_loss": -81.9057885446856, "actor_target_entropy": -1.0, "actor_entropy": 2.357515981120448, "alpha_loss": 0.0006326001988077957, "alpha_value": 0.00440642067564772, "duration": 3.8372106552124023, "step": 156000}
{"episode_reward": 137.36774099219264, "episode": 1249.0, "batch_reward": 0.8127087435722351, "critic_loss": 1.9590738954544067, "actor_loss": -81.89861031184121, "actor_target_entropy": -1.0, "actor_entropy": 2.362189489697653, "alpha_loss": 0.000983917258544973, "alpha_value": 0.004396950461313013, "duration": 3.8450841903686523, "step": 156125}
{"episode_reward": 70.8860520510686, "episode": 1250.0, "batch_reward": 0.8165056357383728, "critic_loss": 1.9570292491912842, "actor_loss": -81.90327355169481, "actor_target_entropy": -1.0, "actor_entropy": 2.3694437242323354, "alpha_loss": 0.0006733526008188605, "alpha_value": 0.004388459477879208, "duration": 3.829904317855835, "step": 156250}
{"episode_reward": 154.25574348573235, "episode": 1251.0, "batch_reward": 0.8243100180625915, "critic_loss": 2.0050987749099733, "actor_loss": -81.91107541038876, "actor_target_entropy": -1.0, "actor_entropy": 2.378743050590394, "alpha_loss": 0.0006860148388936761, "alpha_value": 0.004380606947548023, "duration": 3.8419713973999023, "step": 156375}
{"episode_reward": 156.99665684720978, "episode": 1252.0, "batch_reward": 0.8198558454513549, "critic_loss": 2.012590500831604, "actor_loss": -81.90805016794512, "actor_target_entropy": -1.0, "actor_entropy": 2.386622690385388, "alpha_loss": 0.000646854480897497, "alpha_value": 0.004372611966456698, "duration": 3.8322484493255615, "step": 156500}
{"episode_reward": 68.8494983860247, "episode": 1253.0, "batch_reward": 0.8137168965339661, "critic_loss": 1.9874352407455445, "actor_loss": -81.90705399286179, "actor_target_entropy": -1.0, "actor_entropy": 2.4038809216211714, "alpha_loss": 0.0004791512982346975, "alpha_value": 0.0043661002678366, "duration": 3.8429629802703857, "step": 156625}
{"episode_reward": 208.13835098234426, "episode": 1254.0, "batch_reward": 0.8082013382911682, "critic_loss": 1.9418742017745971, "actor_loss": -81.90458863781345, "actor_target_entropy": -1.0, "actor_entropy": 2.409513581183649, "alpha_loss": 0.0004059759324469093, "alpha_value": 0.004360510934125987, "duration": 3.8394815921783447, "step": 156750}
{"episode_reward": 156.87269927429995, "episode": 1255.0, "batch_reward": 0.8070890698432922, "critic_loss": 1.9503373937606812, "actor_loss": -81.89383794390966, "actor_target_entropy": -1.0, "actor_entropy": 2.410384374951559, "alpha_loss": 0.0003724764401484872, "alpha_value": 0.004355516023558898, "duration": 3.840226173400879, "step": 156875}
{"episode_reward": 168.84079256440467, "episode": 1256.0, "batch_reward": 0.797138261795044, "critic_loss": 1.921189489364624, "actor_loss": -81.87637095297536, "actor_target_entropy": -1.0, "actor_entropy": 2.415027387680546, "alpha_loss": 0.00025574871723356115, "alpha_value": 0.004352064241008485, "duration": 3.8422255516052246, "step": 157000}
{"episode_reward": 225.07046818164986, "episode": 1257.0, "batch_reward": 0.8206658453941346, "critic_loss": 1.972232629776001, "actor_loss": -81.90269651867095, "actor_target_entropy": -1.0, "actor_entropy": 2.425771289401584, "alpha_loss": 0.00021587100225530328, "alpha_value": 0.004348370375818181, "duration": 3.836559534072876, "step": 157125}
{"episode_reward": 139.1476651109254, "episode": 1258.0, "batch_reward": 0.8149226613044739, "critic_loss": 1.9892500143051148, "actor_loss": -81.90366621940366, "actor_target_entropy": -1.0, "actor_entropy": 2.4384524130052134, "alpha_loss": 0.0002034047595976341, "alpha_value": 0.004345543663161041, "duration": 3.8444788455963135, "step": 157250}
{"episode_reward": 121.38150637665457, "episode": 1259.0, "batch_reward": 0.8003352150917054, "critic_loss": 1.9070489435195923, "actor_loss": -81.87806955973308, "actor_target_entropy": -1.0, "actor_entropy": 2.443499686226012, "alpha_loss": 5.815160878386999e-05, "alpha_value": 0.004343729877355108, "duration": 3.84517502784729, "step": 157375}
{"episode_reward": 115.96424802175349, "episode": 1260.0, "batch_reward": 0.817313789844513, "critic_loss": 1.9897796363830567, "actor_loss": -81.894531742219, "actor_target_entropy": -1.0, "actor_entropy": 2.4456921700508363, "alpha_loss": 7.631588584533142e-05, "alpha_value": 0.004342846293343204, "duration": 3.836042881011963, "step": 157500}
{"episode_reward": 108.67986275859843, "episode": 1261.0, "batch_reward": 0.8253532500267029, "critic_loss": 2.0026747856140137, "actor_loss": -81.90046946207683, "actor_target_entropy": -1.0, "actor_entropy": 2.4484488320729088, "alpha_loss": -8.643688777247296e-05, "alpha_value": 0.004343065680524948, "duration": 3.8462886810302734, "step": 157625}
{"episode_reward": 171.52846233351062, "episode": 1262.0, "batch_reward": 0.8176728529930115, "critic_loss": 1.9526721487045289, "actor_loss": -81.89866010604366, "actor_target_entropy": -1.0, "actor_entropy": 2.4472013288928616, "alpha_loss": -7.149379046994352e-05, "alpha_value": 0.004344146632706301, "duration": 3.8338963985443115, "step": 157750}
{"episode_reward": 89.76143778568806, "episode": 1263.0, "batch_reward": 0.8109791240692139, "critic_loss": 1.9873094577789308, "actor_loss": -81.89263056194972, "actor_target_entropy": -1.0, "actor_entropy": 2.4465609959193637, "alpha_loss": 4.055017341179625e-05, "alpha_value": 0.004343823701763708, "duration": 3.8485100269317627, "step": 157875}
{"episode_reward": 57.418397968296574, "episode": 1264.0, "batch_reward": 0.8187208003997802, "critic_loss": 2.0128188772201536, "actor_loss": -81.9041499476279, "actor_target_entropy": -1.0, "actor_entropy": 2.455717179083055, "alpha_loss": -7.315354178577001e-05, "alpha_value": 0.004345092322620174, "duration": 3.8266994953155518, "step": 158000}
{"episode_reward": 213.09288223119793, "episode": 1265.0, "batch_reward": 0.8218767204284668, "critic_loss": 1.9645594892501832, "actor_loss": -81.91774132138207, "actor_target_entropy": -1.0, "actor_entropy": 2.46725889236208, "alpha_loss": -0.00019891781821137382, "alpha_value": 0.004346841919271196, "duration": 3.828402519226074, "step": 158125}
{"episode_reward": 173.3427637364904, "episode": 1266.0, "batch_reward": 0.8162690663337707, "critic_loss": 2.0000615062713623, "actor_loss": -81.90701958440965, "actor_target_entropy": -1.0, "actor_entropy": 2.4831168113216275, "alpha_loss": -0.0005140748817798487, "alpha_value": 0.004352505814615888, "duration": 3.831192970275879, "step": 158250}
{"episode_reward": 77.74894472402559, "episode": 1267.0, "batch_reward": 0.8120950846672058, "critic_loss": 1.933652440071106, "actor_loss": -81.90113116067553, "actor_target_entropy": -1.0, "actor_entropy": 2.4890516371954057, "alpha_loss": -0.00034375722143089487, "alpha_value": 0.004360308588602973, "duration": 3.8419768810272217, "step": 158375}
{"episode_reward": 183.3953368441336, "episode": 1268.0, "batch_reward": 0.8225917663574219, "critic_loss": 1.9803949823379516, "actor_loss": -81.92180990403698, "actor_target_entropy": -1.0, "actor_entropy": 2.492824862080236, "alpha_loss": -0.00040207125223992816, "alpha_value": 0.004365309097748963, "duration": 3.843093156814575, "step": 158500}
{"episode_reward": 89.50707064910172, "episode": 1269.0, "batch_reward": 0.8055665020942688, "critic_loss": 1.988573709487915, "actor_loss": -81.8887951563275, "actor_target_entropy": -1.0, "actor_entropy": 2.492375540354895, "alpha_loss": -0.000479530770722444, "alpha_value": 0.004373371808427862, "duration": 3.8381924629211426, "step": 158625}
{"episode_reward": 136.4634013766427, "episode": 1270.0, "batch_reward": 0.816890673160553, "critic_loss": 2.014145097732544, "actor_loss": -81.90473839544481, "actor_target_entropy": -1.0, "actor_entropy": 2.493080908252347, "alpha_loss": -0.0006086038475557636, "alpha_value": 0.004382318250004716, "duration": 3.8338935375213623, "step": 158750}
{"episode_reward": 105.88296581562926, "episode": 1271.0, "batch_reward": 0.8116456809043884, "critic_loss": 2.031661027908325, "actor_loss": -81.89957658071367, "actor_target_entropy": -1.0, "actor_entropy": 2.494382449558803, "alpha_loss": -0.0004968901625871363, "alpha_value": 0.004392087937549688, "duration": 3.841700792312622, "step": 158875}
{"episode_reward": 50.154962862230484, "episode": 1272.0, "batch_reward": 0.8187595353126526, "critic_loss": 1.9587042770385743, "actor_loss": -81.90447259718373, "actor_target_entropy": -1.0, "actor_entropy": 2.4885941167031564, "alpha_loss": -8.531045023119077e-05, "alpha_value": 0.004397597609881064, "duration": 3.8318934440612793, "step": 159000}
{"episode_reward": 120.42785966735572, "episode": 1273.0, "batch_reward": 0.8184411602020264, "critic_loss": 2.046742754936218, "actor_loss": -81.90874650743272, "actor_target_entropy": -1.0, "actor_entropy": 2.480698555234879, "alpha_loss": -0.00014371973451315646, "alpha_value": 0.004400066598095769, "duration": 3.8432350158691406, "step": 159125}
{"episode_reward": 167.21268574577977, "episode": 1274.0, "batch_reward": 0.8030251245498657, "critic_loss": 1.9158390560150147, "actor_loss": -81.89472862981981, "actor_target_entropy": -1.0, "actor_entropy": 2.4737638811911307, "alpha_loss": 3.520055320076344e-05, "alpha_value": 0.004401652282610744, "duration": 3.8338561058044434, "step": 159250}
{"episode_reward": 152.14104506060724, "episode": 1275.0, "batch_reward": 0.8103184847831726, "critic_loss": 1.9543838634490966, "actor_loss": -81.89650472005208, "actor_target_entropy": -1.0, "actor_entropy": 2.4663801193237305, "alpha_loss": 0.0002298830638340275, "alpha_value": 0.004399896091156196, "duration": 3.846088171005249, "step": 159375}
{"episode_reward": 181.79095404805366, "episode": 1276.0, "batch_reward": 0.8209833679199219, "critic_loss": 1.991039647102356, "actor_loss": -81.90282809349799, "actor_target_entropy": -1.0, "actor_entropy": 2.467942714691162, "alpha_loss": 0.00011457081845653574, "alpha_value": 0.004396443369202144, "duration": 3.8315372467041016, "step": 159500}
{"episode_reward": 156.10362964868844, "episode": 1277.0, "batch_reward": 0.8223791236877441, "critic_loss": 2.1165123891830446, "actor_loss": -81.9096189226423, "actor_target_entropy": -1.0, "actor_entropy": 2.4681171992468456, "alpha_loss": -0.00010866580816495808, "alpha_value": 0.004394062837987156, "duration": 3.8434860706329346, "step": 159625}
{"episode_reward": 134.1605114833098, "episode": 1278.0, "batch_reward": 0.8128627591133117, "critic_loss": 1.9878188953399658, "actor_loss": -81.8960197202621, "actor_target_entropy": -1.0, "actor_entropy": 2.471879636087725, "alpha_loss": 4.4090458804050524e-05, "alpha_value": 0.004395649430138812, "duration": 3.841355085372925, "step": 159750}
{"episode_reward": 194.34100300845148, "episode": 1279.0, "batch_reward": 0.8003068943023681, "critic_loss": 1.9302068161964416, "actor_loss": -81.8865242609902, "actor_target_entropy": -1.0, "actor_entropy": 2.465930666242327, "alpha_loss": -5.1460799272356937e-05, "alpha_value": 0.0043970291171019985, "duration": 3.8403637409210205, "step": 159875}
{"episode_reward": 109.43936237743752, "episode": 1280.0, "batch_reward": 0.8207180504798889, "critic_loss": 1.9513509826660156, "actor_loss": -81.90267821281186, "actor_target_entropy": -1.0, "actor_entropy": 2.465279779126567, "alpha_loss": 0.00011638124945626083, "alpha_value": 0.004394826963848103, "duration": 3.8391969203948975, "step": 160000}
{"episode_reward": 175.99115920280633, "episode": 1281.0, "batch_reward": 0.8164762778282165, "critic_loss": 1.9771187920570374, "actor_loss": -81.90569632393974, "actor_target_entropy": -1.0, "actor_entropy": 2.4747354265243287, "alpha_loss": -9.617564755321909e-05, "alpha_value": 0.004393310246245052, "duration": 7.806278228759766, "step": 160125}
{"episode_reward": 167.081759247041, "episode": 1282.0, "batch_reward": 0.8284134106636047, "critic_loss": 2.1000568437576295, "actor_loss": -81.92693316551947, "actor_target_entropy": -1.0, "actor_entropy": 2.4778149051050984, "alpha_loss": -5.843120766991389e-05, "alpha_value": 0.004395882518797604, "duration": 3.833113670349121, "step": 160250}
{"episode_reward": 148.33060441381986, "episode": 1283.0, "batch_reward": 0.8239808630943298, "critic_loss": 1.9802933740615845, "actor_loss": -81.93136536128937, "actor_target_entropy": -1.0, "actor_entropy": 2.4773573951115684, "alpha_loss": -5.51241146962321e-06, "alpha_value": 0.0043973873055813415, "duration": 3.8403122425079346, "step": 160375}
{"episode_reward": 150.68464992723568, "episode": 1284.0, "batch_reward": 0.8181544790267944, "critic_loss": 1.999385272026062, "actor_loss": -81.92037545481035, "actor_target_entropy": -1.0, "actor_entropy": 2.4819216112936697, "alpha_loss": 5.578484847172794e-05, "alpha_value": 0.004395936638253767, "duration": 3.838838577270508, "step": 160500}
{"episode_reward": 119.7007746412477, "episode": 1285.0, "batch_reward": 0.811144917011261, "critic_loss": 1.9692233629226685, "actor_loss": -81.91748252747551, "actor_target_entropy": -1.0, "actor_entropy": 2.4857535892062717, "alpha_loss": -0.00028160540802803425, "alpha_value": 0.004398343797839957, "duration": 3.8387911319732666, "step": 160625}
{"episode_reward": 181.4253884841171, "episode": 1286.0, "batch_reward": 0.8282526664733887, "critic_loss": 2.094842434883118, "actor_loss": -81.94486814929593, "actor_target_entropy": -1.0, "actor_entropy": 2.4814895353009625, "alpha_loss": -0.0001363826398324642, "alpha_value": 0.004403997495601085, "duration": 3.839618682861328, "step": 160750}
{"episode_reward": 87.8281247072737, "episode": 1287.0, "batch_reward": 0.8262454581260681, "critic_loss": 2.0622421588897706, "actor_loss": -81.94220782083178, "actor_target_entropy": -1.0, "actor_entropy": 2.4746019272577193, "alpha_loss": 0.00018550019642192176, "alpha_value": 0.0044041935670258575, "duration": 3.8417809009552, "step": 160875}
{"episode_reward": 114.790441986772, "episode": 1288.0, "batch_reward": 0.8125993747711182, "critic_loss": 2.014137429237366, "actor_loss": -81.9302963749055, "actor_target_entropy": -1.0, "actor_entropy": 2.4746585969002015, "alpha_loss": -4.739837177405735e-05, "alpha_value": 0.0044027666102255305, "duration": 3.8398075103759766, "step": 161000}
{"episode_reward": 166.82564861297558, "episode": 1289.0, "batch_reward": 0.8212856869697571, "critic_loss": 1.9895466918945313, "actor_loss": -81.94913870190817, "actor_target_entropy": -1.0, "actor_entropy": 2.4799349345858137, "alpha_loss": -0.00015237347993423187, "alpha_value": 0.00440495994085846, "duration": 3.8418891429901123, "step": 161125}
{"episode_reward": 148.1843443084477, "episode": 1290.0, "batch_reward": 0.8164175634384155, "critic_loss": 1.9899948959350586, "actor_loss": -81.95137836087135, "actor_target_entropy": -1.0, "actor_entropy": 2.479349982353949, "alpha_loss": -3.255193434832167e-05, "alpha_value": 0.004406367888886342, "duration": 3.8323628902435303, "step": 161250}
{"episode_reward": 151.19283918289563, "episode": 1291.0, "batch_reward": 0.8142523980140686, "critic_loss": 2.0177822265625, "actor_loss": -81.94374326675657, "actor_target_entropy": -1.0, "actor_entropy": 2.4736304510207403, "alpha_loss": 0.00011838688528985672, "alpha_value": 0.004405489886107771, "duration": 3.841001510620117, "step": 161375}
{"episode_reward": 138.76192734463072, "episode": 1292.0, "batch_reward": 0.8130045900344849, "critic_loss": 1.984643621444702, "actor_loss": -81.94435845651934, "actor_target_entropy": -1.0, "actor_entropy": 2.4766305800407165, "alpha_loss": 0.0001244715376449148, "alpha_value": 0.004401704354952744, "duration": 3.826561212539673, "step": 161500}
{"episode_reward": 186.16306333886143, "episode": 1293.0, "batch_reward": 0.8236850929260254, "critic_loss": 2.0153301563262938, "actor_loss": -81.95696343315973, "actor_target_entropy": -1.0, "actor_entropy": 2.479354192340185, "alpha_loss": -0.00010544551078632977, "alpha_value": 0.004400783319455376, "duration": 3.8468081951141357, "step": 161625}
{"episode_reward": 184.05339956330198, "episode": 1294.0, "batch_reward": 0.8145813865661621, "critic_loss": 2.0595922899246215, "actor_loss": -81.94799767771075, "actor_target_entropy": -1.0, "actor_entropy": 2.482624961483863, "alpha_loss": -6.876110555528993e-05, "alpha_value": 0.004404405415784364, "duration": 3.836418628692627, "step": 161750}
{"episode_reward": 58.23190734558379, "episode": 1295.0, "batch_reward": 0.8169507408142089, "critic_loss": 1.9456507363319397, "actor_loss": -81.96138763427734, "actor_target_entropy": -1.0, "actor_entropy": 2.5000028156098866, "alpha_loss": -0.00014328576452542273, "alpha_value": 0.004406918117735983, "duration": 3.8323733806610107, "step": 161875}
{"episode_reward": 135.91422721711135, "episode": 1296.0, "batch_reward": 0.8264972743988037, "critic_loss": 2.117570152282715, "actor_loss": -81.96099779682774, "actor_target_entropy": -1.0, "actor_entropy": 2.4997480300164994, "alpha_loss": -0.00029581313332704257, "alpha_value": 0.004410858070133885, "duration": 3.8351285457611084, "step": 162000}
{"episode_reward": 211.57308117659434, "episode": 1297.0, "batch_reward": 0.8094781222343445, "critic_loss": 1.973572434425354, "actor_loss": -81.95347801087395, "actor_target_entropy": -1.0, "actor_entropy": 2.5052192627437533, "alpha_loss": -0.00041222506265584677, "alpha_value": 0.004421131163166286, "duration": 3.8372931480407715, "step": 162125}
{"episode_reward": 168.04186826406757, "episode": 1298.0, "batch_reward": 0.8275413589477539, "critic_loss": 2.0247337350845336, "actor_loss": -81.97859905612084, "actor_target_entropy": -1.0, "actor_entropy": 2.504550333945982, "alpha_loss": -0.00014857902152148346, "alpha_value": 0.004428232246047648, "duration": 3.8370907306671143, "step": 162250}
{"episode_reward": 79.47694318008449, "episode": 1299.0, "batch_reward": 0.8141219096183777, "critic_loss": 1.9547051706314087, "actor_loss": -81.9632086375403, "actor_target_entropy": -1.0, "actor_entropy": 2.4991088594709123, "alpha_loss": -0.00017446518304207111, "alpha_value": 0.004428978858120338, "duration": 3.835735321044922, "step": 162375}
{"episode_reward": 175.09293725411206, "episode": 1300.0, "batch_reward": 0.8258824634552002, "critic_loss": 2.0054351844787597, "actor_loss": -81.98369746054372, "actor_target_entropy": -1.0, "actor_entropy": 2.4981617619914394, "alpha_loss": -0.00019264842335213608, "alpha_value": 0.004435318686596407, "duration": 3.8361284732818604, "step": 162500}
{"episode_reward": 139.83291821308083, "episode": 1301.0, "batch_reward": 0.8370076270103455, "critic_loss": 2.1353491926193238, "actor_loss": -82.00423346625433, "actor_target_entropy": -1.0, "actor_entropy": 2.5105096120682973, "alpha_loss": -5.9854999158738385e-05, "alpha_value": 0.0044377765720406935, "duration": 3.8385965824127197, "step": 162625}
{"episode_reward": 196.08550741762372, "episode": 1302.0, "batch_reward": 0.8220551943778992, "critic_loss": 2.074180235862732, "actor_loss": -81.99879332511655, "actor_target_entropy": -1.0, "actor_entropy": 2.5143238805955455, "alpha_loss": -0.00031242759981861095, "alpha_value": 0.0044446783486754085, "duration": 3.8342270851135254, "step": 162750}
{"episode_reward": 144.93271825362535, "episode": 1303.0, "batch_reward": 0.8176381845474243, "critic_loss": 1.9820573320388795, "actor_loss": -82.00102173335968, "actor_target_entropy": -1.0, "actor_entropy": 2.516391163780576, "alpha_loss": -0.00036640800161486756, "alpha_value": 0.0044524409600664085, "duration": 3.8395779132843018, "step": 162875}
{"episode_reward": 146.02029702087725, "episode": 1304.0, "batch_reward": 0.8280350737571717, "critic_loss": 1.9992070760726928, "actor_loss": -82.01263095486549, "actor_target_entropy": -1.0, "actor_entropy": 2.5127932179358696, "alpha_loss": -0.00044691896407804903, "alpha_value": 0.0044620339396138535, "duration": 3.824634075164795, "step": 163000}
{"episode_reward": 58.45492066722251, "episode": 1305.0, "batch_reward": 0.8362313623428345, "critic_loss": 2.1150391750335693, "actor_loss": -82.03155614459325, "actor_target_entropy": -1.0, "actor_entropy": 2.5090758611285495, "alpha_loss": -0.0001375458413681444, "alpha_value": 0.004467996339638753, "duration": 3.8432741165161133, "step": 163125}
{"episode_reward": 234.16750300430772, "episode": 1306.0, "batch_reward": 0.8138234667778015, "critic_loss": 2.012571657180786, "actor_loss": -82.0189669209142, "actor_target_entropy": -1.0, "actor_entropy": 2.5052604982929845, "alpha_loss": -0.00025456967494157594, "alpha_value": 0.004473651637562718, "duration": 3.836289882659912, "step": 163250}
{"episode_reward": 115.85086927682958, "episode": 1307.0, "batch_reward": 0.8366301565170288, "critic_loss": 2.044841411590576, "actor_loss": -82.05930449470641, "actor_target_entropy": -1.0, "actor_entropy": 2.5096051806495305, "alpha_loss": -0.0005829874523139248, "alpha_value": 0.004483181959849143, "duration": 3.836059808731079, "step": 163375}
{"episode_reward": 169.3645197028195, "episode": 1308.0, "batch_reward": 0.8354848155975342, "critic_loss": 2.0963446683883666, "actor_loss": -82.05679407427388, "actor_target_entropy": -1.0, "actor_entropy": 2.5148605377443376, "alpha_loss": -0.00047857650849525066, "alpha_value": 0.004496473264002039, "duration": 3.8358304500579834, "step": 163500}
{"episode_reward": 179.06917852609382, "episode": 1309.0, "batch_reward": 0.8070302085876465, "critic_loss": 1.951730082511902, "actor_loss": -82.04302736312624, "actor_target_entropy": -1.0, "actor_entropy": 2.5173990461561413, "alpha_loss": -0.0003471877245742473, "alpha_value": 0.004507567763555992, "duration": 3.836456537246704, "step": 163625}
{"episode_reward": 153.99497746515246, "episode": 1310.0, "batch_reward": 0.8171118955612182, "critic_loss": 1.9894588060379028, "actor_loss": -82.056885257844, "actor_target_entropy": -1.0, "actor_entropy": 2.514174892056373, "alpha_loss": -0.00032371634733863175, "alpha_value": 0.004516140925440915, "duration": 3.847377300262451, "step": 163750}
{"episode_reward": 197.7572912907003, "episode": 1311.0, "batch_reward": 0.8486317582130433, "critic_loss": 2.1231682205200197, "actor_loss": -82.09690372527592, "actor_target_entropy": -1.0, "actor_entropy": 2.511657684568375, "alpha_loss": -0.00016629623086561286, "alpha_value": 0.004521304340085965, "duration": 3.8381056785583496, "step": 163875}
{"episode_reward": 134.41056278634838, "episode": 1312.0, "batch_reward": 0.8431511907577515, "critic_loss": 2.0874660692214966, "actor_loss": -82.11435034967238, "actor_target_entropy": -1.0, "actor_entropy": 2.517667078202771, "alpha_loss": -0.0004381563565168049, "alpha_value": 0.0045274774071082735, "duration": 3.8333089351654053, "step": 164000}
{"episode_reward": 177.2887053794173, "episode": 1313.0, "batch_reward": 0.8306511816978455, "critic_loss": 2.1006692123413084, "actor_loss": -82.10849507649739, "actor_target_entropy": -1.0, "actor_entropy": 2.5113045071798656, "alpha_loss": -8.010801014726953e-05, "alpha_value": 0.0045374164153382055, "duration": 3.839308261871338, "step": 164125}
{"episode_reward": 188.05131797428842, "episode": 1314.0, "batch_reward": 0.8258732218742371, "critic_loss": 1.9676411619186402, "actor_loss": -82.118590201101, "actor_target_entropy": -1.0, "actor_entropy": 2.4934784212420062, "alpha_loss": 0.00010173070674476725, "alpha_value": 0.00453671361510472, "duration": 3.8362395763397217, "step": 164250}
{"episode_reward": 155.68777261012238, "episode": 1315.0, "batch_reward": 0.8373707284927369, "critic_loss": 2.07042679977417, "actor_loss": -82.13131968180339, "actor_target_entropy": -1.0, "actor_entropy": 2.475676354907808, "alpha_loss": 0.00028035417060545155, "alpha_value": 0.00453103702577277, "duration": 3.8448917865753174, "step": 164375}
{"episode_reward": 170.17076551359656, "episode": 1316.0, "batch_reward": 0.8220371298789978, "critic_loss": 1.9830530757904052, "actor_loss": -82.14686842887632, "actor_target_entropy": -1.0, "actor_entropy": 2.4794629466149116, "alpha_loss": 0.0001305475192155779, "alpha_value": 0.004525646691814402, "duration": 3.822805881500244, "step": 164500}
{"episode_reward": 221.65182283896812, "episode": 1317.0, "batch_reward": 0.8222084865570068, "critic_loss": 1.9871912975311279, "actor_loss": -82.1323966374473, "actor_target_entropy": -1.0, "actor_entropy": 2.4846402425614613, "alpha_loss": 0.00011919438896704436, "alpha_value": 0.004522807986864952, "duration": 3.8336989879608154, "step": 164625}
{"episode_reward": 209.6204667913385, "episode": 1318.0, "batch_reward": 0.8252498450279235, "critic_loss": 2.0712489042282103, "actor_loss": -82.14971702329574, "actor_target_entropy": -1.0, "actor_entropy": 2.4940005117847073, "alpha_loss": 0.00010733363160397857, "alpha_value": 0.004519588069792035, "duration": 3.8311002254486084, "step": 164750}
{"episode_reward": 100.6086451290852, "episode": 1319.0, "batch_reward": 0.8449258794784545, "critic_loss": 2.1049596366882324, "actor_loss": -82.1842793055943, "actor_target_entropy": -1.0, "actor_entropy": 2.4917963270157104, "alpha_loss": -0.00019341012387211242, "alpha_value": 0.0045197043307464695, "duration": 3.8422138690948486, "step": 164875}
{"episode_reward": 169.52439199608423, "episode": 1320.0, "batch_reward": 0.844020339012146, "critic_loss": 2.1185307464599608, "actor_loss": -82.20245705881426, "actor_target_entropy": -1.0, "actor_entropy": 2.4709754297810216, "alpha_loss": 0.0004751811603425942, "alpha_value": 0.004517839636338965, "duration": 3.8361661434173584, "step": 165000}
{"episode_reward": 169.08089096922592, "episode": 1321.0, "batch_reward": 0.8432027797698974, "critic_loss": 2.0572077894210814, "actor_loss": -82.21375855945405, "actor_target_entropy": -1.0, "actor_entropy": 2.4534129793681796, "alpha_loss": 0.0005237856331939203, "alpha_value": 0.004505968217616898, "duration": 3.8380017280578613, "step": 165125}
{"episode_reward": 199.35427883199603, "episode": 1322.0, "batch_reward": 0.8373139629364014, "critic_loss": 2.0951666164398195, "actor_loss": -82.21581945111674, "actor_target_entropy": -1.0, "actor_entropy": 2.420034316278273, "alpha_loss": 0.0010307556888531713, "alpha_value": 0.0044876200311173035, "duration": 3.832819700241089, "step": 165250}
{"episode_reward": 117.1123356608661, "episode": 1323.0, "batch_reward": 0.8317427639961242, "critic_loss": 2.0268277053833006, "actor_loss": -82.22869485522074, "actor_target_entropy": -1.0, "actor_entropy": 2.3849781278579956, "alpha_loss": 0.0015674403495347454, "alpha_value": 0.004455686614057045, "duration": 3.839944362640381, "step": 165375}
{"episode_reward": 122.54457866508544, "episode": 1324.0, "batch_reward": 0.827488941192627, "critic_loss": 1.9881494388580323, "actor_loss": -82.22900722872826, "actor_target_entropy": -1.0, "actor_entropy": 2.3611286378675893, "alpha_loss": 0.001643316872838524, "alpha_value": 0.00441839227152446, "duration": 3.8390984535217285, "step": 165500}
{"episode_reward": 214.15358761456602, "episode": 1325.0, "batch_reward": 0.8258003916740417, "critic_loss": 1.9762106323242188, "actor_loss": -82.23701997787234, "actor_target_entropy": -1.0, "actor_entropy": 2.3671338066222174, "alpha_loss": 0.0018408209739607714, "alpha_value": 0.004378619744591969, "duration": 3.8448901176452637, "step": 165625}
{"episode_reward": 138.8094180275878, "episode": 1326.0, "batch_reward": 0.8275653185844422, "critic_loss": 2.0595921030044555, "actor_loss": -82.244204736525, "actor_target_entropy": -1.0, "actor_entropy": 2.401344330080094, "alpha_loss": 0.0013625240779571955, "alpha_value": 0.004344913860248123, "duration": 3.833357334136963, "step": 165750}
{"episode_reward": 139.3126966063352, "episode": 1327.0, "batch_reward": 0.8315889501571655, "critic_loss": 2.0940425901412962, "actor_loss": -82.2590105571444, "actor_target_entropy": -1.0, "actor_entropy": 2.4155678976149786, "alpha_loss": 0.0011796263101536573, "alpha_value": 0.004319076938679478, "duration": 3.8380343914031982, "step": 165875}
{"episode_reward": 218.4420165606444, "episode": 1328.0, "batch_reward": 0.8362030076980591, "critic_loss": 2.017065188407898, "actor_loss": -82.28275705152943, "actor_target_entropy": -1.0, "actor_entropy": 2.428082819907896, "alpha_loss": 0.0010835801811246652, "alpha_value": 0.004295858910018462, "duration": 3.832810163497925, "step": 166000}
{"episode_reward": 78.45970778325952, "episode": 1329.0, "batch_reward": 0.8422294735908509, "critic_loss": 2.1785883989334107, "actor_loss": -82.30695427788629, "actor_target_entropy": -1.0, "actor_entropy": 2.448546106853182, "alpha_loss": 0.0007435630846192085, "alpha_value": 0.004276866098023316, "duration": 3.844388961791992, "step": 166125}
{"episode_reward": 76.7362901296301, "episode": 1330.0, "batch_reward": 0.8279231686592102, "critic_loss": 1.9989079542160033, "actor_loss": -82.30165543094758, "actor_target_entropy": -1.0, "actor_entropy": 2.465197040188697, "alpha_loss": 0.00010478746257684824, "alpha_value": 0.004268404522971183, "duration": 3.8281869888305664, "step": 166250}
{"episode_reward": 128.94565113926828, "episode": 1331.0, "batch_reward": 0.83467050075531, "critic_loss": 2.0650075397491454, "actor_loss": -82.3231936257983, "actor_target_entropy": -1.0, "actor_entropy": 2.4710448582967124, "alpha_loss": 0.00028614716956369755, "alpha_value": 0.004265949565743672, "duration": 3.8320248126983643, "step": 166375}
{"episode_reward": 75.15011595837582, "episode": 1332.0, "batch_reward": 0.822866696357727, "critic_loss": 2.0689251527786254, "actor_loss": -82.31583982898343, "actor_target_entropy": -1.0, "actor_entropy": 2.492351178200014, "alpha_loss": 9.337746192731203e-06, "alpha_value": 0.004261855471841082, "duration": 3.8273985385894775, "step": 166500}
{"episode_reward": 153.7445731724152, "episode": 1333.0, "batch_reward": 0.8511953430175782, "critic_loss": 2.1868471164703367, "actor_loss": -82.35926782517205, "actor_target_entropy": -1.0, "actor_entropy": 2.510155511280847, "alpha_loss": -2.1536342544658554e-05, "alpha_value": 0.004260179460736253, "duration": 3.8302700519561768, "step": 166625}
{"episode_reward": 210.56103601725957, "episode": 1334.0, "batch_reward": 0.8280220174789429, "critic_loss": 2.0475902614593506, "actor_loss": -82.35302242155998, "actor_target_entropy": -1.0, "actor_entropy": 2.527289959692186, "alpha_loss": -0.00028897013544337824, "alpha_value": 0.004264682173199777, "duration": 3.83815598487854, "step": 166750}
{"episode_reward": 231.39137670845213, "episode": 1335.0, "batch_reward": 0.8255903682708741, "critic_loss": 2.0759403886795043, "actor_loss": -82.36399913969494, "actor_target_entropy": -1.0, "actor_entropy": 2.5335963264344232, "alpha_loss": -0.0005878791333608595, "alpha_value": 0.004274182275760976, "duration": 3.83758544921875, "step": 166875}
{"episode_reward": 112.36398938808166, "episode": 1336.0, "batch_reward": 0.8452570090293884, "critic_loss": 2.194793523788452, "actor_loss": -82.39314085437405, "actor_target_entropy": -1.0, "actor_entropy": 2.5240197489338536, "alpha_loss": -0.000317483143589925, "alpha_value": 0.0042848402075266875, "duration": 3.8381917476654053, "step": 167000}
{"episode_reward": 136.82642915768335, "episode": 1337.0, "batch_reward": 0.8286119527816772, "critic_loss": 2.104444264411926, "actor_loss": -82.37947506374783, "actor_target_entropy": -1.0, "actor_entropy": 2.5114860383291093, "alpha_loss": -0.0004158259154849922, "alpha_value": 0.004291576765975526, "duration": 3.839444160461426, "step": 167125}
{"episode_reward": 162.6023970732096, "episode": 1338.0, "batch_reward": 0.837675434589386, "critic_loss": 2.056173396110535, "actor_loss": -82.41121525918284, "actor_target_entropy": -1.0, "actor_entropy": 2.5014495080517185, "alpha_loss": 0.00011395762961793451, "alpha_value": 0.004296325608181159, "duration": 3.8336305618286133, "step": 167250}
{"episode_reward": 123.70170526016165, "episode": 1339.0, "batch_reward": 0.839342182636261, "critic_loss": 2.0185951175689696, "actor_loss": -82.43448772127667, "actor_target_entropy": -1.0, "actor_entropy": 2.500730272323366, "alpha_loss": -0.0003092536538292373, "alpha_value": 0.004297904154072034, "duration": 3.8425040245056152, "step": 167375}
{"episode_reward": 64.71737842014731, "episode": 1340.0, "batch_reward": 0.8420946187973023, "critic_loss": 2.0880209646224976, "actor_loss": -82.45787675919071, "actor_target_entropy": -1.0, "actor_entropy": 2.4923513166366087, "alpha_loss": 2.273900792070274e-05, "alpha_value": 0.004303194132297344, "duration": 3.831387519836426, "step": 167500}
{"episode_reward": 112.06449369332978, "episode": 1341.0, "batch_reward": 0.8413278427124024, "critic_loss": 2.116642002105713, "actor_loss": -82.46683090452164, "actor_target_entropy": -1.0, "actor_entropy": 2.4887493375747924, "alpha_loss": 0.0001484207142124115, "alpha_value": 0.004297826676358119, "duration": 3.8431408405303955, "step": 167625}
{"episode_reward": 101.59598699093257, "episode": 1342.0, "batch_reward": 0.847027843952179, "critic_loss": 2.1384429273605345, "actor_loss": -82.48938418972877, "actor_target_entropy": -1.0, "actor_entropy": 2.4932482473311888, "alpha_loss": -5.316751729321456e-05, "alpha_value": 0.004297108141062606, "duration": 3.836357355117798, "step": 167750}
{"episode_reward": 142.8981887441268, "episode": 1343.0, "batch_reward": 0.835559353351593, "critic_loss": 2.131420676231384, "actor_loss": -82.49490368555463, "actor_target_entropy": -1.0, "actor_entropy": 2.4824324713812933, "alpha_loss": 5.526389993195023e-05, "alpha_value": 0.004298705803752059, "duration": 3.840993881225586, "step": 167875}
{"episode_reward": 156.7699536184548, "episode": 1344.0, "batch_reward": 0.8316723713874817, "critic_loss": 2.0654870052337646, "actor_loss": -82.49675135458669, "actor_target_entropy": -1.0, "actor_entropy": 2.4776408287786666, "alpha_loss": 0.00021599124198884613, "alpha_value": 0.004295262488262822, "duration": 3.84070086479187, "step": 168000}
{"episode_reward": 92.30668989200868, "episode": 1345.0, "batch_reward": 0.8302694172859192, "critic_loss": 2.0626000843048096, "actor_loss": -82.5117671906002, "actor_target_entropy": -1.0, "actor_entropy": 2.485174133664086, "alpha_loss": 0.000178699731588408, "alpha_value": 0.004289877162544942, "duration": 3.8385117053985596, "step": 168125}
{"episode_reward": 103.65901699053333, "episode": 1346.0, "batch_reward": 0.8366307854652405, "critic_loss": 2.121980376243591, "actor_loss": -82.53603153844034, "actor_target_entropy": -1.0, "actor_entropy": 2.4928717459401777, "alpha_loss": 0.00024294337650175175, "alpha_value": 0.004284340712888299, "duration": 3.8362600803375244, "step": 168250}
{"episode_reward": 194.1787707581341, "episode": 1347.0, "batch_reward": 0.8390550951957703, "critic_loss": 2.1444294805526734, "actor_loss": -82.55430942111545, "actor_target_entropy": -1.0, "actor_entropy": 2.492876128544883, "alpha_loss": 0.00028710304191225164, "alpha_value": 0.0042803568680003816, "duration": 3.8421432971954346, "step": 168375}
{"episode_reward": 141.8248739445679, "episode": 1348.0, "batch_reward": 0.8438950204849243, "critic_loss": 2.1242856149673464, "actor_loss": -82.57330740651777, "actor_target_entropy": -1.0, "actor_entropy": 2.4952374889004614, "alpha_loss": 7.870717015447877e-05, "alpha_value": 0.0042755267390036395, "duration": 3.8349432945251465, "step": 168500}
{"episode_reward": 113.61427145460624, "episode": 1349.0, "batch_reward": 0.8285250320434571, "critic_loss": 2.081537875175476, "actor_loss": -82.5653584798177, "actor_target_entropy": -1.0, "actor_entropy": 2.4872826621645974, "alpha_loss": 1.2134357276076953e-05, "alpha_value": 0.004273452163215312, "duration": 3.8417117595672607, "step": 168625}
{"episode_reward": 204.14212723113093, "episode": 1350.0, "batch_reward": 0.8452637662887573, "critic_loss": 2.1171857624053954, "actor_loss": -82.59686648461127, "actor_target_entropy": -1.0, "actor_entropy": 2.47279114877024, "alpha_loss": 0.0004369503874312936, "alpha_value": 0.004267853004583933, "duration": 3.8356950283050537, "step": 168750}
{"episode_reward": 161.55087987100492, "episode": 1351.0, "batch_reward": 0.8356373605728149, "critic_loss": 2.143834623336792, "actor_loss": -82.60930464002821, "actor_target_entropy": -1.0, "actor_entropy": 2.4642531077067056, "alpha_loss": 0.0005604506749521187, "alpha_value": 0.0042570577023199885, "duration": 3.84401273727417, "step": 168875}
{"episode_reward": 77.0104571036559, "episode": 1352.0, "batch_reward": 0.8433082494735717, "critic_loss": 2.082117042541504, "actor_loss": -82.63764572143555, "actor_target_entropy": -1.0, "actor_entropy": 2.455655851671773, "alpha_loss": 0.0006377611054866124, "alpha_value": 0.0042433443784023256, "duration": 3.836972951889038, "step": 169000}
{"episode_reward": 173.2169670340067, "episode": 1353.0, "batch_reward": 0.847462679386139, "critic_loss": 2.1359715433120727, "actor_loss": -82.65032583569723, "actor_target_entropy": -1.0, "actor_entropy": 2.432238730173262, "alpha_loss": 0.0007617729060011842, "alpha_value": 0.004225117561908451, "duration": 3.84017276763916, "step": 169125}
{"episode_reward": 166.91649403421755, "episode": 1354.0, "batch_reward": 0.8575317611694336, "critic_loss": 2.193896746635437, "actor_loss": -82.67456669961253, "actor_target_entropy": -1.0, "actor_entropy": 2.4124657569393033, "alpha_loss": 0.0011922189495958118, "alpha_value": 0.004202342096033605, "duration": 3.8344452381134033, "step": 169250}
{"episode_reward": 229.76480312021891, "episode": 1355.0, "batch_reward": 0.8402015066146851, "critic_loss": 2.1052654695510866, "actor_loss": -82.68018001980252, "actor_target_entropy": -1.0, "actor_entropy": 2.383468749031188, "alpha_loss": 0.001572418198939265, "alpha_value": 0.004170704235796386, "duration": 3.834928512573242, "step": 169375}
{"episode_reward": 159.63672848623855, "episode": 1356.0, "batch_reward": 0.8491574311256409, "critic_loss": 2.167038384437561, "actor_loss": -82.70389138498614, "actor_target_entropy": -1.0, "actor_entropy": 2.400362968444824, "alpha_loss": 0.0013358609129124576, "alpha_value": 0.004137440846062118, "duration": 3.840550422668457, "step": 169500}
{"episode_reward": 142.52454213876845, "episode": 1357.0, "batch_reward": 0.8342146406173706, "critic_loss": 2.0526341648101805, "actor_loss": -82.71142008947947, "actor_target_entropy": -1.0, "actor_entropy": 2.434478517562624, "alpha_loss": 0.0008087819998821481, "alpha_value": 0.004114658590230848, "duration": 3.8379361629486084, "step": 169625}
{"episode_reward": 199.24425912263908, "episode": 1358.0, "batch_reward": 0.840492582321167, "critic_loss": 2.0381399221420287, "actor_loss": -82.72699466828377, "actor_target_entropy": -1.0, "actor_entropy": 2.4355000526674333, "alpha_loss": 0.0008633992331470513, "alpha_value": 0.004098922419653472, "duration": 3.8370485305786133, "step": 169750}
{"episode_reward": 127.27236331079496, "episode": 1359.0, "batch_reward": 0.8378100867271423, "critic_loss": 2.1098085575103758, "actor_loss": -82.73689814976284, "actor_target_entropy": -1.0, "actor_entropy": 2.4367398458813865, "alpha_loss": 0.0007127450147573467, "alpha_value": 0.004082044807707522, "duration": 3.8369157314300537, "step": 169875}
{"episode_reward": 226.15233765995453, "episode": 1360.0, "batch_reward": 0.8410907225608826, "critic_loss": 2.0597948274612428, "actor_loss": -82.76691030686901, "actor_target_entropy": -1.0, "actor_entropy": 2.433598733717395, "alpha_loss": 0.0007459250261871925, "alpha_value": 0.00406495680102752, "duration": 3.8364076614379883, "step": 170000}
{"episode_reward": 186.34340606213246, "episode": 1361.0, "batch_reward": 0.8328781757354736, "critic_loss": 2.0400829877853393, "actor_loss": -82.7574453202505, "actor_target_entropy": -1.0, "actor_entropy": 2.45748047601609, "alpha_loss": 0.0005147084604167114, "alpha_value": 0.00404982752378233, "duration": 7.816482782363892, "step": 170125}
{"episode_reward": 245.75798779566458, "episode": 1362.0, "batch_reward": 0.842742380619049, "critic_loss": 2.148711046218872, "actor_loss": -82.78502962666172, "actor_target_entropy": -1.0, "actor_entropy": 2.4908597392420613, "alpha_loss": -0.00020799396189695766, "alpha_value": 0.004047478483910001, "duration": 3.837883949279785, "step": 170250}
{"episode_reward": 202.1030980214445, "episode": 1363.0, "batch_reward": 0.8463203358650208, "critic_loss": 2.1582206621170044, "actor_loss": -82.80764915829613, "actor_target_entropy": -1.0, "actor_entropy": 2.505063359699552, "alpha_loss": -5.6200393287110185e-05, "alpha_value": 0.004050507726382011, "duration": 3.8342909812927246, "step": 170375}
{"episode_reward": 137.13713559392488, "episode": 1364.0, "batch_reward": 0.850719464302063, "critic_loss": 2.0854600591659547, "actor_loss": -82.83969337709489, "actor_target_entropy": -1.0, "actor_entropy": 2.5132202333019626, "alpha_loss": -0.0001985109915802886, "alpha_value": 0.004053649298263745, "duration": 3.838996648788452, "step": 170500}
{"episode_reward": 256.84096589381494, "episode": 1365.0, "batch_reward": 0.8298615736961364, "critic_loss": 2.0052311334609985, "actor_loss": -82.82833159915985, "actor_target_entropy": -1.0, "actor_entropy": 2.495644690498473, "alpha_loss": -1.8472539118698074e-05, "alpha_value": 0.004056719957698467, "duration": 3.83614182472229, "step": 170625}
{"episode_reward": 215.57644955953705, "episode": 1366.0, "batch_reward": 0.8493216309547424, "critic_loss": 2.1612014083862303, "actor_loss": -82.86359073269752, "actor_target_entropy": -1.0, "actor_entropy": 2.4906769567920315, "alpha_loss": 0.00017192677290539348, "alpha_value": 0.004055775415963004, "duration": 3.83267879486084, "step": 170750}
{"episode_reward": 118.45070346628547, "episode": 1367.0, "batch_reward": 0.8533356652259827, "critic_loss": 2.1159269914627075, "actor_loss": -82.89319574265252, "actor_target_entropy": -1.0, "actor_entropy": 2.4798753072345066, "alpha_loss": 0.00021884037506958795, "alpha_value": 0.004051058209458651, "duration": 3.8436899185180664, "step": 170875}
{"episode_reward": 185.32964097978362, "episode": 1368.0, "batch_reward": 0.8551104254722596, "critic_loss": 2.1526101760864256, "actor_loss": -82.91694690335181, "actor_target_entropy": -1.0, "actor_entropy": 2.464267638421828, "alpha_loss": 0.000500369118526578, "alpha_value": 0.004042651835392882, "duration": 3.82883358001709, "step": 171000}
{"episode_reward": 119.80445718340341, "episode": 1369.0, "batch_reward": 0.8399304814338684, "critic_loss": 2.088730474472046, "actor_loss": -82.9242206149631, "actor_target_entropy": -1.0, "actor_entropy": 2.4436673663911366, "alpha_loss": 0.0006831528879711331, "alpha_value": 0.004028133297789471, "duration": 3.842374563217163, "step": 171125}
{"episode_reward": 103.17689688483523, "episode": 1370.0, "batch_reward": 0.8238154406547546, "critic_loss": 2.0825602169036865, "actor_loss": -82.92135152509135, "actor_target_entropy": -1.0, "actor_entropy": 2.4330689214891, "alpha_loss": 0.0007921540913699691, "alpha_value": 0.004013531846055214, "duration": 3.8360652923583984, "step": 171250}
{"episode_reward": 153.0145729266951, "episode": 1371.0, "batch_reward": 0.8360104660987854, "critic_loss": 2.1030532245635984, "actor_loss": -82.93425883944073, "actor_target_entropy": -1.0, "actor_entropy": 2.4356259694175115, "alpha_loss": 0.0005511771012116076, "alpha_value": 0.003998500096428156, "duration": 3.839592218399048, "step": 171375}
{"episode_reward": 256.07655887277815, "episode": 1372.0, "batch_reward": 0.8483434567451477, "critic_loss": 2.1885510902404786, "actor_loss": -82.9535280043079, "actor_target_entropy": -1.0, "actor_entropy": 2.431037441376717, "alpha_loss": 0.0007226747073864024, "alpha_value": 0.003982660388135617, "duration": 3.836176633834839, "step": 171500}
{"episode_reward": 169.2674062149987, "episode": 1373.0, "batch_reward": 0.8429194922447205, "critic_loss": 2.1171335926055908, "actor_loss": -82.9840812077598, "actor_target_entropy": -1.0, "actor_entropy": 2.436104971265036, "alpha_loss": 0.0005523932093868978, "alpha_value": 0.003969333764683543, "duration": 3.8364620208740234, "step": 171625}
{"episode_reward": 156.68718935036682, "episode": 1374.0, "batch_reward": 0.8391782660484314, "critic_loss": 2.130380884170532, "actor_loss": -82.99632952290196, "actor_target_entropy": -1.0, "actor_entropy": 2.4347690920675955, "alpha_loss": 0.0005289960225185965, "alpha_value": 0.003957946675914214, "duration": 3.8399465084075928, "step": 171750}
{"episode_reward": 202.0427240464331, "episode": 1375.0, "batch_reward": 0.8389633026123047, "critic_loss": 2.154274537086487, "actor_loss": -83.00482964894128, "actor_target_entropy": -1.0, "actor_entropy": 2.4463989923870755, "alpha_loss": 0.0004039064258991164, "alpha_value": 0.003947317150343115, "duration": 3.8377716541290283, "step": 171875}
{"episode_reward": 179.59029931813055, "episode": 1376.0, "batch_reward": 0.85242453956604, "critic_loss": 2.139487675666809, "actor_loss": -83.03896270259735, "actor_target_entropy": -1.0, "actor_entropy": 2.438424418049474, "alpha_loss": 0.0006845270108897239, "alpha_value": 0.003935459451965261, "duration": 3.8402464389801025, "step": 172000}
{"episode_reward": 177.10105546440522, "episode": 1377.0, "batch_reward": 0.8508001103401184, "critic_loss": 2.162285387992859, "actor_loss": -83.05727350144159, "actor_target_entropy": -1.0, "actor_entropy": 2.443697656903948, "alpha_loss": 0.0005422535459584896, "alpha_value": 0.003920648532009732, "duration": 3.841015338897705, "step": 172125}
{"episode_reward": 49.89972184483209, "episode": 1378.0, "batch_reward": 0.8392352595329284, "critic_loss": 2.0655600481033325, "actor_loss": -83.06692812519688, "actor_target_entropy": -1.0, "actor_entropy": 2.4650050747779106, "alpha_loss": 0.000137853046790922, "alpha_value": 0.003912295852184591, "duration": 3.841519832611084, "step": 172250}
{"episode_reward": 168.30465491438306, "episode": 1379.0, "batch_reward": 0.8455667009353638, "critic_loss": 2.09642262172699, "actor_loss": -83.0843763805571, "actor_target_entropy": -1.0, "actor_entropy": 2.4745576949346635, "alpha_loss": 6.552198176486565e-05, "alpha_value": 0.003911989502932222, "duration": 3.842677116394043, "step": 172375}
{"episode_reward": 171.42833823114907, "episode": 1380.0, "batch_reward": 0.8541810836791992, "critic_loss": 2.0834238052368166, "actor_loss": -83.12007214946132, "actor_target_entropy": -1.0, "actor_entropy": 2.4770361684983775, "alpha_loss": 0.00010116874886256071, "alpha_value": 0.003908592040531421, "duration": 3.832810401916504, "step": 172500}
{"episode_reward": 116.34168927033828, "episode": 1381.0, "batch_reward": 0.8678538665771485, "critic_loss": 2.1872697353363035, "actor_loss": -83.17094469827319, "actor_target_entropy": -1.0, "actor_entropy": 2.465567286052401, "alpha_loss": 0.00036670656164272854, "alpha_value": 0.0039046529202217653, "duration": 3.8388216495513916, "step": 172625}
{"episode_reward": 54.18077237034455, "episode": 1382.0, "batch_reward": 0.8525921487808228, "critic_loss": 2.128405966758728, "actor_loss": -83.17995834350586, "actor_target_entropy": -1.0, "actor_entropy": 2.439545939045568, "alpha_loss": 0.0004474021484530831, "alpha_value": 0.00389343682508725, "duration": 3.834009885787964, "step": 172750}
{"episode_reward": 45.07483075940743, "episode": 1383.0, "batch_reward": 0.8506859073638916, "critic_loss": 2.1923443489074708, "actor_loss": -83.19119517008464, "actor_target_entropy": -1.0, "actor_entropy": 2.425802155146523, "alpha_loss": 0.0004855717001884754, "alpha_value": 0.0038833770300998145, "duration": 3.8393898010253906, "step": 172875}
{"episode_reward": 195.26091573694265, "episode": 1384.0, "batch_reward": 0.8512590713500977, "critic_loss": 2.121663426399231, "actor_loss": -83.22563257525044, "actor_target_entropy": -1.0, "actor_entropy": 2.4355302164631505, "alpha_loss": 0.00040299428468232133, "alpha_value": 0.0038722344713236507, "duration": 3.8372342586517334, "step": 173000}
{"episode_reward": 137.70466231967308, "episode": 1385.0, "batch_reward": 0.8419070472717285, "critic_loss": 2.0900487756729125, "actor_loss": -83.21785760304284, "actor_target_entropy": -1.0, "actor_entropy": 2.440103182716975, "alpha_loss": 0.0005284379440126941, "alpha_value": 0.0038620749578700026, "duration": 3.840193748474121, "step": 173125}
{"episode_reward": 150.3950281718722, "episode": 1386.0, "batch_reward": 0.8493521718978881, "critic_loss": 2.145423860549927, "actor_loss": -83.2577250080724, "actor_target_entropy": -1.0, "actor_entropy": 2.434505139627764, "alpha_loss": 0.00032568468140520816, "alpha_value": 0.0038527803462279787, "duration": 3.8379130363464355, "step": 173250}
{"episode_reward": 187.6650245983204, "episode": 1387.0, "batch_reward": 0.8539066219329834, "critic_loss": 2.089573468208313, "actor_loss": -83.2776848929269, "actor_target_entropy": -1.0, "actor_entropy": 2.4092404501778737, "alpha_loss": 0.0005250938524517955, "alpha_value": 0.0038421541130225175, "duration": 3.839247941970825, "step": 173375}
{"episode_reward": 182.45084063723166, "episode": 1388.0, "batch_reward": 0.8723237166404724, "critic_loss": 2.2663992080688478, "actor_loss": -83.32682701849168, "actor_target_entropy": -1.0, "actor_entropy": 2.3996623100772982, "alpha_loss": 0.0009203049109689141, "alpha_value": 0.00382541539792266, "duration": 3.8438780307769775, "step": 173500}
{"episode_reward": 141.20600970830571, "episode": 1389.0, "batch_reward": 0.8455992755889893, "critic_loss": 2.155640226364136, "actor_loss": -83.32173108297681, "actor_target_entropy": -1.0, "actor_entropy": 2.387105169750395, "alpha_loss": 0.0008018377984482203, "alpha_value": 0.003805067572873227, "duration": 3.8364148139953613, "step": 173625}
{"episode_reward": 126.82322863344184, "episode": 1390.0, "batch_reward": 0.8532704763412475, "critic_loss": 2.1674584674835207, "actor_loss": -83.34251145393618, "actor_target_entropy": -1.0, "actor_entropy": 2.3867609885431107, "alpha_loss": 0.0008315465848652586, "alpha_value": 0.003786307132209682, "duration": 3.8293635845184326, "step": 173750}
{"episode_reward": 113.81158244180072, "episode": 1391.0, "batch_reward": 0.8435599937438965, "critic_loss": 2.097638913154602, "actor_loss": -83.34117138574994, "actor_target_entropy": -1.0, "actor_entropy": 2.3965164668976313, "alpha_loss": 0.0008648914323809246, "alpha_value": 0.003767155519713368, "duration": 3.841470718383789, "step": 173875}
{"episode_reward": 185.27545489145086, "episode": 1392.0, "batch_reward": 0.8471097531318664, "critic_loss": 2.2269479665756227, "actor_loss": -83.37950872605846, "actor_target_entropy": -1.0, "actor_entropy": 2.3928851619843514, "alpha_loss": 0.0009110172590402315, "alpha_value": 0.003748112037724665, "duration": 3.8318119049072266, "step": 174000}
{"episode_reward": 119.95573387118183, "episode": 1393.0, "batch_reward": 0.8514236721992493, "critic_loss": 2.158165337562561, "actor_loss": -83.39549279591394, "actor_target_entropy": -1.0, "actor_entropy": 2.3938269388108027, "alpha_loss": 0.0006236928489266171, "alpha_value": 0.0037299737075527457, "duration": 3.8418374061584473, "step": 174125}
{"episode_reward": 60.807179162295455, "episode": 1394.0, "batch_reward": 0.8533596200942993, "critic_loss": 2.1671966381073, "actor_loss": -83.41488856654013, "actor_target_entropy": -1.0, "actor_entropy": 2.400881936473231, "alpha_loss": 0.0007237348202784967, "alpha_value": 0.003716710936695438, "duration": 3.831977367401123, "step": 174250}
{"episode_reward": 198.6814190730119, "episode": 1395.0, "batch_reward": 0.8565975112915039, "critic_loss": 2.1849466285705565, "actor_loss": -83.4396213349842, "actor_target_entropy": -1.0, "actor_entropy": 2.4038930469089084, "alpha_loss": 0.0006827714911658347, "alpha_value": 0.003700061673525204, "duration": 3.8393747806549072, "step": 174375}
{"episode_reward": 168.4641632489497, "episode": 1396.0, "batch_reward": 0.8440659756660461, "critic_loss": 2.130210163116455, "actor_loss": -83.46162057692005, "actor_target_entropy": -1.0, "actor_entropy": 2.3873586039389334, "alpha_loss": 0.000831988288067101, "alpha_value": 0.0036836263235076874, "duration": 3.8376004695892334, "step": 174500}
{"episode_reward": 40.015664278314965, "episode": 1397.0, "batch_reward": 0.8499986958503724, "critic_loss": 2.140045214653015, "actor_loss": -83.46639941987537, "actor_target_entropy": -1.0, "actor_entropy": 2.376779874165853, "alpha_loss": 0.0007872033561903259, "alpha_value": 0.0036659238550591404, "duration": 3.842968702316284, "step": 174625}
{"episode_reward": 148.0746320867866, "episode": 1398.0, "batch_reward": 0.8647939114570617, "critic_loss": 2.1989927501678466, "actor_loss": -83.51489282423451, "actor_target_entropy": -1.0, "actor_entropy": 2.3898895171380814, "alpha_loss": 0.0007950872615413485, "alpha_value": 0.0036489994384259804, "duration": 3.837108612060547, "step": 174750}
{"episode_reward": 206.5035690283534, "episode": 1399.0, "batch_reward": 0.8598261680603028, "critic_loss": 2.179331029891968, "actor_loss": -83.53780595083086, "actor_target_entropy": -1.0, "actor_entropy": 2.3803978874569847, "alpha_loss": 0.0008459350205994847, "alpha_value": 0.003631656953550034, "duration": 3.8315181732177734, "step": 174875}
{"episode_reward": 163.1156808969527, "episode": 1400.0, "batch_reward": 0.8524082412719727, "critic_loss": 2.1522880630493164, "actor_loss": -83.54210982784149, "actor_target_entropy": -1.0, "actor_entropy": 2.385778873197494, "alpha_loss": 0.0006518303548106023, "alpha_value": 0.003616361795354705, "duration": 3.8412234783172607, "step": 175000}
{"episode_reward": 117.28358058290605, "episode": 1401.0, "batch_reward": 0.8546635222434997, "critic_loss": 2.232860107421875, "actor_loss": -83.57531399197049, "actor_target_entropy": -1.0, "actor_entropy": 2.393956865583147, "alpha_loss": 0.0007350359641898808, "alpha_value": 0.0036004091258185888, "duration": 3.844813108444214, "step": 175125}
{"episode_reward": 128.43290563499824, "episode": 1402.0, "batch_reward": 0.8433127646446228, "critic_loss": 2.1326489515304567, "actor_loss": -83.57502992691532, "actor_target_entropy": -1.0, "actor_entropy": 2.3844502356744584, "alpha_loss": 0.0005729801717191754, "alpha_value": 0.003587982756306504, "duration": 3.8367631435394287, "step": 175250}
{"episode_reward": 121.522207584504, "episode": 1403.0, "batch_reward": 0.853963960647583, "critic_loss": 2.179990964889526, "actor_loss": -83.60538894411117, "actor_target_entropy": -1.0, "actor_entropy": 2.384280038258386, "alpha_loss": 0.0009530494312962724, "alpha_value": 0.003571368227490596, "duration": 3.8430120944976807, "step": 175375}
{"episode_reward": 127.63188488589424, "episode": 1404.0, "batch_reward": 0.8452012891769409, "critic_loss": 2.0890984020233154, "actor_loss": -83.6198616027832, "actor_target_entropy": -1.0, "actor_entropy": 2.3804599700435514, "alpha_loss": 0.0007638627425729928, "alpha_value": 0.0035542418188410875, "duration": 3.8360440731048584, "step": 175500}
{"episode_reward": 138.8517014238032, "episode": 1405.0, "batch_reward": 0.8507984409332275, "critic_loss": 2.125196401596069, "actor_loss": -83.65032958984375, "actor_target_entropy": -1.0, "actor_entropy": 2.3816002134292846, "alpha_loss": 0.0007132094646554574, "alpha_value": 0.0035380862435801033, "duration": 3.8429784774780273, "step": 175625}
{"episode_reward": 175.38622383593145, "episode": 1406.0, "batch_reward": 0.8549203815460205, "critic_loss": 2.152515167236328, "actor_loss": -83.67619975920647, "actor_target_entropy": -1.0, "actor_entropy": 2.37436185344573, "alpha_loss": 0.0006285844227081284, "alpha_value": 0.0035248015015402158, "duration": 3.8317301273345947, "step": 175750}
{"episode_reward": 171.9328410897546, "episode": 1407.0, "batch_reward": 0.8614702854156494, "critic_loss": 2.1500235748291017, "actor_loss": -83.70262448749845, "actor_target_entropy": -1.0, "actor_entropy": 2.371131912110344, "alpha_loss": 0.0006413396543985795, "alpha_value": 0.0035128452846891834, "duration": 3.842628002166748, "step": 175875}
{"episode_reward": 65.5444917185267, "episode": 1408.0, "batch_reward": 0.8442115979194641, "critic_loss": 2.182814531326294, "actor_loss": -83.69749770625945, "actor_target_entropy": -1.0, "actor_entropy": 2.372584988993983, "alpha_loss": 0.0005222163687698588, "alpha_value": 0.003499179718962119, "duration": 3.83697772026062, "step": 176000}
{"episode_reward": 121.23809977979039, "episode": 1409.0, "batch_reward": 0.8508039569854736, "critic_loss": 2.1071740970611574, "actor_loss": -83.72661469474671, "actor_target_entropy": -1.0, "actor_entropy": 2.361847090342688, "alpha_loss": 0.0006218565106373428, "alpha_value": 0.0034895724046263175, "duration": 3.8363468647003174, "step": 176125}
{"episode_reward": 75.64290333972136, "episode": 1410.0, "batch_reward": 0.8469709553718567, "critic_loss": 2.1240035858154296, "actor_loss": -83.73754206011373, "actor_target_entropy": -1.0, "actor_entropy": 2.3648591349201817, "alpha_loss": 0.0007819346209280118, "alpha_value": 0.003473949023342335, "duration": 3.8364384174346924, "step": 176250}
{"episode_reward": 148.3282934069768, "episode": 1411.0, "batch_reward": 0.8428407773971558, "critic_loss": 2.19648934841156, "actor_loss": -83.74136776394315, "actor_target_entropy": -1.0, "actor_entropy": 2.353449443029979, "alpha_loss": 0.0008621003403927066, "alpha_value": 0.003456784655708081, "duration": 3.839099884033203, "step": 176375}
{"episode_reward": 156.41379549284835, "episode": 1412.0, "batch_reward": 0.8488683581352234, "critic_loss": 2.1741775703430175, "actor_loss": -83.76978142030778, "actor_target_entropy": -1.0, "actor_entropy": 2.3569423614009732, "alpha_loss": 0.0007458523677703324, "alpha_value": 0.0034396073384912766, "duration": 3.829138994216919, "step": 176500}
{"episode_reward": 116.58580666684962, "episode": 1413.0, "batch_reward": 0.8684279327392578, "critic_loss": 2.2606126680374143, "actor_loss": -83.8030052790566, "actor_target_entropy": -1.0, "actor_entropy": 2.3507219496227445, "alpha_loss": 0.0007009645683750037, "alpha_value": 0.0034249592606848075, "duration": 3.8393490314483643, "step": 176625}
{"episode_reward": 38.327433689812906, "episode": 1414.0, "batch_reward": 0.8615248999595642, "critic_loss": 2.1768999757766725, "actor_loss": -83.8160049684586, "actor_target_entropy": -1.0, "actor_entropy": 2.3481165978216354, "alpha_loss": 0.0007188877960640727, "alpha_value": 0.0034119551154051676, "duration": 3.8343570232391357, "step": 176750}
{"episode_reward": 201.9596516991458, "episode": 1415.0, "batch_reward": 0.8676455912590026, "critic_loss": 2.2326875047683714, "actor_loss": -83.86442178393168, "actor_target_entropy": -1.0, "actor_entropy": 2.345668156941732, "alpha_loss": 0.0008795994865414243, "alpha_value": 0.0033954651388661272, "duration": 3.841776132583618, "step": 176875}
{"episode_reward": 112.19116808055107, "episode": 1416.0, "batch_reward": 0.8514330348968506, "critic_loss": 2.202372972488403, "actor_loss": -83.86046452676096, "actor_target_entropy": -1.0, "actor_entropy": 2.341793998595207, "alpha_loss": 0.0007134801229356878, "alpha_value": 0.003379430807198316, "duration": 3.8349609375, "step": 177000}
{"episode_reward": 200.10382461746042, "episode": 1417.0, "batch_reward": 0.8396091418266296, "critic_loss": 2.1033411407470703, "actor_loss": -83.86420452783979, "actor_target_entropy": -1.0, "actor_entropy": 2.355562936692011, "alpha_loss": 0.0006854570145526576, "alpha_value": 0.0033651854874460125, "duration": 3.8437626361846924, "step": 177125}
{"episode_reward": 153.0868743086333, "episode": 1418.0, "batch_reward": 0.8544903597831726, "critic_loss": 2.1905382299423217, "actor_loss": -83.89809097782258, "actor_target_entropy": -1.0, "actor_entropy": 2.3518333435058594, "alpha_loss": 0.0006735913447036798, "alpha_value": 0.0033508271618432075, "duration": 3.833766222000122, "step": 177250}
{"episode_reward": 212.9831635530427, "episode": 1419.0, "batch_reward": 0.8695273580551147, "critic_loss": 2.239966452598572, "actor_loss": -83.93404860723587, "actor_target_entropy": -1.0, "actor_entropy": 2.349130252050975, "alpha_loss": 0.0007182984126201416, "alpha_value": 0.003337649973616081, "duration": 3.837869644165039, "step": 177375}
{"episode_reward": 185.66421887498814, "episode": 1420.0, "batch_reward": 0.8630476474761963, "critic_loss": 2.185477436065674, "actor_loss": -83.97198892408802, "actor_target_entropy": -1.0, "actor_entropy": 2.3407819655633744, "alpha_loss": 0.0007043254079161993, "alpha_value": 0.0033233329137349233, "duration": 3.8411178588867188, "step": 177500}
{"episode_reward": 236.0913928767033, "episode": 1421.0, "batch_reward": 0.8619851055145263, "critic_loss": 2.1851794633865356, "actor_loss": -83.98992786710224, "actor_target_entropy": -1.0, "actor_entropy": 2.327013379051572, "alpha_loss": 0.0008650903734618738, "alpha_value": 0.0033077655961773933, "duration": 3.840341091156006, "step": 177625}
{"episode_reward": 71.32326149072782, "episode": 1422.0, "batch_reward": 0.8582469644546509, "critic_loss": 2.1957238836288453, "actor_loss": -84.01845415176884, "actor_target_entropy": -1.0, "actor_entropy": 2.33048185225456, "alpha_loss": 0.0006694517714711237, "alpha_value": 0.003292365370674107, "duration": 3.8390390872955322, "step": 177750}
{"episode_reward": 109.09839422454249, "episode": 1423.0, "batch_reward": 0.8569881520271301, "critic_loss": 2.135713746070862, "actor_loss": -84.04776848687067, "actor_target_entropy": -1.0, "actor_entropy": 2.3298133668445407, "alpha_loss": 0.0005673116070933507, "alpha_value": 0.003280001195838393, "duration": 3.8401691913604736, "step": 177875}
{"episode_reward": 150.32481829668905, "episode": 1424.0, "batch_reward": 0.8539767546653747, "critic_loss": 2.190766111373901, "actor_loss": -84.05566701581401, "actor_target_entropy": -1.0, "actor_entropy": 2.3228920813529723, "alpha_loss": 0.0008154552714615654, "alpha_value": 0.003266122369451517, "duration": 3.840928792953491, "step": 178000}
{"episode_reward": 183.230796035007, "episode": 1425.0, "batch_reward": 0.8676527619361878, "critic_loss": 2.255494662284851, "actor_loss": -84.1158694312686, "actor_target_entropy": -1.0, "actor_entropy": 2.321172699095711, "alpha_loss": 0.00064410253357242, "alpha_value": 0.0032527007156878973, "duration": 3.839029312133789, "step": 178125}
{"episode_reward": 103.98914314984783, "episode": 1426.0, "batch_reward": 0.8646545686721802, "critic_loss": 2.1582907419204713, "actor_loss": -84.12403943461757, "actor_target_entropy": -1.0, "actor_entropy": 2.3129451351781047, "alpha_loss": 0.0007432603278204859, "alpha_value": 0.0032393915997947715, "duration": 3.832434892654419, "step": 178250}
{"episode_reward": 145.911713330358, "episode": 1427.0, "batch_reward": 0.8531068682670593, "critic_loss": 2.1653946599960325, "actor_loss": -84.1386465647864, "actor_target_entropy": -1.0, "actor_entropy": 2.3306493002270896, "alpha_loss": 0.0005627229852723845, "alpha_value": 0.0032248500341264153, "duration": 3.838367223739624, "step": 178375}
{"episode_reward": 161.28197274170662, "episode": 1428.0, "batch_reward": 0.8496835494041443, "critic_loss": 2.150115664482117, "actor_loss": -84.15375949490455, "actor_target_entropy": -1.0, "actor_entropy": 2.3375013566786245, "alpha_loss": 0.0006050006732919194, "alpha_value": 0.0032148725703191414, "duration": 3.837350606918335, "step": 178500}
{"episode_reward": 168.9685754400337, "episode": 1429.0, "batch_reward": 0.8715445337295532, "critic_loss": 2.2097593641281126, "actor_loss": -84.20343320331877, "actor_target_entropy": -1.0, "actor_entropy": 2.338647887820289, "alpha_loss": 0.00044066622845887664, "alpha_value": 0.00320386699627506, "duration": 3.840906858444214, "step": 178625}
{"episode_reward": 104.31586863946512, "episode": 1430.0, "batch_reward": 0.8733117589950562, "critic_loss": 2.215533205986023, "actor_loss": -84.23150819347751, "actor_target_entropy": -1.0, "actor_entropy": 2.3345785448628087, "alpha_loss": 0.00038706673020046323, "alpha_value": 0.0031967226600958724, "duration": 3.8320300579071045, "step": 178750}
{"episode_reward": 63.22291646661779, "episode": 1431.0, "batch_reward": 0.8587894277572632, "critic_loss": 2.164229965209961, "actor_loss": -84.25089009602864, "actor_target_entropy": -1.0, "actor_entropy": 2.323540082053533, "alpha_loss": 0.0004461157631816431, "alpha_value": 0.003187975333152294, "duration": 3.8373186588287354, "step": 178875}
{"episode_reward": 37.3180365785209, "episode": 1432.0, "batch_reward": 0.8792671294212341, "critic_loss": 2.2619457159042358, "actor_loss": -84.2880725245322, "actor_target_entropy": -1.0, "actor_entropy": 2.3164793137581117, "alpha_loss": 0.000422414748754818, "alpha_value": 0.003178434825175576, "duration": 3.837407350540161, "step": 179000}
{"episode_reward": 120.41040772835687, "episode": 1433.0, "batch_reward": 0.8512475090026855, "critic_loss": 2.200672462463379, "actor_loss": -84.3067359318809, "actor_target_entropy": -1.0, "actor_entropy": 2.3029682674105207, "alpha_loss": 0.0004052364145911905, "alpha_value": 0.0031700577934892444, "duration": 3.842846393585205, "step": 179125}
{"episode_reward": 144.00152559188442, "episode": 1434.0, "batch_reward": 0.8584106998443604, "critic_loss": 2.1777868213653564, "actor_loss": -84.34933311708512, "actor_target_entropy": -1.0, "actor_entropy": 2.2739175981090916, "alpha_loss": 0.0007710090123451195, "alpha_value": 0.0031574132691771072, "duration": 3.8426690101623535, "step": 179250}
{"episode_reward": 31.573812558971085, "episode": 1435.0, "batch_reward": 0.8526568984985352, "critic_loss": 2.2147213592529296, "actor_loss": -84.35324011908637, "actor_target_entropy": -1.0, "actor_entropy": 2.265023049854097, "alpha_loss": 0.0007260023556891755, "alpha_value": 0.003142816526792072, "duration": 3.842515230178833, "step": 179375}
{"episode_reward": 216.01154355792806, "episode": 1436.0, "batch_reward": 0.8509737300872803, "critic_loss": 2.1914661960601807, "actor_loss": -84.35495130477413, "actor_target_entropy": -1.0, "actor_entropy": 2.2581131073736374, "alpha_loss": 0.0007722963719354612, "alpha_value": 0.0031273265036389788, "duration": 3.827554225921631, "step": 179500}
{"episode_reward": 151.43255077902785, "episode": 1437.0, "batch_reward": 0.8688287320137024, "critic_loss": 2.2672667055130007, "actor_loss": -84.40979209778801, "actor_target_entropy": -1.0, "actor_entropy": 2.2560444635058206, "alpha_loss": 0.000648746083791752, "alpha_value": 0.0031128623874424584, "duration": 3.8424277305603027, "step": 179625}
{"episode_reward": 68.30636769962915, "episode": 1438.0, "batch_reward": 0.8526751413345337, "critic_loss": 2.112856700897217, "actor_loss": -84.41362307148594, "actor_target_entropy": -1.0, "actor_entropy": 2.2370512100958053, "alpha_loss": 0.0008376181281017771, "alpha_value": 0.0030986531731874915, "duration": 3.832868814468384, "step": 179750}
{"episode_reward": 68.99754097195147, "episode": 1439.0, "batch_reward": 0.8625530405044556, "critic_loss": 2.120190260887146, "actor_loss": -84.45244913252573, "actor_target_entropy": -1.0, "actor_entropy": 2.242567440820119, "alpha_loss": 0.0007600199012178188, "alpha_value": 0.00308268857059899, "duration": 3.838806390762329, "step": 179875}
{"episode_reward": 113.282273081332, "episode": 1440.0, "batch_reward": 0.8480383205413818, "critic_loss": 2.1111574249267577, "actor_loss": -84.42461665984123, "actor_target_entropy": -1.0, "actor_entropy": 2.2452212149097073, "alpha_loss": 0.0006559349513413655, "alpha_value": 0.003068030095352322, "duration": 3.830415964126587, "step": 180000}
{"episode_reward": 181.18385818048665, "episode": 1441.0, "batch_reward": 0.8537441363334656, "critic_loss": 2.208104157447815, "actor_loss": -84.45478178962829, "actor_target_entropy": -1.0, "actor_entropy": 2.2602660466754245, "alpha_loss": 0.000525453495760707, "alpha_value": 0.003055495947301785, "duration": 7.827771186828613, "step": 180125}
{"episode_reward": 108.91284679391794, "episode": 1442.0, "batch_reward": 0.866166540145874, "critic_loss": 2.232366968154907, "actor_loss": -84.4916012671686, "actor_target_entropy": -1.0, "actor_entropy": 2.2750453333700857, "alpha_loss": 0.000595644103258007, "alpha_value": 0.003044505791171103, "duration": 3.8379878997802734, "step": 180250}
{"episode_reward": 140.91854021051944, "episode": 1443.0, "batch_reward": 0.8595396323204041, "critic_loss": 2.172582032203674, "actor_loss": -84.52457561190167, "actor_target_entropy": -1.0, "actor_entropy": 2.2635727382841564, "alpha_loss": 0.0004633183832213815, "alpha_value": 0.00303411857435716, "duration": 3.841763496398926, "step": 180375}
{"episode_reward": 18.00204919387127, "episode": 1444.0, "batch_reward": 0.8600104336738587, "critic_loss": 2.2364737091064453, "actor_loss": -84.53995956913117, "actor_target_entropy": -1.0, "actor_entropy": 2.233018659776257, "alpha_loss": 0.0006236989110250086, "alpha_value": 0.003023520867249122, "duration": 3.8318426609039307, "step": 180500}
{"episode_reward": 155.41435536160654, "episode": 1445.0, "batch_reward": 0.851654130935669, "critic_loss": 2.236767544746399, "actor_loss": -84.55139426579551, "actor_target_entropy": -1.0, "actor_entropy": 2.236067120991056, "alpha_loss": 0.00047575112301505187, "alpha_value": 0.003012854815098089, "duration": 3.8482508659362793, "step": 180625}
{"episode_reward": 94.07178040449224, "episode": 1446.0, "batch_reward": 0.8452677145004273, "critic_loss": 2.0939586610794065, "actor_loss": -84.56329641034526, "actor_target_entropy": -1.0, "actor_entropy": 2.23065120943131, "alpha_loss": 0.0004518414392688071, "alpha_value": 0.0030035057307268432, "duration": 3.836071729660034, "step": 180750}
{"episode_reward": 63.933250880413645, "episode": 1447.0, "batch_reward": 0.8602132358551026, "critic_loss": 2.1686369228363036, "actor_loss": -84.59254273914155, "actor_target_entropy": -1.0, "actor_entropy": 2.2349599656604586, "alpha_loss": 0.0005605639319308842, "alpha_value": 0.002992475953258026, "duration": 3.8472979068756104, "step": 180875}
{"episode_reward": 160.76930440970406, "episode": 1448.0, "batch_reward": 0.8657752785682679, "critic_loss": 2.1664352626800536, "actor_loss": -84.60841197352255, "actor_target_entropy": -1.0, "actor_entropy": 2.2306123395119943, "alpha_loss": 0.0004972279191039683, "alpha_value": 0.0029818824610102967, "duration": 3.840054512023926, "step": 181000}
{"episode_reward": 44.95057213583645, "episode": 1449.0, "batch_reward": 0.8528564248085022, "critic_loss": 2.1782878665924073, "actor_loss": -84.5983397468688, "actor_target_entropy": -1.0, "actor_entropy": 2.2486326278202116, "alpha_loss": 0.00043427255103966987, "alpha_value": 0.0029723690259875687, "duration": 3.842989206314087, "step": 181125}
{"episode_reward": 90.04949498861573, "episode": 1450.0, "batch_reward": 0.8632571244239807, "critic_loss": 2.172278296470642, "actor_loss": -84.64252287341702, "actor_target_entropy": -1.0, "actor_entropy": 2.256584152098625, "alpha_loss": 0.00026568665658311557, "alpha_value": 0.0029639585568654006, "duration": 3.8408989906311035, "step": 181250}
{"episode_reward": 154.48915689938977, "episode": 1451.0, "batch_reward": 0.8476004152297973, "critic_loss": 2.141616495132446, "actor_loss": -84.65454234774151, "actor_target_entropy": -1.0, "actor_entropy": 2.2416657795981756, "alpha_loss": 0.000353141310038082, "alpha_value": 0.0029587753561308595, "duration": 3.8418822288513184, "step": 181375}
{"episode_reward": 69.38170279608399, "episode": 1452.0, "batch_reward": 0.8592590618133545, "critic_loss": 2.1853349142074583, "actor_loss": -84.67512450679656, "actor_target_entropy": -1.0, "actor_entropy": 2.226529029107863, "alpha_loss": 0.00037642851595826927, "alpha_value": 0.0029512055187615994, "duration": 3.8408567905426025, "step": 181500}
{"episode_reward": 156.9145370507811, "episode": 1453.0, "batch_reward": 0.853146490573883, "critic_loss": 2.1761557083129883, "actor_loss": -84.68834964812748, "actor_target_entropy": -1.0, "actor_entropy": 2.2068554863097174, "alpha_loss": 0.0005073296562177203, "alpha_value": 0.0029411925557243216, "duration": 3.842650890350342, "step": 181625}
{"episode_reward": 58.7039202022622, "episode": 1454.0, "batch_reward": 0.8560341873168945, "critic_loss": 2.211760286331177, "actor_loss": -84.7249880144673, "actor_target_entropy": -1.0, "actor_entropy": 2.183051447714529, "alpha_loss": 0.0005972238098864534, "alpha_value": 0.002929852543592065, "duration": 3.8422064781188965, "step": 181750}
{"episode_reward": 185.43022863704869, "episode": 1455.0, "batch_reward": 0.861432665348053, "critic_loss": 2.1286882371902465, "actor_loss": -84.74471791585286, "actor_target_entropy": -1.0, "actor_entropy": 2.1638969693865096, "alpha_loss": 0.0006693144312030488, "alpha_value": 0.0029172167795032083, "duration": 3.8454554080963135, "step": 181875}
{"episode_reward": 180.636044669891, "episode": 1456.0, "batch_reward": 0.8604106545448303, "critic_loss": 2.1915948276519774, "actor_loss": -84.75629080495527, "actor_target_entropy": -1.0, "actor_entropy": 2.158506254996023, "alpha_loss": 0.000561852097880253, "alpha_value": 0.002903762854362965, "duration": 3.8369197845458984, "step": 182000}
{"episode_reward": 170.70339681959788, "episode": 1457.0, "batch_reward": 0.8613378763198852, "critic_loss": 2.17679292011261, "actor_loss": -84.77997540670728, "actor_target_entropy": -1.0, "actor_entropy": 2.158078844585116, "alpha_loss": 0.0007264485497476666, "alpha_value": 0.0028914076270154395, "duration": 3.8459482192993164, "step": 182125}
{"episode_reward": 175.72122960714415, "episode": 1458.0, "batch_reward": 0.8632467617988586, "critic_loss": 2.2710517683029177, "actor_loss": -84.80753609441942, "actor_target_entropy": -1.0, "actor_entropy": 2.150603909646311, "alpha_loss": 0.00046737125200208186, "alpha_value": 0.0028786360749865994, "duration": 3.8391032218933105, "step": 182250}
{"episode_reward": 151.29073291984017, "episode": 1459.0, "batch_reward": 0.8614531331062317, "critic_loss": 2.200830795288086, "actor_loss": -84.82251291426401, "actor_target_entropy": -1.0, "actor_entropy": 2.1478827794392905, "alpha_loss": 0.000582212176393821, "alpha_value": 0.002866917265204866, "duration": 3.846060276031494, "step": 182375}
{"episode_reward": 213.0995094634479, "episode": 1460.0, "batch_reward": 0.8600546908378601, "critic_loss": 2.173051564216614, "actor_loss": -84.84848379319713, "actor_target_entropy": -1.0, "actor_entropy": 2.124924798165598, "alpha_loss": 0.000500682141489139, "alpha_value": 0.0028557414738519817, "duration": 3.834066867828369, "step": 182500}
{"episode_reward": 79.02762095148074, "episode": 1461.0, "batch_reward": 0.862379180431366, "critic_loss": 2.156623646736145, "actor_loss": -84.87339794824994, "actor_target_entropy": -1.0, "actor_entropy": 2.1071446433899896, "alpha_loss": 0.0005538941992516999, "alpha_value": 0.002845966301493963, "duration": 3.8471217155456543, "step": 182625}
{"episode_reward": 231.68701948716776, "episode": 1462.0, "batch_reward": 0.8688808946609498, "critic_loss": 2.280958281517029, "actor_loss": -84.91862217072517, "actor_target_entropy": -1.0, "actor_entropy": 2.078108141499181, "alpha_loss": 0.0004495763832012251, "alpha_value": 0.0028357385883350655, "duration": 3.839341163635254, "step": 182750}
{"episode_reward": 197.6421832220532, "episode": 1463.0, "batch_reward": 0.8768631086349488, "critic_loss": 2.184950472831726, "actor_loss": -84.96578337654235, "actor_target_entropy": -1.0, "actor_entropy": 2.0427879454597595, "alpha_loss": 0.0006050598400641262, "alpha_value": 0.00282494030408113, "duration": 3.8434886932373047, "step": 182875}
{"episode_reward": 84.13355668900127, "episode": 1464.0, "batch_reward": 0.8661918354034424, "critic_loss": 2.118650859832764, "actor_loss": -84.98528179045647, "actor_target_entropy": -1.0, "actor_entropy": 2.007896859799662, "alpha_loss": 0.0006302146453714569, "alpha_value": 0.002811519313061015, "duration": 3.8431038856506348, "step": 183000}
{"episode_reward": 130.7822177956702, "episode": 1465.0, "batch_reward": 0.8630435767173767, "critic_loss": 2.2015937700271606, "actor_loss": -85.00080229744079, "actor_target_entropy": -1.0, "actor_entropy": 1.9729906585481432, "alpha_loss": 0.0006912395447937935, "alpha_value": 0.002797963058059645, "duration": 3.843428134918213, "step": 183125}
{"episode_reward": 194.21805199484885, "episode": 1466.0, "batch_reward": 0.8715745334625244, "critic_loss": 2.2120237913131713, "actor_loss": -85.03301165180821, "actor_target_entropy": -1.0, "actor_entropy": 1.9469469478053432, "alpha_loss": 0.0006554394353917169, "alpha_value": 0.0027842879501439846, "duration": 3.8421289920806885, "step": 183250}
{"episode_reward": 147.72930080708386, "episode": 1467.0, "batch_reward": 0.876254849433899, "critic_loss": 2.232539182662964, "actor_loss": -85.07067398797898, "actor_target_entropy": -1.0, "actor_entropy": 1.9293583480138627, "alpha_loss": 0.0004692061227701959, "alpha_value": 0.002772931857310891, "duration": 3.8436460494995117, "step": 183375}
{"episode_reward": 71.79325907629254, "episode": 1468.0, "batch_reward": 0.8618779072761535, "critic_loss": 2.172768255233765, "actor_loss": -85.08344601046655, "actor_target_entropy": -1.0, "actor_entropy": 1.893123492117851, "alpha_loss": 0.000632312964655519, "alpha_value": 0.0027613109894767344, "duration": 3.838195323944092, "step": 183500}
{"episode_reward": 67.4937146114345, "episode": 1469.0, "batch_reward": 0.8777324213981629, "critic_loss": 2.247770283699036, "actor_loss": -85.12991090804812, "actor_target_entropy": -1.0, "actor_entropy": 1.8547076138239058, "alpha_loss": 0.000500998687274414, "alpha_value": 0.0027497330971163127, "duration": 3.8505544662475586, "step": 183625}
{"episode_reward": 113.13058891611435, "episode": 1470.0, "batch_reward": 0.8593833413124085, "critic_loss": 2.1657465620040894, "actor_loss": -85.137146857477, "actor_target_entropy": -1.0, "actor_entropy": 1.81585027710084, "alpha_loss": 0.00040366941492163367, "alpha_value": 0.0027406576730862322, "duration": 3.8377468585968018, "step": 183750}
{"episode_reward": 59.89746731439929, "episode": 1471.0, "batch_reward": 0.8549431762695312, "critic_loss": 2.1179963903427126, "actor_loss": -85.14940606980096, "actor_target_entropy": -1.0, "actor_entropy": 1.7791253214790708, "alpha_loss": 0.0004217864183634187, "alpha_value": 0.002732016740601583, "duration": 3.8510401248931885, "step": 183875}
{"episode_reward": 76.02216783231603, "episode": 1472.0, "batch_reward": 0.8706844401359558, "critic_loss": 2.1979296169281004, "actor_loss": -85.1766486629363, "actor_target_entropy": -1.0, "actor_entropy": 1.7456576939552062, "alpha_loss": 0.0003754639020048818, "alpha_value": 0.002724463771918855, "duration": 3.841614246368408, "step": 184000}
{"episode_reward": 75.9126019120736, "episode": 1473.0, "batch_reward": 0.8613896913528443, "critic_loss": 2.1422436542510988, "actor_loss": -85.21016450912234, "actor_target_entropy": -1.0, "actor_entropy": 1.6974345332100278, "alpha_loss": 0.00024285648332951251, "alpha_value": 0.0027170617462502515, "duration": 3.8459155559539795, "step": 184125}
{"episode_reward": 65.71717995422343, "episode": 1474.0, "batch_reward": 0.853981011390686, "critic_loss": 2.2064630336761475, "actor_loss": -85.2300053258096, "actor_target_entropy": -1.0, "actor_entropy": 1.6488915451111332, "alpha_loss": 0.00018718168681633899, "alpha_value": 0.0027122123572747275, "duration": 3.8442277908325195, "step": 184250}
{"episode_reward": 119.14727836759724, "episode": 1475.0, "batch_reward": 0.8567971348762512, "critic_loss": 2.144356168746948, "actor_loss": -85.25191582573785, "actor_target_entropy": -1.0, "actor_entropy": 1.588316313804142, "alpha_loss": 6.57367127132602e-05, "alpha_value": 0.002710026331190837, "duration": 3.840207099914551, "step": 184375}
{"episode_reward": 132.78706905981304, "episode": 1476.0, "batch_reward": 0.8564743943214417, "critic_loss": 2.153366604804993, "actor_loss": -85.29378189579133, "actor_target_entropy": -1.0, "actor_entropy": 1.522779114784733, "alpha_loss": -0.0002265502904089273, "alpha_value": 0.0027112030232829404, "duration": 3.8452231884002686, "step": 184500}
{"episode_reward": 126.23924975913359, "episode": 1477.0, "batch_reward": 0.8552022414207459, "critic_loss": 2.1730065927505495, "actor_loss": -85.30094510033017, "actor_target_entropy": -1.0, "actor_entropy": 1.438778591534448, "alpha_loss": -0.00035517252006915414, "alpha_value": 0.002718008006309475, "duration": 3.8467929363250732, "step": 184625}
{"episode_reward": 127.84091165985886, "episode": 1478.0, "batch_reward": 0.8633352966308594, "critic_loss": 2.1613862161636352, "actor_loss": -85.33889413649037, "actor_target_entropy": -1.0, "actor_entropy": 1.3518911677022134, "alpha_loss": -0.0007136708553580027, "alpha_value": 0.002730330661930568, "duration": 3.8417556285858154, "step": 184750}
{"episode_reward": 73.01816690846798, "episode": 1479.0, "batch_reward": 0.8680641388893128, "critic_loss": 2.1884320373535155, "actor_loss": -85.38691880967882, "actor_target_entropy": -1.0, "actor_entropy": 1.2682557654759241, "alpha_loss": -0.0009697536798840803, "alpha_value": 0.002747794913546594, "duration": 3.8451051712036133, "step": 184875}
{"episode_reward": 72.54059841534546, "episode": 1480.0, "batch_reward": 0.8534962501525879, "critic_loss": 2.146749403953552, "actor_loss": -85.38038598337481, "actor_target_entropy": -1.0, "actor_entropy": 1.1803082073888471, "alpha_loss": -0.0013914606139634647, "alpha_value": 0.0027745447347082212, "duration": 3.8393826484680176, "step": 185000}
{"episode_reward": 71.2449502345359, "episode": 1481.0, "batch_reward": 0.8497737903594971, "critic_loss": 2.1259986963272093, "actor_loss": -85.4171381148081, "actor_target_entropy": -1.0, "actor_entropy": 1.1017140906954568, "alpha_loss": -0.001618574503698342, "alpha_value": 0.0028060292833232145, "duration": 3.8508689403533936, "step": 185125}
{"episode_reward": 76.34771606349832, "episode": 1482.0, "batch_reward": 0.8652094860076904, "critic_loss": 2.170418640136719, "actor_loss": -85.4505113170993, "actor_target_entropy": -1.0, "actor_entropy": 1.0187572548466344, "alpha_loss": -0.00201399193610996, "alpha_value": 0.0028409093229775947, "duration": 3.841097354888916, "step": 185250}
{"episode_reward": 70.92584546957346, "episode": 1483.0, "batch_reward": 0.8647425074577332, "critic_loss": 2.2202501697540282, "actor_loss": -85.49352373395648, "actor_target_entropy": -1.0, "actor_entropy": 0.946170172994099, "alpha_loss": -0.0023525884848028893, "alpha_value": 0.0028792958044304034, "duration": 3.849701166152954, "step": 185375}
{"episode_reward": 73.93703993949663, "episode": 1484.0, "batch_reward": 0.8581439571380616, "critic_loss": 2.182275465965271, "actor_loss": -85.49868392944336, "actor_target_entropy": -1.0, "actor_entropy": 0.8823674455765755, "alpha_loss": -0.002635110376192437, "alpha_value": 0.0029192351263039175, "duration": 3.845959424972534, "step": 185500}
{"episode_reward": 74.32559967631661, "episode": 1485.0, "batch_reward": 0.8674334816932678, "critic_loss": 2.174996195793152, "actor_loss": -85.54555838448661, "actor_target_entropy": -1.0, "actor_entropy": 0.8320726837430682, "alpha_loss": -0.002934619780659439, "alpha_value": 0.0029589791066544557, "duration": 3.8488359451293945, "step": 185625}
{"episode_reward": 71.89602329768891, "episode": 1486.0, "batch_reward": 0.8593489017486572, "critic_loss": 2.161459000587463, "actor_loss": -85.52809463008758, "actor_target_entropy": -1.0, "actor_entropy": 0.7902655024682322, "alpha_loss": -0.003187761240218195, "alpha_value": 0.0029984684785533955, "duration": 3.840846300125122, "step": 185750}
{"episode_reward": 69.91535122869871, "episode": 1487.0, "batch_reward": 0.8575399260520935, "critic_loss": 2.2323236474990846, "actor_loss": -85.61966608441065, "actor_target_entropy": -1.0, "actor_entropy": 0.7465815790115841, "alpha_loss": -0.003444940151114549, "alpha_value": 0.003037128545250944, "duration": 3.8447492122650146, "step": 185875}
{"episode_reward": 74.72562839931139, "episode": 1488.0, "batch_reward": 0.8490591850280762, "critic_loss": 2.075269048690796, "actor_loss": -85.5947638480894, "actor_target_entropy": -1.0, "actor_entropy": 0.7083305428105016, "alpha_loss": -0.0036433515957586707, "alpha_value": 0.0030753630763976766, "duration": 3.845583438873291, "step": 186000}
{"episode_reward": 70.66199406883625, "episode": 1489.0, "batch_reward": 0.8524336323738099, "critic_loss": 2.049447805404663, "actor_loss": -85.6093502952939, "actor_target_entropy": -1.0, "actor_entropy": 0.6836931308110555, "alpha_loss": -0.003883206326189259, "alpha_value": 0.0031127491247849755, "duration": 3.8439605236053467, "step": 186125}
{"episode_reward": 74.47261732779616, "episode": 1490.0, "batch_reward": 0.850813663482666, "critic_loss": 2.1129632091522215, "actor_loss": -85.64955446797032, "actor_target_entropy": -1.0, "actor_entropy": 0.6650241613388062, "alpha_loss": -0.004021957201222258, "alpha_value": 0.003149611027993203, "duration": 3.83772873878479, "step": 186250}
{"episode_reward": 73.68306462951135, "episode": 1491.0, "batch_reward": 0.8643521842956543, "critic_loss": 2.2230834512710573, "actor_loss": -85.68670327322823, "actor_target_entropy": -1.0, "actor_entropy": 0.6480281182697841, "alpha_loss": -0.004184987517960724, "alpha_value": 0.003185223226557938, "duration": 3.8450396060943604, "step": 186375}
{"episode_reward": 69.90132381820584, "episode": 1492.0, "batch_reward": 0.8525373387336731, "critic_loss": 2.1076276016235354, "actor_loss": -85.70966499082503, "actor_target_entropy": -1.0, "actor_entropy": 0.6334120265899166, "alpha_loss": -0.004330645289061771, "alpha_value": 0.0032202159032162633, "duration": 3.840379476547241, "step": 186500}
{"episode_reward": 73.72462145855104, "episode": 1493.0, "batch_reward": 0.8509765100479126, "critic_loss": 2.099712684631348, "actor_loss": -85.70975954570467, "actor_target_entropy": -1.0, "actor_entropy": 0.6237846120955453, "alpha_loss": -0.004478153573083026, "alpha_value": 0.003254514677433022, "duration": 3.850816488265991, "step": 186625}
{"episode_reward": 73.88422704389409, "episode": 1494.0, "batch_reward": 0.8511699600219726, "critic_loss": 2.1631513137817384, "actor_loss": -85.72286925777313, "actor_target_entropy": -1.0, "actor_entropy": 0.6184927302022134, "alpha_loss": -0.004515561399110142, "alpha_value": 0.0032881450778950044, "duration": 3.8398780822753906, "step": 186750}
{"episode_reward": 73.9621429682379, "episode": 1495.0, "batch_reward": 0.8540113530158997, "critic_loss": 2.159839430809021, "actor_loss": -85.7519060165163, "actor_target_entropy": -1.0, "actor_entropy": 0.6089395965848651, "alpha_loss": -0.0046628787226620175, "alpha_value": 0.0033210835275021265, "duration": 3.85034441947937, "step": 186875}
{"episode_reward": 72.98893687940024, "episode": 1496.0, "batch_reward": 0.8502926383018493, "critic_loss": 2.1413941917419432, "actor_loss": -85.74737327329574, "actor_target_entropy": -1.0, "actor_entropy": 0.6100555427612797, "alpha_loss": -0.004845150776447788, "alpha_value": 0.0033537286730765817, "duration": 3.840830087661743, "step": 187000}
{"episode_reward": 72.56424981019987, "episode": 1497.0, "batch_reward": 0.8529342565536498, "critic_loss": 2.157086367607117, "actor_loss": -85.807618156312, "actor_target_entropy": -1.0, "actor_entropy": 0.6069090574506729, "alpha_loss": -0.004973405188629551, "alpha_value": 0.003386342318732127, "duration": 3.8494832515716553, "step": 187125}
{"episode_reward": 72.72071365709674, "episode": 1498.0, "batch_reward": 0.8566670999526977, "critic_loss": 2.151090789794922, "actor_loss": -85.80777875838741, "actor_target_entropy": -1.0, "actor_entropy": 0.6036087043823735, "alpha_loss": -0.005050077869166289, "alpha_value": 0.003418585187749254, "duration": 3.847562789916992, "step": 187250}
{"episode_reward": 72.52649447337521, "episode": 1499.0, "batch_reward": 0.8503841161727905, "critic_loss": 2.1021692724227905, "actor_loss": -85.82550618005178, "actor_target_entropy": -1.0, "actor_entropy": 0.6056675854183379, "alpha_loss": -0.005069243411223094, "alpha_value": 0.0034501680072991803, "duration": 3.8450052738189697, "step": 187375}
{"episode_reward": 74.98358332671788, "episode": 1500.0, "batch_reward": 0.8524549298286438, "critic_loss": 2.1732839088439944, "actor_loss": -85.82444738572643, "actor_target_entropy": -1.0, "actor_entropy": 0.6109536117123019, "alpha_loss": -0.0051298600381180165, "alpha_value": 0.0034811277729373253, "duration": 3.8453099727630615, "step": 187500}
{"episode_reward": 74.47034113364843, "episode": 1501.0, "batch_reward": 0.8669278168678284, "critic_loss": 2.1483973121643065, "actor_loss": -85.87700640966021, "actor_target_entropy": -1.0, "actor_entropy": 0.6128727159802876, "alpha_loss": -0.005146269553474018, "alpha_value": 0.0035118132298209053, "duration": 3.8471906185150146, "step": 187625}
{"episode_reward": 74.84753452910707, "episode": 1502.0, "batch_reward": 0.8624268283843994, "critic_loss": 2.1004014406204226, "actor_loss": -85.87526985906786, "actor_target_entropy": -1.0, "actor_entropy": 0.6197687618194088, "alpha_loss": -0.0051263439273762125, "alpha_value": 0.003541816585893106, "duration": 3.8409383296966553, "step": 187750}
{"episode_reward": 75.1440050899342, "episode": 1503.0, "batch_reward": 0.8559857993125916, "critic_loss": 2.1066116218566893, "actor_loss": -85.91496301075769, "actor_target_entropy": -1.0, "actor_entropy": 0.627269913279821, "alpha_loss": -0.005289298630068226, "alpha_value": 0.0035716476339927206, "duration": 3.8468129634857178, "step": 187875}
{"episode_reward": 72.58439369240253, "episode": 1504.0, "batch_reward": 0.8622993154525757, "critic_loss": 2.1662030324935913, "actor_loss": -85.95936141475555, "actor_target_entropy": -1.0, "actor_entropy": 0.6308809595723306, "alpha_loss": -0.005404805952322579, "alpha_value": 0.0036016728241715246, "duration": 3.8417718410491943, "step": 188000}
{"episode_reward": 72.94678778755133, "episode": 1505.0, "batch_reward": 0.8477775845527649, "critic_loss": 2.062278045654297, "actor_loss": -85.91883753216456, "actor_target_entropy": -1.0, "actor_entropy": 0.6422998810571338, "alpha_loss": -0.00531526632045233, "alpha_value": 0.0036316379459875115, "duration": 3.8497884273529053, "step": 188125}
{"episode_reward": 72.76001662379946, "episode": 1506.0, "batch_reward": 0.8514724926948547, "critic_loss": 2.0902654523849487, "actor_loss": -85.93767436858147, "actor_target_entropy": -1.0, "actor_entropy": 0.6575183599225937, "alpha_loss": -0.005263141236237941, "alpha_value": 0.00366049096721487, "duration": 3.836430788040161, "step": 188250}
{"episode_reward": 70.76810342254774, "episode": 1507.0, "batch_reward": 0.8564203329086304, "critic_loss": 2.0939149675369264, "actor_loss": -85.94161393907335, "actor_target_entropy": -1.0, "actor_entropy": 0.6730270858794923, "alpha_loss": -0.005363187870927273, "alpha_value": 0.003689343409325166, "duration": 3.8498775959014893, "step": 188375}
{"episode_reward": 73.70870397164171, "episode": 1508.0, "batch_reward": 0.8641033897399902, "critic_loss": 2.1844958162307737, "actor_loss": -85.9807979214576, "actor_target_entropy": -1.0, "actor_entropy": 0.6894595738380186, "alpha_loss": -0.005304395626749723, "alpha_value": 0.0037179302029756787, "duration": 3.83975887298584, "step": 188500}
{"episode_reward": 72.20973178728921, "episode": 1509.0, "batch_reward": 0.8630224709510803, "critic_loss": 2.102281608581543, "actor_loss": -85.97054109119233, "actor_target_entropy": -1.0, "actor_entropy": 0.7002128286967202, "alpha_loss": -0.005319833770276062, "alpha_value": 0.003746204644250201, "duration": 3.849108934402466, "step": 188625}
{"episode_reward": 72.76845429559076, "episode": 1510.0, "batch_reward": 0.860219301700592, "critic_loss": 2.2026160221099853, "actor_loss": -86.01466123519405, "actor_target_entropy": -1.0, "actor_entropy": 0.7176652608379241, "alpha_loss": -0.005245930939582327, "alpha_value": 0.0037740939478049934, "duration": 3.843928575515747, "step": 188750}
{"episode_reward": 70.84213697027812, "episode": 1511.0, "batch_reward": 0.8563239283561707, "critic_loss": 2.140769298553467, "actor_loss": -86.00004722958519, "actor_target_entropy": -1.0, "actor_entropy": 0.7312007801873344, "alpha_loss": -0.005277460418818962, "alpha_value": 0.0038017549323874755, "duration": 3.8482022285461426, "step": 188875}
{"episode_reward": 73.81342642021362, "episode": 1512.0, "batch_reward": 0.8514029788970947, "critic_loss": 2.1421034955978393, "actor_loss": -85.9914901487289, "actor_target_entropy": -1.0, "actor_entropy": 0.7467628948150142, "alpha_loss": -0.005176384159694275, "alpha_value": 0.003828995048967757, "duration": 3.8423619270324707, "step": 189000}
{"episode_reward": 75.82934107487768, "episode": 1513.0, "batch_reward": 0.8503653349876403, "critic_loss": 2.0863593254089356, "actor_loss": -85.99668920607795, "actor_target_entropy": -1.0, "actor_entropy": 0.7711210875284105, "alpha_loss": -0.00511402575417407, "alpha_value": 0.0038560924902990294, "duration": 3.8469772338867188, "step": 189125}
{"episode_reward": 74.91851641446128, "episode": 1514.0, "batch_reward": 0.8560282669067383, "critic_loss": 2.1154223880767824, "actor_loss": -86.003174812563, "actor_target_entropy": -1.0, "actor_entropy": 0.7902940357885053, "alpha_loss": -0.005058585793801373, "alpha_value": 0.0038825431483621407, "duration": 3.842747449874878, "step": 189250}
{"episode_reward": 75.43301019920015, "episode": 1515.0, "batch_reward": 0.8570747075080871, "critic_loss": 2.096578824043274, "actor_loss": -86.01741524348184, "actor_target_entropy": -1.0, "actor_entropy": 0.8065743540960645, "alpha_loss": -0.004876126187838732, "alpha_value": 0.003908562814434396, "duration": 3.8682286739349365, "step": 189375}
{"episode_reward": 71.13498839688413, "episode": 1516.0, "batch_reward": 0.8656024127006531, "critic_loss": 2.206460915565491, "actor_loss": -86.02406335646107, "actor_target_entropy": -1.0, "actor_entropy": 0.8179664496452578, "alpha_loss": -0.004866950578176447, "alpha_value": 0.003934048862848153, "duration": 3.840181350708008, "step": 189500}
{"episode_reward": 71.91190520338078, "episode": 1517.0, "batch_reward": 0.8592695713043212, "critic_loss": 2.100792637825012, "actor_loss": -86.03320300389849, "actor_target_entropy": -1.0, "actor_entropy": 0.8237217059211125, "alpha_loss": -0.004775490190479017, "alpha_value": 0.003959707304161389, "duration": 3.84208607673645, "step": 189625}
{"episode_reward": 72.3988657235399, "episode": 1518.0, "batch_reward": 0.8552215728759766, "critic_loss": 2.0524017610549925, "actor_loss": -86.04351166755923, "actor_target_entropy": -1.0, "actor_entropy": 0.8293342321149765, "alpha_loss": -0.004908475506630155, "alpha_value": 0.003985201774033297, "duration": 3.8385541439056396, "step": 189750}
{"episode_reward": 75.1308718536799, "episode": 1519.0, "batch_reward": 0.8620407433509827, "critic_loss": 2.129960334777832, "actor_loss": -86.0438479468936, "actor_target_entropy": -1.0, "actor_entropy": 0.829969498846266, "alpha_loss": -0.004812188926965944, "alpha_value": 0.004010866847181734, "duration": 3.850917100906372, "step": 189875}
{"episode_reward": 71.4785706119001, "episode": 1520.0, "batch_reward": 0.8643365416526795, "critic_loss": 2.176799276351929, "actor_loss": -86.06822622975996, "actor_target_entropy": -1.0, "actor_entropy": 0.8123531380007344, "alpha_loss": -0.00490911484831163, "alpha_value": 0.004036622831120488, "duration": 3.8396191596984863, "step": 190000}
{"episode_reward": 72.95378326774501, "episode": 1521.0, "batch_reward": 0.8524081249237061, "critic_loss": 2.076955256462097, "actor_loss": -86.07042124914744, "actor_target_entropy": -1.0, "actor_entropy": 0.8117946462025718, "alpha_loss": -0.0049114119601509874, "alpha_value": 0.0040631985318073365, "duration": 7.829039573669434, "step": 190125}
{"episode_reward": 73.72619169816404, "episode": 1522.0, "batch_reward": 0.8535507035255432, "critic_loss": 2.1215175609588623, "actor_loss": -86.067687619117, "actor_target_entropy": -1.0, "actor_entropy": 0.8122087947783931, "alpha_loss": -0.004913809942081571, "alpha_value": 0.0040894272132976205, "duration": 3.8306570053100586, "step": 190250}
{"episode_reward": 76.63527088352559, "episode": 1523.0, "batch_reward": 0.8582479057312011, "critic_loss": 2.176713409423828, "actor_loss": -86.0646485828218, "actor_target_entropy": -1.0, "actor_entropy": 0.8272904914522928, "alpha_loss": -0.004850208966268433, "alpha_value": 0.0041158893055596515, "duration": 3.851001501083374, "step": 190375}
{"episode_reward": 73.26856656110337, "episode": 1524.0, "batch_reward": 0.8513421893119812, "critic_loss": 2.189806661605835, "actor_loss": -86.05248888077274, "actor_target_entropy": -1.0, "actor_entropy": 0.8430973060669438, "alpha_loss": -0.004809801402922359, "alpha_value": 0.004142063251232325, "duration": 3.8396973609924316, "step": 190500}
{"episode_reward": 73.5439238182972, "episode": 1525.0, "batch_reward": 0.8563768100738526, "critic_loss": 2.144986918926239, "actor_loss": -86.07144988529267, "actor_target_entropy": -1.0, "actor_entropy": 0.8594363246645246, "alpha_loss": -0.004756045986026052, "alpha_value": 0.004168213637049345, "duration": 3.8509740829467773, "step": 190625}
{"episode_reward": 73.88227347975207, "episode": 1526.0, "batch_reward": 0.858063904762268, "critic_loss": 2.1720236864089966, "actor_loss": -86.09038297591671, "actor_target_entropy": -1.0, "actor_entropy": 0.8527597958041776, "alpha_loss": -0.00466840720224765, "alpha_value": 0.0041940965922993775, "duration": 3.8403868675231934, "step": 190750}
{"episode_reward": 76.21485856379158, "episode": 1527.0, "batch_reward": 0.8590540971755981, "critic_loss": 2.1404445905685425, "actor_loss": -86.10335020035032, "actor_target_entropy": -1.0, "actor_entropy": 0.8426635851935734, "alpha_loss": -0.00472329178499797, "alpha_value": 0.004219956019240275, "duration": 3.8489184379577637, "step": 190875}
{"episode_reward": 74.70311313232008, "episode": 1528.0, "batch_reward": 0.8517797751426697, "critic_loss": 2.117987151145935, "actor_loss": -86.11370123586347, "actor_target_entropy": -1.0, "actor_entropy": 0.8393640710461524, "alpha_loss": -0.004778638129092513, "alpha_value": 0.004246301987226978, "duration": 3.842813014984131, "step": 191000}
{"episode_reward": 74.23345657970324, "episode": 1529.0, "batch_reward": 0.8446809525489807, "critic_loss": 2.0379444961547852, "actor_loss": -86.1209709530785, "actor_target_entropy": -1.0, "actor_entropy": 0.8311996933013673, "alpha_loss": -0.00492841505726415, "alpha_value": 0.004273334622422482, "duration": 3.845834970474243, "step": 191125}
{"episode_reward": 71.97730947903185, "episode": 1530.0, "batch_reward": 0.8560404572486877, "critic_loss": 2.2014485712051393, "actor_loss": -86.09487976566437, "actor_target_entropy": -1.0, "actor_entropy": 0.8385450032449537, "alpha_loss": -0.004800606447632515, "alpha_value": 0.004300907092803229, "duration": 3.84738826751709, "step": 191250}
{"episode_reward": 71.49313547904694, "episode": 1531.0, "batch_reward": 0.8368816933631897, "critic_loss": 2.0976937713623047, "actor_loss": -86.04112764388796, "actor_target_entropy": -1.0, "actor_entropy": 0.8746319895698911, "alpha_loss": -0.004654156812836254, "alpha_value": 0.004327730470630198, "duration": 3.843094825744629, "step": 191375}
{"episode_reward": 74.09070994226661, "episode": 1532.0, "batch_reward": 0.8381686725616455, "critic_loss": 2.0515803880691528, "actor_loss": -86.05824488978232, "actor_target_entropy": -1.0, "actor_entropy": 0.9017524603874453, "alpha_loss": -0.004320363262518038, "alpha_value": 0.0043530381620413726, "duration": 3.8426339626312256, "step": 191500}
{"episode_reward": 72.13482202232429, "episode": 1533.0, "batch_reward": 0.8549439282417297, "critic_loss": 2.181555914878845, "actor_loss": -86.06275625077505, "actor_target_entropy": -1.0, "actor_entropy": 0.9109413983329894, "alpha_loss": -0.004277543493709158, "alpha_value": 0.004377941108354785, "duration": 3.8499233722686768, "step": 191625}
{"episode_reward": 72.27722033547643, "episode": 1534.0, "batch_reward": 0.8515705671310425, "critic_loss": 2.155440863609314, "actor_loss": -86.09278869628906, "actor_target_entropy": -1.0, "actor_entropy": 0.8922128715822774, "alpha_loss": -0.004482711409969676, "alpha_value": 0.004403193096144847, "duration": 3.8418076038360596, "step": 191750}
{"episode_reward": 74.54551321069955, "episode": 1535.0, "batch_reward": 0.8370589637756347, "critic_loss": 2.1092887296676635, "actor_loss": -86.05202229817708, "actor_target_entropy": -1.0, "actor_entropy": 0.8733046262983292, "alpha_loss": -0.0045600050195519415, "alpha_value": 0.004429654625903577, "duration": 3.8513853549957275, "step": 191875}
{"episode_reward": 73.06477769253026, "episode": 1536.0, "batch_reward": 0.8443937110900879, "critic_loss": 2.052793285369873, "actor_loss": -86.05435488300938, "actor_target_entropy": -1.0, "actor_entropy": 0.8676481593039728, "alpha_loss": -0.004476114596811033, "alpha_value": 0.004456273601157528, "duration": 3.840212345123291, "step": 192000}
{"episode_reward": 72.07841572030735, "episode": 1537.0, "batch_reward": 0.8543977494239807, "critic_loss": 2.0615879821777345, "actor_loss": -86.0938450646779, "actor_target_entropy": -1.0, "actor_entropy": 0.8492011285963512, "alpha_loss": -0.004637187198987083, "alpha_value": 0.004483423266348847, "duration": 3.8516550064086914, "step": 192125}
{"episode_reward": 72.16890840688194, "episode": 1538.0, "batch_reward": 0.8536549592018128, "critic_loss": 2.101329874992371, "actor_loss": -86.06252141152659, "actor_target_entropy": -1.0, "actor_entropy": 0.8458859574410224, "alpha_loss": -0.004586728747874018, "alpha_value": 0.004511102373931397, "duration": 3.8447794914245605, "step": 192250}
{"episode_reward": 74.40104947781221, "episode": 1539.0, "batch_reward": 0.844959493637085, "critic_loss": 2.0760338916778562, "actor_loss": -86.0752700321258, "actor_target_entropy": -1.0, "actor_entropy": 0.8506729054072547, "alpha_loss": -0.004677316757835566, "alpha_value": 0.00453909802558297, "duration": 3.847561836242676, "step": 192375}
{"episode_reward": 71.56017750713396, "episode": 1540.0, "batch_reward": 0.8547885899543762, "critic_loss": 2.100225363731384, "actor_loss": -86.08013411491147, "actor_target_entropy": -1.0, "actor_entropy": 0.8277433956823042, "alpha_loss": -0.004719592687193184, "alpha_value": 0.004567562525491691, "duration": 3.8344316482543945, "step": 192500}
{"episode_reward": 74.02917815262127, "episode": 1541.0, "batch_reward": 0.8370498533248901, "critic_loss": 2.0088076171875, "actor_loss": -86.05023132808624, "actor_target_entropy": -1.0, "actor_entropy": 0.8363927224325756, "alpha_loss": -0.004723552751192261, "alpha_value": 0.004596546205832431, "duration": 3.836909532546997, "step": 192625}
{"episode_reward": 72.42757896140935, "episode": 1542.0, "batch_reward": 0.8485339555740357, "critic_loss": 2.076986456871033, "actor_loss": -86.04807859851468, "actor_target_entropy": -1.0, "actor_entropy": 0.8514330348660869, "alpha_loss": -0.004621866744973006, "alpha_value": 0.004625366857737345, "duration": 3.839118242263794, "step": 192750}
{"episode_reward": 72.1687261778062, "episode": 1543.0, "batch_reward": 0.8467955923080445, "critic_loss": 2.078393184661865, "actor_loss": -86.03636823381696, "actor_target_entropy": -1.0, "actor_entropy": 0.8550502251064966, "alpha_loss": -0.004594693030600274, "alpha_value": 0.00465357710446481, "duration": 3.846146583557129, "step": 192875}
{"episode_reward": 72.8938705280704, "episode": 1544.0, "batch_reward": 0.8595046753883362, "critic_loss": 2.164375069618225, "actor_loss": -86.07294587166079, "actor_target_entropy": -1.0, "actor_entropy": 0.8764660935248098, "alpha_loss": -0.004446897697034141, "alpha_value": 0.0046820542902286716, "duration": 3.8452513217926025, "step": 193000}
{"episode_reward": 73.22812638520517, "episode": 1545.0, "batch_reward": 0.8478293628692627, "critic_loss": 2.1325099506378176, "actor_loss": -86.01241799006387, "actor_target_entropy": -1.0, "actor_entropy": 0.9006078981217884, "alpha_loss": -0.004196135911144434, "alpha_value": 0.004709369582013264, "duration": 3.8461368083953857, "step": 193125}
{"episode_reward": 72.92499162857689, "episode": 1546.0, "batch_reward": 0.8488044962882996, "critic_loss": 2.101673701286316, "actor_loss": -86.0194727989935, "actor_target_entropy": -1.0, "actor_entropy": 0.9496387089452436, "alpha_loss": -0.003928625993731041, "alpha_value": 0.0047352641697127554, "duration": 3.8422977924346924, "step": 193250}
{"episode_reward": 73.26212600256441, "episode": 1547.0, "batch_reward": 0.84777032995224, "critic_loss": 2.0433101539611815, "actor_loss": -86.01593296111577, "actor_target_entropy": -1.0, "actor_entropy": 0.9896366501611377, "alpha_loss": -0.0035183903288155322, "alpha_value": 0.004758923702797895, "duration": 3.852240800857544, "step": 193375}
{"episode_reward": 73.07384652051805, "episode": 1548.0, "batch_reward": 0.8611415066719055, "critic_loss": 2.141850419998169, "actor_loss": -86.01183085287771, "actor_target_entropy": -1.0, "actor_entropy": 1.0189062895313385, "alpha_loss": -0.0033338132066532008, "alpha_value": 0.004781637109264015, "duration": 3.8410682678222656, "step": 193500}
{"episode_reward": 72.34721766497377, "episode": 1549.0, "batch_reward": 0.8489218797683716, "critic_loss": 2.225830604553223, "actor_loss": -85.96518949478391, "actor_target_entropy": -1.0, "actor_entropy": 1.0839763690554907, "alpha_loss": -0.002809815714874911, "alpha_value": 0.004802211034373637, "duration": 3.8517935276031494, "step": 193625}
{"episode_reward": 73.5273620424284, "episode": 1550.0, "batch_reward": 0.847840292930603, "critic_loss": 2.1234149656295775, "actor_loss": -85.97781692012664, "actor_target_entropy": -1.0, "actor_entropy": 1.1067617824000697, "alpha_loss": -0.0026052312065486705, "alpha_value": 0.0048204912688039276, "duration": 3.834512710571289, "step": 193750}
{"episode_reward": 74.5197416754125, "episode": 1551.0, "batch_reward": 0.8430644116401672, "critic_loss": 2.1014402675628663, "actor_loss": -85.98381769089471, "actor_target_entropy": -1.0, "actor_entropy": 1.0523437034516108, "alpha_loss": -0.00290612953840681, "alpha_value": 0.0048395285863726606, "duration": 3.84594988822937, "step": 193875}
{"episode_reward": 73.3879980199794, "episode": 1552.0, "batch_reward": 0.8438148908615112, "critic_loss": 2.0997140769958498, "actor_loss": -85.95572034774288, "actor_target_entropy": -1.0, "actor_entropy": 1.0636407982918523, "alpha_loss": -0.002548829639225357, "alpha_value": 0.00485934080696569, "duration": 3.843400001525879, "step": 194000}
{"episode_reward": 75.36749522905394, "episode": 1553.0, "batch_reward": 0.8531105237007142, "critic_loss": 2.0717550830841063, "actor_loss": -85.97364952450707, "actor_target_entropy": -1.0, "actor_entropy": 1.064378755433219, "alpha_loss": -0.0024667023976762143, "alpha_value": 0.004877153810745975, "duration": 3.8423871994018555, "step": 194125}
{"episode_reward": 76.0302719900379, "episode": 1554.0, "batch_reward": 0.8508190317153931, "critic_loss": 2.1178906593322755, "actor_loss": -85.94958274595199, "actor_target_entropy": -1.0, "actor_entropy": 1.0875900368536673, "alpha_loss": -0.002465718245554355, "alpha_value": 0.004895705568578655, "duration": 3.845219612121582, "step": 194250}
{"episode_reward": 75.13793801104393, "episode": 1555.0, "batch_reward": 0.8556259474754333, "critic_loss": 2.185419927597046, "actor_loss": -85.93528117830792, "actor_target_entropy": -1.0, "actor_entropy": 1.1102759970559015, "alpha_loss": -0.0022145704632358892, "alpha_value": 0.004913992225855569, "duration": 3.8441929817199707, "step": 194375}
{"episode_reward": 72.99892523817489, "episode": 1556.0, "batch_reward": 0.8400910677909851, "critic_loss": 2.061857894897461, "actor_loss": -85.93082624866116, "actor_target_entropy": -1.0, "actor_entropy": 1.1155933910800564, "alpha_loss": -0.0019253621407363925, "alpha_value": 0.004929846924435887, "duration": 3.8336617946624756, "step": 194500}
{"episode_reward": 74.15199410484709, "episode": 1557.0, "batch_reward": 0.8440365781784057, "critic_loss": 2.0631244983673094, "actor_loss": -85.90171826074994, "actor_target_entropy": -1.0, "actor_entropy": 1.1036677001014588, "alpha_loss": -0.001966521506556236, "alpha_value": 0.004945501669868806, "duration": 3.848724842071533, "step": 194625}
{"episode_reward": 70.21833875206949, "episode": 1558.0, "batch_reward": 0.8555557775497437, "critic_loss": 2.159616022109985, "actor_loss": -85.92872841127458, "actor_target_entropy": -1.0, "actor_entropy": 1.099869885752278, "alpha_loss": -0.0018617244270224605, "alpha_value": 0.004961375109087472, "duration": 3.838449716567993, "step": 194750}
{"episode_reward": 74.43901275804275, "episode": 1559.0, "batch_reward": 0.8367193856239319, "critic_loss": 2.043374478340149, "actor_loss": -85.91515786307198, "actor_target_entropy": -1.0, "actor_entropy": 1.087938522535657, "alpha_loss": -0.0020638241539783185, "alpha_value": 0.00497765022463987, "duration": 3.846148729324341, "step": 194875}
{"episode_reward": 73.70626034979175, "episode": 1560.0, "batch_reward": 0.8691643962860107, "critic_loss": 2.199669506072998, "actor_loss": -85.9242810895366, "actor_target_entropy": -1.0, "actor_entropy": 1.0747985416843044, "alpha_loss": -0.0020460011292016134, "alpha_value": 0.00499560666378947, "duration": 3.8380727767944336, "step": 195000}
{"episode_reward": 77.40356404675981, "episode": 1561.0, "batch_reward": 0.8449907650947571, "critic_loss": 2.098273160457611, "actor_loss": -85.88674636114212, "actor_target_entropy": -1.0, "actor_entropy": 1.0866764935236128, "alpha_loss": -0.001758977738929735, "alpha_value": 0.005012504160921117, "duration": 3.848241090774536, "step": 195125}
{"episode_reward": 71.9162803574248, "episode": 1562.0, "batch_reward": 0.8457330355644226, "critic_loss": 2.0543582763671875, "actor_loss": -85.89236450195312, "actor_target_entropy": -1.0, "actor_entropy": 1.0721603093608734, "alpha_loss": -0.001832566017495288, "alpha_value": 0.005029056507134621, "duration": 3.841491937637329, "step": 195250}
{"episode_reward": 75.13462928027991, "episode": 1563.0, "batch_reward": 0.8543097066879273, "critic_loss": 2.111397074699402, "actor_loss": -85.88416798909505, "actor_target_entropy": -1.0, "actor_entropy": 1.0724984748022897, "alpha_loss": -0.0017769525491906004, "alpha_value": 0.005045460350102538, "duration": 3.840888023376465, "step": 195375}
{"episode_reward": 72.21615546754336, "episode": 1564.0, "batch_reward": 0.8437229723930358, "critic_loss": 2.0642821559906004, "actor_loss": -85.8737410268476, "actor_target_entropy": -1.0, "actor_entropy": 1.0677925117554203, "alpha_loss": -0.001733359158782649, "alpha_value": 0.005062632490608967, "duration": 3.8383264541625977, "step": 195500}
{"episode_reward": 71.09952897817335, "episode": 1565.0, "batch_reward": 0.8418147554397583, "critic_loss": 1.9961704730987548, "actor_loss": -85.86265685066344, "actor_target_entropy": -1.0, "actor_entropy": 1.0706677834192913, "alpha_loss": -0.001765007759252238, "alpha_value": 0.005079402557424919, "duration": 3.8471271991729736, "step": 195625}
{"episode_reward": 73.86526792052697, "episode": 1566.0, "batch_reward": 0.842655101776123, "critic_loss": 2.078334979057312, "actor_loss": -85.84969994329637, "actor_target_entropy": -1.0, "actor_entropy": 1.0688330627256823, "alpha_loss": -0.0016757649976962938, "alpha_value": 0.005096681133955081, "duration": 3.8453283309936523, "step": 195750}
{"episode_reward": 74.34852960274671, "episode": 1567.0, "batch_reward": 0.8536131172180176, "critic_loss": 2.053098412513733, "actor_loss": -85.8342530992296, "actor_target_entropy": -1.0, "actor_entropy": 1.0911186630763705, "alpha_loss": -0.0014516956531830754, "alpha_value": 0.005113751922243616, "duration": 3.8477611541748047, "step": 195875}
{"episode_reward": 73.68881018575318, "episode": 1568.0, "batch_reward": 0.862399022102356, "critic_loss": 2.2207007637023928, "actor_loss": -85.80990132977885, "actor_target_entropy": -1.0, "actor_entropy": 1.1356241203123523, "alpha_loss": -0.0010815410890744157, "alpha_value": 0.005126830803007719, "duration": 3.8379077911376953, "step": 196000}
{"episode_reward": 74.45748600499078, "episode": 1569.0, "batch_reward": 0.83665895986557, "critic_loss": 2.014068126678467, "actor_loss": -85.79777647956969, "actor_target_entropy": -1.0, "actor_entropy": 1.1718201580501737, "alpha_loss": -0.0007681887755530798, "alpha_value": 0.0051367271075378656, "duration": 3.8466882705688477, "step": 196125}
{"episode_reward": 83.95678417444394, "episode": 1570.0, "batch_reward": 0.8470191988945007, "critic_loss": 2.1001142587661743, "actor_loss": -85.80144808369297, "actor_target_entropy": -1.0, "actor_entropy": 1.169486326556052, "alpha_loss": -0.0005964298186647225, "alpha_value": 0.005144230907906066, "duration": 3.837564706802368, "step": 196250}
{"episode_reward": 80.65522833494701, "episode": 1571.0, "batch_reward": 0.8679818029403686, "critic_loss": 2.1762033100128173, "actor_loss": -85.78104836600167, "actor_target_entropy": -1.0, "actor_entropy": 1.2062437288344852, "alpha_loss": -0.0004529411315969709, "alpha_value": 0.005149626018149774, "duration": 3.8488502502441406, "step": 196375}
{"episode_reward": 75.08434056743097, "episode": 1572.0, "batch_reward": 0.8345609555244445, "critic_loss": 2.0249772481918336, "actor_loss": -85.73525348786384, "actor_target_entropy": -1.0, "actor_entropy": 1.2690500943891463, "alpha_loss": -0.00015239933887759463, "alpha_value": 0.0051541684571900555, "duration": 3.8353989124298096, "step": 196500}
{"episode_reward": 101.43098739928807, "episode": 1573.0, "batch_reward": 0.8449683346748352, "critic_loss": 2.0332426624298097, "actor_loss": -85.73471323649089, "actor_target_entropy": -1.0, "actor_entropy": 1.326775870625935, "alpha_loss": 0.00042649534900972085, "alpha_value": 0.005151861090185691, "duration": 3.8382701873779297, "step": 196625}
{"episode_reward": 71.64994809019802, "episode": 1574.0, "batch_reward": 0.8373387970924377, "critic_loss": 2.1029225749969482, "actor_loss": -85.71865684755387, "actor_target_entropy": -1.0, "actor_entropy": 1.3479775959445583, "alpha_loss": 0.0005932968147868862, "alpha_value": 0.005145806940903724, "duration": 3.8384296894073486, "step": 196750}
{"episode_reward": 72.72731002367163, "episode": 1575.0, "batch_reward": 0.8522592782974243, "critic_loss": 2.0746094665527344, "actor_loss": -85.72252667139448, "actor_target_entropy": -1.0, "actor_entropy": 1.3689905669954088, "alpha_loss": 0.00043146581193136553, "alpha_value": 0.005139055362814586, "duration": 3.8480567932128906, "step": 196875}
{"episode_reward": 62.68586918992273, "episode": 1576.0, "batch_reward": 0.8534142112731934, "critic_loss": 2.135730136871338, "actor_loss": -85.73105744392642, "actor_target_entropy": -1.0, "actor_entropy": 1.4019695135854906, "alpha_loss": 0.0009662262053743395, "alpha_value": 0.00513046485047556, "duration": 3.8445122241973877, "step": 197000}
{"episode_reward": 72.6078665426855, "episode": 1577.0, "batch_reward": 0.8358845720291138, "critic_loss": 2.053936689853668, "actor_loss": -85.6896007477291, "actor_target_entropy": -1.0, "actor_entropy": 1.416457072136894, "alpha_loss": 0.0009732965933388129, "alpha_value": 0.005117805634826715, "duration": 3.843061685562134, "step": 197125}
{"episode_reward": 78.05988726493773, "episode": 1578.0, "batch_reward": 0.8552042102813721, "critic_loss": 2.1750325107574464, "actor_loss": -85.7037114789409, "actor_target_entropy": -1.0, "actor_entropy": 1.4366470498423423, "alpha_loss": 0.001041623037435197, "alpha_value": 0.005103142635685055, "duration": 3.841480255126953, "step": 197250}
{"episode_reward": 87.06491233455169, "episode": 1579.0, "batch_reward": 0.8422166752815247, "critic_loss": 2.060845712661743, "actor_loss": -85.66807580372644, "actor_target_entropy": -1.0, "actor_entropy": 1.4577549847345503, "alpha_loss": 0.0012623728505873476, "alpha_value": 0.005087938843344194, "duration": 3.8445699214935303, "step": 197375}
{"episode_reward": 90.73985033773525, "episode": 1580.0, "batch_reward": 0.8403403992652894, "critic_loss": 2.0224612216949462, "actor_loss": -85.64403238604146, "actor_target_entropy": -1.0, "actor_entropy": 1.4869749507596415, "alpha_loss": 0.0013301402535533622, "alpha_value": 0.005068785698558394, "duration": 3.844907760620117, "step": 197500}
{"episode_reward": 64.29595041250242, "episode": 1581.0, "batch_reward": 0.841506193637848, "critic_loss": 2.0561054773330687, "actor_loss": -85.62489343067956, "actor_target_entropy": -1.0, "actor_entropy": 1.5233338390077864, "alpha_loss": 0.0017276004957874113, "alpha_value": 0.005047282662052804, "duration": 3.8474619388580322, "step": 197625}
{"episode_reward": 68.66321445963993, "episode": 1582.0, "batch_reward": 0.8355044980049133, "critic_loss": 1.9981834149360658, "actor_loss": -85.60368433306294, "actor_target_entropy": -1.0, "actor_entropy": 1.5607429358267015, "alpha_loss": 0.001984563765994784, "alpha_value": 0.005020458576261542, "duration": 3.840569257736206, "step": 197750}
{"episode_reward": 71.38981229241675, "episode": 1583.0, "batch_reward": 0.837504831790924, "critic_loss": 2.086237579345703, "actor_loss": -85.57143680633061, "actor_target_entropy": -1.0, "actor_entropy": 1.5995073942911058, "alpha_loss": 0.001908759727643522, "alpha_value": 0.004992460364018199, "duration": 3.846604347229004, "step": 197875}
{"episode_reward": 88.00763250378334, "episode": 1584.0, "batch_reward": 0.8479102535247802, "critic_loss": 2.066443552017212, "actor_loss": -85.57666384789252, "actor_target_entropy": -1.0, "actor_entropy": 1.642660129454828, "alpha_loss": 0.0021020901561226517, "alpha_value": 0.0049635969464257666, "duration": 3.838927745819092, "step": 198000}
{"episode_reward": 90.31157024527118, "episode": 1585.0, "batch_reward": 0.8512043738365174, "critic_loss": 2.0989806499481203, "actor_loss": -85.57806844559927, "actor_target_entropy": -1.0, "actor_entropy": 1.6628331702853005, "alpha_loss": 0.0021038072498788733, "alpha_value": 0.004934499382886606, "duration": 3.8498451709747314, "step": 198125}
{"episode_reward": 101.53718635445938, "episode": 1586.0, "batch_reward": 0.8408308773040771, "critic_loss": 2.0023951416015624, "actor_loss": -85.57181155297064, "actor_target_entropy": -1.0, "actor_entropy": 1.668822092394675, "alpha_loss": 0.002110668559438519, "alpha_value": 0.004904267794032018, "duration": 3.8391432762145996, "step": 198250}
{"episode_reward": 68.91881237137777, "episode": 1587.0, "batch_reward": 0.8292849373817444, "critic_loss": 1.9972907238006592, "actor_loss": -85.52627515035962, "actor_target_entropy": -1.0, "actor_entropy": 1.675350206238883, "alpha_loss": 0.0021161247065128196, "alpha_value": 0.004874455332805095, "duration": 3.8405277729034424, "step": 198375}
{"episode_reward": 90.8333515075543, "episode": 1588.0, "batch_reward": 0.853735755443573, "critic_loss": 2.1004094619750977, "actor_loss": -85.53275803596743, "actor_target_entropy": -1.0, "actor_entropy": 1.7110267031577326, "alpha_loss": 0.002252775102650987, "alpha_value": 0.004844599112999264, "duration": 3.842360258102417, "step": 198500}
{"episode_reward": 61.85726882243152, "episode": 1589.0, "batch_reward": 0.8565342192649841, "critic_loss": 2.093221787452698, "actor_loss": -85.53351193382626, "actor_target_entropy": -1.0, "actor_entropy": 1.7185123250598, "alpha_loss": 0.002274402742928249, "alpha_value": 0.004812831992433211, "duration": 3.844245195388794, "step": 198625}
{"episode_reward": 77.46910477841244, "episode": 1590.0, "batch_reward": 0.8407886590957642, "critic_loss": 2.012946856498718, "actor_loss": -85.49548709008002, "actor_target_entropy": -1.0, "actor_entropy": 1.7631075805233372, "alpha_loss": 0.0024787996287247344, "alpha_value": 0.004781472807761725, "duration": 3.830214738845825, "step": 198750}
{"episode_reward": 148.90694728235542, "episode": 1591.0, "batch_reward": 0.8575726323127747, "critic_loss": 2.1534869689941405, "actor_loss": -85.5408208937872, "actor_target_entropy": -1.0, "actor_entropy": 1.761596923782712, "alpha_loss": 0.0023151640064223477, "alpha_value": 0.004748984543103565, "duration": 3.845505475997925, "step": 198875}
{"episode_reward": 137.15148283447118, "episode": 1592.0, "batch_reward": 0.8476853733062744, "critic_loss": 2.076165728569031, "actor_loss": -85.50791352795017, "actor_target_entropy": -1.0, "actor_entropy": 1.7485925189910396, "alpha_loss": 0.0023385330644105713, "alpha_value": 0.004719170421550589, "duration": 3.842642307281494, "step": 199000}
{"episode_reward": 73.00052210118798, "episode": 1593.0, "batch_reward": 0.8502516436576844, "critic_loss": 2.0486926851272584, "actor_loss": -85.51361919584728, "actor_target_entropy": -1.0, "actor_entropy": 1.754294094585237, "alpha_loss": 0.0025381547350820806, "alpha_value": 0.004687388928333835, "duration": 3.8497540950775146, "step": 199125}
{"episode_reward": 226.65005461127691, "episode": 1594.0, "batch_reward": 0.8504669418334961, "critic_loss": 2.1552714309692385, "actor_loss": -85.48528289794922, "actor_target_entropy": -1.0, "actor_entropy": 1.7670683437778103, "alpha_loss": 0.002473058176204382, "alpha_value": 0.004654498504656857, "duration": 3.839158058166504, "step": 199250}
{"episode_reward": 56.68549184274517, "episode": 1595.0, "batch_reward": 0.831075954914093, "critic_loss": 2.0147115335464476, "actor_loss": -85.46847740052239, "actor_target_entropy": -1.0, "actor_entropy": 1.7641446571501473, "alpha_loss": 0.0024202281021557396, "alpha_value": 0.004624125453606698, "duration": 3.83868145942688, "step": 199375}
{"episode_reward": 36.125235330435466, "episode": 1596.0, "batch_reward": 0.8558769659996033, "critic_loss": 2.1271634588241577, "actor_loss": -85.47982320477885, "actor_target_entropy": -1.0, "actor_entropy": 1.7689861520644157, "alpha_loss": 0.002424371971902738, "alpha_value": 0.0045941027828376715, "duration": 3.830857515335083, "step": 199500}
{"episode_reward": 68.8712467328358, "episode": 1597.0, "batch_reward": 0.8561679449081421, "critic_loss": 2.1410932326316834, "actor_loss": -85.47161574590774, "actor_target_entropy": -1.0, "actor_entropy": 1.7969153741049388, "alpha_loss": 0.002592818447506972, "alpha_value": 0.004563132155488568, "duration": 3.8476884365081787, "step": 199625}
{"episode_reward": 115.55642523226157, "episode": 1598.0, "batch_reward": 0.8407961483001709, "critic_loss": 2.1297254915237427, "actor_loss": -85.42030223723381, "actor_target_entropy": -1.0, "actor_entropy": 1.8109955210839548, "alpha_loss": 0.0024309815170483725, "alpha_value": 0.004533036437270156, "duration": 3.836486577987671, "step": 199750}
{"episode_reward": 143.48536656302562, "episode": 1599.0, "batch_reward": 0.8471948986053467, "critic_loss": 1.992294906616211, "actor_loss": -85.43377043708922, "actor_target_entropy": -1.0, "actor_entropy": 1.8302679837696136, "alpha_loss": 0.0027288666719363797, "alpha_value": 0.0045025470335636674, "duration": 3.846285581588745, "step": 199875}
{"episode_reward": 95.99255173984582, "episode": 1600.0, "batch_reward": 0.8380528001785278, "critic_loss": 2.07006219291687, "actor_loss": -85.4054099052183, "actor_target_entropy": -1.0, "actor_entropy": 1.8518378849952453, "alpha_loss": 0.0026118192294116824, "alpha_value": 0.004471002402409835, "duration": 3.8385961055755615, "step": 200000}
{"episode_reward": 133.90875717068062, "episode": 1601.0, "batch_reward": 0.8555895223617553, "critic_loss": 2.1238092861175537, "actor_loss": -85.42972625248017, "actor_target_entropy": -1.0, "actor_entropy": 1.87133951224978, "alpha_loss": 0.0025828498690980413, "alpha_value": 0.004440477930550408, "duration": 7.8242104053497314, "step": 200125}
{"episode_reward": 95.61469589554682, "episode": 1602.0, "batch_reward": 0.8349690532684326, "critic_loss": 1.9270423374176024, "actor_loss": -85.3913452394547, "actor_target_entropy": -1.0, "actor_entropy": 1.8802685314609158, "alpha_loss": 0.0024198445053996457, "alpha_value": 0.004412232489751768, "duration": 3.842911720275879, "step": 200250}
{"episode_reward": 78.63100436769051, "episode": 1603.0, "batch_reward": 0.85263010597229, "critic_loss": 2.0716390047073365, "actor_loss": -85.39158521379743, "actor_target_entropy": -1.0, "actor_entropy": 1.8935120162509738, "alpha_loss": 0.0026091387752251376, "alpha_value": 0.004384554364345836, "duration": 3.8483073711395264, "step": 200375}
{"episode_reward": 179.93993470157636, "episode": 1604.0, "batch_reward": 0.8442617816925049, "critic_loss": 1.9952251224517823, "actor_loss": -85.3786114108178, "actor_target_entropy": -1.0, "actor_entropy": 1.9195883697079075, "alpha_loss": 0.0025547145614250293, "alpha_value": 0.004355789401780958, "duration": 3.8338096141815186, "step": 200500}
{"episode_reward": 68.89911708604137, "episode": 1605.0, "batch_reward": 0.8311883854866028, "critic_loss": 1.9829217176437377, "actor_loss": -85.35283672998823, "actor_target_entropy": -1.0, "actor_entropy": 1.9213979225310067, "alpha_loss": 0.0024995310841837808, "alpha_value": 0.004327981135424315, "duration": 3.839714765548706, "step": 200625}
{"episode_reward": 70.12671374552316, "episode": 1606.0, "batch_reward": 0.8500359840393067, "critic_loss": 2.0219508285522463, "actor_loss": -85.36460470384166, "actor_target_entropy": -1.0, "actor_entropy": 1.9295633416022024, "alpha_loss": 0.0026773282105193264, "alpha_value": 0.004300221720643847, "duration": 3.8377718925476074, "step": 200750}
{"episode_reward": 124.41644509401144, "episode": 1607.0, "batch_reward": 0.8495835299491883, "critic_loss": 2.0868005113601686, "actor_loss": -85.35894630068825, "actor_target_entropy": -1.0, "actor_entropy": 1.9321929254229107, "alpha_loss": 0.0025617657820620233, "alpha_value": 0.004272132848076413, "duration": 3.844264507293701, "step": 200875}
{"episode_reward": 101.58979334005163, "episode": 1608.0, "batch_reward": 0.8352178697586059, "critic_loss": 1.9951066989898683, "actor_loss": -85.31410204979682, "actor_target_entropy": -1.0, "actor_entropy": 1.9335547301077074, "alpha_loss": 0.0025331806541690903, "alpha_value": 0.004244542010744185, "duration": 3.8454458713531494, "step": 201000}
{"episode_reward": 163.4803108961903, "episode": 1609.0, "batch_reward": 0.8389140253067017, "critic_loss": 2.031597067832947, "actor_loss": -85.32625216529483, "actor_target_entropy": -1.0, "actor_entropy": 1.9392332368426852, "alpha_loss": 0.0026712570476183106, "alpha_value": 0.004217482691191944, "duration": 3.843170166015625, "step": 201125}
{"episode_reward": 28.933606019973237, "episode": 1610.0, "batch_reward": 0.8356903829574585, "critic_loss": 2.0548789081573484, "actor_loss": -85.29406036869172, "actor_target_entropy": -1.0, "actor_entropy": 1.9448157933450514, "alpha_loss": 0.0025695823377088435, "alpha_value": 0.00418989555467909, "duration": 3.8389718532562256, "step": 201250}
{"episode_reward": 104.37119073895398, "episode": 1611.0, "batch_reward": 0.8398068857192993, "critic_loss": 2.0408761472702026, "actor_loss": -85.2925785609654, "actor_target_entropy": -1.0, "actor_entropy": 1.9585778088796706, "alpha_loss": 0.0026653637307592565, "alpha_value": 0.004163416937642778, "duration": 3.841102123260498, "step": 201375}
{"episode_reward": 64.79976151991562, "episode": 1612.0, "batch_reward": 0.8514359221458435, "critic_loss": 2.086014621734619, "actor_loss": -85.2958601674726, "actor_target_entropy": -1.0, "actor_entropy": 1.9689154971030451, "alpha_loss": 0.0026939976678770636, "alpha_value": 0.004135668144063538, "duration": 3.830289125442505, "step": 201500}
{"episode_reward": 151.64770879709707, "episode": 1613.0, "batch_reward": 0.8326203761100769, "critic_loss": 2.0061302967071533, "actor_loss": -85.27110133095393, "actor_target_entropy": -1.0, "actor_entropy": 1.9741160547922527, "alpha_loss": 0.002598261578925072, "alpha_value": 0.0041096560190980415, "duration": 3.8495893478393555, "step": 201625}
{"episode_reward": 211.89995468568304, "episode": 1614.0, "batch_reward": 0.8557987461090087, "critic_loss": 2.290611406326294, "actor_loss": -85.26179725893083, "actor_target_entropy": -1.0, "actor_entropy": 1.9801334142684937, "alpha_loss": 0.0026243536567856227, "alpha_value": 0.00408290762802297, "duration": 3.835817337036133, "step": 201750}
{"episode_reward": 189.33873648728954, "episode": 1615.0, "batch_reward": 0.8376209454536439, "critic_loss": 2.0041818761825563, "actor_loss": -85.24692838154142, "actor_target_entropy": -1.0, "actor_entropy": 1.998316592640347, "alpha_loss": 0.0026500611556767827, "alpha_value": 0.0040577000691077204, "duration": 3.8467235565185547, "step": 201875}
{"episode_reward": 98.16133305487512, "episode": 1616.0, "batch_reward": 0.8419127459526062, "critic_loss": 2.016897925376892, "actor_loss": -85.25283493534211, "actor_target_entropy": -1.0, "actor_entropy": 2.004592449434342, "alpha_loss": 0.0024210138574069845, "alpha_value": 0.004032511930265254, "duration": 3.84116792678833, "step": 202000}
{"episode_reward": 123.78698606965055, "episode": 1617.0, "batch_reward": 0.8343925113677979, "critic_loss": 1.9474757108688354, "actor_loss": -85.22402881440662, "actor_target_entropy": -1.0, "actor_entropy": 2.0142644851926774, "alpha_loss": 0.0022399499494996336, "alpha_value": 0.004009957740287484, "duration": 3.8475542068481445, "step": 202125}
{"episode_reward": 55.543979122146354, "episode": 1618.0, "batch_reward": 0.8518918414115906, "critic_loss": 2.1092486772537233, "actor_loss": -85.2384990569084, "actor_target_entropy": -1.0, "actor_entropy": 2.020694132774107, "alpha_loss": 0.0023697906196297656, "alpha_value": 0.00398773665495691, "duration": 3.8367223739624023, "step": 202250}
{"episode_reward": 186.60773376208599, "episode": 1619.0, "batch_reward": 0.8519405446052551, "critic_loss": 2.0649005012512207, "actor_loss": -85.23531704857236, "actor_target_entropy": -1.0, "actor_entropy": 2.024717860751682, "alpha_loss": 0.00243292723427571, "alpha_value": 0.003964193294496619, "duration": 3.8343617916107178, "step": 202375}
{"episode_reward": 69.42640214158114, "episode": 1620.0, "batch_reward": 0.8404485478401184, "critic_loss": 2.051940393447876, "actor_loss": -85.20295112363753, "actor_target_entropy": -1.0, "actor_entropy": 2.02765566302884, "alpha_loss": 0.002216794836943248, "alpha_value": 0.0039416049297576325, "duration": 3.8416216373443604, "step": 202500}
{"episode_reward": 114.94405258623092, "episode": 1621.0, "batch_reward": 0.8374559578895568, "critic_loss": 1.9949849224090577, "actor_loss": -85.21835109165737, "actor_target_entropy": -1.0, "actor_entropy": 2.0305632939414373, "alpha_loss": 0.0024537843437717546, "alpha_value": 0.003919244589568521, "duration": 3.8443093299865723, "step": 202625}
{"episode_reward": 157.66829736941364, "episode": 1622.0, "batch_reward": 0.8531988959312439, "critic_loss": 2.1037731323242186, "actor_loss": -85.19674190398186, "actor_target_entropy": -1.0, "actor_entropy": 2.043034630437051, "alpha_loss": 0.002326203867625971, "alpha_value": 0.0038961424011386228, "duration": 3.829155921936035, "step": 202750}
{"episode_reward": 158.14155979912044, "episode": 1623.0, "batch_reward": 0.8564179611206054, "critic_loss": 2.131114616394043, "actor_loss": -85.2127938649011, "actor_target_entropy": -1.0, "actor_entropy": 2.0557130631946383, "alpha_loss": 0.0023667388706512396, "alpha_value": 0.003873852802588582, "duration": 3.8406078815460205, "step": 202875}
{"episode_reward": 180.47068838408987, "episode": 1624.0, "batch_reward": 0.8403987860679627, "critic_loss": 2.037588797092438, "actor_loss": -85.18531060987904, "actor_target_entropy": -1.0, "actor_entropy": 2.0657781939352713, "alpha_loss": 0.002351339448303465, "alpha_value": 0.003851321363202542, "duration": 3.8335635662078857, "step": 203000}
{"episode_reward": 138.67470494996542, "episode": 1625.0, "batch_reward": 0.8449627294540405, "critic_loss": 2.118977578163147, "actor_loss": -85.19502645825582, "actor_target_entropy": -1.0, "actor_entropy": 2.0719721809266107, "alpha_loss": 0.0021204487965737896, "alpha_value": 0.00382990900873358, "duration": 3.846071720123291, "step": 203125}
{"episode_reward": 144.57465920110621, "episode": 1626.0, "batch_reward": 0.847597427368164, "critic_loss": 2.137837627410889, "actor_loss": -85.16441554407919, "actor_target_entropy": -1.0, "actor_entropy": 2.076326493294008, "alpha_loss": 0.0021990388153015727, "alpha_value": 0.003809578889877712, "duration": 3.831862211227417, "step": 203250}
{"episode_reward": 154.3872369508527, "episode": 1627.0, "batch_reward": 0.8407932529449463, "critic_loss": 2.044374168395996, "actor_loss": -85.16531093536861, "actor_target_entropy": -1.0, "actor_entropy": 2.0826104784768726, "alpha_loss": 0.0021475281525728486, "alpha_value": 0.0037888876665654668, "duration": 3.84588623046875, "step": 203375}
{"episode_reward": 155.84662912868723, "episode": 1628.0, "batch_reward": 0.8464627542495727, "critic_loss": 2.0589659309387205, "actor_loss": -85.16689780450636, "actor_target_entropy": -1.0, "actor_entropy": 2.0744059008936726, "alpha_loss": 0.002224705651432516, "alpha_value": 0.0037681468920216245, "duration": 3.836972713470459, "step": 203500}
{"episode_reward": 193.12547493118512, "episode": 1629.0, "batch_reward": 0.8338448767662048, "critic_loss": 1.9984064798355103, "actor_loss": -85.15080733526321, "actor_target_entropy": -1.0, "actor_entropy": 2.07096743205237, "alpha_loss": 0.0021750087995776935, "alpha_value": 0.003746925056961141, "duration": 3.8460817337036133, "step": 203625}
{"episode_reward": 210.93760115080565, "episode": 1630.0, "batch_reward": 0.8477006273269654, "critic_loss": 1.9762395219802857, "actor_loss": -85.15371371853736, "actor_target_entropy": -1.0, "actor_entropy": 2.071999042264877, "alpha_loss": 0.0022020869552262967, "alpha_value": 0.0037267982811682266, "duration": 3.8351998329162598, "step": 203750}
{"episode_reward": 198.52817126045625, "episode": 1631.0, "batch_reward": 0.8621674880981446, "critic_loss": 2.1133201847076415, "actor_loss": -85.16747392926898, "actor_target_entropy": -1.0, "actor_entropy": 2.069369573441763, "alpha_loss": 0.002328313192323087, "alpha_value": 0.003705032350800672, "duration": 3.8391566276550293, "step": 203875}
{"episode_reward": 102.37059046722854, "episode": 1632.0, "batch_reward": 0.8398849787712097, "critic_loss": 2.0684515647888184, "actor_loss": -85.13027855657762, "actor_target_entropy": -1.0, "actor_entropy": 2.068943700482768, "alpha_loss": 0.0023732724085059618, "alpha_value": 0.0036826424685879773, "duration": 3.8434786796569824, "step": 204000}
{"episode_reward": 158.3794509739034, "episode": 1633.0, "batch_reward": 0.8495613741874695, "critic_loss": 2.0848932304382326, "actor_loss": -85.11940583728608, "actor_target_entropy": -1.0, "actor_entropy": 2.091098739987328, "alpha_loss": 0.002128747147729709, "alpha_value": 0.003662100403180222, "duration": 3.843770980834961, "step": 204125}
{"episode_reward": 141.01531740497342, "episode": 1634.0, "batch_reward": 0.8549858531951904, "critic_loss": 2.0817346630096436, "actor_loss": -85.13747246034684, "actor_target_entropy": -1.0, "actor_entropy": 2.1061034971667874, "alpha_loss": 0.002095647371231368, "alpha_value": 0.0036420499999060287, "duration": 3.8398704528808594, "step": 204250}
{"episode_reward": 217.30072972984783, "episode": 1635.0, "batch_reward": 0.8574673652648925, "critic_loss": 2.1275890436172484, "actor_loss": -85.13311040969123, "actor_target_entropy": -1.0, "actor_entropy": 2.1088083206661166, "alpha_loss": 0.0022244578881544016, "alpha_value": 0.0036217469045653566, "duration": 3.8443727493286133, "step": 204375}
{"episode_reward": 137.84254878395015, "episode": 1636.0, "batch_reward": 0.8410104832649231, "critic_loss": 2.0346783466339113, "actor_loss": -85.11213031891853, "actor_target_entropy": -1.0, "actor_entropy": 2.1058393447629866, "alpha_loss": 0.002191705689314873, "alpha_value": 0.003601436229740399, "duration": 3.8357064723968506, "step": 204500}
{"episode_reward": 38.06723836905341, "episode": 1637.0, "batch_reward": 0.8600081825256347, "critic_loss": 2.1198443756103518, "actor_loss": -85.13626692030165, "actor_target_entropy": -1.0, "actor_entropy": 2.1012747174217585, "alpha_loss": 0.0022722543937908042, "alpha_value": 0.003580393345362349, "duration": 3.8470511436462402, "step": 204625}
{"episode_reward": 60.40959381736053, "episode": 1638.0, "batch_reward": 0.8448878426551819, "critic_loss": 2.0039769916534422, "actor_loss": -85.10929673717868, "actor_target_entropy": -1.0, "actor_entropy": 2.106102789601972, "alpha_loss": 0.002157201999873524, "alpha_value": 0.003559936505748289, "duration": 3.837899684906006, "step": 204750}
{"episode_reward": 107.66300295796717, "episode": 1639.0, "batch_reward": 0.8521774253845215, "critic_loss": 2.116639049530029, "actor_loss": -85.11383807469927, "actor_target_entropy": -1.0, "actor_entropy": 2.1152668756151956, "alpha_loss": 0.0021759425252971666, "alpha_value": 0.003539698273114005, "duration": 3.842698574066162, "step": 204875}
{"episode_reward": 172.83855646732778, "episode": 1640.0, "batch_reward": 0.8622270011901856, "critic_loss": 2.1967559642791747, "actor_loss": -85.13037995369204, "actor_target_entropy": -1.0, "actor_entropy": 2.1165580288056405, "alpha_loss": 0.0021306567190725718, "alpha_value": 0.003519583108926645, "duration": 3.829188823699951, "step": 205000}
{"episode_reward": 58.126573843224016, "episode": 1641.0, "batch_reward": 0.8418772397041321, "critic_loss": 1.9856464242935181, "actor_loss": -85.10329994322761, "actor_target_entropy": -1.0, "actor_entropy": 2.1120718093145463, "alpha_loss": 0.002177625680194488, "alpha_value": 0.0035000116752795974, "duration": 3.847151279449463, "step": 205125}
{"episode_reward": 92.97112239034189, "episode": 1642.0, "batch_reward": 0.8537524161338806, "critic_loss": 2.0607298097610474, "actor_loss": -85.12227421422159, "actor_target_entropy": -1.0, "actor_entropy": 2.110102930376607, "alpha_loss": 0.002134951392015923, "alpha_value": 0.0034799441768812714, "duration": 3.8405261039733887, "step": 205250}
{"episode_reward": 49.545281241161916, "episode": 1643.0, "batch_reward": 0.8500569505691529, "critic_loss": 2.0956354398727415, "actor_loss": -85.11100151425316, "actor_target_entropy": -1.0, "actor_entropy": 2.103696520366366, "alpha_loss": 0.0022005100728988295, "alpha_value": 0.0034601403604409818, "duration": 3.837934732437134, "step": 205375}
{"episode_reward": 113.94881021737282, "episode": 1644.0, "batch_reward": 0.8503588819503785, "critic_loss": 2.044861011505127, "actor_loss": -85.1083370331795, "actor_target_entropy": -1.0, "actor_entropy": 2.106000300376646, "alpha_loss": 0.002238243459648783, "alpha_value": 0.0034394334243922045, "duration": 3.832949161529541, "step": 205500}
{"episode_reward": 127.06956261691063, "episode": 1645.0, "batch_reward": 0.8579997444152831, "critic_loss": 2.085340269088745, "actor_loss": -85.1153077625093, "actor_target_entropy": -1.0, "actor_entropy": 2.113763415624225, "alpha_loss": 0.002271562818408249, "alpha_value": 0.0034192320114623635, "duration": 3.834900140762329, "step": 205625}
{"episode_reward": 66.3831118645896, "episode": 1646.0, "batch_reward": 0.8596661071777344, "critic_loss": 2.1061167459487917, "actor_loss": -85.11764194119361, "actor_target_entropy": -1.0, "actor_entropy": 2.1176912861485637, "alpha_loss": 0.0021110654699676218, "alpha_value": 0.00339951879826882, "duration": 3.840240001678467, "step": 205750}
{"episode_reward": 225.89221958208773, "episode": 1647.0, "batch_reward": 0.8510169081687927, "critic_loss": 2.0622391290664672, "actor_loss": -85.11106630355593, "actor_target_entropy": -1.0, "actor_entropy": 2.1122660712590293, "alpha_loss": 0.002149397326219413, "alpha_value": 0.003380159210897231, "duration": 3.842165946960449, "step": 205875}
{"episode_reward": 156.51059815197576, "episode": 1648.0, "batch_reward": 0.8524116950035096, "critic_loss": 2.130966471672058, "actor_loss": -85.10639006091702, "actor_target_entropy": -1.0, "actor_entropy": 2.125219052837741, "alpha_loss": 0.0021563698593977717, "alpha_value": 0.003361003568204085, "duration": 3.8238441944122314, "step": 206000}
{"episode_reward": 171.514085670292, "episode": 1649.0, "batch_reward": 0.8532549166679382, "critic_loss": 2.0725524559020996, "actor_loss": -85.11928134494357, "actor_target_entropy": -1.0, "actor_entropy": 2.1197354604327487, "alpha_loss": 0.002231143941614954, "alpha_value": 0.003341287773216492, "duration": 3.838679552078247, "step": 206125}
{"episode_reward": 41.193543519676346, "episode": 1650.0, "batch_reward": 0.8574798145294189, "critic_loss": 2.0778182401657106, "actor_loss": -85.1289808211788, "actor_target_entropy": -1.0, "actor_entropy": 2.1123455416771675, "alpha_loss": 0.002232828763343634, "alpha_value": 0.003321155139890348, "duration": 3.8355884552001953, "step": 206250}
{"episode_reward": 78.61846093233089, "episode": 1651.0, "batch_reward": 0.8377620358467102, "critic_loss": 2.025430458068848, "actor_loss": -85.09354449075366, "actor_target_entropy": -1.0, "actor_entropy": 2.1179422651018416, "alpha_loss": 0.002175329726592209, "alpha_value": 0.003301387216255622, "duration": 3.8462002277374268, "step": 206375}
{"episode_reward": 162.13736865097468, "episode": 1652.0, "batch_reward": 0.8506368584632874, "critic_loss": 2.061444133758545, "actor_loss": -85.0914435848113, "actor_target_entropy": -1.0, "actor_entropy": 2.1180265180526243, "alpha_loss": 0.002231792528970888, "alpha_value": 0.00328208758626662, "duration": 3.839087963104248, "step": 206500}
{"episode_reward": 131.78107481224149, "episode": 1653.0, "batch_reward": 0.849909571647644, "critic_loss": 2.074101781845093, "actor_loss": -85.10423109266493, "actor_target_entropy": -1.0, "actor_entropy": 2.1269218656751843, "alpha_loss": 0.0022296052248705, "alpha_value": 0.0032625055496634933, "duration": 3.8468618392944336, "step": 206625}
{"episode_reward": 103.74357241421035, "episode": 1654.0, "batch_reward": 0.8400257849693298, "critic_loss": 1.986969515800476, "actor_loss": -85.08703022618448, "actor_target_entropy": -1.0, "actor_entropy": 2.1182820258602018, "alpha_loss": 0.0022532117605629947, "alpha_value": 0.003242923854828466, "duration": 3.8385961055755615, "step": 206750}
{"episode_reward": 126.08547136734286, "episode": 1655.0, "batch_reward": 0.842094530582428, "critic_loss": 1.9810477857589721, "actor_loss": -85.08232237800719, "actor_target_entropy": -1.0, "actor_entropy": 2.109873014783102, "alpha_loss": 0.0021280323391750693, "alpha_value": 0.0032239080765288407, "duration": 3.8452389240264893, "step": 206875}
{"episode_reward": 179.84380232519914, "episode": 1656.0, "batch_reward": 0.8526215705871582, "critic_loss": 2.0682815313339233, "actor_loss": -85.08379007154896, "actor_target_entropy": -1.0, "actor_entropy": 2.1124954223632812, "alpha_loss": 0.0022087982037074625, "alpha_value": 0.0032047197252931705, "duration": 3.838414430618286, "step": 207000}
{"episode_reward": 56.85399399064967, "episode": 1657.0, "batch_reward": 0.8324517397880554, "critic_loss": 2.0153558473587037, "actor_loss": -85.07675631084139, "actor_target_entropy": -1.0, "actor_entropy": 2.104237950037396, "alpha_loss": 0.002261427893591601, "alpha_value": 0.0031853986925450524, "duration": 3.8259639739990234, "step": 207125}
{"episode_reward": 151.41940704307635, "episode": 1658.0, "batch_reward": 0.8520392942428588, "critic_loss": 2.039491678237915, "actor_loss": -85.07658804616621, "actor_target_entropy": -1.0, "actor_entropy": 2.1012773359975507, "alpha_loss": 0.00233210856846023, "alpha_value": 0.0031656264833085862, "duration": 3.840015172958374, "step": 207250}
{"episode_reward": 208.46977875333542, "episode": 1659.0, "batch_reward": 0.8433365130424499, "critic_loss": 2.004605694770813, "actor_loss": -85.06429218110584, "actor_target_entropy": -1.0, "actor_entropy": 2.1011481966291154, "alpha_loss": 0.002345369761026213, "alpha_value": 0.0031458959175880547, "duration": 3.8398072719573975, "step": 207375}
{"episode_reward": 145.31698728975968, "episode": 1660.0, "batch_reward": 0.8427478995323181, "critic_loss": 2.089659507751465, "actor_loss": -85.05890470935452, "actor_target_entropy": -1.0, "actor_entropy": 2.099502763440532, "alpha_loss": 0.002268054608007773, "alpha_value": 0.0031260912552923486, "duration": 3.8352015018463135, "step": 207500}
{"episode_reward": 154.09670970853225, "episode": 1661.0, "batch_reward": 0.8587974734306335, "critic_loss": 2.0983039360046387, "actor_loss": -85.05678461468409, "actor_target_entropy": -1.0, "actor_entropy": 2.1107669406467013, "alpha_loss": 0.0022205327386184345, "alpha_value": 0.0031076416358353227, "duration": 3.8379108905792236, "step": 207625}
{"episode_reward": 42.44355184438381, "episode": 1662.0, "batch_reward": 0.8455322570800782, "critic_loss": 2.0422580213546753, "actor_loss": -85.06267744495022, "actor_target_entropy": -1.0, "actor_entropy": 2.101478868915189, "alpha_loss": 0.002118046560715283, "alpha_value": 0.0030896798304624515, "duration": 3.8256912231445312, "step": 207750}
{"episode_reward": 68.17020009307525, "episode": 1663.0, "batch_reward": 0.8447314510345459, "critic_loss": 2.066200322151184, "actor_loss": -85.05970994253008, "actor_target_entropy": -1.0, "actor_entropy": 2.0891241346086775, "alpha_loss": 0.0022041151994868875, "alpha_value": 0.003071474965233959, "duration": 3.846593141555786, "step": 207875}
{"episode_reward": 200.49846484589125, "episode": 1664.0, "batch_reward": 0.8600801668167114, "critic_loss": 2.1029176139831542, "actor_loss": -85.0733995745259, "actor_target_entropy": -1.0, "actor_entropy": 2.0800570518739763, "alpha_loss": 0.0022458475319698692, "alpha_value": 0.0030529685867529675, "duration": 3.8374664783477783, "step": 208000}
{"episode_reward": 176.83956274762522, "episode": 1665.0, "batch_reward": 0.8606055045127868, "critic_loss": 2.109859076499939, "actor_loss": -85.08244820246621, "actor_target_entropy": -1.0, "actor_entropy": 2.0758964296371216, "alpha_loss": 0.0022801860135846902, "alpha_value": 0.0030342714893065183, "duration": 3.838144063949585, "step": 208125}
{"episode_reward": 81.50053713489662, "episode": 1666.0, "batch_reward": 0.8612935380935669, "critic_loss": 2.1077907333374024, "actor_loss": -85.07368567682082, "actor_target_entropy": -1.0, "actor_entropy": 2.0850329399108887, "alpha_loss": 0.002373524485231047, "alpha_value": 0.003015327608677304, "duration": 3.8398947715759277, "step": 208250}
{"episode_reward": 151.1656374704989, "episode": 1667.0, "batch_reward": 0.8519501819610595, "critic_loss": 2.03106561088562, "actor_loss": -85.07737574501643, "actor_target_entropy": -1.0, "actor_entropy": 2.0764985008845254, "alpha_loss": 0.002421066952159717, "alpha_value": 0.0029960064868500887, "duration": 3.840176820755005, "step": 208375}
{"episode_reward": 54.69808344532589, "episode": 1668.0, "batch_reward": 0.849409893989563, "critic_loss": 2.04315661239624, "actor_loss": -85.06350572647587, "actor_target_entropy": -1.0, "actor_entropy": 2.0840344275197675, "alpha_loss": 0.0023186399353547923, "alpha_value": 0.0029766996914876893, "duration": 3.8333420753479004, "step": 208500}
{"episode_reward": 51.11233141290476, "episode": 1669.0, "batch_reward": 0.8448574180603028, "critic_loss": 2.02294220161438, "actor_loss": -85.04554978628008, "actor_target_entropy": -1.0, "actor_entropy": 2.1071564961993503, "alpha_loss": 0.00212606508100021, "alpha_value": 0.00295889250404334, "duration": 3.836176872253418, "step": 208625}
{"episode_reward": 85.39759220865007, "episode": 1670.0, "batch_reward": 0.8419420166015625, "critic_loss": 2.0606526565551757, "actor_loss": -85.04088383336222, "actor_target_entropy": -1.0, "actor_entropy": 2.114095410993022, "alpha_loss": 0.002144052992544828, "alpha_value": 0.0029421696770746955, "duration": 3.8326399326324463, "step": 208750}
{"episode_reward": 51.775817510552336, "episode": 1671.0, "batch_reward": 0.8425090999603272, "critic_loss": 2.023291584968567, "actor_loss": -85.03902362641834, "actor_target_entropy": -1.0, "actor_entropy": 2.107754344031924, "alpha_loss": 0.0022688892463015187, "alpha_value": 0.002924434019123565, "duration": 3.839452028274536, "step": 208875}
{"episode_reward": 83.86339777118285, "episode": 1672.0, "batch_reward": 0.8632269582748413, "critic_loss": 2.138046844482422, "actor_loss": -85.0593753937752, "actor_target_entropy": -1.0, "actor_entropy": 2.1176103622682634, "alpha_loss": 0.0021304723322241297, "alpha_value": 0.0029072361521682764, "duration": 3.833146333694458, "step": 209000}
{"episode_reward": 131.25673708627184, "episode": 1673.0, "batch_reward": 0.8567518801689148, "critic_loss": 2.113257905960083, "actor_loss": -85.04771701873295, "actor_target_entropy": -1.0, "actor_entropy": 2.128914893619598, "alpha_loss": 0.0020585463932966666, "alpha_value": 0.0028905205070469463, "duration": 3.8466527462005615, "step": 209125}
{"episode_reward": 182.02978584980073, "episode": 1674.0, "batch_reward": 0.8611250033378601, "critic_loss": 2.1004536027908327, "actor_loss": -85.06661630445912, "actor_target_entropy": -1.0, "actor_entropy": 2.136914837744928, "alpha_loss": 0.0019645667203041094, "alpha_value": 0.002874884848295572, "duration": 3.837244749069214, "step": 209250}
{"episode_reward": 40.17051841286618, "episode": 1675.0, "batch_reward": 0.8663470697402954, "critic_loss": 2.1090124855041505, "actor_loss": -85.07725633893695, "actor_target_entropy": -1.0, "actor_entropy": 2.1402652377174016, "alpha_loss": 0.001999184481858734, "alpha_value": 0.0028590553853915365, "duration": 3.8434102535247803, "step": 209375}
{"episode_reward": 113.99023734149897, "episode": 1676.0, "batch_reward": 0.8540751957893371, "critic_loss": 2.086258412361145, "actor_loss": -85.06580414310578, "actor_target_entropy": -1.0, "actor_entropy": 2.1519312858581543, "alpha_loss": 0.002047452435363084, "alpha_value": 0.0028435469334658057, "duration": 3.8377881050109863, "step": 209500}
{"episode_reward": 147.39548441572464, "episode": 1677.0, "batch_reward": 0.8531171517372131, "critic_loss": 2.0691897258758547, "actor_loss": -85.07531241765098, "actor_target_entropy": -1.0, "actor_entropy": 2.1454785362122553, "alpha_loss": 0.001935984035732136, "alpha_value": 0.00282787167587515, "duration": 3.842367649078369, "step": 209625}
{"episode_reward": 119.87266121683612, "episode": 1678.0, "batch_reward": 0.8741114339828491, "critic_loss": 2.191409104347229, "actor_loss": -85.10872871645036, "actor_target_entropy": -1.0, "actor_entropy": 2.126363415871897, "alpha_loss": 0.00210123875125822, "alpha_value": 0.0028117879126912347, "duration": 3.838287353515625, "step": 209750}
{"episode_reward": 116.91177849608873, "episode": 1679.0, "batch_reward": 0.8453357567787171, "critic_loss": 2.0497633228302004, "actor_loss": -85.06973872109064, "actor_target_entropy": -1.0, "actor_entropy": 2.1285358005099826, "alpha_loss": 0.002146379517701765, "alpha_value": 0.0027948956405225715, "duration": 3.8415467739105225, "step": 209875}
{"episode_reward": 176.5522827982062, "episode": 1680.0, "batch_reward": 0.8424546556472778, "critic_loss": 2.024609210014343, "actor_loss": -85.07089245703912, "actor_target_entropy": -1.0, "actor_entropy": 2.130112571101035, "alpha_loss": 0.002045129369493694, "alpha_value": 0.002778764253388755, "duration": 3.836169958114624, "step": 210000}
{"episode_reward": 165.1566717267934, "episode": 1681.0, "batch_reward": 0.8450264592170715, "critic_loss": 2.042208312034607, "actor_loss": -85.07752421545604, "actor_target_entropy": -1.0, "actor_entropy": 2.1178005006578235, "alpha_loss": 0.002081693970553932, "alpha_value": 0.0027627164563262434, "duration": 7.8155529499053955, "step": 210125}
{"episode_reward": 112.0716196251609, "episode": 1682.0, "batch_reward": 0.852602605342865, "critic_loss": 2.0706991491317748, "actor_loss": -85.07847262967017, "actor_target_entropy": -1.0, "actor_entropy": 2.1062976006538636, "alpha_loss": 0.002168026694562286, "alpha_value": 0.002746234998912782, "duration": 3.8373732566833496, "step": 210250}
{"episode_reward": 229.1806804246713, "episode": 1683.0, "batch_reward": 0.8514233565330506, "critic_loss": 2.013745524406433, "actor_loss": -85.08333369663784, "actor_target_entropy": -1.0, "actor_entropy": 2.111744668748644, "alpha_loss": 0.0021982640841059268, "alpha_value": 0.0027292513145439515, "duration": 3.8372976779937744, "step": 210375}
{"episode_reward": 38.71040768283322, "episode": 1684.0, "batch_reward": 0.8489070725440979, "critic_loss": 2.0206147365570066, "actor_loss": -85.07577773063413, "actor_target_entropy": -1.0, "actor_entropy": 2.1168040460155857, "alpha_loss": 0.0020713211476592525, "alpha_value": 0.002712752100323489, "duration": 3.833773374557495, "step": 210500}
{"episode_reward": 129.51512879619025, "episode": 1685.0, "batch_reward": 0.8470337901115418, "critic_loss": 2.0432483072280885, "actor_loss": -85.06699492439391, "actor_target_entropy": -1.0, "actor_entropy": 2.1163635405283125, "alpha_loss": 0.0020270556255820252, "alpha_value": 0.0026973069663220606, "duration": 3.8340485095977783, "step": 210625}
{"episode_reward": 68.02392279993077, "episode": 1686.0, "batch_reward": 0.8329577035903931, "critic_loss": 2.002165185928345, "actor_loss": -85.048891252087, "actor_target_entropy": -1.0, "actor_entropy": 2.11099269313197, "alpha_loss": 0.0020543955503061653, "alpha_value": 0.002681585547200885, "duration": 3.8394665718078613, "step": 210750}
{"episode_reward": 167.1854157618526, "episode": 1687.0, "batch_reward": 0.8562711358070374, "critic_loss": 2.119919711112976, "actor_loss": -85.07876962328714, "actor_target_entropy": -1.0, "actor_entropy": 2.1067818232945035, "alpha_loss": 0.0021574370163892, "alpha_value": 0.002665539751409666, "duration": 3.8409860134124756, "step": 210875}
{"episode_reward": 115.26288467690641, "episode": 1688.0, "batch_reward": 0.8515338921546936, "critic_loss": 2.1072670936584474, "actor_loss": -85.05703181605185, "actor_target_entropy": -1.0, "actor_entropy": 2.10976408373925, "alpha_loss": 0.002120649937780634, "alpha_value": 0.0026493651050812994, "duration": 3.8375864028930664, "step": 211000}
{"episode_reward": 64.14133518587677, "episode": 1689.0, "batch_reward": 0.8473059978485108, "critic_loss": 2.062670413017273, "actor_loss": -85.05879477849082, "actor_target_entropy": -1.0, "actor_entropy": 2.1150889169602167, "alpha_loss": 0.0019975281024854335, "alpha_value": 0.0026338132860281773, "duration": 3.8433187007904053, "step": 211125}
{"episode_reward": 131.7812347766997, "episode": 1690.0, "batch_reward": 0.8667192134857178, "critic_loss": 2.1411005029678343, "actor_loss": -85.08278988253686, "actor_target_entropy": -1.0, "actor_entropy": 2.1317984365647837, "alpha_loss": 0.002041107638844199, "alpha_value": 0.0026184102731242457, "duration": 3.832920789718628, "step": 211250}
{"episode_reward": 77.89011668212189, "episode": 1691.0, "batch_reward": 0.845773675441742, "critic_loss": 2.052285020828247, "actor_loss": -85.07855091397724, "actor_target_entropy": -1.0, "actor_entropy": 2.1272422396947466, "alpha_loss": 0.001955790201290732, "alpha_value": 0.0026038990717855226, "duration": 3.847057580947876, "step": 211375}
{"episode_reward": 145.3831132512637, "episode": 1692.0, "batch_reward": 0.8442383584976196, "critic_loss": 1.9976052856445312, "actor_loss": -85.05480157175371, "actor_target_entropy": -1.0, "actor_entropy": 2.1363696744365077, "alpha_loss": 0.0019399614097745789, "alpha_value": 0.0025889436043250807, "duration": 3.8310699462890625, "step": 211500}
{"episode_reward": 82.36639190455945, "episode": 1693.0, "batch_reward": 0.8559579539299011, "critic_loss": 2.0995978507995607, "actor_loss": -85.05895669119698, "actor_target_entropy": -1.0, "actor_entropy": 2.149033228556315, "alpha_loss": 0.0018703552667007205, "alpha_value": 0.0025747702205589627, "duration": 3.8415913581848145, "step": 211625}
{"episode_reward": 212.75956135449803, "episode": 1694.0, "batch_reward": 0.8458010807037354, "critic_loss": 2.025715147972107, "actor_loss": -85.05440188992408, "actor_target_entropy": -1.0, "actor_entropy": 2.159107208251953, "alpha_loss": 0.0018650392772659899, "alpha_value": 0.002561111331061362, "duration": 3.836129903793335, "step": 211750}
{"episode_reward": 59.14191661474126, "episode": 1695.0, "batch_reward": 0.8449624714851379, "critic_loss": 2.0556453676223754, "actor_loss": -85.05132923428974, "actor_target_entropy": -1.0, "actor_entropy": 2.1602405669197204, "alpha_loss": 0.001795049410753159, "alpha_value": 0.0025470141722292597, "duration": 3.839597463607788, "step": 211875}
{"episode_reward": 197.9548330481677, "episode": 1696.0, "batch_reward": 0.8391891474723816, "critic_loss": 2.0050293416976928, "actor_loss": -85.03757784443516, "actor_target_entropy": -1.0, "actor_entropy": 2.166359301536314, "alpha_loss": 0.0017873299610425507, "alpha_value": 0.002533725241478758, "duration": 3.841409921646118, "step": 212000}
{"episode_reward": 160.1389640249428, "episode": 1697.0, "batch_reward": 0.8606801857948303, "critic_loss": 2.1581808605194093, "actor_loss": -85.05251566569011, "actor_target_entropy": -1.0, "actor_entropy": 2.1574958165486655, "alpha_loss": 0.0018276373905661916, "alpha_value": 0.0025201015335957395, "duration": 3.8305211067199707, "step": 212125}
{"episode_reward": 189.62215797969213, "episode": 1698.0, "batch_reward": 0.835841061592102, "critic_loss": 1.999161551475525, "actor_loss": -85.03103846888388, "actor_target_entropy": -1.0, "actor_entropy": 2.1617175225288636, "alpha_loss": 0.0018661597982094053, "alpha_value": 0.002506339386446587, "duration": 3.8347678184509277, "step": 212250}
{"episode_reward": 135.69808892502402, "episode": 1699.0, "batch_reward": 0.8470828261375427, "critic_loss": 2.0375497283935546, "actor_loss": -85.04076082744295, "actor_target_entropy": -1.0, "actor_entropy": 2.157785445924789, "alpha_loss": 0.0018071970100411111, "alpha_value": 0.002492245383079853, "duration": 3.8425464630126953, "step": 212375}
{"episode_reward": 83.84952221649795, "episode": 1700.0, "batch_reward": 0.8763157835006714, "critic_loss": 2.1990846309661864, "actor_loss": -85.06862911101311, "actor_target_entropy": -1.0, "actor_entropy": 2.158889247525123, "alpha_loss": 0.0018573460730558803, "alpha_value": 0.0024784183213707052, "duration": 3.83642578125, "step": 212500}
{"episode_reward": 46.83451157333677, "episode": 1701.0, "batch_reward": 0.8394770860671997, "critic_loss": 2.0027493391036986, "actor_loss": -85.03931354341053, "actor_target_entropy": -1.0, "actor_entropy": 2.17644406878759, "alpha_loss": 0.0018248856187768516, "alpha_value": 0.002464644163634201, "duration": 3.845482349395752, "step": 212625}
{"episode_reward": 195.0707517270136, "episode": 1702.0, "batch_reward": 0.8550394234657288, "critic_loss": 2.047336148262024, "actor_loss": -85.04920147311303, "actor_target_entropy": -1.0, "actor_entropy": 2.1775606370741323, "alpha_loss": 0.0017335895569093765, "alpha_value": 0.0024513371747274357, "duration": 3.834949493408203, "step": 212750}
{"episode_reward": 123.39270924740617, "episode": 1703.0, "batch_reward": 0.855946077823639, "critic_loss": 2.046226643562317, "actor_loss": -85.0538344610305, "actor_target_entropy": -1.0, "actor_entropy": 2.1760830652146113, "alpha_loss": 0.0017658444583445552, "alpha_value": 0.0024383549597079717, "duration": 3.8397650718688965, "step": 212875}
{"episode_reward": 126.46466036643089, "episode": 1704.0, "batch_reward": 0.8424139795303345, "critic_loss": 2.0787441024780273, "actor_loss": -85.03267743510585, "actor_target_entropy": -1.0, "actor_entropy": 2.170386529737903, "alpha_loss": 0.0018072928125489383, "alpha_value": 0.0024247978298795755, "duration": 3.830510139465332, "step": 213000}
{"episode_reward": 180.59427169593627, "episode": 1705.0, "batch_reward": 0.8641729063987732, "critic_loss": 2.1634788484573364, "actor_loss": -85.05209689670139, "actor_target_entropy": -1.0, "actor_entropy": 2.1789914085751487, "alpha_loss": 0.001719723778983785, "alpha_value": 0.0024111280488305653, "duration": 3.8388733863830566, "step": 213125}
{"episode_reward": 60.18614077074929, "episode": 1706.0, "batch_reward": 0.8646604914665222, "critic_loss": 2.099381693840027, "actor_loss": -85.07002935101909, "actor_target_entropy": -1.0, "actor_entropy": 2.181717380400627, "alpha_loss": 0.0015900725810488144, "alpha_value": 0.0023987119942914335, "duration": 3.8344924449920654, "step": 213250}
{"episode_reward": 76.91564906293137, "episode": 1707.0, "batch_reward": 0.8540105204582215, "critic_loss": 2.100191495895386, "actor_loss": -85.06324683295355, "actor_target_entropy": -1.0, "actor_entropy": 2.1734669246370832, "alpha_loss": 0.0017364923629747142, "alpha_value": 0.002386517262035672, "duration": 3.8417670726776123, "step": 213375}
{"episode_reward": 149.9291321288164, "episode": 1708.0, "batch_reward": 0.8498978505134582, "critic_loss": 2.10058895778656, "actor_loss": -85.05438367782101, "actor_target_entropy": -1.0, "actor_entropy": 2.1716777893804733, "alpha_loss": 0.0016594102095452048, "alpha_value": 0.002373403351033841, "duration": 3.8387036323547363, "step": 213500}
{"episode_reward": 233.1253388884982, "episode": 1709.0, "batch_reward": 0.849480092048645, "critic_loss": 2.0531530952453614, "actor_loss": -85.05690668499659, "actor_target_entropy": -1.0, "actor_entropy": 2.179262918139261, "alpha_loss": 0.001546403966910605, "alpha_value": 0.002361009472706575, "duration": 3.839512586593628, "step": 213625}
{"episode_reward": 149.37954308281724, "episode": 1710.0, "batch_reward": 0.8625027079582215, "critic_loss": 2.117941390991211, "actor_loss": -85.0692971752536, "actor_target_entropy": -1.0, "actor_entropy": 2.1797595331745763, "alpha_loss": 0.0017075443043253354, "alpha_value": 0.002348716512600275, "duration": 3.835033416748047, "step": 213750}
{"episode_reward": 218.38482369983703, "episode": 1711.0, "batch_reward": 0.865037383556366, "critic_loss": 2.0890382432937624, "actor_loss": -85.09222981286428, "actor_target_entropy": -1.0, "actor_entropy": 2.167813952006991, "alpha_loss": 0.0017436937787496144, "alpha_value": 0.0023355216100804897, "duration": 3.838681936264038, "step": 213875}
{"episode_reward": 111.51892912950977, "episode": 1712.0, "batch_reward": 0.8662825832366944, "critic_loss": 2.1607121305465697, "actor_loss": -85.07882985761088, "actor_target_entropy": -1.0, "actor_entropy": 2.1560995040401334, "alpha_loss": 0.0017732606427143178, "alpha_value": 0.002322131229797036, "duration": 3.83594012260437, "step": 214000}
{"episode_reward": 201.85980909815692, "episode": 1713.0, "batch_reward": 0.8493548851013184, "critic_loss": 2.0164767150878906, "actor_loss": -85.07612779405382, "actor_target_entropy": -1.0, "actor_entropy": 2.1484958860609265, "alpha_loss": 0.001640656831792541, "alpha_value": 0.0023092717186743873, "duration": 3.845268726348877, "step": 214125}
{"episode_reward": 162.13578161131565, "episode": 1714.0, "batch_reward": 0.8622630314826966, "critic_loss": 2.100873822212219, "actor_loss": -85.09231075163811, "actor_target_entropy": -1.0, "actor_entropy": 2.140727981444328, "alpha_loss": 0.0018106439684127127, "alpha_value": 0.002296182384017335, "duration": 3.8334805965423584, "step": 214250}
{"episode_reward": 185.05127564766667, "episode": 1715.0, "batch_reward": 0.8547857437133789, "critic_loss": 2.0790607099533083, "actor_loss": -85.09348999507843, "actor_target_entropy": -1.0, "actor_entropy": 2.1401887167067755, "alpha_loss": 0.0018544257396743411, "alpha_value": 0.00228228777203874, "duration": 3.8444132804870605, "step": 214375}
{"episode_reward": 77.12029744319787, "episode": 1716.0, "batch_reward": 0.8728171606063843, "critic_loss": 2.17986936378479, "actor_loss": -85.10193264868951, "actor_target_entropy": -1.0, "actor_entropy": 2.141035541411369, "alpha_loss": 0.0018064352015273706, "alpha_value": 0.002268355082983976, "duration": 3.8288943767547607, "step": 214500}
{"episode_reward": 239.83518879173974, "episode": 1717.0, "batch_reward": 0.840900634765625, "critic_loss": 2.0768107652664183, "actor_loss": -85.07871863955543, "actor_target_entropy": -1.0, "actor_entropy": 2.143481633019826, "alpha_loss": 0.0017683901010997712, "alpha_value": 0.0022550577116297967, "duration": 3.849181890487671, "step": 214625}
{"episode_reward": 172.72324666185943, "episode": 1718.0, "batch_reward": 0.8559859533309937, "critic_loss": 2.0622214183807372, "actor_loss": -85.0899292730516, "actor_target_entropy": -1.0, "actor_entropy": 2.139388315139278, "alpha_loss": 0.0018161331648908316, "alpha_value": 0.0022416002187086908, "duration": 3.833988666534424, "step": 214750}
{"episode_reward": 120.24511658626113, "episode": 1719.0, "batch_reward": 0.8637245035171509, "critic_loss": 2.148082902908325, "actor_loss": -85.09725685725137, "actor_target_entropy": -1.0, "actor_entropy": 2.1401539757138206, "alpha_loss": 0.0018017412096794163, "alpha_value": 0.00222813959196273, "duration": 3.846588611602783, "step": 214875}
{"episode_reward": 133.10161726304034, "episode": 1720.0, "batch_reward": 0.8684221963882446, "critic_loss": 2.143392476081848, "actor_loss": -85.11211432180097, "actor_target_entropy": -1.0, "actor_entropy": 2.1402034144247732, "alpha_loss": 0.0018497541830349233, "alpha_value": 0.0022147162394847617, "duration": 3.8459527492523193, "step": 215000}
{"episode_reward": 235.753831214533, "episode": 1721.0, "batch_reward": 0.8510204367637634, "critic_loss": 2.0353734436035156, "actor_loss": -85.10710870651971, "actor_target_entropy": -1.0, "actor_entropy": 2.1282179544842434, "alpha_loss": 0.0018650604271522118, "alpha_value": 0.0022009639135700805, "duration": 3.8417255878448486, "step": 215125}
{"episode_reward": 182.9198658217184, "episode": 1722.0, "batch_reward": 0.8390603199005127, "critic_loss": 1.9900011615753175, "actor_loss": -85.08148550218151, "actor_target_entropy": -1.0, "actor_entropy": 2.1171869001080914, "alpha_loss": 0.0018703963930508302, "alpha_value": 0.0021873482888130663, "duration": 3.8444581031799316, "step": 215250}
{"episode_reward": 66.49527664684284, "episode": 1723.0, "batch_reward": 0.8540710740089417, "critic_loss": 2.1366453285217286, "actor_loss": -85.09350767589751, "actor_target_entropy": -1.0, "actor_entropy": 2.110762323651995, "alpha_loss": 0.0019444652799783008, "alpha_value": 0.0021734437117313142, "duration": 3.846073865890503, "step": 215375}
{"episode_reward": 71.7410980063083, "episode": 1724.0, "batch_reward": 0.8414222807884216, "critic_loss": 2.0152978506088255, "actor_loss": -85.07281850999401, "actor_target_entropy": -1.0, "actor_entropy": 2.1060695186738045, "alpha_loss": 0.0019481801202580814, "alpha_value": 0.0021594335161851256, "duration": 3.836520195007324, "step": 215500}
{"episode_reward": 179.89599338371215, "episode": 1725.0, "batch_reward": 0.851262044429779, "critic_loss": 2.088110101699829, "actor_loss": -85.07613990420387, "actor_target_entropy": -1.0, "actor_entropy": 2.098857425508045, "alpha_loss": 0.0019337426896931396, "alpha_value": 0.002145514169616923, "duration": 3.8521761894226074, "step": 215625}
{"episode_reward": 167.72159203863526, "episode": 1726.0, "batch_reward": 0.8556286315917969, "critic_loss": 2.160359266281128, "actor_loss": -85.08455707180885, "actor_target_entropy": -1.0, "actor_entropy": 2.101750450749551, "alpha_loss": 0.001920596910490384, "alpha_value": 0.0021320202240591056, "duration": 3.8304085731506348, "step": 215750}
{"episode_reward": 163.65704118839136, "episode": 1727.0, "batch_reward": 0.8651479616165161, "critic_loss": 2.0591574716567993, "actor_loss": -85.09458257281591, "actor_target_entropy": -1.0, "actor_entropy": 2.104359899248396, "alpha_loss": 0.00188222119311196, "alpha_value": 0.0021187875267959367, "duration": 3.849280834197998, "step": 215875}
{"episode_reward": 162.31428379976205, "episode": 1728.0, "batch_reward": 0.8542380290031433, "critic_loss": 2.1251770763397215, "actor_loss": -85.08854982929844, "actor_target_entropy": -1.0, "actor_entropy": 2.097463330914897, "alpha_loss": 0.0019046982220794644, "alpha_value": 0.002105487953252116, "duration": 3.8326048851013184, "step": 216000}
{"episode_reward": 154.0526622957111, "episode": 1729.0, "batch_reward": 0.8513017067909241, "critic_loss": 2.083005641937256, "actor_loss": -85.08648027692523, "actor_target_entropy": -1.0, "actor_entropy": 2.0956389563424245, "alpha_loss": 0.001902492916477578, "alpha_value": 0.0020923901397529596, "duration": 3.840503692626953, "step": 216125}
{"episode_reward": 180.75682842989502, "episode": 1730.0, "batch_reward": 0.8592273979187012, "critic_loss": 2.156402575492859, "actor_loss": -85.09135486233619, "actor_target_entropy": -1.0, "actor_entropy": 2.085747734192879, "alpha_loss": 0.001977272752311922, "alpha_value": 0.002079073612822336, "duration": 3.8397531509399414, "step": 216250}
{"episode_reward": 173.44892186259443, "episode": 1731.0, "batch_reward": 0.8467341680526733, "critic_loss": 2.004438603401184, "actor_loss": -85.08442566886781, "actor_target_entropy": -1.0, "actor_entropy": 2.0925135536799355, "alpha_loss": 0.0019524822488338465, "alpha_value": 0.0020655079495959503, "duration": 3.8429291248321533, "step": 216375}
{"episode_reward": 171.3697835995232, "episode": 1732.0, "batch_reward": 0.8563738179206848, "critic_loss": 2.0517309064865112, "actor_loss": -85.09549122471964, "actor_target_entropy": -1.0, "actor_entropy": 2.107032068314091, "alpha_loss": 0.001884283950447195, "alpha_value": 0.00205275049083699, "duration": 3.8398537635803223, "step": 216500}
{"episode_reward": 198.02065810007468, "episode": 1733.0, "batch_reward": 0.8610129547119141, "critic_loss": 2.112019033432007, "actor_loss": -85.09990764799572, "actor_target_entropy": -1.0, "actor_entropy": 2.105264012775724, "alpha_loss": 0.001830744268816142, "alpha_value": 0.002040318171900045, "duration": 3.8409152030944824, "step": 216625}
{"episode_reward": 95.46491097286703, "episode": 1734.0, "batch_reward": 0.8619473056793213, "critic_loss": 2.131226062774658, "actor_loss": -85.096496212867, "actor_target_entropy": -1.0, "actor_entropy": 2.1123178082127727, "alpha_loss": 0.0018155881027210384, "alpha_value": 0.002027993040288523, "duration": 3.8368139266967773, "step": 216750}
{"episode_reward": 78.7541032110291, "episode": 1735.0, "batch_reward": 0.8611198649406433, "critic_loss": 2.100630660057068, "actor_loss": -85.10961478097099, "actor_target_entropy": -1.0, "actor_entropy": 2.1034633848402233, "alpha_loss": 0.0018208721441970695, "alpha_value": 0.002015906225201328, "duration": 3.8326098918914795, "step": 216875}
{"episode_reward": 163.06376242387896, "episode": 1736.0, "batch_reward": 0.8650497326850891, "critic_loss": 2.063704795837402, "actor_loss": -85.14118723715505, "actor_target_entropy": -1.0, "actor_entropy": 2.096113527974775, "alpha_loss": 0.0018512998959199795, "alpha_value": 0.002003992075126972, "duration": 3.828000068664551, "step": 217000}
{"episode_reward": 178.4155642368278, "episode": 1737.0, "batch_reward": 0.8641739296913147, "critic_loss": 2.1981033754348753, "actor_loss": -85.1210220579117, "actor_target_entropy": -1.0, "actor_entropy": 2.089261176094176, "alpha_loss": 0.0018592017373838831, "alpha_value": 0.0019916155907058882, "duration": 3.8419101238250732, "step": 217125}
{"episode_reward": 141.20871593996824, "episode": 1738.0, "batch_reward": 0.8740656509399414, "critic_loss": 2.148232211112976, "actor_loss": -85.14924043224704, "actor_target_entropy": -1.0, "actor_entropy": 2.1067243699104554, "alpha_loss": 0.0017845718774028242, "alpha_value": 0.0019795714916172736, "duration": 3.828444004058838, "step": 217250}
{"episode_reward": 233.50360298703276, "episode": 1739.0, "batch_reward": 0.8520762162208557, "critic_loss": 2.0406891469955446, "actor_loss": -85.13561442541697, "actor_target_entropy": -1.0, "actor_entropy": 2.130873453049433, "alpha_loss": 0.001764980235344006, "alpha_value": 0.001968080853399821, "duration": 3.846635103225708, "step": 217375}
{"episode_reward": 202.29403724554396, "episode": 1740.0, "batch_reward": 0.8617035837173462, "critic_loss": 2.1093747606277464, "actor_loss": -85.14839369250882, "actor_target_entropy": -1.0, "actor_entropy": 2.144777282591789, "alpha_loss": 0.0016223361261279111, "alpha_value": 0.001957067567227994, "duration": 3.8312816619873047, "step": 217500}
{"episode_reward": 114.66928560736893, "episode": 1741.0, "batch_reward": 0.8592191524505616, "critic_loss": 2.0695868611335753, "actor_loss": -85.16130877298022, "actor_target_entropy": -1.0, "actor_entropy": 2.1383581464252774, "alpha_loss": 0.0016676227281254435, "alpha_value": 0.0019463465643368065, "duration": 3.8456106185913086, "step": 217625}
{"episode_reward": 113.63373901975034, "episode": 1742.0, "batch_reward": 0.8576346445083618, "critic_loss": 2.09066321849823, "actor_loss": -85.15193459295458, "actor_target_entropy": -1.0, "actor_entropy": 2.138643526261853, "alpha_loss": 0.0016655929146274443, "alpha_value": 0.0019354504663042181, "duration": 3.8367276191711426, "step": 217750}
{"episode_reward": 113.22371501501178, "episode": 1743.0, "batch_reward": 0.8483935899734497, "critic_loss": 2.0371055307388306, "actor_loss": -85.15609922863189, "actor_target_entropy": -1.0, "actor_entropy": 2.154901353139726, "alpha_loss": 0.001644878105873922, "alpha_value": 0.0019246711673878581, "duration": 3.842526912689209, "step": 217875}
{"episode_reward": 150.17220283109867, "episode": 1744.0, "batch_reward": 0.8574151344299317, "critic_loss": 2.093118369102478, "actor_loss": -85.1645612409038, "actor_target_entropy": -1.0, "actor_entropy": 2.166262011374197, "alpha_loss": 0.0015593153413295026, "alpha_value": 0.0019140010809658176, "duration": 3.840416193008423, "step": 218000}
{"episode_reward": 193.58401347039822, "episode": 1745.0, "batch_reward": 0.8710006866455078, "critic_loss": 2.1428415422439575, "actor_loss": -85.17994157094805, "actor_target_entropy": -1.0, "actor_entropy": 2.177422356983972, "alpha_loss": 0.0015044933691295602, "alpha_value": 0.0019041460467846085, "duration": 3.839629650115967, "step": 218125}
{"episode_reward": 148.52585823155226, "episode": 1746.0, "batch_reward": 0.8537171449661255, "critic_loss": 2.0642551803588867, "actor_loss": -85.182679330149, "actor_target_entropy": -1.0, "actor_entropy": 2.1745652998647382, "alpha_loss": 0.0015195851090304073, "alpha_value": 0.001894226816244155, "duration": 3.8345682621002197, "step": 218250}
{"episode_reward": 133.096475468619, "episode": 1747.0, "batch_reward": 0.8610795712471009, "critic_loss": 2.1370536460876464, "actor_loss": -85.17702048165458, "actor_target_entropy": -1.0, "actor_entropy": 2.178943391830202, "alpha_loss": 0.0014296679836993534, "alpha_value": 0.0018846741631595241, "duration": 3.8390767574310303, "step": 218375}
{"episode_reward": 179.57037425712866, "episode": 1748.0, "batch_reward": 0.8821808876991272, "critic_loss": 2.1865221281051634, "actor_loss": -85.22106638262349, "actor_target_entropy": -1.0, "actor_entropy": 2.18975914678266, "alpha_loss": 0.0014343793605334095, "alpha_value": 0.0018750519676164169, "duration": 3.8367300033569336, "step": 218500}
{"episode_reward": 85.2194665257407, "episode": 1749.0, "batch_reward": 0.8699792685508728, "critic_loss": 2.1632120695114136, "actor_loss": -85.22703830779545, "actor_target_entropy": -1.0, "actor_entropy": 2.2018674668811618, "alpha_loss": 0.001360594403065209, "alpha_value": 0.001865861068103407, "duration": 3.8427462577819824, "step": 218625}
{"episode_reward": 183.3744784754015, "episode": 1750.0, "batch_reward": 0.8615273051261901, "critic_loss": 2.1533862800598143, "actor_loss": -85.21802053143901, "actor_target_entropy": -1.0, "actor_entropy": 2.210298045989006, "alpha_loss": 0.0012873230969548345, "alpha_value": 0.001856842757482773, "duration": 3.8266353607177734, "step": 218750}
{"episode_reward": 113.6896782254425, "episode": 1751.0, "batch_reward": 0.857669816493988, "critic_loss": 2.1028183364868163, "actor_loss": -85.22176300533233, "actor_target_entropy": -1.0, "actor_entropy": 2.2165057469928073, "alpha_loss": 0.0012554772794597768, "alpha_value": 0.0018481903476423387, "duration": 3.846001386642456, "step": 218875}
{"episode_reward": 172.3426485568499, "episode": 1752.0, "batch_reward": 0.8623829917907715, "critic_loss": 2.0821619472503663, "actor_loss": -85.2264911282447, "actor_target_entropy": -1.0, "actor_entropy": 2.226163817990211, "alpha_loss": 0.0013113382432962798, "alpha_value": 0.0018396327637228863, "duration": 3.8378496170043945, "step": 219000}
{"episode_reward": 130.61395628142355, "episode": 1753.0, "batch_reward": 0.8572935209274292, "critic_loss": 2.1454422454833986, "actor_loss": -85.22134956480964, "actor_target_entropy": -1.0, "actor_entropy": 2.225759248884897, "alpha_loss": 0.0012837289726280326, "alpha_value": 0.001830729443391049, "duration": 3.8355026245117188, "step": 219125}
{"episode_reward": 139.10167133384982, "episode": 1754.0, "batch_reward": 0.8649762754440308, "critic_loss": 2.0464919452667236, "actor_loss": -85.22821389475176, "actor_target_entropy": -1.0, "actor_entropy": 2.2283866020940963, "alpha_loss": 0.00128538204514752, "alpha_value": 0.0018218681432645675, "duration": 3.840097665786743, "step": 219250}
{"episode_reward": 71.07630686855232, "episode": 1755.0, "batch_reward": 0.8633568043708801, "critic_loss": 2.101379056930542, "actor_loss": -85.23831685384114, "actor_target_entropy": -1.0, "actor_entropy": 2.2307422274634954, "alpha_loss": 0.0012928626633116177, "alpha_value": 0.0018128739947422812, "duration": 3.841857433319092, "step": 219375}
{"episode_reward": 84.02129616369656, "episode": 1756.0, "batch_reward": 0.8615315871238709, "critic_loss": 2.095170805931091, "actor_loss": -85.23670368809854, "actor_target_entropy": -1.0, "actor_entropy": 2.221283282003095, "alpha_loss": 0.001295797314660083, "alpha_value": 0.0018039577236446658, "duration": 3.835015058517456, "step": 219500}
{"episode_reward": 173.93634527694854, "episode": 1757.0, "batch_reward": 0.8631012020111084, "critic_loss": 2.116334527015686, "actor_loss": -85.23601604643322, "actor_target_entropy": -1.0, "actor_entropy": 2.2269025378757052, "alpha_loss": 0.001296558151287692, "alpha_value": 0.0017947856636054613, "duration": 3.842078447341919, "step": 219625}
{"episode_reward": 195.57425003163684, "episode": 1758.0, "batch_reward": 0.8731973958015442, "critic_loss": 2.199967016220093, "actor_loss": -85.26208717592301, "actor_target_entropy": -1.0, "actor_entropy": 2.2361021810962307, "alpha_loss": 0.0012041553009992404, "alpha_value": 0.0017858756027525717, "duration": 3.838719606399536, "step": 219750}
{"episode_reward": 160.98495779376918, "episode": 1759.0, "batch_reward": 0.8670407838821411, "critic_loss": 2.064550072669983, "actor_loss": -85.26356058272104, "actor_target_entropy": -1.0, "actor_entropy": 2.244733734736367, "alpha_loss": 0.0011503424519480811, "alpha_value": 0.0017776517557499827, "duration": 3.8384666442871094, "step": 219875}
{"episode_reward": 36.9182979021533, "episode": 1760.0, "batch_reward": 0.8617541780471801, "critic_loss": 2.037524440765381, "actor_loss": -85.28063497235698, "actor_target_entropy": -1.0, "actor_entropy": 2.238587010291315, "alpha_loss": 0.0011823618101076253, "alpha_value": 0.0017693712662399971, "duration": 3.83620285987854, "step": 220000}
{"episode_reward": 107.80813280729181, "episode": 1761.0, "batch_reward": 0.8563151054382324, "critic_loss": 2.1397550792694093, "actor_loss": -85.25539846268912, "actor_target_entropy": -1.0, "actor_entropy": 2.2319733150421626, "alpha_loss": 0.001152597354366518, "alpha_value": 0.0017608253176055215, "duration": 7.806817293167114, "step": 220125}
{"episode_reward": 183.7779815804053, "episode": 1762.0, "batch_reward": 0.872734495639801, "critic_loss": 2.1268658151626587, "actor_loss": -85.30020498460338, "actor_target_entropy": -1.0, "actor_entropy": 2.2375669787006993, "alpha_loss": 0.0011391740803035997, "alpha_value": 0.001752592826439564, "duration": 3.8579256534576416, "step": 220250}
{"episode_reward": 182.60827880700845, "episode": 1763.0, "batch_reward": 0.8758497738838196, "critic_loss": 2.1364394693374633, "actor_loss": -85.31066143701948, "actor_target_entropy": -1.0, "actor_entropy": 2.234346102154444, "alpha_loss": 0.0011714070865381804, "alpha_value": 0.0017440736657773476, "duration": 3.835331916809082, "step": 220375}
{"episode_reward": 209.26296804258695, "episode": 1764.0, "batch_reward": 0.8671914415359497, "critic_loss": 2.1456322917938233, "actor_loss": -85.31504711028069, "actor_target_entropy": -1.0, "actor_entropy": 2.246830171154391, "alpha_loss": 0.0011518622956035898, "alpha_value": 0.001735325372696311, "duration": 3.827944278717041, "step": 220500}
{"episode_reward": 193.11261288117916, "episode": 1765.0, "batch_reward": 0.8649306077957153, "critic_loss": 2.0936614141464234, "actor_loss": -85.32585955423022, "actor_target_entropy": -1.0, "actor_entropy": 2.257107447064112, "alpha_loss": 0.001118094694989157, "alpha_value": 0.0017272228026539887, "duration": 4.9085423946380615, "step": 220625}
{"episode_reward": 143.44709111987734, "episode": 1766.0, "batch_reward": 0.858347749710083, "critic_loss": 2.052068197250366, "actor_loss": -85.3285304654029, "actor_target_entropy": -1.0, "actor_entropy": 2.261363337116857, "alpha_loss": 0.0010702982216307352, "alpha_value": 0.001719139719067954, "duration": 9.174147605895996, "step": 220750}
{"episode_reward": 46.13249316335967, "episode": 1767.0, "batch_reward": 0.8587332282066346, "critic_loss": 2.129301543235779, "actor_loss": -85.31368352496435, "actor_target_entropy": -1.0, "actor_entropy": 2.266213053748721, "alpha_loss": 0.0010685765012148915, "alpha_value": 0.0017109381878727139, "duration": 10.368914365768433, "step": 220875}
{"episode_reward": 191.78857707393252, "episode": 1768.0, "batch_reward": 0.8678267192840576, "critic_loss": 2.137750123977661, "actor_loss": -85.34223211965254, "actor_target_entropy": -1.0, "actor_entropy": 2.2662991554506364, "alpha_loss": 0.001079071483071593, "alpha_value": 0.0017029175516557503, "duration": 10.892085075378418, "step": 221000}
{"episode_reward": 41.04405586949761, "episode": 1769.0, "batch_reward": 0.8674264950752258, "critic_loss": 2.1628076667785643, "actor_loss": -85.33805205330016, "actor_target_entropy": -1.0, "actor_entropy": 2.2531884359934975, "alpha_loss": 0.001091250688731966, "alpha_value": 0.001694553314251129, "duration": 10.963074207305908, "step": 221125}
{"episode_reward": 170.1707678575134, "episode": 1770.0, "batch_reward": 0.8706459369659424, "critic_loss": 2.145425325393677, "actor_loss": -85.36042908699282, "actor_target_entropy": -1.0, "actor_entropy": 2.2416622407974733, "alpha_loss": 0.0011603301231403866, "alpha_value": 0.0016859908123937194, "duration": 10.880637884140015, "step": 221250}
{"episode_reward": 129.22851549920068, "episode": 1771.0, "batch_reward": 0.8648681221008301, "critic_loss": 2.10423886013031, "actor_loss": -85.36554487924727, "actor_target_entropy": -1.0, "actor_entropy": 2.2392512276059104, "alpha_loss": 0.0011331206483263818, "alpha_value": 0.0016772283959260914, "duration": 11.06088376045227, "step": 221375}
{"episode_reward": 176.8680371682845, "episode": 1772.0, "batch_reward": 0.8699139976501464, "critic_loss": 2.211725124359131, "actor_loss": -85.38649811283234, "actor_target_entropy": -1.0, "actor_entropy": 2.2314615557270665, "alpha_loss": 0.0011115322469718635, "alpha_value": 0.0016686162063960326, "duration": 11.10020112991333, "step": 221500}
{"episode_reward": 158.36624507659897, "episode": 1773.0, "batch_reward": 0.8661720652580261, "critic_loss": 2.1322819423675536, "actor_loss": -85.37445564875527, "actor_target_entropy": -1.0, "actor_entropy": 2.2282359562222918, "alpha_loss": 0.00119739083669311, "alpha_value": 0.0016596199217948902, "duration": 11.126077651977539, "step": 221625}
{"episode_reward": 185.07945329592803, "episode": 1774.0, "batch_reward": 0.8743719868659973, "critic_loss": 2.136054801940918, "actor_loss": -85.39945971581244, "actor_target_entropy": -1.0, "actor_entropy": 2.228065352286062, "alpha_loss": 0.0011599275486303432, "alpha_value": 0.0016504966828419312, "duration": 11.092785835266113, "step": 221750}
{"episode_reward": 61.71733429351918, "episode": 1775.0, "batch_reward": 0.8639674243927002, "critic_loss": 2.1103469009399416, "actor_loss": -85.40279860723587, "actor_target_entropy": -1.0, "actor_entropy": 2.2300667535691034, "alpha_loss": 0.0011588134096070593, "alpha_value": 0.001641609604232143, "duration": 11.09228229522705, "step": 221875}
{"episode_reward": 139.66133538107835, "episode": 1776.0, "batch_reward": 0.8649147229194641, "critic_loss": 2.1034654388427736, "actor_loss": -85.4118187196793, "actor_target_entropy": -1.0, "actor_entropy": 2.2304793327085433, "alpha_loss": 0.0011641263249217563, "alpha_value": 0.001632793726974807, "duration": 11.175909519195557, "step": 222000}
{"episode_reward": 115.28123450900499, "episode": 1777.0, "batch_reward": 0.8771402506828309, "critic_loss": 2.1899189548492433, "actor_loss": -85.42959231422061, "actor_target_entropy": -1.0, "actor_entropy": 2.230691713000101, "alpha_loss": 0.0011901867031748037, "alpha_value": 0.001623357840962614, "duration": 11.461127519607544, "step": 222125}
{"episode_reward": 137.22881986709757, "episode": 1778.0, "batch_reward": 0.8658717288970947, "critic_loss": 2.1553607549667357, "actor_loss": -85.42913190780148, "actor_target_entropy": -1.0, "actor_entropy": 2.2337257016089653, "alpha_loss": 0.0011392727042661018, "alpha_value": 0.0016144499080015813, "duration": 11.333460092544556, "step": 222250}
{"episode_reward": 128.08270266711247, "episode": 1779.0, "batch_reward": 0.8629829092025757, "critic_loss": 2.0445414409637452, "actor_loss": -85.43096499972873, "actor_target_entropy": -1.0, "actor_entropy": 2.2470285476200162, "alpha_loss": 0.0010924878010955003, "alpha_value": 0.0016058155228181963, "duration": 11.228052139282227, "step": 222375}
{"episode_reward": 247.33862949162315, "episode": 1780.0, "batch_reward": 0.8639888634681702, "critic_loss": 2.1255570688247682, "actor_loss": -85.43877976940524, "actor_target_entropy": -1.0, "actor_entropy": 2.2505631908293693, "alpha_loss": 0.0010394654706150533, "alpha_value": 0.0015977372886608325, "duration": 11.037657499313354, "step": 222500}
{"episode_reward": 186.92330702899176, "episode": 1781.0, "batch_reward": 0.8624640011787414, "critic_loss": 2.1201300277709962, "actor_loss": -85.44730449858166, "actor_target_entropy": -1.0, "actor_entropy": 2.241364494202629, "alpha_loss": 0.0011067409622704698, "alpha_value": 0.0015893378125007027, "duration": 11.226707220077515, "step": 222625}
{"episode_reward": 101.12975042239184, "episode": 1782.0, "batch_reward": 0.8635545196533203, "critic_loss": 2.137961298942566, "actor_loss": -85.45420345183342, "actor_target_entropy": -1.0, "actor_entropy": 2.2385006566201486, "alpha_loss": 0.0011821467628432137, "alpha_value": 0.0015802854665001185, "duration": 11.229596376419067, "step": 222750}
{"episode_reward": 150.27817750421804, "episode": 1783.0, "batch_reward": 0.8626878943443298, "critic_loss": 2.117828921318054, "actor_loss": -85.44896903870598, "actor_target_entropy": -1.0, "actor_entropy": 2.2405163447062173, "alpha_loss": 0.0011044799780753989, "alpha_value": 0.0015714106339351477, "duration": 11.5611891746521, "step": 222875}
{"episode_reward": 159.47681327389066, "episode": 1784.0, "batch_reward": 0.8594986381530761, "critic_loss": 2.064614122390747, "actor_loss": -85.45659255981445, "actor_target_entropy": -1.0, "actor_entropy": 2.252621650695801, "alpha_loss": 0.0010198709468597607, "alpha_value": 0.0015632012857060612, "duration": 11.407001733779907, "step": 223000}
{"episode_reward": 150.47464956244082, "episode": 1785.0, "batch_reward": 0.8798963193893432, "critic_loss": 2.250763500213623, "actor_loss": -85.49189952063182, "actor_target_entropy": -1.0, "actor_entropy": 2.2461425236293246, "alpha_loss": 0.0010564887149181839, "alpha_value": 0.0015551219276981707, "duration": 11.387596368789673, "step": 223125}
{"episode_reward": 138.7279689289708, "episode": 1786.0, "batch_reward": 0.8706395964622498, "critic_loss": 2.165247045516968, "actor_loss": -85.4815803035613, "actor_target_entropy": -1.0, "actor_entropy": 2.242236275826731, "alpha_loss": 0.001007688360386378, "alpha_value": 0.0015471115368082592, "duration": 11.251381635665894, "step": 223250}
{"episode_reward": 64.75143298691172, "episode": 1787.0, "batch_reward": 0.8729100213050842, "critic_loss": 2.1673808393478393, "actor_loss": -85.51343136742001, "actor_target_entropy": -1.0, "actor_entropy": 2.2311320380559043, "alpha_loss": 0.001090261900413131, "alpha_value": 0.001538623619027737, "duration": 11.434364795684814, "step": 223375}
{"episode_reward": 118.72849173212286, "episode": 1788.0, "batch_reward": 0.8666781449317932, "critic_loss": 2.1756660003662107, "actor_loss": -85.51384784329322, "actor_target_entropy": -1.0, "actor_entropy": 2.2234124214418474, "alpha_loss": 0.0011420945276416118, "alpha_value": 0.001530068549000156, "duration": 11.38352084159851, "step": 223500}
{"episode_reward": 138.45420053301058, "episode": 1789.0, "batch_reward": 0.8644887008666993, "critic_loss": 2.109068573951721, "actor_loss": -85.51529536171564, "actor_target_entropy": -1.0, "actor_entropy": 2.2274535042898997, "alpha_loss": 0.0011209437987648896, "alpha_value": 0.0015211443319241705, "duration": 11.194107055664062, "step": 223625}
{"episode_reward": 163.91142992652343, "episode": 1790.0, "batch_reward": 0.8562434196472168, "critic_loss": 2.092169285774231, "actor_loss": -85.50954548005134, "actor_target_entropy": -1.0, "actor_entropy": 2.232285837973318, "alpha_loss": 0.0010750786309325767, "alpha_value": 0.001512415852188113, "duration": 11.467329978942871, "step": 223750}
{"episode_reward": 221.04395216687806, "episode": 1791.0, "batch_reward": 0.8578477401733399, "critic_loss": 2.169981201171875, "actor_loss": -85.49234965490916, "actor_target_entropy": -1.0, "actor_entropy": 2.2324898886302162, "alpha_loss": 0.0010743266514812906, "alpha_value": 0.0015041872086828416, "duration": 11.54179334640503, "step": 223875}
{"episode_reward": 143.4987369064945, "episode": 1792.0, "batch_reward": 0.8729587917327881, "critic_loss": 2.1364668698310854, "actor_loss": -85.53346560078282, "actor_target_entropy": -1.0, "actor_entropy": 2.227331884445683, "alpha_loss": 0.0010755478194163692, "alpha_value": 0.001495767231147459, "duration": 11.41349744796753, "step": 224000}
{"episode_reward": 134.03519432878096, "episode": 1793.0, "batch_reward": 0.8638890433311462, "critic_loss": 2.0763814001083376, "actor_loss": -85.53460208953373, "actor_target_entropy": -1.0, "actor_entropy": 2.221482276916504, "alpha_loss": 0.0011145065460974972, "alpha_value": 0.0014872172295234388, "duration": 11.30824327468872, "step": 224125}
{"episode_reward": 141.46856118856974, "episode": 1794.0, "batch_reward": 0.8681957373619079, "critic_loss": 2.1323207387924192, "actor_loss": -85.54095926592427, "actor_target_entropy": -1.0, "actor_entropy": 2.221225430888514, "alpha_loss": 0.0011059472726042113, "alpha_value": 0.0014786336350585982, "duration": 11.443952083587646, "step": 224250}
{"episode_reward": 136.10745156381645, "episode": 1795.0, "batch_reward": 0.8689281044006347, "critic_loss": 2.1598677740097045, "actor_loss": -85.551023695204, "actor_target_entropy": -1.0, "actor_entropy": 2.209785340324281, "alpha_loss": 0.0011009868993867365, "alpha_value": 0.0014701324725056816, "duration": 11.509106874465942, "step": 224375}
{"episode_reward": 145.3108969701826, "episode": 1796.0, "batch_reward": 0.872541889667511, "critic_loss": 2.173482364654541, "actor_loss": -85.56112400177986, "actor_target_entropy": -1.0, "actor_entropy": 2.2064008712768555, "alpha_loss": 0.0011117011627873345, "alpha_value": 0.0014616336295626003, "duration": 11.53011155128479, "step": 224500}
{"episode_reward": 155.00521632212934, "episode": 1797.0, "batch_reward": 0.863800663471222, "critic_loss": 2.168524781227112, "actor_loss": -85.55889941018725, "actor_target_entropy": -1.0, "actor_entropy": 2.1962527320498513, "alpha_loss": 0.0011324032693953506, "alpha_value": 0.0014529049841581158, "duration": 11.188210487365723, "step": 224625}
{"episode_reward": 222.44024656336734, "episode": 1798.0, "batch_reward": 0.8781076140403747, "critic_loss": 2.174761590003967, "actor_loss": -85.58059692382812, "actor_target_entropy": -1.0, "actor_entropy": 2.1967337362227903, "alpha_loss": 0.0011049968935924793, "alpha_value": 0.0014443487264124495, "duration": 11.458635330200195, "step": 224750}
{"episode_reward": 103.62818043069481, "episode": 1799.0, "batch_reward": 0.8675064311027527, "critic_loss": 2.09797762298584, "actor_loss": -85.58053419325087, "actor_target_entropy": -1.0, "actor_entropy": 2.1926116337851873, "alpha_loss": 0.0011601585992759773, "alpha_value": 0.0014357022853552213, "duration": 11.579484224319458, "step": 224875}
{"episode_reward": 189.248952071446, "episode": 1800.0, "batch_reward": 0.8758326535224914, "critic_loss": 2.1416789608001707, "actor_loss": -85.60525832637664, "actor_target_entropy": -1.0, "actor_entropy": 2.2029024554837133, "alpha_loss": 0.0011769997156901104, "alpha_value": 0.0014267116266185398, "duration": 11.444187879562378, "step": 225000}
{"episode_reward": 163.6153833317763, "episode": 1801.0, "batch_reward": 0.8642868795394898, "critic_loss": 2.1816871662139894, "actor_loss": -85.58571043468658, "actor_target_entropy": -1.0, "actor_entropy": 2.2129222930423795, "alpha_loss": 0.0011192456586286426, "alpha_value": 0.0014181265035856725, "duration": 11.60066294670105, "step": 225125}
{"episode_reward": 148.86739205745198, "episode": 1802.0, "batch_reward": 0.8683300609588623, "critic_loss": 2.117996396064758, "actor_loss": -85.60567843529486, "actor_target_entropy": -1.0, "actor_entropy": 2.2092691698381977, "alpha_loss": 0.0010740993081614556, "alpha_value": 0.0014098738023221495, "duration": 11.628801822662354, "step": 225250}
{"episode_reward": 139.93603839043595, "episode": 1803.0, "batch_reward": 0.8668676028251648, "critic_loss": 2.1773929719924925, "actor_loss": -85.60699402339874, "actor_target_entropy": -1.0, "actor_entropy": 2.200514929635184, "alpha_loss": 0.0010726996420306108, "alpha_value": 0.0014018204120307273, "duration": 11.537158489227295, "step": 225375}
{"episode_reward": 103.42402282904668, "episode": 1804.0, "batch_reward": 0.8658298773765564, "critic_loss": 2.1163043212890624, "actor_loss": -85.62315405568769, "actor_target_entropy": -1.0, "actor_entropy": 2.198221698884041, "alpha_loss": 0.0011085921414046278, "alpha_value": 0.0013936497901941786, "duration": 11.592289924621582, "step": 225500}
{"episode_reward": 148.6995231125816, "episode": 1805.0, "batch_reward": 0.8653358006477356, "critic_loss": 2.1102365283966065, "actor_loss": -85.62242913624597, "actor_target_entropy": -1.0, "actor_entropy": 2.194534831576877, "alpha_loss": 0.0011446932607906916, "alpha_value": 0.0013853271428483234, "duration": 11.438030481338501, "step": 225625}
{"episode_reward": 47.38475029848724, "episode": 1806.0, "batch_reward": 0.8829090428352356, "critic_loss": 2.201258969306946, "actor_loss": -85.65430425828502, "actor_target_entropy": -1.0, "actor_entropy": 2.1973519632893224, "alpha_loss": 0.0010605470358108682, "alpha_value": 0.0013770844459074297, "duration": 11.380063533782959, "step": 225750}
{"episode_reward": 115.73794016215074, "episode": 1807.0, "batch_reward": 0.8702542796134949, "critic_loss": 2.137502429008484, "actor_loss": -85.65721663217695, "actor_target_entropy": -1.0, "actor_entropy": 2.1875321978614446, "alpha_loss": 0.0011070851007446883, "alpha_value": 0.001369105345661808, "duration": 11.335791826248169, "step": 225875}
{"episode_reward": 149.4987558438421, "episode": 1808.0, "batch_reward": 0.8777959370613098, "critic_loss": 2.253324239730835, "actor_loss": -85.66694124283329, "actor_target_entropy": -1.0, "actor_entropy": 2.1988980847020305, "alpha_loss": 0.0011033571199438865, "alpha_value": 0.0013608702473559078, "duration": 11.406883239746094, "step": 226000}
{"episode_reward": 165.73977821954585, "episode": 1809.0, "batch_reward": 0.8848665599822998, "critic_loss": 2.2275381412506103, "actor_loss": -85.68985687740265, "actor_target_entropy": -1.0, "actor_entropy": 2.205884539891803, "alpha_loss": 0.0010271526971048423, "alpha_value": 0.0013530999325190257, "duration": 11.509843587875366, "step": 226125}
{"episode_reward": 148.948142703883, "episode": 1810.0, "batch_reward": 0.8678177418708801, "critic_loss": 2.104869246482849, "actor_loss": -85.6902812834709, "actor_target_entropy": -1.0, "actor_entropy": 2.2128031484542356, "alpha_loss": 0.0010093744776602234, "alpha_value": 0.0013456194439207347, "duration": 11.8456392288208, "step": 226250}
{"episode_reward": 45.41250078108517, "episode": 1811.0, "batch_reward": 0.8617263169288635, "critic_loss": 2.161380016326904, "actor_loss": -85.68326847136967, "actor_target_entropy": -1.0, "actor_entropy": 2.226724003988599, "alpha_loss": 0.0009757595225459053, "alpha_value": 0.001338319936086067, "duration": 11.4792160987854, "step": 226375}
{"episode_reward": 141.38212118477983, "episode": 1812.0, "batch_reward": 0.8826503591537476, "critic_loss": 2.1562342929840086, "actor_loss": -85.72321294969127, "actor_target_entropy": -1.0, "actor_entropy": 2.2361897960785897, "alpha_loss": 0.0009012068255669287, "alpha_value": 0.001331371880870277, "duration": 11.777216672897339, "step": 226500}
{"episode_reward": 147.24755706227185, "episode": 1813.0, "batch_reward": 0.8776780581474304, "critic_loss": 2.21201465511322, "actor_loss": -85.72510104709201, "actor_target_entropy": -1.0, "actor_entropy": 2.226505340091766, "alpha_loss": 0.0009565163169994891, "alpha_value": 0.0013245432523439572, "duration": 11.646191835403442, "step": 226625}
{"episode_reward": 107.16698440700058, "episode": 1814.0, "batch_reward": 0.8635579161643981, "critic_loss": 2.0722688589096068, "actor_loss": -85.71978821293, "actor_target_entropy": -1.0, "actor_entropy": 2.2453088760375977, "alpha_loss": 0.0008930568921289617, "alpha_value": 0.0013177368450995946, "duration": 11.271856307983398, "step": 226750}
{"episode_reward": 143.1071722339935, "episode": 1815.0, "batch_reward": 0.8731042098999023, "critic_loss": 2.1861997995376585, "actor_loss": -85.73421030195932, "actor_target_entropy": -1.0, "actor_entropy": 2.258481979370117, "alpha_loss": 0.0008700779359233344, "alpha_value": 0.001311124148395758, "duration": 11.586500406265259, "step": 226875}
{"episode_reward": 178.01769160240843, "episode": 1816.0, "batch_reward": 0.870019835948944, "critic_loss": 2.0654050388336183, "actor_loss": -85.74651152087796, "actor_target_entropy": -1.0, "actor_entropy": 2.258068976863738, "alpha_loss": 0.0008631697447497338, "alpha_value": 0.0013046615627567426, "duration": 11.520844459533691, "step": 227000}
{"episode_reward": 142.85639356144574, "episode": 1817.0, "batch_reward": 0.8739950060844421, "critic_loss": 2.1660360584259033, "actor_loss": -85.7527843656994, "actor_target_entropy": -1.0, "actor_entropy": 2.2616822833106633, "alpha_loss": 0.000858121183386723, "alpha_value": 0.0012982957028091517, "duration": 11.952430009841919, "step": 227125}
{"episode_reward": 190.51033008082976, "episode": 1818.0, "batch_reward": 0.8708016366958619, "critic_loss": 2.169848171234131, "actor_loss": -85.76730801982265, "actor_target_entropy": -1.0, "actor_entropy": 2.2735960868097123, "alpha_loss": 0.0007658010360882467, "alpha_value": 0.0012919768090001243, "duration": 11.755104303359985, "step": 227250}
{"episode_reward": 39.05663574902959, "episode": 1819.0, "batch_reward": 0.8936349158287048, "critic_loss": 2.2205603981018065, "actor_loss": -85.80741930764819, "actor_target_entropy": -1.0, "actor_entropy": 2.2767971583775113, "alpha_loss": 0.0007746661140117794, "alpha_value": 0.0012861928218433785, "duration": 11.19525408744812, "step": 227375}
{"episode_reward": 74.30539360717947, "episode": 1820.0, "batch_reward": 0.8699850096702576, "critic_loss": 2.1296159133911132, "actor_loss": -85.79074748869866, "actor_target_entropy": -1.0, "actor_entropy": 2.271855092817737, "alpha_loss": 0.0008050321414503419, "alpha_value": 0.0012800666033306427, "duration": 11.553738117218018, "step": 227500}
{"episode_reward": 180.41011007825932, "episode": 1821.0, "batch_reward": 0.8772433724403381, "critic_loss": 2.284915259361267, "actor_loss": -85.79965573265439, "actor_target_entropy": -1.0, "actor_entropy": 2.2649753812759643, "alpha_loss": 0.0007998612834074135, "alpha_value": 0.0012739602113368282, "duration": 11.684755086898804, "step": 227625}
{"episode_reward": 237.92600463588496, "episode": 1822.0, "batch_reward": 0.8802280397415161, "critic_loss": 2.146344355583191, "actor_loss": -85.82782216225901, "actor_target_entropy": -1.0, "actor_entropy": 2.2617627113096175, "alpha_loss": 0.0008021207442300604, "alpha_value": 0.0012675667412712774, "duration": 11.527721643447876, "step": 227750}
{"episode_reward": 225.64172512459174, "episode": 1823.0, "batch_reward": 0.8791842603683472, "critic_loss": 2.1862207231521604, "actor_loss": -85.84000166635664, "actor_target_entropy": -1.0, "actor_entropy": 2.26439262571789, "alpha_loss": 0.0008138490633832084, "alpha_value": 0.0012612501957183558, "duration": 11.239750146865845, "step": 227875}
{"episode_reward": 106.39110546079976, "episode": 1824.0, "batch_reward": 0.8769980754852295, "critic_loss": 2.216338282585144, "actor_loss": -85.84356184928647, "actor_target_entropy": -1.0, "actor_entropy": 2.2601182537694133, "alpha_loss": 0.0007981936611148769, "alpha_value": 0.0012548895304505872, "duration": 11.51745343208313, "step": 228000}
{"episode_reward": 128.5337979757339, "episode": 1825.0, "batch_reward": 0.8820571961402893, "critic_loss": 2.1524766988754274, "actor_loss": -85.8690923055013, "actor_target_entropy": -1.0, "actor_entropy": 2.2517011279151555, "alpha_loss": 0.0008409961664010697, "alpha_value": 0.0012485669232623925, "duration": 11.251336574554443, "step": 228125}
{"episode_reward": 121.71119144912284, "episode": 1826.0, "batch_reward": 0.8742464289665223, "critic_loss": 2.199205753326416, "actor_loss": -85.86467029202369, "actor_target_entropy": -1.0, "actor_entropy": 2.2418311488243843, "alpha_loss": 0.0008835325899135862, "alpha_value": 0.0012416717520409017, "duration": 11.850117444992065, "step": 228250}
{"episode_reward": 125.75484517083792, "episode": 1827.0, "batch_reward": 0.8868752298355103, "critic_loss": 2.2320958223342897, "actor_loss": -85.89882369268508, "actor_target_entropy": -1.0, "actor_entropy": 2.2252673043145075, "alpha_loss": 0.0008982287060158948, "alpha_value": 0.0012346340518101255, "duration": 11.617426872253418, "step": 228375}
{"episode_reward": 140.42452735520436, "episode": 1828.0, "batch_reward": 0.86724360704422, "critic_loss": 2.1841238651275634, "actor_loss": -85.8905387386199, "actor_target_entropy": -1.0, "actor_entropy": 2.215973977119692, "alpha_loss": 0.0008939666609700409, "alpha_value": 0.0012276023845811015, "duration": 11.885409593582153, "step": 228500}
{"episode_reward": 101.56938439506688, "episode": 1829.0, "batch_reward": 0.8796605625152588, "critic_loss": 2.168886137008667, "actor_loss": -85.90968952481708, "actor_target_entropy": -1.0, "actor_entropy": 2.2204517485603454, "alpha_loss": 0.0008679198393125147, "alpha_value": 0.001220632392121246, "duration": 11.489420175552368, "step": 228625}
{"episode_reward": 166.73709185133214, "episode": 1830.0, "batch_reward": 0.8620306782722473, "critic_loss": 2.113270601272583, "actor_loss": -85.90464388939643, "actor_target_entropy": -1.0, "actor_entropy": 2.2232910433123187, "alpha_loss": 0.0008676005517988796, "alpha_value": 0.0012138448472075328, "duration": 11.31091570854187, "step": 228750}
{"episode_reward": 34.481080643143834, "episode": 1831.0, "batch_reward": 0.8640409698486328, "critic_loss": 2.099387710571289, "actor_loss": -85.9105234297495, "actor_target_entropy": -1.0, "actor_entropy": 2.2184932648189486, "alpha_loss": 0.0009045327416739412, "alpha_value": 0.0012068810860018245, "duration": 11.6302011013031, "step": 228875}
{"episode_reward": 85.53746070295412, "episode": 1832.0, "batch_reward": 0.8731485433578491, "critic_loss": 2.172077959060669, "actor_loss": -85.92289180140341, "actor_target_entropy": -1.0, "actor_entropy": 2.2162442822610178, "alpha_loss": 0.0009013034080365492, "alpha_value": 0.0011996823636617141, "duration": 11.601899147033691, "step": 229000}
{"episode_reward": 219.3440410426687, "episode": 1833.0, "batch_reward": 0.860021854877472, "critic_loss": 2.056924892425537, "actor_loss": -85.91629985022166, "actor_target_entropy": -1.0, "actor_entropy": 2.2199533704727417, "alpha_loss": 0.0008603492285132349, "alpha_value": 0.001192837489553018, "duration": 11.321847915649414, "step": 229125}
{"episode_reward": 174.76932475686314, "episode": 1834.0, "batch_reward": 0.873213873386383, "critic_loss": 2.208018589019775, "actor_loss": -85.92391881635112, "actor_target_entropy": -1.0, "actor_entropy": 2.197976743021319, "alpha_loss": 0.0009294183738905215, "alpha_value": 0.0011860433328478052, "duration": 11.791518211364746, "step": 229250}
{"episode_reward": 136.74139085469602, "episode": 1835.0, "batch_reward": 0.8883226408958435, "critic_loss": 2.223399903297424, "actor_loss": -85.95542374868242, "actor_target_entropy": -1.0, "actor_entropy": 2.1812634089636425, "alpha_loss": 0.0009574802390979751, "alpha_value": 0.0011786619064676732, "duration": 11.44469952583313, "step": 229375}
{"episode_reward": 125.35699007217704, "episode": 1836.0, "batch_reward": 0.8741491293907165, "critic_loss": 2.123190484046936, "actor_loss": -85.95419200774163, "actor_target_entropy": -1.0, "actor_entropy": 2.178704415598223, "alpha_loss": 0.0009545328174417298, "alpha_value": 0.0011713241249046184, "duration": 11.683726787567139, "step": 229500}
{"episode_reward": 180.64099260616445, "episode": 1837.0, "batch_reward": 0.8844111647605896, "critic_loss": 2.1535136699676514, "actor_loss": -85.97975752088759, "actor_target_entropy": -1.0, "actor_entropy": 2.1594267194233243, "alpha_loss": 0.001010365324050543, "alpha_value": 0.0011637514128820254, "duration": 11.684639930725098, "step": 229625}
{"episode_reward": 105.15197913841229, "episode": 1838.0, "batch_reward": 0.8757951822280884, "critic_loss": 2.1366236410140993, "actor_loss": -85.97671804120463, "actor_target_entropy": -1.0, "actor_entropy": 2.1496992265024493, "alpha_loss": 0.0009939924432640715, "alpha_value": 0.0011562105956594683, "duration": 11.51764178276062, "step": 229750}
{"episode_reward": 165.02956957287532, "episode": 1839.0, "batch_reward": 0.8894780654907226, "critic_loss": 2.2430377054214476, "actor_loss": -86.00286247616722, "actor_target_entropy": -1.0, "actor_entropy": 2.143579331655351, "alpha_loss": 0.0010305357947280364, "alpha_value": 0.0011485519883385159, "duration": 11.639901876449585, "step": 229875}
{"episode_reward": 124.95341908159614, "episode": 1840.0, "batch_reward": 0.8868801469802856, "critic_loss": 2.1672303619384765, "actor_loss": -86.02611381776872, "actor_target_entropy": -1.0, "actor_entropy": 2.1367083364917385, "alpha_loss": 0.0010478252961841081, "alpha_value": 0.0011410597672255034, "duration": 11.472866296768188, "step": 230000}
{"episode_reward": 199.51690990741668, "episode": 1841.0, "batch_reward": 0.8804220890998841, "critic_loss": 2.1998641986846925, "actor_loss": -86.04179999941871, "actor_target_entropy": -1.0, "actor_entropy": 2.117815683758448, "alpha_loss": 0.0010897868279633777, "alpha_value": 0.001133220175572393, "duration": 15.81237506866455, "step": 230125}
{"episode_reward": 134.01811196493355, "episode": 1842.0, "batch_reward": 0.87712602186203, "critic_loss": 2.1210858516693114, "actor_loss": -86.04285357075352, "actor_target_entropy": -1.0, "actor_entropy": 2.1039880014234975, "alpha_loss": 0.0011072594648031818, "alpha_value": 0.001125250160563696, "duration": 11.923057317733765, "step": 230250}
{"episode_reward": 192.2555432018122, "episode": 1843.0, "batch_reward": 0.8772458429336548, "critic_loss": 2.1339473571777345, "actor_loss": -86.05684879847935, "actor_target_entropy": -1.0, "actor_entropy": 2.081310272216797, "alpha_loss": 0.0011586744942524959, "alpha_value": 0.001117272848460085, "duration": 11.815973997116089, "step": 230375}
{"episode_reward": 237.84587576658944, "episode": 1844.0, "batch_reward": 0.8677166137695312, "critic_loss": 2.2819444274902345, "actor_loss": -86.03978175501669, "actor_target_entropy": -1.0, "actor_entropy": 2.0853656953380955, "alpha_loss": 0.0010972940560144884, "alpha_value": 0.001109365965607015, "duration": 11.142818927764893, "step": 230500}
{"episode_reward": 88.81665557366065, "episode": 1845.0, "batch_reward": 0.8756759538650513, "critic_loss": 2.173682899475098, "actor_loss": -86.06799861363002, "actor_target_entropy": -1.0, "actor_entropy": 2.1040194829305015, "alpha_loss": 0.0010742867385805954, "alpha_value": 0.0011019204028162536, "duration": 11.61773943901062, "step": 230625}
{"episode_reward": 228.28216099190547, "episode": 1846.0, "batch_reward": 0.8694066138267517, "critic_loss": 2.1569905338287354, "actor_loss": -86.06828061995968, "actor_target_entropy": -1.0, "actor_entropy": 2.1137833902912755, "alpha_loss": 0.0010630833876935104, "alpha_value": 0.0010947770070197118, "duration": 11.118951082229614, "step": 230750}
{"episode_reward": 83.50122280224369, "episode": 1847.0, "batch_reward": 0.8873560128211975, "critic_loss": 2.270382590293884, "actor_loss": -86.09117501879496, "actor_target_entropy": -1.0, "actor_entropy": 2.10520685286749, "alpha_loss": 0.0010417121885684393, "alpha_value": 0.0010876974384251507, "duration": 11.298258781433105, "step": 230875}
{"episode_reward": 176.34504139105925, "episode": 1848.0, "batch_reward": 0.8793248977661133, "critic_loss": 2.227466661453247, "actor_loss": -86.09663292669481, "actor_target_entropy": -1.0, "actor_entropy": 2.0894840148187455, "alpha_loss": 0.0010775384941934458, "alpha_value": 0.0010806120421664814, "duration": 11.391576766967773, "step": 231000}
{"episode_reward": 250.62728947415135, "episode": 1849.0, "batch_reward": 0.8885607976913452, "critic_loss": 2.2846797609329226, "actor_loss": -86.1219719780816, "actor_target_entropy": -1.0, "actor_entropy": 2.087142505342998, "alpha_loss": 0.0010698038820428626, "alpha_value": 0.0010736000516799206, "duration": 11.95280909538269, "step": 231125}
{"episode_reward": 133.8730885048029, "episode": 1850.0, "batch_reward": 0.873598457813263, "critic_loss": 2.211764629364014, "actor_loss": -86.12011952554026, "actor_target_entropy": -1.0, "actor_entropy": 2.0747854325079147, "alpha_loss": 0.0010933373592823983, "alpha_value": 0.001066541343895296, "duration": 11.500752210617065, "step": 231250}
{"episode_reward": 105.23210881616791, "episode": 1851.0, "batch_reward": 0.8641571173667908, "critic_loss": 2.1381383752822876, "actor_loss": -86.10937160915799, "actor_target_entropy": -1.0, "actor_entropy": 2.0713016267806763, "alpha_loss": 0.0011165362527771365, "alpha_value": 0.0010593904219776654, "duration": 11.707808256149292, "step": 231375}
{"episode_reward": 189.97283930383173, "episode": 1852.0, "batch_reward": 0.8877555432319642, "critic_loss": 2.190188558578491, "actor_loss": -86.14492810157037, "actor_target_entropy": -1.0, "actor_entropy": 2.079632620657644, "alpha_loss": 0.0010502695062783577, "alpha_value": 0.0010525427481607305, "duration": 11.158539772033691, "step": 231500}
{"episode_reward": 207.6803117187088, "episode": 1853.0, "batch_reward": 0.8817493386268616, "critic_loss": 2.288354974269867, "actor_loss": -86.14165860130673, "actor_target_entropy": -1.0, "actor_entropy": 2.090884466019888, "alpha_loss": 0.0010607553727274377, "alpha_value": 0.0010458839003662098, "duration": 11.708235263824463, "step": 231625}
{"episode_reward": 141.92871862949016, "episode": 1854.0, "batch_reward": 0.8932325210571289, "critic_loss": 2.218063522338867, "actor_loss": -86.18053337835497, "actor_target_entropy": -1.0, "actor_entropy": 2.073156172229398, "alpha_loss": 0.0010502640892105597, "alpha_value": 0.0010392314454393482, "duration": 11.434595108032227, "step": 231750}
{"episode_reward": 170.48659383590922, "episode": 1855.0, "batch_reward": 0.8904197597503662, "critic_loss": 2.1898286066055297, "actor_loss": -86.19608718629867, "actor_target_entropy": -1.0, "actor_entropy": 2.0618354101029652, "alpha_loss": 0.0010751525655255786, "alpha_value": 0.0010326433038736142, "duration": 11.895328760147095, "step": 231875}
{"episode_reward": 31.83503564032443, "episode": 1856.0, "batch_reward": 0.8959181699752807, "critic_loss": 2.3036303005218506, "actor_loss": -86.21814826227003, "actor_target_entropy": -1.0, "actor_entropy": 2.0822407045672016, "alpha_loss": 0.001009217805169042, "alpha_value": 0.0010261345042961486, "duration": 11.125446081161499, "step": 232000}
{"episode_reward": 216.19317242244003, "episode": 1857.0, "batch_reward": 0.8717676334381104, "critic_loss": 2.195769797325134, "actor_loss": -86.20707085019066, "actor_target_entropy": -1.0, "actor_entropy": 2.104140190851121, "alpha_loss": 0.0009757242145179402, "alpha_value": 0.0010201203574857847, "duration": 11.554610967636108, "step": 232125}
{"episode_reward": 193.87287300992296, "episode": 1858.0, "batch_reward": 0.8830877075195313, "critic_loss": 2.1976118755340575, "actor_loss": -86.22786158900107, "actor_target_entropy": -1.0, "actor_entropy": 2.122476916159353, "alpha_loss": 0.0009355191357298604, "alpha_value": 0.0010142753030374816, "duration": 11.354430913925171, "step": 232250}
{"episode_reward": 128.3729396567025, "episode": 1859.0, "batch_reward": 0.8872960858345031, "critic_loss": 2.197767328262329, "actor_loss": -86.25646282377697, "actor_target_entropy": -1.0, "actor_entropy": 2.120903620644221, "alpha_loss": 0.001003791440448295, "alpha_value": 0.0010083594245859637, "duration": 11.166551351547241, "step": 232375}
{"episode_reward": 125.76752391530042, "episode": 1860.0, "batch_reward": 0.8817310590744019, "critic_loss": 2.184966299057007, "actor_loss": -86.25914727487871, "actor_target_entropy": -1.0, "actor_entropy": 2.09254523246519, "alpha_loss": 0.000987994519340235, "alpha_value": 0.0010022813332075135, "duration": 11.762362957000732, "step": 232500}
{"episode_reward": 68.93762753626594, "episode": 1861.0, "batch_reward": 0.8795378942489624, "critic_loss": 2.170999676704407, "actor_loss": -86.26676335410467, "actor_target_entropy": -1.0, "actor_entropy": 2.0725090995667474, "alpha_loss": 0.0009975815016318053, "alpha_value": 0.000996260175594153, "duration": 11.928080320358276, "step": 232625}
{"episode_reward": 106.79955462262157, "episode": 1862.0, "batch_reward": 0.8941520466804505, "critic_loss": 2.2275548391342164, "actor_loss": -86.29764716855941, "actor_target_entropy": -1.0, "actor_entropy": 2.073805070692493, "alpha_loss": 0.001001256723670409, "alpha_value": 0.000990208791149237, "duration": 11.778416633605957, "step": 232750}
{"episode_reward": 199.78182040254882, "episode": 1863.0, "batch_reward": 0.8867443060874939, "critic_loss": 2.2262163848876955, "actor_loss": -86.29971361917163, "actor_target_entropy": -1.0, "actor_entropy": 2.063661363389757, "alpha_loss": 0.0010421579335964032, "alpha_value": 0.00098409238254102, "duration": 11.011691808700562, "step": 232875}
{"episode_reward": 160.1013896967241, "episode": 1864.0, "batch_reward": 0.8821182408332825, "critic_loss": 2.1655116300582886, "actor_loss": -86.30374785392515, "actor_target_entropy": -1.0, "actor_entropy": 2.036026523959252, "alpha_loss": 0.0010463733802504476, "alpha_value": 0.000977941397899592, "duration": 11.481598377227783, "step": 233000}
{"episode_reward": 116.44248933344065, "episode": 1865.0, "batch_reward": 0.8821440181732177, "critic_loss": 2.195864601135254, "actor_loss": -86.32113502139137, "actor_target_entropy": -1.0, "actor_entropy": 2.038600452362545, "alpha_loss": 0.0010395993899908803, "alpha_value": 0.0009717310064395527, "duration": 11.637990713119507, "step": 233125}
{"episode_reward": 229.50741245777056, "episode": 1866.0, "batch_reward": 0.8907892107963562, "critic_loss": 2.2455967645645143, "actor_loss": -86.35388811172977, "actor_target_entropy": -1.0, "actor_entropy": 2.043001913255261, "alpha_loss": 0.0010621258660384843, "alpha_value": 0.0009656118210564464, "duration": 11.87492060661316, "step": 233250}
{"episode_reward": 138.3726038011499, "episode": 1867.0, "batch_reward": 0.9020852956771851, "critic_loss": 2.342915496826172, "actor_loss": -86.36511920747303, "actor_target_entropy": -1.0, "actor_entropy": 2.0293438623821927, "alpha_loss": 0.0010817636475188746, "alpha_value": 0.0009593411721741183, "duration": 11.599202394485474, "step": 233375}
{"episode_reward": 70.13740432848257, "episode": 1868.0, "batch_reward": 0.8806802477836609, "critic_loss": 2.1870958099365234, "actor_loss": -86.37115109351373, "actor_target_entropy": -1.0, "actor_entropy": 2.0411369723658406, "alpha_loss": 0.001026724491478695, "alpha_value": 0.0009532332880237878, "duration": 11.769257307052612, "step": 233500}
{"episode_reward": 196.3265439445424, "episode": 1869.0, "batch_reward": 0.8918136377334595, "critic_loss": 2.2626140880584718, "actor_loss": -86.39696151491195, "actor_target_entropy": -1.0, "actor_entropy": 2.0195423913380455, "alpha_loss": 0.0010556260203306992, "alpha_value": 0.0009473128655089902, "duration": 11.582104682922363, "step": 233625}
{"episode_reward": 133.62998973743728, "episode": 1870.0, "batch_reward": 0.8985265097618103, "critic_loss": 2.2635549392700196, "actor_loss": -86.42022323608398, "actor_target_entropy": -1.0, "actor_entropy": 1.9977185245483153, "alpha_loss": 0.0010921135357010267, "alpha_value": 0.0009411283087625472, "duration": 11.710825204849243, "step": 233750}
{"episode_reward": 118.60378329518329, "episode": 1871.0, "batch_reward": 0.8790736217498779, "critic_loss": 2.2098634061813356, "actor_loss": -86.41367691282242, "actor_target_entropy": -1.0, "actor_entropy": 1.985372333299546, "alpha_loss": 0.0011005649067801497, "alpha_value": 0.0009349738821971966, "duration": 11.62281060218811, "step": 233875}
{"episode_reward": 186.50005513487477, "episode": 1872.0, "batch_reward": 0.8857089366912841, "critic_loss": 2.150795775413513, "actor_loss": -86.43619168189264, "actor_target_entropy": -1.0, "actor_entropy": 1.9932397603988647, "alpha_loss": 0.0010846595968976016, "alpha_value": 0.0009289154153533653, "duration": 11.678852558135986, "step": 234000}
{"episode_reward": 143.62049909864353, "episode": 1873.0, "batch_reward": 0.8742404317855835, "critic_loss": 2.2043739128112794, "actor_loss": -86.43100314670139, "actor_target_entropy": -1.0, "actor_entropy": 1.9696014059914484, "alpha_loss": 0.0011004401187944626, "alpha_value": 0.0009229142817828317, "duration": 11.753967761993408, "step": 234125}
{"episode_reward": 188.1002497125307, "episode": 1874.0, "batch_reward": 0.8770617575645446, "critic_loss": 2.1452655248641967, "actor_loss": -86.43964545957503, "actor_target_entropy": -1.0, "actor_entropy": 1.9506031966978503, "alpha_loss": 0.0011113467879758606, "alpha_value": 0.0009168790593131489, "duration": 11.429261207580566, "step": 234250}
{"episode_reward": 133.3468976193131, "episode": 1875.0, "batch_reward": 0.8844576063156128, "critic_loss": 2.216587356567383, "actor_loss": -86.47032468281095, "actor_target_entropy": -1.0, "actor_entropy": 1.9350864944003878, "alpha_loss": 0.001151540164192695, "alpha_value": 0.0009107401136565584, "duration": 11.572797060012817, "step": 234375}
{"episode_reward": 75.63862067684326, "episode": 1876.0, "batch_reward": 0.8934656038284302, "critic_loss": 2.228610450744629, "actor_loss": -86.4905881574077, "actor_target_entropy": -1.0, "actor_entropy": 1.931830625380239, "alpha_loss": 0.0011442903008672498, "alpha_value": 0.0009045908913236638, "duration": 11.302289962768555, "step": 234500}
{"episode_reward": 176.63639881524657, "episode": 1877.0, "batch_reward": 0.888904405117035, "critic_loss": 2.187579610824585, "actor_loss": -86.50045631045387, "actor_target_entropy": -1.0, "actor_entropy": 1.9198195612619793, "alpha_loss": 0.001147472010444968, "alpha_value": 0.000898548818892189, "duration": 11.402660608291626, "step": 234625}
{"episode_reward": 90.0617697238394, "episode": 1878.0, "batch_reward": 0.8922453355789185, "critic_loss": 2.2204897480010986, "actor_loss": -86.50904157084804, "actor_target_entropy": -1.0, "actor_entropy": 1.9186311421855804, "alpha_loss": 0.0011380241738797555, "alpha_value": 0.0008926342557122435, "duration": 11.357903718948364, "step": 234750}
{"episode_reward": 175.32426270876897, "episode": 1879.0, "batch_reward": 0.8822263822555542, "critic_loss": 2.2093259620666506, "actor_loss": -86.53224048917255, "actor_target_entropy": -1.0, "actor_entropy": 1.9051596493948073, "alpha_loss": 0.001144266209661192, "alpha_value": 0.0008867287966416976, "duration": 11.630441188812256, "step": 234875}
{"episode_reward": 66.32094893811231, "episode": 1880.0, "batch_reward": 0.8726531219482422, "critic_loss": 2.173839940071106, "actor_loss": -86.5207283266129, "actor_target_entropy": -1.0, "actor_entropy": 1.8766095599820536, "alpha_loss": 0.0011475994007571811, "alpha_value": 0.0008808728926789531, "duration": 11.48427438735962, "step": 235000}
{"episode_reward": 215.78850282348705, "episode": 1881.0, "batch_reward": 0.8778999342918395, "critic_loss": 2.1586269245147705, "actor_loss": -86.53337496802921, "actor_target_entropy": -1.0, "actor_entropy": 1.8736145855888489, "alpha_loss": 0.001165095055180173, "alpha_value": 0.0008750225356189024, "duration": 11.566065073013306, "step": 235125}
{"episode_reward": 120.96292528704849, "episode": 1882.0, "batch_reward": 0.8859744844436646, "critic_loss": 2.233997838973999, "actor_loss": -86.54133827455583, "actor_target_entropy": -1.0, "actor_entropy": 1.8842045607105378, "alpha_loss": 0.0011444282605342806, "alpha_value": 0.0008692234739577387, "duration": 11.712125778198242, "step": 235250}
{"episode_reward": 145.1747514677145, "episode": 1883.0, "batch_reward": 0.8752196741104126, "critic_loss": 2.234865231513977, "actor_loss": -86.54742649623326, "actor_target_entropy": -1.0, "actor_entropy": 1.8845711378824144, "alpha_loss": 0.0011321033539605282, "alpha_value": 0.0008636157245840634, "duration": 11.41828989982605, "step": 235375}
{"episode_reward": 224.21190692461388, "episode": 1884.0, "batch_reward": 0.8819458656311036, "critic_loss": 2.225427327156067, "actor_loss": -86.55916927706811, "actor_target_entropy": -1.0, "actor_entropy": 1.881021734206907, "alpha_loss": 0.001116634625378215, "alpha_value": 0.0008581087650423742, "duration": 11.27962327003479, "step": 235500}
{"episode_reward": 94.00554075763834, "episode": 1885.0, "batch_reward": 0.8739947075843811, "critic_loss": 2.2293032579422, "actor_loss": -86.55048212929377, "actor_target_entropy": -1.0, "actor_entropy": 1.8669000826184712, "alpha_loss": 0.0011166687906971054, "alpha_value": 0.0008526670944129208, "duration": 11.529303550720215, "step": 235625}
{"episode_reward": 61.750157499665896, "episode": 1886.0, "batch_reward": 0.8912196564674377, "critic_loss": 2.282620400428772, "actor_loss": -86.58781236217868, "actor_target_entropy": -1.0, "actor_entropy": 1.8838265211351457, "alpha_loss": 0.0011246079774273018, "alpha_value": 0.0008472529421524425, "duration": 11.316375255584717, "step": 235750}
{"episode_reward": 185.5653167237524, "episode": 1887.0, "batch_reward": 0.8778331837654114, "critic_loss": 2.2317591810226443, "actor_loss": -86.579592023577, "actor_target_entropy": -1.0, "actor_entropy": 1.8840615276306394, "alpha_loss": 0.001108852519084596, "alpha_value": 0.0008418846050861662, "duration": 11.388938903808594, "step": 235875}
{"episode_reward": 134.17944365152724, "episode": 1888.0, "batch_reward": 0.8838967804908753, "critic_loss": 2.1907281951904296, "actor_loss": -86.60084939772084, "actor_target_entropy": -1.0, "actor_entropy": 1.8897554835965555, "alpha_loss": 0.0010973504085409185, "alpha_value": 0.00083663228265279, "duration": 11.435129642486572, "step": 236000}
{"episode_reward": 133.46724501117825, "episode": 1889.0, "batch_reward": 0.8934481554031372, "critic_loss": 2.225375414848328, "actor_loss": -86.63385385180277, "actor_target_entropy": -1.0, "actor_entropy": 1.8892598549524944, "alpha_loss": 0.0010775189083586964, "alpha_value": 0.0008314910981337441, "duration": 11.495116472244263, "step": 236125}
{"episode_reward": 31.48238643962549, "episode": 1890.0, "batch_reward": 0.8906515574455262, "critic_loss": 2.2209940519332885, "actor_loss": -86.63650857248614, "actor_target_entropy": -1.0, "actor_entropy": 1.8890549636656238, "alpha_loss": 0.0010882319437505136, "alpha_value": 0.0008264070837341668, "duration": 11.533626794815063, "step": 236250}
{"episode_reward": 153.2329308708417, "episode": 1891.0, "batch_reward": 0.885025972366333, "critic_loss": 2.227736657142639, "actor_loss": -86.64687553284661, "actor_target_entropy": -1.0, "actor_entropy": 1.8903596685046242, "alpha_loss": 0.00108426590893595, "alpha_value": 0.0008213140116211384, "duration": 11.780117511749268, "step": 236375}
{"episode_reward": 118.21223126703661, "episode": 1892.0, "batch_reward": 0.8933672986030579, "critic_loss": 2.195622181892395, "actor_loss": -86.67321272819272, "actor_target_entropy": -1.0, "actor_entropy": 1.8743545355335358, "alpha_loss": 0.0010895668209770755, "alpha_value": 0.000816259224894044, "duration": 11.245775699615479, "step": 236500}
{"episode_reward": 88.36186626683771, "episode": 1893.0, "batch_reward": 0.8948952536582947, "critic_loss": 2.237341812133789, "actor_loss": -86.68405248248388, "actor_target_entropy": -1.0, "actor_entropy": 1.871311038259476, "alpha_loss": 0.001083361262100793, "alpha_value": 0.0008111983233705248, "duration": 11.41821575164795, "step": 236625}
{"episode_reward": 211.19380927089776, "episode": 1894.0, "batch_reward": 0.8908150243759155, "critic_loss": 2.2558457145690918, "actor_loss": -86.69533415763608, "actor_target_entropy": -1.0, "actor_entropy": 1.867895991571488, "alpha_loss": 0.0010773287128446804, "alpha_value": 0.0008062787175260404, "duration": 11.615655899047852, "step": 236750}
{"episode_reward": 112.48105655087429, "episode": 1895.0, "batch_reward": 0.8787112493515015, "critic_loss": 2.2159666328430174, "actor_loss": -86.69582742358011, "actor_target_entropy": -1.0, "actor_entropy": 1.8610156093324934, "alpha_loss": 0.0010835108419303737, "alpha_value": 0.0008013250702035047, "duration": 11.536067485809326, "step": 236875}
{"episode_reward": 100.80086959636809, "episode": 1896.0, "batch_reward": 0.8742121248245239, "critic_loss": 2.1765156412124633, "actor_loss": -86.7011609231272, "actor_target_entropy": -1.0, "actor_entropy": 1.8647951656772244, "alpha_loss": 0.0010759608891432084, "alpha_value": 0.0007963985388914036, "duration": 11.358917713165283, "step": 237000}
{"episode_reward": 157.83349691338512, "episode": 1897.0, "batch_reward": 0.8910308766365052, "critic_loss": 2.225359601020813, "actor_loss": -86.71692100403801, "actor_target_entropy": -1.0, "actor_entropy": 1.8602687309658716, "alpha_loss": 0.0010620875566798662, "alpha_value": 0.0007915407781308553, "duration": 11.401354551315308, "step": 237125}
{"episode_reward": 107.58376062439052, "episode": 1898.0, "batch_reward": 0.8863440985679627, "critic_loss": 2.2212219762802126, "actor_loss": -86.73781191918158, "actor_target_entropy": -1.0, "actor_entropy": 1.852761995407843, "alpha_loss": 0.001072384684624511, "alpha_value": 0.0007867470457382127, "duration": 11.518859624862671, "step": 237250}
{"episode_reward": 136.93199611193364, "episode": 1899.0, "batch_reward": 0.8755315256118774, "critic_loss": 2.1800415925979615, "actor_loss": -86.73512607150607, "actor_target_entropy": -1.0, "actor_entropy": 1.8343626222913227, "alpha_loss": 0.001089173430089085, "alpha_value": 0.0007819026562712324, "duration": 11.429619550704956, "step": 237375}
{"episode_reward": 188.63626257801027, "episode": 1900.0, "batch_reward": 0.8783371939659118, "critic_loss": 2.2368906183242796, "actor_loss": -86.72054733768586, "actor_target_entropy": -1.0, "actor_entropy": 1.833348354985637, "alpha_loss": 0.0010720404323130365, "alpha_value": 0.0007770434478818464, "duration": 11.520326614379883, "step": 237500}
{"episode_reward": 104.40586754144768, "episode": 1901.0, "batch_reward": 0.8821718964576721, "critic_loss": 2.2186220293045045, "actor_loss": -86.73542155916729, "actor_target_entropy": -1.0, "actor_entropy": 1.819735332140847, "alpha_loss": 0.0010768215020468075, "alpha_value": 0.0007722965190029818, "duration": 11.548677682876587, "step": 237625}
{"episode_reward": 197.76890055649386, "episode": 1902.0, "batch_reward": 0.9039471416473389, "critic_loss": 2.296033242225647, "actor_loss": -86.78541737218058, "actor_target_entropy": -1.0, "actor_entropy": 1.8014685300088698, "alpha_loss": 0.0010743053318301758, "alpha_value": 0.0007675416719931153, "duration": 11.516221523284912, "step": 237750}
{"episode_reward": 52.290685020437344, "episode": 1903.0, "batch_reward": 0.883866199016571, "critic_loss": 2.2636605558395386, "actor_loss": -86.77904813251799, "actor_target_entropy": -1.0, "actor_entropy": 1.7863756229007055, "alpha_loss": 0.001104911844733925, "alpha_value": 0.0007627626026272043, "duration": 11.517075300216675, "step": 237875}
{"episode_reward": 186.02638334010203, "episode": 1904.0, "batch_reward": 0.8929222249984741, "critic_loss": 2.22217467212677, "actor_loss": -86.80395950809601, "actor_target_entropy": -1.0, "actor_entropy": 1.7800262089698546, "alpha_loss": 0.0010907434531667781, "alpha_value": 0.0007579817463547715, "duration": 11.361818313598633, "step": 238000}
{"episode_reward": 285.5457798351076, "episode": 1905.0, "batch_reward": 0.884400098323822, "critic_loss": 2.1684107370376586, "actor_loss": -86.79926287938677, "actor_target_entropy": -1.0, "actor_entropy": 1.776981340514289, "alpha_loss": 0.0010852752325479827, "alpha_value": 0.0007532697015622826, "duration": 11.622468709945679, "step": 238125}
{"episode_reward": 67.51295600681625, "episode": 1906.0, "batch_reward": 0.8719699621200562, "critic_loss": 2.205863522529602, "actor_loss": -86.79671552104335, "actor_target_entropy": -1.0, "actor_entropy": 1.764409146001262, "alpha_loss": 0.0010864792650775803, "alpha_value": 0.0007486033257608208, "duration": 11.328070640563965, "step": 238250}
{"episode_reward": 145.3065124440728, "episode": 1907.0, "batch_reward": 0.8841655473709107, "critic_loss": 2.2176528644561766, "actor_loss": -86.82248130677239, "actor_target_entropy": -1.0, "actor_entropy": 1.7272342216400873, "alpha_loss": 0.001092710326211379, "alpha_value": 0.000743942637292352, "duration": 11.497504711151123, "step": 238375}
{"episode_reward": 95.3988261456288, "episode": 1908.0, "batch_reward": 0.8708347382545472, "critic_loss": 2.2201339225769043, "actor_loss": -86.81911628477035, "actor_target_entropy": -1.0, "actor_entropy": 1.713758287891265, "alpha_loss": 0.0011080554592603398, "alpha_value": 0.0007392560299650039, "duration": 11.527834177017212, "step": 238500}
{"episode_reward": 132.46777902378125, "episode": 1909.0, "batch_reward": 0.8738725433349609, "critic_loss": 2.1993967332839968, "actor_loss": -86.8214863368443, "actor_target_entropy": -1.0, "actor_entropy": 1.6798796899734982, "alpha_loss": 0.0011139980088623743, "alpha_value": 0.0007345694674636711, "duration": 11.429302453994751, "step": 238625}
{"episode_reward": 155.71443679780205, "episode": 1910.0, "batch_reward": 0.8861820979118347, "critic_loss": 2.300902663230896, "actor_loss": -86.83031980452999, "actor_target_entropy": -1.0, "actor_entropy": 1.671492011316361, "alpha_loss": 0.0011045566756248235, "alpha_value": 0.0007299126115823784, "duration": 11.176771402359009, "step": 238750}
{"episode_reward": 184.65873859486726, "episode": 1911.0, "batch_reward": 0.8955063123703003, "critic_loss": 2.2721346740722654, "actor_loss": -86.86499083988251, "actor_target_entropy": -1.0, "actor_entropy": 1.6808532703490484, "alpha_loss": 0.0011057333728771597, "alpha_value": 0.0007253065892340533, "duration": 11.477736473083496, "step": 238875}
{"episode_reward": 197.74659027498694, "episode": 1912.0, "batch_reward": 0.886562617301941, "critic_loss": 2.250598825454712, "actor_loss": -86.86780917259955, "actor_target_entropy": -1.0, "actor_entropy": 1.6720277609363678, "alpha_loss": 0.001092309023313705, "alpha_value": 0.0007207816277211814, "duration": 11.360395431518555, "step": 239000}
{"episode_reward": 72.53619971483795, "episode": 1913.0, "batch_reward": 0.8832629222869873, "critic_loss": 2.1664040327072143, "actor_loss": -86.87489137195405, "actor_target_entropy": -1.0, "actor_entropy": 1.6475293466023035, "alpha_loss": 0.0010946939887833736, "alpha_value": 0.0007163032950719798, "duration": 11.790924310684204, "step": 239125}
{"episode_reward": 74.82754961809589, "episode": 1914.0, "batch_reward": 0.8960467801094055, "critic_loss": 2.192885327339172, "actor_loss": -86.8982057879048, "actor_target_entropy": -1.0, "actor_entropy": 1.6389555200453727, "alpha_loss": 0.0011002012329446452, "alpha_value": 0.0007118269908383473, "duration": 11.393911838531494, "step": 239250}
{"episode_reward": 90.16587403756357, "episode": 1915.0, "batch_reward": 0.8843050179481506, "critic_loss": 2.2035018739700316, "actor_loss": -86.90764496818421, "actor_target_entropy": -1.0, "actor_entropy": 1.6243658992979262, "alpha_loss": 0.0010957920365774678, "alpha_value": 0.000707381782824171, "duration": 11.561564922332764, "step": 239375}
{"episode_reward": 139.98972509862577, "episode": 1916.0, "batch_reward": 0.8756400475502014, "critic_loss": 2.142449049949646, "actor_loss": -86.9028464286558, "actor_target_entropy": -1.0, "actor_entropy": 1.6126633036521174, "alpha_loss": 0.001088002595239349, "alpha_value": 0.0007029879916620207, "duration": 11.611084938049316, "step": 239500}
{"episode_reward": 158.97863747448957, "episode": 1917.0, "batch_reward": 0.8875428586006164, "critic_loss": 2.1995034284591677, "actor_loss": -86.9209944709899, "actor_target_entropy": -1.0, "actor_entropy": 1.5871900092987787, "alpha_loss": 0.0010925266182138806, "alpha_value": 0.0006986241145437414, "duration": 11.606694221496582, "step": 239625}
{"episode_reward": 100.83537159515345, "episode": 1918.0, "batch_reward": 0.8955645589828491, "critic_loss": 2.240023696899414, "actor_loss": -86.94224757532919, "actor_target_entropy": -1.0, "actor_entropy": 1.562185122120765, "alpha_loss": 0.0011034585092396987, "alpha_value": 0.0006942436038496747, "duration": 11.84705138206482, "step": 239750}
{"episode_reward": 107.75702420305558, "episode": 1919.0, "batch_reward": 0.8872272257804871, "critic_loss": 2.309837321281433, "actor_loss": -86.95111556280227, "actor_target_entropy": -1.0, "actor_entropy": 1.5629874808447701, "alpha_loss": 0.0010859722692874215, "alpha_value": 0.0006899282905322878, "duration": 11.781580686569214, "step": 239875}
{"episode_reward": 91.8342010329106, "episode": 1920.0, "batch_reward": 0.8843679308891297, "critic_loss": 2.2851031856536865, "actor_loss": -86.96017763691563, "actor_target_entropy": -1.0, "actor_entropy": 1.5615659567617601, "alpha_loss": 0.0010693597404526608, "alpha_value": 0.0006856978216211359, "duration": 11.421525478363037, "step": 240000}
{"episode_reward": 146.10303627382837, "episode": 1921.0, "batch_reward": 0.8841547646522522, "critic_loss": 2.226140097618103, "actor_loss": -86.95859273274739, "actor_target_entropy": -1.0, "actor_entropy": 1.5650265122216844, "alpha_loss": 0.0010704454441096574, "alpha_value": 0.0006815141989599747, "duration": 15.21570611000061, "step": 240125}
{"episode_reward": 161.0406189901895, "episode": 1922.0, "batch_reward": 0.8819179759025574, "critic_loss": 2.2073377742767333, "actor_loss": -86.97809625441029, "actor_target_entropy": -1.0, "actor_entropy": 1.543747890380121, "alpha_loss": 0.0010659164850479893, "alpha_value": 0.0006773622754422795, "duration": 11.366533517837524, "step": 240250}
{"episode_reward": 56.08892245504884, "episode": 1923.0, "batch_reward": 0.894364625453949, "critic_loss": 2.293331622123718, "actor_loss": -86.9956537882487, "actor_target_entropy": -1.0, "actor_entropy": 1.5233158100219, "alpha_loss": 0.0010725543483175218, "alpha_value": 0.0006732224591830205, "duration": 11.727125406265259, "step": 240375}
{"episode_reward": 159.6577457980247, "episode": 1924.0, "batch_reward": 0.8870967411994934, "critic_loss": 2.216111741065979, "actor_loss": -87.00230776879096, "actor_target_entropy": -1.0, "actor_entropy": 1.5037278398390739, "alpha_loss": 0.0010697820032345912, "alpha_value": 0.0006690958071116896, "duration": 11.751203536987305, "step": 240500}
{"episode_reward": 44.118579353721124, "episode": 1925.0, "batch_reward": 0.8976384215354919, "critic_loss": 2.2904108839035033, "actor_loss": -87.03130897643074, "actor_target_entropy": -1.0, "actor_entropy": 1.4929316251996965, "alpha_loss": 0.0010609616348076435, "alpha_value": 0.0006650101383731456, "duration": 11.585424661636353, "step": 240625}
{"episode_reward": 123.49943892827108, "episode": 1926.0, "batch_reward": 0.8833740763664245, "critic_loss": 2.2310274782180786, "actor_loss": -87.03155271468624, "actor_target_entropy": -1.0, "actor_entropy": 1.465483715457301, "alpha_loss": 0.0010582701445767475, "alpha_value": 0.0006609658267652953, "duration": 11.332841634750366, "step": 240750}
{"episode_reward": 177.67066340643913, "episode": 1927.0, "batch_reward": 0.8801590094566345, "critic_loss": 2.2362920808792115, "actor_loss": -87.03042529878162, "actor_target_entropy": -1.0, "actor_entropy": 1.463260289222475, "alpha_loss": 0.0010520745944675234, "alpha_value": 0.0006569584977602701, "duration": 11.304133415222168, "step": 240875}
{"episode_reward": 88.32017631287614, "episode": 1928.0, "batch_reward": 0.8857884860038757, "critic_loss": 2.1977432641983032, "actor_loss": -87.0541733772524, "actor_target_entropy": -1.0, "actor_entropy": 1.4606459256141417, "alpha_loss": 0.0010444799948844217, "alpha_value": 0.0006529965589692729, "duration": 11.70615816116333, "step": 241000}
{"episode_reward": 84.14943468727009, "episode": 1929.0, "batch_reward": 0.895528486251831, "critic_loss": 2.24194585609436, "actor_loss": -87.06411936926463, "actor_target_entropy": -1.0, "actor_entropy": 1.441017712865557, "alpha_loss": 0.001043666466434915, "alpha_value": 0.0006490634014049048, "duration": 11.838159799575806, "step": 241125}
{"episode_reward": 104.66563894271499, "episode": 1930.0, "batch_reward": 0.8896562557220459, "critic_loss": 2.235126799583435, "actor_loss": -87.0802613535235, "actor_target_entropy": -1.0, "actor_entropy": 1.4448590163261659, "alpha_loss": 0.0010270607571357922, "alpha_value": 0.0006451766218972817, "duration": 12.095795392990112, "step": 241250}
{"episode_reward": 83.49184817723726, "episode": 1931.0, "batch_reward": 0.8798251657485961, "critic_loss": 2.2065415506362913, "actor_loss": -87.06564791240389, "actor_target_entropy": -1.0, "actor_entropy": 1.4585760831832886, "alpha_loss": 0.001037032509754811, "alpha_value": 0.0006413231225811619, "duration": 12.145874738693237, "step": 241375}
{"episode_reward": 101.39496872588364, "episode": 1932.0, "batch_reward": 0.871284653186798, "critic_loss": 2.0958957595825196, "actor_loss": -87.07384146413496, "actor_target_entropy": -1.0, "actor_entropy": 1.466240563700276, "alpha_loss": 0.0010242639240928956, "alpha_value": 0.0006374777651970531, "duration": 11.39107084274292, "step": 241500}
{"episode_reward": 66.97446264131605, "episode": 1933.0, "batch_reward": 0.9017102880477905, "critic_loss": 2.2876916427612306, "actor_loss": -87.1053466796875, "actor_target_entropy": -1.0, "actor_entropy": 1.462276157878694, "alpha_loss": 0.0010197338147369761, "alpha_value": 0.0006336922522738956, "duration": 10.998117685317993, "step": 241625}
{"episode_reward": 156.64938131861226, "episode": 1934.0, "batch_reward": 0.8971229577064515, "critic_loss": 2.224027331352234, "actor_loss": -87.13584604570943, "actor_target_entropy": -1.0, "actor_entropy": 1.4505428229608843, "alpha_loss": 0.0010078596401839487, "alpha_value": 0.0006299408227222467, "duration": 11.40645146369934, "step": 241750}
{"episode_reward": 132.91876958172404, "episode": 1935.0, "batch_reward": 0.8960974884033203, "critic_loss": 2.286047863960266, "actor_loss": -87.14336358933221, "actor_target_entropy": -1.0, "actor_entropy": 1.4574250134210738, "alpha_loss": 0.0010039786168832391, "alpha_value": 0.0006262207608160489, "duration": 11.52177095413208, "step": 241875}
{"episode_reward": 158.71345009073738, "episode": 1936.0, "batch_reward": 0.8884901132583618, "critic_loss": 2.275408699989319, "actor_loss": -87.14896725070092, "actor_target_entropy": -1.0, "actor_entropy": 1.4672484436342794, "alpha_loss": 0.0009956608841856641, "alpha_value": 0.000622542295748206, "duration": 11.505523681640625, "step": 242000}
{"episode_reward": 158.72195736117078, "episode": 1937.0, "batch_reward": 0.8885499820709228, "critic_loss": 2.2938589067459105, "actor_loss": -87.15593380398221, "actor_target_entropy": -1.0, "actor_entropy": 1.4647509275920807, "alpha_loss": 0.000993813084076262, "alpha_value": 0.0006188936376703534, "duration": 11.483138799667358, "step": 242125}
{"episode_reward": 144.9585992891988, "episode": 1938.0, "batch_reward": 0.8958064246177674, "critic_loss": 2.325681065559387, "actor_loss": -87.18090451148248, "actor_target_entropy": -1.0, "actor_entropy": 1.4381632074233024, "alpha_loss": 0.0009944337615442852, "alpha_value": 0.0006152492623269374, "duration": 11.393245458602905, "step": 242250}
{"episode_reward": 136.15634078374467, "episode": 1939.0, "batch_reward": 0.8912832717895508, "critic_loss": 2.272984150886536, "actor_loss": -87.1859622531467, "actor_target_entropy": -1.0, "actor_entropy": 1.430642735390436, "alpha_loss": 0.000981520009522755, "alpha_value": 0.0006116428559234757, "duration": 11.429177284240723, "step": 242375}
{"episode_reward": 182.14871643093932, "episode": 1940.0, "batch_reward": 0.8902341222763062, "critic_loss": 2.19192311668396, "actor_loss": -87.20229696458385, "actor_target_entropy": -1.0, "actor_entropy": 1.4304403528090446, "alpha_loss": 0.000982199785216982, "alpha_value": 0.0006080558020567341, "duration": 11.913113355636597, "step": 242500}
{"episode_reward": 68.94247407595458, "episode": 1941.0, "batch_reward": 0.8961558661460877, "critic_loss": 2.2682161455154417, "actor_loss": -87.21754116482205, "actor_target_entropy": -1.0, "actor_entropy": 1.4316324525409274, "alpha_loss": 0.0009810829688499253, "alpha_value": 0.000604490071465407, "duration": 11.557774066925049, "step": 242625}
{"episode_reward": 257.9619337857521, "episode": 1942.0, "batch_reward": 0.8875144958496094, "critic_loss": 2.1514435386657715, "actor_loss": -87.21904028615644, "actor_target_entropy": -1.0, "actor_entropy": 1.4372500642653434, "alpha_loss": 0.0009686808963681781, "alpha_value": 0.0006009475549559714, "duration": 11.494039058685303, "step": 242750}
{"episode_reward": 82.48216534458732, "episode": 1943.0, "batch_reward": 0.8935059385299683, "critic_loss": 2.2812759552001953, "actor_loss": -87.23285626608228, "actor_target_entropy": -1.0, "actor_entropy": 1.4432436189954243, "alpha_loss": 0.0009626777637528167, "alpha_value": 0.0005974500758226781, "duration": 12.135205268859863, "step": 242875}
{"episode_reward": 34.98380682928575, "episode": 1944.0, "batch_reward": 0.8941815299987793, "critic_loss": 2.331826780319214, "actor_loss": -87.25191965410787, "actor_target_entropy": -1.0, "actor_entropy": 1.4344159595427974, "alpha_loss": 0.0009555024303300606, "alpha_value": 0.0005939825234516314, "duration": 11.639364004135132, "step": 243000}
{"episode_reward": 72.75960342747192, "episode": 1945.0, "batch_reward": 0.8930455112457275, "critic_loss": 2.206088786125183, "actor_loss": -87.26836431594123, "actor_target_entropy": -1.0, "actor_entropy": 1.4314870247765192, "alpha_loss": 0.0009524951908840901, "alpha_value": 0.0005905377474376904, "duration": 11.492706060409546, "step": 243125}
{"episode_reward": 115.61220731930513, "episode": 1946.0, "batch_reward": 0.8746548509597778, "critic_loss": 2.157671399116516, "actor_loss": -87.25044139739006, "actor_target_entropy": -1.0, "actor_entropy": 1.426600367792191, "alpha_loss": 0.0009450132746414672, "alpha_value": 0.0005871228036908538, "duration": 11.26284909248352, "step": 243250}
{"episode_reward": 194.6516626380661, "episode": 1947.0, "batch_reward": 0.8952088642120362, "critic_loss": 2.233441123962402, "actor_loss": -87.28527420286149, "actor_target_entropy": -1.0, "actor_entropy": 1.425896964375935, "alpha_loss": 0.000936934508250228, "alpha_value": 0.0005837338738644121, "duration": 11.467884540557861, "step": 243375}
{"episode_reward": 164.30064223965195, "episode": 1948.0, "batch_reward": 0.888094825744629, "critic_loss": 2.2167629680633545, "actor_loss": -87.28107378559727, "actor_target_entropy": -1.0, "actor_entropy": 1.4348531576894945, "alpha_loss": 0.0009325641477780957, "alpha_value": 0.0005803753675523718, "duration": 11.54981255531311, "step": 243500}
{"episode_reward": 52.191161164230465, "episode": 1949.0, "batch_reward": 0.8761350135803223, "critic_loss": 2.1921179723739623, "actor_loss": -87.27193123953683, "actor_target_entropy": -1.0, "actor_entropy": 1.4430485244781253, "alpha_loss": 0.0009296355595339149, "alpha_value": 0.0005770277829528946, "duration": 11.954783916473389, "step": 243625}
{"episode_reward": 226.14748987838146, "episode": 1950.0, "batch_reward": 0.8835449380874634, "critic_loss": 2.177777319908142, "actor_loss": -87.28654861450195, "actor_target_entropy": -1.0, "actor_entropy": 1.4662634057383384, "alpha_loss": 0.0009220870110326477, "alpha_value": 0.0005737131305610899, "duration": 11.700504779815674, "step": 243750}
{"episode_reward": 179.51690577754144, "episode": 1951.0, "batch_reward": 0.8756166710853577, "critic_loss": 2.1836676683425904, "actor_loss": -87.28922029525515, "actor_target_entropy": -1.0, "actor_entropy": 1.4757072982333956, "alpha_loss": 0.0009152121483422224, "alpha_value": 0.0005704270885909412, "duration": 11.673290491104126, "step": 243875}
{"episode_reward": 229.57718363267168, "episode": 1952.0, "batch_reward": 0.8915504469871521, "critic_loss": 2.285522660255432, "actor_loss": -87.31639923587922, "actor_target_entropy": -1.0, "actor_entropy": 1.4688180685043335, "alpha_loss": 0.0009080720455160424, "alpha_value": 0.0005671599082270786, "duration": 11.613696098327637, "step": 244000}
{"episode_reward": 187.34987984107732, "episode": 1953.0, "batch_reward": 0.8908540363311768, "critic_loss": 2.2359609832763674, "actor_loss": -87.32678912934803, "actor_target_entropy": -1.0, "actor_entropy": 1.4315568397915552, "alpha_loss": 0.0009046013352446376, "alpha_value": 0.0005639204244664834, "duration": 11.766290187835693, "step": 244125}
{"episode_reward": 114.23870142295841, "episode": 1954.0, "batch_reward": 0.907529296875, "critic_loss": 2.289566032409668, "actor_loss": -87.35566871396956, "actor_target_entropy": -1.0, "actor_entropy": 1.4314920402342273, "alpha_loss": 0.0009075818440666603, "alpha_value": 0.0005606772764197465, "duration": 11.728559970855713, "step": 244250}
{"episode_reward": 132.78165545858621, "episode": 1955.0, "batch_reward": 0.8941378521919251, "critic_loss": 2.283007085800171, "actor_loss": -87.36633700416202, "actor_target_entropy": -1.0, "actor_entropy": 1.429985517547244, "alpha_loss": 0.000895835743803117, "alpha_value": 0.0005574585302068488, "duration": 11.735174179077148, "step": 244375}
{"episode_reward": 118.19349417673263, "episode": 1956.0, "batch_reward": 0.8872812886238098, "critic_loss": 2.200500171661377, "actor_loss": -87.3582184084, "actor_target_entropy": -1.0, "actor_entropy": 1.424096526638154, "alpha_loss": 0.0008894277843571599, "alpha_value": 0.0005542840699930047, "duration": 11.539684534072876, "step": 244500}
{"episode_reward": 78.38029367423684, "episode": 1957.0, "batch_reward": 0.8879356470108032, "critic_loss": 2.327569128990173, "actor_loss": -87.37325734940787, "actor_target_entropy": -1.0, "actor_entropy": 1.4223853690283639, "alpha_loss": 0.0008897988942436992, "alpha_value": 0.0005511083768520214, "duration": 11.676199436187744, "step": 244625}
{"episode_reward": 138.41188212089827, "episode": 1958.0, "batch_reward": 0.8811737599372864, "critic_loss": 2.1906788139343263, "actor_loss": -87.37696764546055, "actor_target_entropy": -1.0, "actor_entropy": 1.4455273266761535, "alpha_loss": 0.0008822917044463177, "alpha_value": 0.0005479499593835946, "duration": 11.489860534667969, "step": 244750}
{"episode_reward": 180.69657606306532, "episode": 1959.0, "batch_reward": 0.8982305145263672, "critic_loss": 2.3454004402160646, "actor_loss": -87.40343402680897, "actor_target_entropy": -1.0, "actor_entropy": 1.4518582801970223, "alpha_loss": 0.0008754397415378619, "alpha_value": 0.0005448262844220119, "duration": 11.719073057174683, "step": 244875}
{"episode_reward": 106.42657821007623, "episode": 1960.0, "batch_reward": 0.8955852251052856, "critic_loss": 2.2583997802734377, "actor_loss": -87.407228531376, "actor_target_entropy": -1.0, "actor_entropy": 1.4546168119676652, "alpha_loss": 0.00087271919736879, "alpha_value": 0.0005417203625616244, "duration": 11.559996604919434, "step": 245000}
{"episode_reward": 270.62834236413687, "episode": 1961.0, "batch_reward": 0.8901912341117859, "critic_loss": 2.226455186843872, "actor_loss": -87.4129145788768, "actor_target_entropy": -1.0, "actor_entropy": 1.4517816834979587, "alpha_loss": 0.0008719602049077077, "alpha_value": 0.0005386257433014479, "duration": 11.789203405380249, "step": 245125}
{"episode_reward": 211.99661560008957, "episode": 1962.0, "batch_reward": 0.8978063287734985, "critic_loss": 2.3001424160003663, "actor_loss": -87.43130603913337, "actor_target_entropy": -1.0, "actor_entropy": 1.4603679910782845, "alpha_loss": 0.0008663336667532642, "alpha_value": 0.0005355330273384581, "duration": 11.40372896194458, "step": 245250}
{"episode_reward": 212.12551925386316, "episode": 1963.0, "batch_reward": 0.891940456867218, "critic_loss": 2.235748178482056, "actor_loss": -87.4420898679703, "actor_target_entropy": -1.0, "actor_entropy": 1.4694244161484733, "alpha_loss": 0.0008561860036385792, "alpha_value": 0.0005324813321184353, "duration": 11.391832828521729, "step": 245375}
{"episode_reward": 118.23288928570875, "episode": 1964.0, "batch_reward": 0.9003192372322083, "critic_loss": 2.3020444278717043, "actor_loss": -87.46054052537487, "actor_target_entropy": -1.0, "actor_entropy": 1.4712301108144945, "alpha_loss": 0.0008531183393056234, "alpha_value": 0.0005294511753686368, "duration": 11.823001623153687, "step": 245500}
{"episode_reward": 54.97930949175233, "episode": 1965.0, "batch_reward": 0.9054631285667419, "critic_loss": 2.40515425491333, "actor_loss": -87.49207015264602, "actor_target_entropy": -1.0, "actor_entropy": 1.479155148778643, "alpha_loss": 0.0008467781063657077, "alpha_value": 0.0005264356189189039, "duration": 11.635626554489136, "step": 245625}
{"episode_reward": 223.00310082428564, "episode": 1966.0, "batch_reward": 0.8921199069023132, "critic_loss": 2.2178237009048463, "actor_loss": -87.4982072153399, "actor_target_entropy": -1.0, "actor_entropy": 1.4878394103819323, "alpha_loss": 0.0008402791150259755, "alpha_value": 0.0005234509310631253, "duration": 11.24299669265747, "step": 245750}
{"episode_reward": 156.74308216798232, "episode": 1967.0, "batch_reward": 0.8960548777580262, "critic_loss": 2.279383535385132, "actor_loss": -87.50453622000558, "actor_target_entropy": -1.0, "actor_entropy": 1.4780795858019875, "alpha_loss": 0.0008403824860348352, "alpha_value": 0.0005204774439824412, "duration": 11.542697429656982, "step": 245875}
{"episode_reward": 153.49423033671835, "episode": 1968.0, "batch_reward": 0.8975939774513244, "critic_loss": 2.333570335388184, "actor_loss": -87.52572656446888, "actor_target_entropy": -1.0, "actor_entropy": 1.463997813963121, "alpha_loss": 0.0008393679998980294, "alpha_value": 0.0005175080241642369, "duration": 11.353117942810059, "step": 246000}
{"episode_reward": 220.98103140597928, "episode": 1969.0, "batch_reward": 0.8994270257949829, "critic_loss": 2.256199215888977, "actor_loss": -87.54222046382843, "actor_target_entropy": -1.0, "actor_entropy": 1.4692543442287143, "alpha_loss": 0.000831063350825201, "alpha_value": 0.000514548298327179, "duration": 11.62955904006958, "step": 246125}
{"episode_reward": 164.5478860469453, "episode": 1970.0, "batch_reward": 0.8900054092407227, "critic_loss": 2.2542242488861084, "actor_loss": -87.54667282104492, "actor_target_entropy": -1.0, "actor_entropy": 1.479222209222855, "alpha_loss": 0.0008226160547741118, "alpha_value": 0.0005116329861619259, "duration": 11.457369327545166, "step": 246250}
{"episode_reward": 198.00794158830084, "episode": 1971.0, "batch_reward": 0.8913034062385559, "critic_loss": 2.258494757652283, "actor_loss": -87.55904691181486, "actor_target_entropy": -1.0, "actor_entropy": 1.4910674189764357, "alpha_loss": 0.0008158886736805832, "alpha_value": 0.0005087377650408227, "duration": 11.824138879776001, "step": 246375}
{"episode_reward": 141.80352654025705, "episode": 1972.0, "batch_reward": 0.8812615728378296, "critic_loss": 2.177012746810913, "actor_loss": -87.55572878929877, "actor_target_entropy": -1.0, "actor_entropy": 1.4839157635165798, "alpha_loss": 0.0008163157758498264, "alpha_value": 0.0005058559414340275, "duration": 11.209241151809692, "step": 246500}
{"episode_reward": 33.60058211160029, "episode": 1973.0, "batch_reward": 0.8899898428916931, "critic_loss": 2.287962682723999, "actor_loss": -87.56453632173084, "actor_target_entropy": -1.0, "actor_entropy": 1.4689468372435797, "alpha_loss": 0.0008115893394301927, "alpha_value": 0.0005029822322341371, "duration": 11.328899383544922, "step": 246625}
{"episode_reward": 109.66853034859709, "episode": 1974.0, "batch_reward": 0.8942376370429993, "critic_loss": 2.311765337944031, "actor_loss": -87.5757415525375, "actor_target_entropy": -1.0, "actor_entropy": 1.4747330950152489, "alpha_loss": 0.0008033133241453118, "alpha_value": 0.0005001242016793633, "duration": 11.50876784324646, "step": 246750}
{"episode_reward": 80.2866610481355, "episode": 1975.0, "batch_reward": 0.8973209691047669, "critic_loss": 2.226459098815918, "actor_loss": -87.58877829899863, "actor_target_entropy": -1.0, "actor_entropy": 1.4995815962079972, "alpha_loss": 0.0007994176491001059, "alpha_value": 0.000497301845023988, "duration": 11.530545949935913, "step": 246875}
{"episode_reward": 90.35675872830318, "episode": 1976.0, "batch_reward": 0.897625159740448, "critic_loss": 2.2844935731887817, "actor_loss": -87.60851472423923, "actor_target_entropy": -1.0, "actor_entropy": 1.5024574225948704, "alpha_loss": 0.000794369102110185, "alpha_value": 0.0004944930433523791, "duration": 11.432432889938354, "step": 247000}
{"episode_reward": 159.8305938373645, "episode": 1977.0, "batch_reward": 0.8883566722869873, "critic_loss": 2.2205687437057495, "actor_loss": -87.60965365455264, "actor_target_entropy": -1.0, "actor_entropy": 1.506215218513731, "alpha_loss": 0.0007882320325792073, "alpha_value": 0.0004916968661989109, "duration": 11.8751802444458, "step": 247125}
{"episode_reward": 142.1785980386285, "episode": 1978.0, "batch_reward": 0.8944235243797303, "critic_loss": 2.285807300567627, "actor_loss": -87.61292266845703, "actor_target_entropy": -1.0, "actor_entropy": 1.5019887993412633, "alpha_loss": 0.0007845758743989732, "alpha_value": 0.0004889231341066132, "duration": 11.607646942138672, "step": 247250}
{"episode_reward": 84.76302411890461, "episode": 1979.0, "batch_reward": 0.909802891254425, "critic_loss": 2.2530414714813234, "actor_loss": -87.66022237141927, "actor_target_entropy": -1.0, "actor_entropy": 1.4834725535105144, "alpha_loss": 0.0007872789717530684, "alpha_value": 0.0004861524735880846, "duration": 11.38892674446106, "step": 247375}
{"episode_reward": 170.31564640399353, "episode": 1980.0, "batch_reward": 0.9071704602241516, "critic_loss": 2.329201386451721, "actor_loss": -87.67699297012821, "actor_target_entropy": -1.0, "actor_entropy": 1.4672939277464343, "alpha_loss": 0.0007821142911956074, "alpha_value": 0.00048338687895710196, "duration": 11.518829584121704, "step": 247500}
{"episode_reward": 129.88996169717112, "episode": 1981.0, "batch_reward": 0.8971993918418885, "critic_loss": 2.2824419507980345, "actor_loss": -87.68394785078745, "actor_target_entropy": -1.0, "actor_entropy": 1.4714086036833505, "alpha_loss": 0.0007764175414137305, "alpha_value": 0.0004806373133962754, "duration": 11.749151706695557, "step": 247625}
{"episode_reward": 29.170105041790652, "episode": 1982.0, "batch_reward": 0.9055936803817749, "critic_loss": 2.319172890663147, "actor_loss": -87.6983172508978, "actor_target_entropy": -1.0, "actor_entropy": 1.46894504562501, "alpha_loss": 0.0007694170992415879, "alpha_value": 0.00047791463622118795, "duration": 11.631611347198486, "step": 247750}
{"episode_reward": 169.60766921270118, "episode": 1983.0, "batch_reward": 0.8889234170913697, "critic_loss": 2.286196473121643, "actor_loss": -87.6914531162807, "actor_target_entropy": -1.0, "actor_entropy": 1.476548438980466, "alpha_loss": 0.0007678286915290214, "alpha_value": 0.00047521048642651, "duration": 11.457477569580078, "step": 247875}
{"episode_reward": 247.18716137476045, "episode": 1984.0, "batch_reward": 0.8898772811889648, "critic_loss": 2.2683247628211975, "actor_loss": -87.70701611426568, "actor_target_entropy": -1.0, "actor_entropy": 1.4742332773823892, "alpha_loss": 0.0007648546081562076, "alpha_value": 0.000472516428589152, "duration": 11.72842288017273, "step": 248000}
{"episode_reward": 191.33339403135767, "episode": 1985.0, "batch_reward": 0.8983102631568909, "critic_loss": 2.2065508041381836, "actor_loss": -87.71856774224176, "actor_target_entropy": -1.0, "actor_entropy": 1.476480379937187, "alpha_loss": 0.0007601497086903288, "alpha_value": 0.0004698308465062605, "duration": 11.730326414108276, "step": 248125}
{"episode_reward": 159.87654245214728, "episode": 1986.0, "batch_reward": 0.9042123675346374, "critic_loss": 2.313087406158447, "actor_loss": -87.73491705617597, "actor_target_entropy": -1.0, "actor_entropy": 1.4771024527088288, "alpha_loss": 0.0007552319298303055, "alpha_value": 0.000467165302220881, "duration": 11.267905950546265, "step": 248250}
{"episode_reward": 135.1933522254217, "episode": 1987.0, "batch_reward": 0.894564519405365, "critic_loss": 2.294769048690796, "actor_loss": -87.7395759461418, "actor_target_entropy": -1.0, "actor_entropy": 1.4660140162422544, "alpha_loss": 0.0007510954996437899, "alpha_value": 0.00046451447000875004, "duration": 11.57890796661377, "step": 248375}
{"episode_reward": 171.8600246692904, "episode": 1988.0, "batch_reward": 0.9090043320655823, "critic_loss": 2.3420978956222536, "actor_loss": -87.77295623287078, "actor_target_entropy": -1.0, "actor_entropy": 1.4533889870489798, "alpha_loss": 0.0007503360590612095, "alpha_value": 0.00046187583258209126, "duration": 11.711632251739502, "step": 248500}
{"episode_reward": 238.10006875059804, "episode": 1989.0, "batch_reward": 0.8986622462272644, "critic_loss": 2.277029849052429, "actor_loss": -87.78264775351873, "actor_target_entropy": -1.0, "actor_entropy": 1.4583196507559881, "alpha_loss": 0.0007411197635404293, "alpha_value": 0.00045925477341109827, "duration": 11.777207612991333, "step": 248625}
{"episode_reward": 166.1798796298275, "episode": 1990.0, "batch_reward": 0.8882660098075866, "critic_loss": 2.247250395774841, "actor_loss": -87.77876220210906, "actor_target_entropy": -1.0, "actor_entropy": 1.4446566527889622, "alpha_loss": 0.0007404677782042493, "alpha_value": 0.0004566512760423504, "duration": 11.332077503204346, "step": 248750}
{"episode_reward": 96.29472459948258, "episode": 1991.0, "batch_reward": 0.8923036580085755, "critic_loss": 2.25583922290802, "actor_loss": -87.78743719676184, "actor_target_entropy": -1.0, "actor_entropy": 1.4628040393193562, "alpha_loss": 0.0007356876019565832, "alpha_value": 0.0004540607283092441, "duration": 11.720956087112427, "step": 248875}
{"episode_reward": 167.05002129566486, "episode": 1992.0, "batch_reward": 0.9068885698318482, "critic_loss": 2.2748788995742797, "actor_loss": -87.81284479941091, "actor_target_entropy": -1.0, "actor_entropy": 1.4529869056517077, "alpha_loss": 0.0007280324906816766, "alpha_value": 0.00045149008695739173, "duration": 11.596843957901001, "step": 249000}
{"episode_reward": 138.1352156987153, "episode": 1993.0, "batch_reward": 0.9014722776412963, "critic_loss": 2.2329413766860964, "actor_loss": -87.82576182531932, "actor_target_entropy": -1.0, "actor_entropy": 1.463319522993905, "alpha_loss": 0.0007307787337118672, "alpha_value": 0.00044892887239067036, "duration": 11.724902391433716, "step": 249125}
{"episode_reward": 40.295037643107634, "episode": 1994.0, "batch_reward": 0.8897525935173035, "critic_loss": 2.2290650300979613, "actor_loss": -87.82587555916079, "actor_target_entropy": -1.0, "actor_entropy": 1.4586068622527584, "alpha_loss": 0.0007238444785827831, "alpha_value": 0.0004463765688875228, "duration": 11.442050218582153, "step": 249250}
{"episode_reward": 94.06241076982818, "episode": 1995.0, "batch_reward": 0.9010538973808289, "critic_loss": 2.3632279081344603, "actor_loss": -87.841062999907, "actor_target_entropy": -1.0, "actor_entropy": 1.444281640506926, "alpha_loss": 0.0007223979632798878, "alpha_value": 0.0004438426943297946, "duration": 11.687105655670166, "step": 249375}
{"episode_reward": 168.5546638894844, "episode": 1996.0, "batch_reward": 0.8934669618606568, "critic_loss": 2.270336323738098, "actor_loss": -87.85717195080173, "actor_target_entropy": -1.0, "actor_entropy": 1.4273253756184732, "alpha_loss": 0.0007178603799172467, "alpha_value": 0.00044131470427628616, "duration": 11.396337509155273, "step": 249500}
{"episode_reward": 86.7879691192195, "episode": 1997.0, "batch_reward": 0.9086070671081543, "critic_loss": 2.2933244504928587, "actor_loss": -87.8853527250744, "actor_target_entropy": -1.0, "actor_entropy": 1.4217302099106803, "alpha_loss": 0.0007160831481173989, "alpha_value": 0.000438807197378215, "duration": 11.939894437789917, "step": 249625}
{"episode_reward": 169.20842855105928, "episode": 1998.0, "batch_reward": 0.9067892909049988, "critic_loss": 2.271077754020691, "actor_loss": -87.89356207078502, "actor_target_entropy": -1.0, "actor_entropy": 1.421335239564219, "alpha_loss": 0.0007094276708460623, "alpha_value": 0.00043630821907286873, "duration": 11.825083494186401, "step": 249750}
{"episode_reward": 61.115842238923655, "episode": 1999.0, "batch_reward": 0.8896615376472473, "critic_loss": 2.2545881328582764, "actor_loss": -87.89342244466145, "actor_target_entropy": -1.0, "actor_entropy": 1.4054518219024417, "alpha_loss": 0.0007077747464386953, "alpha_value": 0.0004338263216194139, "duration": 11.57819938659668, "step": 249875}
{"episode_reward": 197.4479919765527, "episode": 2000.0, "batch_reward": 0.8908612728118896, "critic_loss": 2.1857680978775025, "actor_loss": -87.89745958389774, "actor_target_entropy": -1.0, "actor_entropy": 1.4259229360088226, "alpha_loss": 0.0007042447095661755, "alpha_value": 0.00043135551432718427, "duration": 11.701395034790039, "step": 250000}
{"episode_reward": 152.88190212067792, "episode": 2001.0, "batch_reward": 0.9016228127479553, "critic_loss": 2.3205114889144896, "actor_loss": -87.92227742028615, "actor_target_entropy": -1.0, "actor_entropy": 1.4262603142904857, "alpha_loss": 0.0006975510364605321, "alpha_value": 0.0004289084727108897, "duration": 15.487932443618774, "step": 250125}
{"episode_reward": 123.43912144975394, "episode": 2002.0, "batch_reward": 0.9002138829231262, "critic_loss": 2.275036067008972, "actor_loss": -87.94814928116337, "actor_target_entropy": -1.0, "actor_entropy": 1.4248955211331766, "alpha_loss": 0.0006917342299505347, "alpha_value": 0.0004264752902217837, "duration": 11.620052099227905, "step": 250250}
{"episode_reward": 223.19072479717562, "episode": 2003.0, "batch_reward": 0.8909235167503357, "critic_loss": 2.30057559967041, "actor_loss": -87.93955642457992, "actor_target_entropy": -1.0, "actor_entropy": 1.4216147093545823, "alpha_loss": 0.0006922355581385394, "alpha_value": 0.0004240627078232959, "duration": 11.735035181045532, "step": 250375}
{"episode_reward": 117.24862704058147, "episode": 2004.0, "batch_reward": 0.9032610158920288, "critic_loss": 2.293713248252869, "actor_loss": -87.96081825994676, "actor_target_entropy": -1.0, "actor_entropy": 1.4235480562333138, "alpha_loss": 0.0006847656022141417, "alpha_value": 0.00042165379172119156, "duration": 11.442522048950195, "step": 250500}
{"episode_reward": 56.03681264078272, "episode": 2005.0, "batch_reward": 0.8888067831993103, "critic_loss": 2.2669752798080443, "actor_loss": -87.95627061147539, "actor_target_entropy": -1.0, "actor_entropy": 1.4279334223459637, "alpha_loss": 0.0006811421148345939, "alpha_value": 0.00041926815357317424, "duration": 11.681073665618896, "step": 250625}
{"episode_reward": 133.4592973422212, "episode": 2006.0, "batch_reward": 0.8900125770568847, "critic_loss": 2.2208202962875365, "actor_loss": -87.969545056743, "actor_target_entropy": -1.0, "actor_entropy": 1.4144578633769866, "alpha_loss": 0.0006775620417864693, "alpha_value": 0.00041689882517886384, "duration": 11.263344287872314, "step": 250750}
{"episode_reward": 174.53203905549125, "episode": 2007.0, "batch_reward": 0.8944885759353638, "critic_loss": 2.3238704710006712, "actor_loss": -87.96766505165705, "actor_target_entropy": -1.0, "actor_entropy": 1.4349716447648548, "alpha_loss": 0.0006749252991987363, "alpha_value": 0.00041453479205242125, "duration": 11.313727855682373, "step": 250875}
{"episode_reward": 242.6137940364757, "episode": 2008.0, "batch_reward": 0.8919377570152283, "critic_loss": 2.231721106529236, "actor_loss": -87.98558204404769, "actor_target_entropy": -1.0, "actor_entropy": 1.4462269852238316, "alpha_loss": 0.0006694195279476023, "alpha_value": 0.0004121905182111781, "duration": 11.61384892463684, "step": 251000}
{"episode_reward": 254.49408141416995, "episode": 2009.0, "batch_reward": 0.9135805487632751, "critic_loss": 2.4427436265945435, "actor_loss": -88.01359981960721, "actor_target_entropy": -1.0, "actor_entropy": 1.4229608282210335, "alpha_loss": 0.0006685161137110775, "alpha_value": 0.0004098554801678768, "duration": 11.385483980178833, "step": 251125}
{"episode_reward": 202.93659820091412, "episode": 2010.0, "batch_reward": 0.8970490937232971, "critic_loss": 2.3004145793914796, "actor_loss": -88.01778510309035, "actor_target_entropy": -1.0, "actor_entropy": 1.4047711626175912, "alpha_loss": 0.0006632791895930084, "alpha_value": 0.000407530026065031, "duration": 11.187502145767212, "step": 251250}
{"episode_reward": 81.72173502436083, "episode": 2011.0, "batch_reward": 0.8914641346931458, "critic_loss": 2.2630966482162473, "actor_loss": -88.02174207899306, "actor_target_entropy": -1.0, "actor_entropy": 1.3934787284760248, "alpha_loss": 0.0006574372130830491, "alpha_value": 0.0004052271226772207, "duration": 11.48496961593628, "step": 251375}
{"episode_reward": 58.319583276660694, "episode": 2012.0, "batch_reward": 0.9078333683013916, "critic_loss": 2.350616394996643, "actor_loss": -88.05260713638798, "actor_target_entropy": -1.0, "actor_entropy": 1.3896148012530418, "alpha_loss": 0.0006548243221796809, "alpha_value": 0.00040293807408699206, "duration": 11.481914520263672, "step": 251500}
{"episode_reward": 42.82435703745979, "episode": 2013.0, "batch_reward": 0.9054528756141662, "critic_loss": 2.301790616989136, "actor_loss": -88.06389678470673, "actor_target_entropy": -1.0, "actor_entropy": 1.3795177539189656, "alpha_loss": 0.000652527477267006, "alpha_value": 0.00040065865848906164, "duration": 11.399644613265991, "step": 251625}
{"episode_reward": 85.32429266859958, "episode": 2014.0, "batch_reward": 0.9100314259529114, "critic_loss": 2.2974833459854125, "actor_loss": -88.08672665011498, "actor_target_entropy": -1.0, "actor_entropy": 1.3973370098298596, "alpha_loss": 0.000646681418725019, "alpha_value": 0.0003983917382613605, "duration": 11.659813165664673, "step": 251750}
{"episode_reward": 107.16816376038499, "episode": 2015.0, "batch_reward": 0.9026729550361633, "critic_loss": 2.2823875102996825, "actor_loss": -88.09804014175657, "actor_target_entropy": -1.0, "actor_entropy": 1.4173236896121313, "alpha_loss": 0.0006393831729563693, "alpha_value": 0.00039615066688379586, "duration": 11.831833362579346, "step": 251875}
{"episode_reward": 140.6875321196838, "episode": 2016.0, "batch_reward": 0.9076411757469177, "critic_loss": 2.400082631111145, "actor_loss": -88.11180483910346, "actor_target_entropy": -1.0, "actor_entropy": 1.4075178984672791, "alpha_loss": 0.0006427017816026966, "alpha_value": 0.0003939151160566431, "duration": 11.303855895996094, "step": 252000}
{"episode_reward": 63.889094500098025, "episode": 2017.0, "batch_reward": 0.8944616675376892, "critic_loss": 2.215170904159546, "actor_loss": -88.11532750205389, "actor_target_entropy": -1.0, "actor_entropy": 1.4067417496726626, "alpha_loss": 0.0006350454678463321, "alpha_value": 0.0003916885625409934, "duration": 11.386888027191162, "step": 252125}
